nama_dokumen,kalimat,summary
Alfharizky Fauzi_Kualifikasi.txt,pada metodologi penelitian ini menjelaskan mengenai bagaimana proses dari analisis system perancangan dan analisis program yang dilakukan pada penelitian ini. berikut analisis dan perancangan pada penelitian ini. 3.1 tahapan penelitian gambar 3. 1 tahapan penelitian dokumentasi peneliti tahapan penelitian dapat dilihat pada gambar 3.1. tahapan penelitian yang dilakukan terdiri dari 9 tahapan yaitu dimulai dari studi literatur sebagai dasar penelitian analisis kebutuhan pada system yang akan dibangun pengumpulan dataset preprocessing data membangun model training model evaluasi model deployme nt model dan implementasi model yang telah dibuat ke dalam smartphone. saat program telah dijalankan program akan mengakuisisi dataset kemudian dataset akan melalui tahap preprocessing untuk m enormalkan data kemudian setelah melalui tahap preprocessing selanjutnya mentraining dataset yang sudah didapatkan jika dataset berhasil dilatih dan juga divalidasi maka berlanjut ke tahap berikutnya yaitu tahapan test ing dengan menerapkan model yang dibuat kedalam mobile phone atau smartphone. tahap selanjutnya jika camera telah menyala maka artinya sudah siap untuk mendeteksi objek jenis penyakit kulit . pada tahap terakhir yaitu saat ada objek jenis penyakit kulit yang masuk atau terdeteksi oleh camera m aka citra tersebut sudah dapat dilakukan proses klasifikasi kemudian divalidasikan bahwa data tersebut sama dengan yang ada pada database untuk memunculkan label nama pada dataset serta memunculkan nilai confidence pada citra jenis penyakit kulit yang terdete ksi. 3.2 analisis kebutuhan analisis kebutuhan merupakan menganalisis komponen yang diperlukan dalam pembuatan dan menjalankan program proses ini mencakup evaluasi identifikasi dan pemetaan kebutuhan dari berbagai perangkat yang terlibat dalam pembuatan system dan program pada penelitian ini. berikut analisis kebutuhan dari penelitian yang dibuat . 3.2.1. analisis kebutuhan perangkat keras perangkat keras yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan laptop acer predator helios neo 16 dan mobile phone atau smartphone xiaomi redmi note 7 dengan bahasa pemrograman python dengan spesifikasi yang dapat dilihat pada tabel 3.1. tabel 3. 1 daftar perangkat keras no perangkat qty spesifikasi 1 laptop acer predator helios neo 16 1 13th gen intelr core tm i7 13700hx 24 cpus 2.1ghz. random acces memory 8gb. graphics card nvidia geforce rtx 4060 8gb solid state drive 2tb. 2 mobile phone smartphone 1 camera hd 48mp 169 1280x720 f1.8 wide dual led flash hdr panorama rgb red green blue 3.2.2. analisis kebutuhan perangkat lunak perangkat lunak yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan operating system windows jupyter lab dengan bahasa pemrograman python dan visual studio sebagai text editor yang dapat dilihat pada tabel 3.2. tabel 3. 2 daftar perangkat keras no perangkat lunak version 1 operating system windows 11 pro single language 64 bit 10.0 build 22631 2 python 3.7.0 3 jupyter notebook labs 7.2.1 4.2.2 4 visual studio code may 2024 version 1.90 3.2.3. analisis objek program dengan menggunakan metode bidirectional image text matching deep learning ini mempunyai beberapa objek yang diterapkan pada penelitian ini yaitu 1. identifikasi berbagai macam jenis penyakit kulit dengan memunculkan citra gambar yang didapat dan deskripsi mengenai penyakit kulit yang teridentifikasi dibawah citra gambar untuk setiap objek penyakit kulit yang terdeteksi data yang digunakan memiliki variasi jenis penyakit kulit dengan kategori 2 penyakit kulit menular candidiasis dan molluscum dan 2 penyakit kulit tidak menular eczhema dan melanoma dengan masing masing kelas memiliki 1000 citra penyakit kulit yang di dapat pada website international dermnet nz dermnetnz.org 2024 dan the international skin imaging collaboration isic isicarchive.com 2024 . 2. program identifikasi berbagai macam objek penyakit kulit pada manusia ditampilkan secara real time menggunakan file upload kamera mobile phone. 3.3 akuisisi data set proses akuisisi citra dilakukan dengan melakukan pengunduhan data dari berbagai sumber online international skin disease seperti pada website dermnetnz.org dan www.isic archive.com yang merupakan referensi gratis berbasis website untuk informasi tentang berbagai kondisi kulit. website ini menyediakan gambar gambar resolusi tinggi dari berbagai penyakit kulit baik yang menular maupun tidak menular serta memberikan deskripsi lengkap tentang penyakti tersebut meliputi gejala dan pengobatan. citra yang diperoleh kemudian diseleksi berdasarkan fokus penelitian yaitu identifikasi penyakit kulit menular candidiasis dan molluscum dan tidak menular eczhema dan melanoma . data citra yang digunakan berasal dari pasien dewasa dan anak anak dengan kondisi kulit yang jelas menunjukkan ge jala atau kelainan seperti lesi atau ruam. contoh citra yang akan digunakan pada penelitian seperti terlihat pada gambar 3. 2 gambar 3. 2 citra penyakit kulit yang berasal dari website isic isicarchive.com 2024 3.3.1. dataset penyakit kulit dataset pada penelitian ini dibagi menjadi 2 bagian yaitu 80 data training dan 20 data testing objek jenis penyakit kulit . dataset bersumber dari citra data image dan deskripsi data teks beberapa jenis penyakit kulit sejumlah 4000 citra dengan 4 jenis penyakit kulit yang terdiri dari echzema melanoma candidiasis dan molluscum dengan memiliki 1000 citra berbeda setiap jenis penyakit kulit . dari keempat jenis penyakit kulit tersebut dibagi menjadi 2 kelompok sebagai penyakit kulit menular dan tidak menular. 3.3.1.1. data gambar data image ini mencakup berbagai jenis gambar yang menampilkan gejala dan karakteristik penyakit kulit yang digunakan pada peneltian ini eczhema melanoma candidiasis dan molluscum seperti ruam bintik bintik lepuhan atau lesi kulit lainnya . ukuran citra asli yang didapat berukuran 294 x 222 yang akan diproses menjadi 256 x 256 sehingga ukuran gambar menjadi presisi dan pengambilan gambar diambil dari berbagai posisi yang berbeda sehingga posisi dalam proses training data akan mendapat banyak posisi p engenalan 1 jenis penyakit kulit dengan format citra jpeg joint photographic experts group serta pengambilan gambar dengan kamera . penggunaan data gambar sangat penting dalam penelitian ini untuk membandingkan dan mempelajari pola visual yang terkait dengan berbagai penyakit kulit. data image pada penelitian ini terdiri 4000 gambar dari 4 jenis penyakit kulit yaitu eczhema melanoma candidiasis dan molluscum yang dibagi menjadi 2 kelompok menular dan tidak menular. data gambar dapat dilihat pada gambar 3.3 . gambar 3. 3 data gambar penyakit kulit 3.3.1.2. data teks data teks penyakit kulit merujuk kepada informasi tertulis yang berisi deskripsi dan karakteristik berbagai kondisi dermatologis. data pada penelitian ini meliputi penjelasan tentang gejala gejala khas seperti gatal gatal perubahan warna kulit tekstur dan lokasi lesi serta penjelasan mengenai cara penanganan maupun pengobatan yang dapat dilakukan pasien . informasi ini penting untuk diagnosis dan pemahaman lebih lanjut tentang berbagai penyakit kulit seperti dermatitis eksim psoriasis dan infeksi jamur kulit. pada penelitian ini data teks diproses menggunakan teknik pengolahan bahasa alami atau natural language processing nlp untuk mengidentifikasi kata kunci dan pola yang terkait dengan setiap kondisi kulit. berikut data teks yang digunakan pada penelitian ini dapat dilihat pada tabel 3.3 tabel 3. 3 data teks penyakit kulit 3.4 pre processing data pada tahapan ini data gambar penyakit kulit preprocessing mencakup berbagai teknik seperti pengubahan ukuran gambar normalisasi piksel peningkatan kontras penghapusan noise serta melakukan segmentasi dan fitur ekstraksi. teknik ini bertujuan untuk meningkatkan kualitas gambar dan memastikan konsistensi data sehingga fitur fitur penting dapat diekstraksi dengan lebih efektif oleh algoritma analisis atau mode l kecerdasan buatan. sedangkan pada data teks penyakit kulit preprocessing melibatkan beberapa tahap seperti tokenisasi penghapusan stop words stemming lemmatization dan tagging . langkah langkah ini membantu dalam menyederhanakan teks mengurangi dime nsionalitas dan meningkatkan efisiensi analisis teks. dengan preprocessing yang tepat data gambar dan teks menjadi lebih bersih dan terstruktur memungkinkan model machine learning untuk menghasilkan prediksi yang lebih akurat dan andal. tahapan preprocessing dapat dilihat pada gambar 3.4. gambar 3. 4. tahapan preprocessing data 3.4.1. preprocessing data gambar proses ini melibatkan beberapa teknik utama. pertama pengubahan ukuran resizing gambar dilakukan untuk memastikan bahwa semua gambar memiliki dimensi yang seragam yaitu 256 x 256 yang penting untuk pengolahan batch dan integrasi dalam model. kedua normalisasi piksel diterapkan untuk mengatur nilai piksel dalam rentang tertentu biasanya antara 0 dan 1 guna meningkatkan stabilitas dan kecepatan konvergensi model. ketiga peningk atan kontras contrast enhancement dan penghapusan noise bertujuan untuk memperjelas fitur fitur penting dalam gambar seperti tepi atau tekstur yang mungkin relevan untuk diagnosis penyakit kulit. keempat segmentasi data untuk memisahkan area kulit yang terkena penyakit dari bagian yang sehat . kelima fitur ekstraksi memungkinkan identifikasi karakteristik spesifik dari kondisi kulit seperti ukuran dan bentuk lesi distribusi warna dan tekstur permukaan kulit. preprocessing data gambar dapat dilihat pada gambar 3.5. gambar 3. 5 preprocessing data gambar 3.4.1.1. resizing data pada tahap resize da ta ini betujuan untuk mengubah ukuran citra penyakit kulit menjadi resolusi tetap 256x256 piksel. langkah ini penting untuk memastikan bahwa semua citra memiliki ukuran yang konsisten sebelum digunakan dalam proses analisis data atau pelatihan model pembelajaran mesin. skrip ini menggunakan pustaka opencv untuk memuat mengubah ukuran dan menyimpan citra. dapat dilihat pada algoritma 3.1. algoritma 3.1 algoritma resize citra input citra penyakit kulit dengan ukuran asli ouput citra penyakit kulit dengan ukuran sama 256x256 proses 1. inisialisasi citra 2. periksa dan buat direktori output 3. iterasi melalui citra dalam direktori input 4. muat citra 5. ubah ukuran citra 6. simpan citra yang telah diubah ukurannya ukuran dan bentuk citra hasil resizing disimpan pada folder output masing masing penyakit kulit yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3.1 diatas dapat dikonversi kedalam pseudo code 1 yang dapat diimplementasikan pada pemrograman python. pseudocode 1. resize citra def resize_imageimage size256 256 resized_image cv2.resizeimage size interpolationcv2.inter_area return resized_image sehingga tampilan hasil program terlihat pada gambar 3. 6 berikut. seperti terlihat pada gambar proses resize ditujukan pada ukuran gambar yang terlihat presisi dan sama yaitu 256x256. gambar 3. 6. hasil resize data gambar 3.4.1.2. normalisasi data pada tahapan ini data yang telah di resize pada tahap sebelumya dinormalisasi. melalui tahap normalisasi data bertujuan untuk mengubah nilai piksel citra ke dalam rentang yang konsisten biasanya antara 0 dan 1 atau 1 dan 1. proses ini membantu dalam mengurangi variasi yang tidak diinginkan antar citra seperti perbedaan pencahayaan dan kontras sehingga fitur yang relevan menjadi lebih menonjol. normalisasi dilakukan dengan membagi nilai piksel setiap citra dengan nilai maksimum piksel biasanya 255 untuk citra 8 bit sehingga setiap piksel memiliki nilai yang proporsional dalam rentang yang diinginkan. langkah langkah normalisasi data d apat di lihat pada algoritma 3.2. algoritma 3. 2 algoritma no rmalisasi citra input citra penyakit kulit hasil resize ouput citra penyakit kulit dengan hasil normalisasi proses 1. inisialisasi citra 2. muat data citra 3. ubah tipe data citra 4. normalisasi nilai piksel 5. simpan dan gunakan hasil normalisasi citra hasil normalisasi disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. 2 diatas dapat dikonversi kedalam pseudo code 2 yang dapat diimplementasikan pada pemrograman python. pseudocode 2. normalisasi citra def normalize_imageimage convert image to float32 type for normalization image image.astypenp.float32 normalize the image normalized_image image 255.0 return normalized_image sehingga tampilan hasil program terlihat pada gambar 3.7 berikut. seperti terlihat pada gambar proses normalisasi ditujukan mengubah nilai piksel citra ke dalam rentang yang konsisten biasanya antara 0 dan 1 atau 1 dan 1. gambar 3. 7 hasil normalisasi data citra 3.4.1.3. peningkatan kontras data pada tahap ini dilakuakn peningkatan kontras pada data citra yang telah di normalisasi bertujuan untuk meningkatkan perbedaan antara nilai intensitas piksel yang berdekatan. dengan meningkatkan perbedaan antara nilai intensitas piksel proses ini membantu dalam meningkatkan ketajaman citra dan membuatnya lebih mudah untuk dianalisis. proses ini tidak hanya membuat citra lebih tajam dan lebih jelas tetapi juga dapat meningkatkan kemampuan sistem analisis citra seperti deteksi objek atau segmentasi yang lebih baik. langkah langkah peningkatan kontras dapat dilihat pada algoritma 3.3 . algoritma 3. 3 algoritma peningkatan kontras input citra penyakit kulit hasil normalisasi ouput citra penyakit kulit dengan peningkatan kontras proses 1. inisialisasi citra 2. muat data citra 3. ubah tipe data citra 4. hitung rata rata intensitas piksel 5. peningkatan kontras 6. simpan hasil peningkatan kontras citra hasil peningkatan kontras disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. 3 diatas dapat dikonversi kedalam pseudo code 3 yang dapat diimplementasikan pada pemrograman python. pseudocode 3. peningkatan kontras citra def normalize_imageimage convert image to float32 type for normalization image image.astypenp.float32 normalize the image normalized_image image 255.0 return normalized_image sehingga tampilan hasil program terlihat pada gambar 3.8 berikut. seperti terlihat pada gambar proses peningkatan kontras ditujukan untuk meningkatkan perbedaan antara nilai intensitas piksel yang berdekatan. dengan meningkatkan perbedaan antara nilai intensitas piksel proses ini membantu dalam meningkatkan ketajaman citra dan membuatnya lebih mudah untuk dianalisis. gambar 3. 8 hasil peningkatan kontras 3.4.1.4. penghapusan noise data pada tahap ini dilakukan penghapusan noise yang bertujuan untuk menghilangkan noise pada citra . noise pada citra kulit dapat muncul karena berbagai alasan seperti kualitas kamera yang rendah kondisi pencahayaan yang buruk atau bahkan gangguan selama pengambilan gambar. untuk membersihkan gambar dari gangguan ini digunakan berbagai teknik penghapusan noise. filter median misalnya sangat baik untuk mengatasi noise jenis salt andpepper dengan menggantikan nilai setiap piksel dengan median dari piksel piksel sekitarnya sementara filter gaussian menghaluskan gambar dengan mempertahankan tepi dan detail penting . dengan menghilangkan noise gambar kulit menjadi lebih bersih dan detail penting seperti warna bentuk dan tekstur lesi menjadi lebih jelas. ini sangat membantu dokter atau sistem analisis otomatis untuk mengidentifikasi dan mengevaluasi kondisi kulit dengan lebih akurat memastikan diagnosis dan rencana perawatan yang lebih efektif. langkah langkah penghapusan noise menggunakan median dan gaussian filter dapat dilihat pada algoritma 3.4. algoritma 3. 4 algoritma penghapusan noise input citra penyakit kulit hasil peningkatan kontras ouput citra penyakit kulit dengan penghapusan noise proses 1. inisialisasi citra 2. muat data citra 3. penghapusan noise menggunakan filter median 4. penghapusan noise menggunakan filter gaussian 5. tampilakan dan simpan hasil citra hasil penghapusan noise menggunakan median filter dan gaussian filter disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. 4 diatas dapat dikonversi kedalam pseudo code 4 yang dapat diimplementasikan pada pemrograman python. pseudocode 4. penghapusan noise def denoise_medianimage kernel_size3 denoised_image cv2.medianblurimage kernel_size return denoised_image def denoise_gaussianimage kernel_size3 denoised_image cv2.gaussianblurimage kernel_size kernel_size 0 return denoised_image sehingga tampilan hasil program terlihat pada gambar 3. 9 berikut. seperti terlihat pada gambar proses penghapusan noise menggunakan gabungan median filter dan gaussian filter ditujukan untuk m enghilangkan objek objek yang tidak terpakai dengan menggunakan kernel rendah citra yang dihasilkan tidak terlalu mendapatkan blur yang sangat singnifikan sehingga objek suatu penyakit kulit masih dapat terlihat jelas tanpa adanya noise yang tidak terpakai . dengan menghapus noise maka citra yang dihasilkan menjadi lebih bersih proses ini membantu dalam meningkatkan fokus citra terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. gambar 3. 9 hasil penghapusan noise 3.4.1.5. segmentasi data pada tahap ini dilakukan segmentasi dengan thresholding atau penghapusan bagian yang tidak diperlukan seperti background untuk mendapatkan objek penyakit kulit yang digunakan pada penelitian serta menambahkan active contour untuk mendapatkan objek yang ditandai sebagai penyakit kulit . proses ini melibatkan beberapa tahapan penting. pertama citra awal dimuat dan mungkin diubah menjadi citra skala abu abu untuk mempermudah analisis intensitas piksel. selanjutnya nilai ambang dipilih atau dihitung berdasarkan karakteristik citra sepert i histogram int ensitas piksel. pada tahap thresholding piksel dalam citra yang melebihi nilai ambang akan diberi warna atau nilai putih 255 sementara piksel yang lebih rendah akan diberi warna atau nilai hitam 0 menghasilkan citra biner. langkah langkah segmentasi menggunakan thresholding atau penghapusan bagian yang tidah dibutuhkan dapat dilihat pada algoritma 3.5. algoritma 3. 5 algoritma segmentasi input citra penyakit kulit hasil penghapusan noise ouput citra penyakit kulit hasil segmentasi thresholding proses 1. inisialisasi citra 2. muat data citra 3. konversi ke citra grayscale 4. tentukan nilai threshold 5. segmentasi dengan thresholding 6. inversi citra hasil thresholding 7. pemulihan warna asli 8. simpan hasil citra hasil segmentasi menggunakan thresholding disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. 5 diatas dapat dikonversi kedalam pseudo code 5 yang dapat diimplementasikan pada pemrograman python. pseudocode 5. segmentasi def segment_with_thresholdimage threshold_value _ segmented_image cv2.thresholdimage threshold_value 255 cv2.thresh_binary return segmented_image def invert_imageimage inverted_image cv2.bitwise_notimage return inverted_image def find_contoursimage contours _ cv2.findcontoursimage cv2.retr_external cv2.chain_approx_simple return contours def draw_contoursimage contours image_with_contours image.copy cv2.drawcontoursimage_with_contours contours 1 0 255 0 2 return image_with_contours def restore_colororiginal_image inverted_segmented_image mask cv2.mergeinverted_segmented_image inverted_segmented_image inverted_segmented_image inverted_mask cv2.bitwise_notmask restored_image cv2.bitwise_ororiginal_image inverted_mask return restored_image sehingga tampilan hasil program terlihat pada gambar 3.10 berikut. seperti terlihat pada gambar proses segmentasi menggunakan thresholding dan active contour ditujukan untuk menghilangkan objek objek yang tidak digunakan dan memberi tanda pada objek yang digunakan untuk proses selanjutnya . dengan menghapus nilainilai pada citra yang tidak terpakai maka citra yang dihasilkan menjadi lebih bersih proses ini membantu dalam menentukan focus objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. gambar 3. 10 hasil segmentasi 3.4.1.6. ekstraksi fitur tahapan ini melibatkan pengambilan informasi relevan dari citra yang dapat digunakan untuk mengklasifikasikan dan mendiagnosis kondisi kulit. setelah citra tersegmentasi dengan baik langkah berikutnya yaitu mengekstraksi fitur fitur yang relevan dari setiap area tersegmentasi. fitur fitur ini berupa tekstur bentuk dan warna yang dapat membedakan antara lesi kulit yang berbeda. dalam beberapa kasus tidak semua fitur yang diekstraksi diperlukan. proses seleksi fitur membantu dalam memilih subset fitur terbaik yang paling bermakna untuk klasifikasi atau diagnosa yang akurat. 3.4.1.6.1. ekstraksi fitur warna tahap ini dimulai dengan memuat citra dalam format yang sesuai seperti jpeg atau png dan memisahkan informasi warna menjadi tiga kanal utama merah red hijau green dan biru blue. setiap kanal ini mewakili intensitas cahaya pada panjang gelombang yang berbeda dan memiliki rentang nilai dari 0 hingga 255 dalam skala 8 bit. langkah langkah ekstraksi fitur warna dapat dilihat pada algoritma 3.6 . algoritma 3. 6 ekstraksi fitur warna input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi warna proses 1. inisialisasi citra 2. muat data citra 3. pisahkan kanal warna r g b 4. hitung statistik kanal a ratarata mean b standar deviasi standard deviation 5. simpan fitur nilai hasil ektraksi fitur warna menggunakan rgb disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. 6 diatas dapat dikonversi kedalam pseudo code 6 yang dapat diimplementasikan pada pemrograman python. pseudocode 6. ektraksi fitur warna def extract_rgb_featuresimage split the image into rgb channels b g r cv2.splitimage calculate mean and standard deviation for each channel r_mean b.mean g_mean g.mean b_mean r.mean r_std b.std g_std g.std b_std r.std return r_mean g_mean b_mean r_std g_std b_std sehingga tampilan hasil program terlihat pada gambar 3.11 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan rgb dan menunjukan hasil histogram ditujukan untuk memisahkan informasi warna menjadi tiga kanal utama merah red hijau green dan biru blue. dengan mendapatkan nilai nilai pada setiap kanal rgb maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap warna yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. gambar 3. 11 hasil ektraksi fitur warna 3.4.1.6.2. ektraksi fitur bentuk tahapan ini dimulai dengan pra pemrosesan citra untuk meningkatkan kualitas dan mempersiapkannya untuk ekstraksi fitur. langkah pertama biasanya melibatkan segmentasi objek dari latar belakang yang dapat dilakukan dengan metode seperti thresholding atau d eteksi tepi. setelah objek tersegmentasi berbagai fitur geometris seperti luas keliling bentuk dan orientasi dapat diekstraksi. langkah langkah ekstraksi fitur bentuk dapat dilihat pada algoritma 3.7. algoritma 3. 7 ekstraksi fitur bentuk input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi bentuk proses 1. inisialisasi citra 2. muat data citra 3. ekstraksi kontur 4. ekstraksi fitur geometris 5. simpan hasil nilai hasil ektraksi fitur bentuk menggunakan contour dan geometris disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. 7 diatas dapat dikonversi kedalam pseudo code 7 yang dapat diimplementasikan pada pemrograman python. pseudocode 7. ektraksi fitur bentuk def extract_shape_featuresimage gray cv2.cvtcolorimage cv2.color_bgr2gray _ thresh cv2.thresholdgray 0 255 cv2.thresh_binary cv2.thresh_otsu contours _ cv2.findcontoursthresh cv2.retr_external cv2.chain_approx_simple areas perimeters circularities eccentricities for contour in contours area cv2.contourareacontour perimeter cv2.arclengthcontour true circularity 4 np.pi area perimeter 2 if perimeter 0 else 0 if lencontour 5 ellipse cv2.fitellipsecontour center axes orientation ellipse major_axis maxaxes minor_axis minaxes eccentricity np.sqrt1 minor_axis 2 major_axis 2 if major_axis 0 else 0 else eccentricity 0 areas.appendarea perimeters.appendperimeter circularities.appendcircularity eccentricities.appendeccentricity avg_area np.meanareas avg_perimeter np.meanperimeters avg_circularity np.mean circularities avg_eccentricity np.meaneccentricities return avg_area avg_perimeter avg_circularity avg_eccentricity sehingga tampilan hasil program terlihat pada gambar 3.12 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan bentuk contour dan geometris menunjukan hasil nilai untuk setiap citra ditujukan untuk memisahkan informasi bentuk menjadi area perimeter circularity dan exccentricity . dengan mendapatkan nilainilai bentuk maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap bentuk yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. gambar 3. 12 hasil ektraksi fitur bentuk 3.4.1.6.3. ektraksi fitur tekstur pada tahapan ekstraksi fitur tekstur melibatkan beberapa langkah kunci untuk menggambarkan dan menganalisis tekstur citra secara sistematis . tahap awal mencakup pemilihan glcm sebagai metode utama untuk mengekstraksi fitur tekstur. setelah glcm terbentuk tahap selanjutnya adalah ekstraksi fitur fitur statistik dari matriks glcm. fitur fitur ini mungkin mencakup energi kontras homogenitas dan korelasi yang masing masing memberikan informasi tentang struktur dan pola tekstur dalam citra yang d ianalisis. langkah langkah ekstraksi fitur tekstur dengan menggunakan metode glcm sebagai acuan tekstur dapat dilihat pada algoritma 3. 8. algoritma 3. 8 ekstraksi fitur tektur input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi tekstur proses 1. inisialisasi citra 2. muat data citra 3. pembentukan glcm 4. normalisasi glcm 5. ekstraksi fitur statistik 6. simpan hasil nilai hasil ektraksi fitur tekstur menggunakan glcm disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. 8 diatas dapat dikonversi kedalam pseudo code 8 yang dapat diimplementasikan pada pemrograman python . pseudocode 8. ektraksi fitur tektur def calculate_glcm_featuresimage_path load gambar dan konversi ke grayscale image io.imreadimage_path gray_image color.rgb2grayimage gray_image img_as_ubytegray_image konversi ke tipe data uint8 hitung glcm dengan jarak dan arah yang ditentukan distances 1 2 3 jarak d angles 0 np.pi4 np.pi2 3np.pi4 arah θ glcm graycomatrixgray_image distancesdistances anglesangles symmetrictrue normedtrue ekstraksi fitur tekstur dari glcm contrast graycopropsglcm contrast dissimilarity graycopropsglcm dissimilarity homogeneity graycopropsglcm homogeneity energy graycopropsglcm energy correlation graycopropsglcm correlation mengembalikan hasil fitur sebagai tuple return contrast.mean dissimilarity.mean homogeneity.mean energy.mean correlation.mean sehingga tampilan hasil program terlihat pada gambar 3.13 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan glcm menunjukan hasil nilai untuk setiap citra ditujukan untuk memisahkan informasi tekstur menjadi contrast dissimilarity homogeneity energy dan correlation. dengan mendapatkan nilai nilai tekstur maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap tekstur yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. gambar 3. 13 hasil ekstraksi fitur tekstur dengan glcm 3.4.2. preprocessing data teks tahap pre processing data teks dilakukan serangkaian langkah penting dalam pengolahan informasi teks yang bertujuan untuk membersihkan merapihkan dan mempersiapkan data sebelum dilakukan analisis lebih lanjut. proses ini krusial karena data teks sering kali tidak terstruktur dan dapat mengandu ng berbagai jenis noise atau informasi yang tidak relevan yang dapat mempengaruhi hasil analisis. beberapa tahap yang dilakukan pada preprocessing data teks ini meliputi pertama tokenisasi dilakukan untuk memecah te ks menjadi unitunit yang lebih kecil seperti kata kata atau kalimat. setelah itu langkah pembersihan cleaning dilakukan untuk menghilangkan elemen elemen yang tidak relevan seperti karakter khusus atau token seperti stopwords yang tidak memberikan banyak informasi. selanjutnya stemming atau lemmatisasi proses ini mengubah kata kata menjadi bentuk dasarnya lemmas atau akar kata stems untuk mengurangi variasi kata yang memiliki arti yang sama.,1 tahapan penelitian dokumentasi peneliti tahapan penelitian dapat dilihat pada gambar 3.1. tahapan penelitian yang dilakukan terdiri dari 9 tahapan yaitu dimulai dari studi literatur sebagai dasar penelitian analisis kebutuhan pada system yang akan dibangun pengumpulan dataset preprocessing data membangun model training model evaluasi model deployme nt model dan implementasi model yang telah dibuat ke dalam smartphone. saat program telah dijalankan program akan mengakuisisi dataset kemudian dataset akan melalui tahap preprocessing untuk m enormalkan data kemudian setelah melalui tahap preprocessing selanjutnya mentraining dataset yang sudah didapatkan jika dataset berhasil dilatih dan juga divalidasi maka berlanjut ke tahap berikutnya yaitu tahapan test ing dengan menerapkan model yang dibuat kedalam mobile phone atau smartphone. tahap selanjutnya jika camera telah menyala maka artinya sudah siap untuk mendeteksi objek jenis penyakit kulit . pada tahap terakhir yaitu saat ada objek jenis penyakit kulit yang masuk atau terdeteksi oleh camera m aka citra tersebut sudah dapat dilakukan proses klasifikasi kemudian divalidasikan bahwa data tersebut sama dengan yang ada pada database untuk memunculkan label nama pada dataset serta memunculkan nilai confidence pada citra jenis penyakit kulit yang terdete ksi. 3.2 analisis kebutuhan analisis kebutuhan merupakan menganalisis komponen yang diperlukan dalam pembuatan dan menjalankan program proses ini mencakup evaluasi identifikasi dan pemetaan kebutuhan dari berbagai perangkat yang terlibat dalam pembuatan system dan program pada penelitian ini. 3.2.1. analisis kebutuhan perangkat keras perangkat keras yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan laptop acer predator helios neo 16 dan mobile phone atau smartphone xiaomi redmi note 7 dengan bahasa pemrograman python dengan spesifikasi yang dapat dilihat pada tabel 3.1. tabel 3. 2 mobile phone smartphone 1 camera hd 48mp 169 1280x720 f1.8 wide dual led flash hdr panorama rgb red green blue 3.2.2. analisis kebutuhan perangkat lunak perangkat lunak yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan operating system windows jupyter lab dengan bahasa pemrograman python dan visual studio sebagai text editor yang dapat dilihat pada tabel 3.2. tabel 3. identifikasi berbagai macam jenis penyakit kulit dengan memunculkan citra gambar yang didapat dan deskripsi mengenai penyakit kulit yang teridentifikasi dibawah citra gambar untuk setiap objek penyakit kulit yang terdeteksi data yang digunakan memiliki variasi jenis penyakit kulit dengan kategori 2 penyakit kulit menular candidiasis dan molluscum dan 2 penyakit kulit tidak menular eczhema dan melanoma dengan masing masing kelas memiliki 1000 citra penyakit kulit yang di dapat pada website international dermnet nz dermnetnz.org 2024 dan the international skin imaging collaboration isic isicarchive.com 2024 . program identifikasi berbagai macam objek penyakit kulit pada manusia ditampilkan secara real time menggunakan file upload kamera mobile phone. website ini menyediakan gambar gambar resolusi tinggi dari berbagai penyakit kulit baik yang menular maupun tidak menular serta memberikan deskripsi lengkap tentang penyakti tersebut meliputi gejala dan pengobatan. citra yang diperoleh kemudian diseleksi berdasarkan fokus penelitian yaitu identifikasi penyakit kulit menular candidiasis dan molluscum dan tidak menular eczhema dan melanoma . dari keempat jenis penyakit kulit tersebut dibagi menjadi 2 kelompok sebagai penyakit kulit menular dan tidak menular. penggunaan data gambar sangat penting dalam penelitian ini untuk membandingkan dan mempelajari pola visual yang terkait dengan berbagai penyakit kulit. informasi ini penting untuk diagnosis dan pemahaman lebih lanjut tentang berbagai penyakit kulit seperti dermatitis eksim psoriasis dan infeksi jamur kulit. 3 data teks penyakit kulit 3.4 pre processing data pada tahapan ini data gambar penyakit kulit preprocessing mencakup berbagai teknik seperti pengubahan ukuran gambar normalisasi piksel peningkatan kontras penghapusan noise serta melakukan segmentasi dan fitur ekstraksi. teknik ini bertujuan untuk meningkatkan kualitas gambar dan memastikan konsistensi data sehingga fitur fitur penting dapat diekstraksi dengan lebih efektif oleh algoritma analisis atau mode l kecerdasan buatan. langkah langkah ini membantu dalam menyederhanakan teks mengurangi dime nsionalitas dan meningkatkan efisiensi analisis teks. dengan preprocessing yang tepat data gambar dan teks menjadi lebih bersih dan terstruktur memungkinkan model machine learning untuk menghasilkan prediksi yang lebih akurat dan andal. kedua normalisasi piksel diterapkan untuk mengatur nilai piksel dalam rentang tertentu biasanya antara 0 dan 1 guna meningkatkan stabilitas dan kecepatan konvergensi model. dapat dilihat pada algoritma 3.1. algoritma 3.1 algoritma resize citra input citra penyakit kulit dengan ukuran asli ouput citra penyakit kulit dengan ukuran sama 256x256 proses 1. simpan citra yang telah diubah ukurannya ukuran dan bentuk citra hasil resizing disimpan pada folder output masing masing penyakit kulit yang selanjutnya akan diproses pada tahap berikutnya. resize citra def resize_imageimage size256 256 resized_image cv2.resizeimage size interpolationcv2.inter_area return resized_image sehingga tampilan hasil program terlihat pada gambar 3. hasil resize data gambar 3.4.1.2. normalisasi data pada tahapan ini data yang telah di resize pada tahap sebelumya dinormalisasi. 2 algoritma no rmalisasi citra input citra penyakit kulit hasil resize ouput citra penyakit kulit dengan hasil normalisasi proses 1. simpan dan gunakan hasil normalisasi citra hasil normalisasi disimpan yang selanjutnya akan diproses pada tahap berikutnya. normalisasi citra def normalize_imageimage convert image to float32 type for normalization image image.astypenp.float32 normalize the image normalized_image image 255.0 return normalized_image sehingga tampilan hasil program terlihat pada gambar 3.7 berikut. dengan meningkatkan perbedaan antara nilai intensitas piksel proses ini membantu dalam meningkatkan ketajaman citra dan membuatnya lebih mudah untuk dianalisis. langkah langkah peningkatan kontras dapat dilihat pada algoritma 3.3 . 3 algoritma peningkatan kontras input citra penyakit kulit hasil normalisasi ouput citra penyakit kulit dengan peningkatan kontras proses 1. dengan meningkatkan perbedaan antara nilai intensitas piksel proses ini membantu dalam meningkatkan ketajaman citra dan membuatnya lebih mudah untuk dianalisis. 4 algoritma penghapusan noise input citra penyakit kulit hasil peningkatan kontras ouput citra penyakit kulit dengan penghapusan noise proses 1. seperti terlihat pada gambar proses penghapusan noise menggunakan gabungan median filter dan gaussian filter ditujukan untuk m enghilangkan objek objek yang tidak terpakai dengan menggunakan kernel rendah citra yang dihasilkan tidak terlalu mendapatkan blur yang sangat singnifikan sehingga objek suatu penyakit kulit masih dapat terlihat jelas tanpa adanya noise yang tidak terpakai . dengan menghapus noise maka citra yang dihasilkan menjadi lebih bersih proses ini membantu dalam meningkatkan fokus citra terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 9 hasil penghapusan noise 3.4.1.5. segmentasi data pada tahap ini dilakukan segmentasi dengan thresholding atau penghapusan bagian yang tidak diperlukan seperti background untuk mendapatkan objek penyakit kulit yang digunakan pada penelitian serta menambahkan active contour untuk mendapatkan objek yang ditandai sebagai penyakit kulit . pada tahap thresholding piksel dalam citra yang melebihi nilai ambang akan diberi warna atau nilai putih 255 sementara piksel yang lebih rendah akan diberi warna atau nilai hitam 0 menghasilkan citra biner. 5 algoritma segmentasi input citra penyakit kulit hasil penghapusan noise ouput citra penyakit kulit hasil segmentasi thresholding proses 1. inversi citra hasil thresholding 7. simpan hasil citra hasil segmentasi menggunakan thresholding disimpan yang selanjutnya akan diproses pada tahap berikutnya. segmentasi def segment_with_thresholdimage threshold_value _ segmented_image cv2.thresholdimage threshold_value 255 cv2.thresh_binary return segmented_image def invert_imageimage inverted_image cv2.bitwise_notimage return inverted_image def find_contoursimage contours _ cv2.findcontoursimage cv2.retr_external cv2.chain_approx_simple return contours def draw_contoursimage contours image_with_contours image.copy cv2.drawcontoursimage_with_contours contours 1 0 255 0 2 return image_with_contours def restore_colororiginal_image inverted_segmented_image mask cv2.mergeinverted_segmented_image inverted_segmented_image inverted_segmented_image inverted_mask cv2.bitwise_notmask restored_image cv2.bitwise_ororiginal_image inverted_mask return restored_image sehingga tampilan hasil program terlihat pada gambar 3.10 berikut. dengan menghapus nilainilai pada citra yang tidak terpakai maka citra yang dihasilkan menjadi lebih bersih proses ini membantu dalam menentukan focus objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 10 hasil segmentasi 3.4.1.6. ekstraksi fitur tahapan ini melibatkan pengambilan informasi relevan dari citra yang dapat digunakan untuk mengklasifikasikan dan mendiagnosis kondisi kulit. 6 ekstraksi fitur warna input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi warna proses 1. simpan fitur nilai hasil ektraksi fitur warna menggunakan rgb disimpan yang selanjutnya akan diproses pada tahap berikutnya. ektraksi fitur warna def extract_rgb_featuresimage split the image into rgb channels b g r cv2.splitimage calculate mean and standard deviation for each channel r_mean b.mean g_mean g.mean b_mean r.mean r_std b.std g_std g.std b_std r.std return r_mean g_mean b_mean r_std g_std b_std sehingga tampilan hasil program terlihat pada gambar 3.11 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan rgb dan menunjukan hasil histogram ditujukan untuk memisahkan informasi warna menjadi tiga kanal utama merah red hijau green dan biru blue. dengan mendapatkan nilai nilai pada setiap kanal rgb maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap warna yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 11 hasil ektraksi fitur warna 3.4.1.6.2. ektraksi fitur bentuk tahapan ini dimulai dengan pra pemrosesan citra untuk meningkatkan kualitas dan mempersiapkannya untuk ekstraksi fitur. 7 ekstraksi fitur bentuk input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi bentuk proses 1. simpan hasil nilai hasil ektraksi fitur bentuk menggunakan contour dan geometris disimpan yang selanjutnya akan diproses pada tahap berikutnya. ektraksi fitur bentuk def extract_shape_featuresimage gray cv2.cvtcolorimage cv2.color_bgr2gray _ thresh cv2.thresholdgray 0 255 cv2.thresh_binary cv2.thresh_otsu contours _ cv2.findcontoursthresh cv2.retr_external cv2.chain_approx_simple areas perimeters circularities eccentricities for contour in contours area cv2.contourareacontour perimeter cv2.arclengthcontour true circularity 4 np.pi area perimeter 2 if perimeter 0 else 0 if lencontour 5 ellipse cv2.fitellipsecontour center axes orientation ellipse major_axis maxaxes minor_axis minaxes eccentricity np.sqrt1 minor_axis 2 major_axis 2 if major_axis 0 else 0 else eccentricity 0 areas.appendarea perimeters.appendperimeter circularities.appendcircularity eccentricities.appendeccentricity avg_area np.meanareas avg_perimeter np.meanperimeters avg_circularity np.mean circularities avg_eccentricity np.meaneccentricities return avg_area avg_perimeter avg_circularity avg_eccentricity sehingga tampilan hasil program terlihat pada gambar 3.12 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan bentuk contour dan geometris menunjukan hasil nilai untuk setiap citra ditujukan untuk memisahkan informasi bentuk menjadi area perimeter circularity dan exccentricity . dengan mendapatkan nilainilai bentuk maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap bentuk yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 12 hasil ektraksi fitur bentuk 3.4.1.6.3. ektraksi fitur tekstur pada tahapan ekstraksi fitur tekstur melibatkan beberapa langkah kunci untuk menggambarkan dan menganalisis tekstur citra secara sistematis . langkah langkah ekstraksi fitur tekstur dengan menggunakan metode glcm sebagai acuan tekstur dapat dilihat pada algoritma 3. algoritma 3. 8 ekstraksi fitur tektur input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi tekstur proses 1. simpan hasil nilai hasil ektraksi fitur tekstur menggunakan glcm disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. ektraksi fitur tektur def calculate_glcm_featuresimage_path load gambar dan konversi ke grayscale image io.imreadimage_path gray_image color.rgb2grayimage gray_image img_as_ubytegray_image konversi ke tipe data uint8 hitung glcm dengan jarak dan arah yang ditentukan distances 1 2 3 jarak d angles 0 np.pi4 np.pi2 3np.pi4 arah θ glcm graycomatrixgray_image distancesdistances anglesangles symmetrictrue normedtrue ekstraksi fitur tekstur dari glcm contrast graycopropsglcm contrast dissimilarity graycopropsglcm dissimilarity homogeneity graycopropsglcm homogeneity energy graycopropsglcm energy correlation graycopropsglcm correlation mengembalikan hasil fitur sebagai tuple return contrast.mean dissimilarity.mean homogeneity.mean energy.mean correlation.mean sehingga tampilan hasil program terlihat pada gambar 3.13 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan glcm menunjukan hasil nilai untuk setiap citra ditujukan untuk memisahkan informasi tekstur menjadi contrast dissimilarity homogeneity energy dan correlation. dengan mendapatkan nilai nilai tekstur maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap tekstur yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 13 hasil ekstraksi fitur tekstur dengan glcm 3.4.2. preprocessing data teks tahap pre processing data teks dilakukan serangkaian langkah penting dalam pengolahan informasi teks yang bertujuan untuk membersihkan merapihkan dan mempersiapkan data sebelum dilakukan analisis lebih lanjut. proses ini krusial karena data teks sering kali tidak terstruktur dan dapat mengandu ng berbagai jenis noise atau informasi yang tidak relevan yang dapat mempengaruhi hasil analisis.
Alifurrohman_Kualifikasi.txt,3.2 pengumpulan data langkah awal adalah mengumpulkan dataset yang akurat dan relevan. dataset didapatkan dari data sekunder dataset ini merupakan hal yang penting dari simulasi dan eksperimen mencakup koordinat lokasi yang mungkin meliputi lokasi depot dan titik pengiriman jendela waktu untuk setiap pengiriman yang menentukan batas awal dan akhir kapan pengiriman harus dilakukan serta jumlah kendaraan. data ini harus mencerminkan situasi dunia nyata untuk memastikan bahwa model yang dikembangkan dapat diaplikasikan secara praktis. 3.3 persiapan data langkah berikutnya adalah persiapan data. pada persiapan data dilakukan normalisasi data. n ormalisasi merupakan proses penting untuk menyamakan skala data memastikan bahwa model dapat memprosesnya dengan efisien. normalisasi minmax digunakan pada penelitian ini. minmax adalah teknik yang mengubah skala nilai data ke dalam rentang baru seperti 0 hingga 1 atau 1 hingga 1. teknik ini memastikan bahwa setiap fitur atau kolom data memberikan kontribusi yang seimbang dalam analisis tanpa membiarkan fitur dengan skala besar m endominasi. pengecekan matriks korelasi dilakukan untuk memahami hubungan antara variabel variabel dalam dataset. korelasi membantu mengidentifikasi fitur fitur yang saling terkait dan memberikan wawasan tentang bagaimana setiap fitur dapat mempengaruhi model prediksi rute. koefisien korelasi pearson digunakan untuk mengukur hubungan linear antara fitur. 3.4 desain model implementasi deep q network dqn dengan mekanisme attention untuk dynamic vehicle routing problem with time windows dvrptw melibatkan beberapa langkah utama mulai dari pemilihan kerangka kerja hingga pembuatan lingkungan simulasi. 1. pemilihan kerangka kerja 28 kerangka kerja yang digunakan yaitu tensorflow dimana kerangka kerja ini menawarkan lingkungan yang komprehensif dengan tensorboard untuk visualisasi serta dukungan terhadap tpu untuk akselerasi komputasi. tensorflow mungkin lebih cocok untuk produksi dan skala besar. 2. desain model dqn dan multi head erattention dqn adalah algoritma pembelajaran penguatan yang menggunakan jaringan saraf tiruan untuk memperkirakan fungsi nilai q yang merepresentasikan nilai maksimum hadiah kumulatif yang diharapkan diberikan sebuah state dan semua strategi yang mungkin diambil. i mplementasi dqn melibatkan beberapa komponen utama jaringan q jaringan ini memperkirakan nilai q untuk setiap aksi dari state tertentu. dalam kasus dvrptw input bisa berupa representasi dari state saat ini misalnya lokasi kendaraan status pengiriman dan output adalah nilai q untuk setiap kemungkinan aksi misalnya memilih lokasi pengiriman berikutnya. memory replay untuk meningkatkan stabilitas dan efisiensi pembelajaran dqn menggunakan teknik memory replay di mana transisi state aksi reward state baru disimpan dalam sebuah buffer . batch transisi ini kemudian digunakan untuk melatih jaringan q memungkinkan pengalaman dari masa lalu digunakan kembali. strategi eksplorasi seperti εgreedy di mana aksi acak dipilih dengan probabilitas ε untuk mendorong eksplorasi lingkungan. mekanis me attention terdiri dari tiga matriks utama query q key k dan value v untuk setiap head i. adapun langkah langkahnya implementasinya sebagai berikut a. definisikan ukuran input dan parameter mentukan jumlah fitur input dimensi embedding jumlah heads untuk mekanisme attention dan jumlah unit dalam lapisan tersembunyi dqn. serta jumlah tindakan yang mungkin dilakukan oleh agen. b. definisikan multi head er attention menerapkan mekanisme multi head er attention pada representasi vektor dari embedding layer . multi head er attention menggunakan query q key k 29 dan value v untuk menangkap hubungan kontekstual dalam data. proses ini membantu model untuk fokus pada aspek aspek penting dari data input. attention score dihitung dengan mengalikan query dengan key kemudian membaginya dengan skala biasanya akar dari dimensi key dan menerapkan fungsi softmax untuk mendapatkan bobot attention . output attention diperoleh dengan mengalikan bobot perhatian dengan value . multi head er attention melakukan proses ini beberapa kali secara paralel dengan beberapa heads dan hasilnya digabungkan untuk data i nput. c. definisikan dqn dengan lapisan tersembunyi memb uat beberapa lapisan tersembunyi hidden layers menggunakan fungsi aktivasi relu. lapisan tersembunyi ini memungkinkan jaringan untuk belajar representasi yang kompleks dari data input. output dari mekanisme attention diberikan sebagai input ke dqn. dqn memperkirakan q value s untuk setiap tindakan yang mungkin dilakukan oleh agen berdasarkan representasi state yang telah diperkaya. d. output layer untuk q value s lapisan output menghasilkan q value s untuk setiap tindakan yang mungkin dilakukan oleh agen. q value s ini menunjukkan seberapa baik setiap tindakan dalam memaksimalkan reward di masa depan. misalnya jika agen memiliki 5 kemungkinan tindakan lapisan output akan menghasilkan 5 q value s satu untuk setiap tindakan. e. memilih tindakan menggunakan strategi εgreedy implementasikan strategi εgreedy untuk memastikan agen mengeksplorasi lingkungan sekaligus mengeksploitasi pengetahuan yang ada. dengan probabilitas ε agen memilih tindakan secara acak untuk eksplorasi dan dengan probabilitas 1 ε agen memilih tindakan dengan q value tertinggi untuk eksploitasi. f. memperbarui model dengan pengalaman dari replay buffer mengg unakan replay buffer untuk menyimpan transisi state action reward next state dan menggunakannya untuk melatih model. batch transisi 30 diambil secara acak dari replay buffer untuk mengurangi korelasi antara sampel pelatihan dan meningkatkan stabilitas pelatihan. 3.5 pelatihan model selama fase pelatihan model secara berulang kali dihadapkan pada berbagai skenario dari masalah r ute kendaraan. untuk setiap episode model mengambil serangkaian aksi berdasarkan policy atau kebijakan saat ini yang awalnya adalah kebijakan acak dengan tujuan meminimalkan jarak total dan memenuhi jendela waktu pengiriman. setelah mengambil aksi model menerima feedback dari lingkungan berupa reward yang merupakan ukuran dari performa aksi tersebut dan state baru yang mencerminkan kondisi terkini dari lingk ungan setelah aksi diambil. informasi ini digunakan untuk memperbarui kebijakan model dengan cara mengoptimalkan parameter jaringan sehingga meningkatkan estimasi nilai q yang merepresentasikan hadiah kumulatif yang diharapkan. untuk meningkatkan stabilitas dan efisiensi pelatihan teknik seperti experience replay dan target networks digunakan. experience replay memungkinkan model untuk belajar dari pengalaman masa lalu yang disimpan dalam memory replay sedangkan target networks membantu mengurangi pergeseran target yang bergerak selama proses pembelajaran. melalui interaksi yang berulang dan proses optimisasi ini model secara bertahap belajar untuk memprediksi nilai q yang lebih akurat untuk setiap kombinasi state dan aksi yang mengarah pada pembentukan kebijakan rute yang lebih optimal. selain itu pada tahap pelatihan model ini juga dilakukan penyetelan hyperparameter untuk menemukan nilai optimal hyperparameter guna meningkatkan kinerja model. ini merupakan langkah penting dalam machine learning karena dapat menghasilkan peningkatan akurasi efisiensi dan generalizability model. penyetelan hyperparameter menggunakan teknik random search yaitu teknik yang digunakan untuk penyetelan hyperparameter yang melibatkan pemilihan acak dari ruang yang ditentukan untuk menemukan kombinasi terbaik yang mengoptimalkan kinerja model. teknik ini lebih efektif dan 31 efisien untuk penyetelan hyperparameter terutama pada kasus dengan ruang pencarian yang besar serta dapat menemukan solusi yang baik dalam waktu yang lebih singkat. 3.6 evaluasi model setelah fase pelatihan model deep q network dqn dengan multi header attention untuk dynamic vehicle routing problem with time windows dvrptw selesai langkah evaluasi menjadi penting untuk memahami seberapa efektif model dalam menyelesaikan masalah yang ditargetkan. evaluasi dilakukan dengan menguji model terhadap kumpulan data pengujian yang tidak terlibat selama proses pelatihan me mberikan masukan penting tentang kemampuan generalisasi model terhadap skenario baru dan belum pernah dilihat. dalam kont eks dvrptw metrik yang relevan seperti total jarak tempuh oleh semua kendaraan dan kepatuhan terhadap jendela waktu pengiriman menjadi fokus utama. total jarak tempuh mencerminkan efisiensi rute yang dihasilkan sementara kepatuhan terhadap jendela waktu mencerminkan kualitas layanan yang dapat dijamin oleh model. 3.7 analisis dan penyempurnaan langkah terakhir yaitu analisis secara mendalam kinerja model pada dataset pengujian. penyempurnaan dilakukan untuk mengatasi kelemahan yang telah dianalisis sebelumnya seperti penyempurnaan pada tuning hyperparameter untuk peningkatan kinerja modifikasi arsitektur dan pelatihan ulang model. 3.8 jadwal penelitian jadwal penelitian digunakan untuk meningkatkan efektivitas dalam proses penelitian. adanya jadwal penelitian ini setiap proses penelitian sudah terjadwal dalam tabel 3.1 sehingga penelitian lebih efektif dan optimal.,3.2 pengumpulan data langkah awal adalah mengumpulkan dataset yang akurat dan relevan. dataset didapatkan dari data sekunder dataset ini merupakan hal yang penting dari simulasi dan eksperimen mencakup koordinat lokasi yang mungkin meliputi lokasi depot dan titik pengiriman jendela waktu untuk setiap pengiriman yang menentukan batas awal dan akhir kapan pengiriman harus dilakukan serta jumlah kendaraan. data ini harus mencerminkan situasi dunia nyata untuk memastikan bahwa model yang dikembangkan dapat diaplikasikan secara praktis. n ormalisasi merupakan proses penting untuk menyamakan skala data memastikan bahwa model dapat memprosesnya dengan efisien. 3.4 desain model implementasi deep q network dqn dengan mekanisme attention untuk dynamic vehicle routing problem with time windows dvrptw melibatkan beberapa langkah utama mulai dari pemilihan kerangka kerja hingga pembuatan lingkungan simulasi. memory replay untuk meningkatkan stabilitas dan efisiensi pembelajaran dqn menggunakan teknik memory replay di mana transisi state aksi reward state baru disimpan dalam sebuah buffer . multi head er attention melakukan proses ini beberapa kali secara paralel dengan beberapa heads dan hasilnya digabungkan untuk data i nput. output layer untuk q value s lapisan output menghasilkan q value s untuk setiap tindakan yang mungkin dilakukan oleh agen. misalnya jika agen memiliki 5 kemungkinan tindakan lapisan output akan menghasilkan 5 q value s satu untuk setiap tindakan. batch transisi 30 diambil secara acak dari replay buffer untuk mengurangi korelasi antara sampel pelatihan dan meningkatkan stabilitas pelatihan. informasi ini digunakan untuk memperbarui kebijakan model dengan cara mengoptimalkan parameter jaringan sehingga meningkatkan estimasi nilai q yang merepresentasikan hadiah kumulatif yang diharapkan. untuk meningkatkan stabilitas dan efisiensi pelatihan teknik seperti experience replay dan target networks digunakan. selain itu pada tahap pelatihan model ini juga dilakukan penyetelan hyperparameter untuk menemukan nilai optimal hyperparameter guna meningkatkan kinerja model. ini merupakan langkah penting dalam machine learning karena dapat menghasilkan peningkatan akurasi efisiensi dan generalizability model. 3.6 evaluasi model setelah fase pelatihan model deep q network dqn dengan multi header attention untuk dynamic vehicle routing problem with time windows dvrptw selesai langkah evaluasi menjadi penting untuk memahami seberapa efektif model dalam menyelesaikan masalah yang ditargetkan. total jarak tempuh mencerminkan efisiensi rute yang dihasilkan sementara kepatuhan terhadap jendela waktu mencerminkan kualitas layanan yang dapat dijamin oleh model. 3.7 analisis dan penyempurnaan langkah terakhir yaitu analisis secara mendalam kinerja model pada dataset pengujian. penyempurnaan dilakukan untuk mengatasi kelemahan yang telah dianalisis sebelumnya seperti penyempurnaan pada tuning hyperparameter untuk peningkatan kinerja modifikasi arsitektur dan pelatihan ulang model. 3.8 jadwal penelitian jadwal penelitian digunakan untuk meningkatkan efektivitas dalam proses penelitian. adanya jadwal penelitian ini setiap proses penelitian sudah terjadwal dalam tabel 3.1 sehingga penelitian lebih efektif dan optimal.
Armando Tirta Dwilaga_Kualifikasi.txt,3.1 gambaran umum penelitian penelitian ini digunakan untuk mengatasi sensitivitas terhadap cacat pada gambar ban dengan melibatkan penggunaan jaringan syaraf menggunakan algoritma convolutional neural network cnn dan membangun model atau kerangka kerja menggunakan keras. berikut adalah gambar 3.1 blok diagram gambaran umum penelitian. data preparation data augmentasi data splitting model training forward pass model evaluation backward passfinetuning if neededinput unit processing unit output unit model deployment inference12 gambar 3.1 blok diagram gambaran umum penelitian berdasarkan gambar 3.1 blok diagram gambaran umum penelitian maka dapat dijelaskan di blok tersebut terbagi menjadi 3 bagian yaitu bagian pertama adalah unit masukan berisikan data preparation di mana gambar ban dimuat diubah menjadi format yang sesuai dipersiapkan untuk pelatihan model convolutional neural network cnn seperti pemrosesan gambar ban selanjutnya data augmentation di mana data dibuat lebih ber variasi dari training data yang ada sehingga dapat meningkatkan keberagaman training data tanpa h arus mengambil data baru mencakup rotasi pergeseran horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel selanjutnya data di mana dataset yang telah di augmentasi dan disiapkan dibagi menjadi subset yang berbeda untuk training untuk melatih model validation untuk menyempurnakan model serta me mvalidasi performanya selama pelatihan dan testing untuk mengevaluasi kinerja model akhir . data set dibagi menjadi training data validation data dan testing data dalam proporsi tertentu. bagian kedua adalah unit pemrosesan yang bertindak adalah model training forward pass tahap di mana input diproses melalui model untuk menghasilkan prediksi tujuannya melatih model convolutional neural network cnn menggunakan dataset pelatihan di mana data dari unit masukan diteruskan melalui jaringan neural di lakukan transformasi linier konvulasi dan non linier fungsi aktivasi dilakukan pada data di setiap lapisan untuk menghasilkan output prediksi yang melibatkan komputasi di setiap neuron dan lapisan jaringan yang merupakan inti dari proses pembelajaran dalam jaringan saraf. selanjutnya unit pemrosesan finetuning tujuannya dilakukan untuk menyempurnakan model lebih lanjut setelah pelatihan awal dengan dataset yang lebih kecil atau lebih spesifik nantinya. proses di dalam finetuning menyesuaikan bobot menggunakan kumpulan data yang lebih kecil untuk menyesuaikan bobot model untuk performa yang lebih baik pelatihan khusus fokus pada fitur data yang lebih relevan dengan objek . bagian ketiga adalah unit keluaran yang bertindak ada proses model evaluatioan backward pass tahap di mana gradien memperbarui parameter model dalam arah yang akan mengurangi fungsi loss dari fungsi loss metrik yang mengukur seberapa baik atau buruk model melakukan prediksi dibandingkan nilai aktualnya dihitung dan digunakan untuk memperbarui parameter model selama pelatihan tujuannya mengevaluasi performa model yang dilatih dan model dievaluasi menggunakan metrik yang relevan accuracy precision recall dan f1 score berdasarkan prediksi yang dihasilkan dari model terhadap validasi atau uji data. output dari proses ini adalah tentang hasil evaluasi model yang memberikan informasi kinerja model. selanjutnya ada dua alur pilihan yang bisa dilakukan alur pertama jika hasil prediksi sudah sesuai dengan keinginan maka bisa langsung masuk ke model deployment inference dan alu r kedua jika hasil prediksi masih perlu diperbaiki pada bagian unit pemrosesan terlebih dahulu fine tuning untuk penggunaan data set lebih kecil jika menunjukan model belum mencapai performa yang diharapkan baru masuk ke model deployment inference tujuannya menerapkan model terlatih untuk membuat prediksi pada data baru yang belum terlihat. model deployment inference yang telah dilatih digunakan untuk membuat prediksi pada data baru atau dalam situasi dunia nyata tahap di mana model menerima input baru dan menghasilkan output berdasarkan pada pembelajaran yang dilakukan selama proses pelatihan dan merupakan output akhir dari keseluruhan proses di mana model mengambil keputusan atau membuat prediksi berdasarkan pada pengalaman yang telah diperoleh selama pelatihan. 3.2. tahapan penelitian penelitian ini di dalamnya terdapat tahapan tahapan yang dilakukan untuk membentuk satu kesatuan yang utuh dari awal sampai akhir dan membentuk kerangka penelitian mengenai klasifikasi pada produk ban menggunakan algoritma convolutional neural network cnn . berikut gambar 3.2 tahapan penelitian. study of literature data acquisition data augmentation data splitting model buildingdata preprocessing model evaluation testing gambar 3.2 tahapan penelitian berdasarkan gambar 3.2 tahapan penelitian maka dapat dijelaskan proses yang terlibat di dalamnya ada 8 yaitu studi literatur data aquisition data preprocessing data augmentation texture feature extraction data splitting model building dan model evaluation testing di mana tahap ke dua sampai lima merupakan tahap proses menyiapkan sebuah data sebelum dilakukan pemodelan. 3.2.1 studi literatur tahap pertama adalah studi literatur di mana studi yang dilakukan berasal dari artikel ilmiah dan buku yang menunjang dalam menganalisis terkait dengan metode pen gukuran kualitas mengenai klasifikasi produk ban meninjau penggunaan pembelajaran mesin algoritma convolutional neural network cnn dari beberapa tahun ke belakang dalam konteks peng ukuran kualitas untuk klasifikasi terhadap kondisi kondisi produk ban . sehingga dapat menemukan teknik terbaik yang dapat diaplikasikan pada masalah yang ada. berikut merupakan gambar 3. 3 tahapan study literature . study of literature load libraries initialize imagedatagenerator set image directory and parameters create test training and validation dataset gambar 3. 3 tahapan study literature 3.2.2 data aquisition tahap k edua adalah data aquisition dengan mengumpulkan kumpulan data sesuai tujuan penelitian dengan target untuk kumpulan data gambar ban untuk training data validation data dan testing data memastikan bahwa kumpulan data tersebut memiliki varian yang secara akurat memang mewakili kondisi produk ban dan diperoleh dari sumber sumber terpercaya . berikut merupakan gambar 3. 4 tahapan data aquisition . data acquisition normal defecttire dataset gambar 3. 4 tahapan data aquisition 3.2.3 data preprocessing tahap ketiga adalah data preprocessing melakukan pra pemrosesan data untuk menyiapkan gambar untuk model pelatihan dan pengujian proses ini meliputi normalisasi dan penskalaan dengan fitur dalam program image data generator . bermaksud merapikan menata dan menyiapkan data untuk pemeriksaan tambahan. normalisasi data pengkodean variabel mengatasi nilai yang hilang menghapus data yang tidak relevan atau hilang dan modifikasi data lainnya untuk memenuhi persyaratan analisis a dalah persiapan data. berikut merupakan gambar 3.5 tahapan data preprocessing . data preprocessing data normalization data scalinginitiation split data into training and validation sets rescale target_size gambar 3. 5 tahapan data preprocessing 3.2.4 data augmentation tahap keempat adalah data augmentation meningkatkan variasi dalam dataset dengan teknik augmentasi data menggunakan operasi seperti rotasi pergeserarn horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel untuk memperkaya dataset dan mengurangi overfitting saat disajikan dengan data baru yang belum pernah dilihat sebelumnya performa model akan menurun drastis karena model tersebut dapat menyesuaikan diri dengan kumpulan training data dengan sangat efektif. augmentasi data dilakukan dengan dua cara secara statis dan dinamis yang artinya secara statis yaitu menambah data secara fisiknya dan dinamis tidak menambah secara fisik tetapi secara k uantitas dataset yang dapat diakses secara fisik di komputer tidak bertambah ketika image data generator digunakan pada dataset. sebaliknya pada saat runtime hanya menghasilkan variasi dari gambar yang sudah ada dibuat secara dinami s dan cukup bagi model untuk berlatih dari berbagai kondisi gambar ban yang ada pada kenyataaanya. secara lebih jelas nilai teknik augmentasi pertama dilakukan dengan manual menggunakan bantuan dari website roboflow dengan resize gambar menjadi 640 x 640 pada augmentasinya menggunakan model flip horizontal dan vertikal 90 pemutaran searah jarum jam berlawanan arah jarum jam dan terbalik rotasi 45 dan 45 shear 5 horizontal dan 5 vertikal brightness 20 sampai 20. data asli pada dataset berjumlah 1 .028 data gambar ban setelah dilakukan augmentasi secara fisik menggunakan website roboflow ada data yang tidak dapat diidentifikasi ada 3 gambar sehingga total gambar asli yang berhasil di upload dan dijadikan data asli yang tetap berjumlah 1.025 data ga mbar dan setelah di augmentasi bertambah menjadi 2 .050 data gambar ban. rinciannya pada data asli training adalah 560 gambar dan setelah dilakukan augmentasi bertambah menjadi sebanyak 1.121 gambar. rincian data asli pada validation data berjumlah 140 gambar dan setelah dilakukan augmentasi bertambah menjadi sebanyak 279 gambar. rincian data asli pada testing data berjumlah 328 gambar dan setelah dilakukan augmentasi bertambah menjadi sebanyak 6 50 gambar. testing data pada prosesnya sebenarnya tidak mengalami augmentasi karena pada proses pengujian atau evaluasi mode l ingin menggunakan data asli yang sebenarnya untuk melihat kinerja model pada kasus kasus yang belum pernah dilihat sebelumnya. augmentasi kedua yaitu dilakukan rotasi melakukan pemutaran gambar secara penuh dan secara acak dengan nilai 360 atau rentang nilai 0 360 derajat kedua width shift range yang menggeser gambar secara acak ke kiri atau kanan dengan nilai 0 .05 atau gambar dapat digeser sampai 5 dari lebar aslinya . ketiga height shift range gambar dapat digeser secara vertikal dengan nilai 0 .05 atau gambar dapat digeser sampai 5 dari tinggi aslinya . keempat shear range untuk menggeser gambar dengan sudut geser berlawanan arah jarum jam dengan nilai 0.05. kelima zoom range memperbesar gambar sebanyak 0.05 atau gambar dapat diperbesar sampai 5. keenam horizontal flip adalah memberikan variasi tambahan dengan mengubah orientasi gambar secara horizontal acak dengan keterangan nilai true. ketujuh vertikal flip adalah memberikan variasi tambahan dengan mengubah orientasi gambar secara vertikal acak dengan keterangan nilai true. kedelapan brightness range mengubah atau menentukan kecerahan pada gambar secara acak dengan nilai rentan 0.75 1.25 atau kecerahan dapat diubah mulai dari rentnag 75 sampai 125 dari kecerahan asli gambarnya. kesembilan resecale mengubah nilai skala piksel 0.1 dengan membaginya setiap nilai piksel pada nilai 255 sehingga dapat membant u untuk normalisasi data. kesepuluh validation split mengatur pembagian data untuk validasi dengan nilai 0.2 atau 20 data dari keseluruhan data untuk alokasi validation data dan 80 un tuk alokasi training data. merupakan pendekatan augmentasi awal di mana sebelum data masuk ke model untuk proses pelatihan dan akan diperbesar sebelum pembagian dataset menjadi batch untuk setiap epoch nya sehingga model akan dilatih menggunakan dataset yang telah diaugmentsi sejak awal dan seluruh augmentasi akan diterapkan pada setiap epoch nya dengan penggunaan ukuran batch 64 dengan jumlah batch training 36 dan validasi 10. rinciannya data asli pada training data berjumlah 1.121 gambar dan setelah dilakukan augmentasi bertambah sebanyak 1.152 gambar sehingga data pada training data berjumlah total menjadi 2 .273 gambar. rincian data asli pada validation data berjumlah 2 79 gambar dan setelah dilakukan augmentasi bertambah sebanyak 320 gambar sehingga data pada validation data berjumlah total menjadi 59 9 gambar. testing data tidak mengalami augmentasi karena pada proses pengujian atau evaluasi mode l ingin menggunakan data asli yang sebenarnya untuk melihat kinerja model pada kasus kasus yang belum pernah dilihat sebelumnya. berikut merupakan gambar 3. 6 tahapan data augmentation . data augmentation flip rotation shear brightness gambar 3. 6 tahapan data augmentation 3.2.5 data splitting tahap ke lima data splitting dengan membagi file dataset menjadi subset training data validation data dan testing data berisikan gambar ban normal dan gambar ban tidak normal sehingga subset training data digunakan untuk melatih model sedangkan subset validation data digunakan untuk menguji kinerja model. sebenarnya langkah langkah dalam proses pra pemrosesan data yang mempersiapkan data mentah untuk digunakan dalam pelatihan model adalah tahapan yang sudah disebutkan sebelumnya data aquisition data prerocessing data augmentation dan splitting data. prosedur yang disebutkan di atas berkonsentrasi pada pengumpulan sanitasi pengorganisasian dan penambahan jumlah data yang diperlukan untuk pelatihan model. rinciannya yaitu file yang tersimpan di dalam komputer total data gambar sebanyak 2.050 gambar yang dibagi menjadi dua pertama adalah file testing data dengan jumlah data tersimpan sebanyak 650 gambar yang dibagi menjadi sub file crack berjumlah 420 dan sub file normal berjumlah 230 data. kedua adalah file training data dengan jumlah data tersimpan sebanyak 1400 gambar yang dibagi menjadi sub file crack berjumlah 654 dan sub file normal berjumlah 746 data. maka ketika dilakukan data splitting pada program secara otomatis yang pada data augmentasi diatur menjadi pembagian 80 untuk training data dan 20 untuk validation data yaitu untuk train data sebanyak 1.121 gambar dengan 2 kelas validation data sebanyak 279 gambar dengan 2 kelas dan test data sebanyak 650 gambar dengan 2 kelas. testing data bernilai tetap h al ini bertujuan agar kuantitas data awal yang telah ditentukan sebelumnya tetap terjaga dan testing data tidak terpengaruh oleh prosedur pemisahan. setelah model dilatih dan divalidasi testing data digunakan untuk mengevaluasi performa akhir model. akibatnya testing data tidak terbagi dan rincian asli 648 foto masih berlaku. berikut merupakan gambar 3.7 tahapan splitting data . data splitting training data validation data testing data gambar 3. 7 tahapan splitting data 3.2.6 model building tahap ke enam adalah model building membangun model convolutional neural network cnn dengan keras membangun arsitektur model convolutional neural network cnn menggunakan keras mengatur lapisan lapisan seperti convolutional maxpooling2d flatten dan dense untuk membangun model. learning rate dalam penggunaan algoritma optimasi menggunakan adaptive momentum adam untuk menghasilkan pembelajaran yang adaptif pemilihan penggunaan adaptive momentum adam jika dibandingkan dengan learning rate lain seperti stochastic gradient descent sgd karena kecepatan pembelajaran adaptif untuk adaptive momentum adam bisa secara otomatis menyesuaikan learning rate untuk setiap parameter dalam model klasifikasi ban sedangkan stochastic gradient descent sgd memiliki learning rate tetap selama pelatihan model klasifikasi ban yang penentuannya dari user dan tidak bisa menyesuaikan learning rate secara otomatis berdasarkan kondisi a ktual dari setiap parameter. selanjutnya secara kestabilan dan konvergensi adaptive momentum adam menyambung dari awal dapat mengubah kecepatan pembelajaran secara adaptif sehingga membuatnya lebih stabil dan kecil kemungkinannya terjebak pada tingkat minimum lokal nilai yang dianggap sebagai titik terendah dari loss function dalam model sehingga adaptive momentum adam cenderung mencapai konvergensi tingkat kinerja yang diharapkan lebih cepat dan andal dalam berbagai keadaan sedangkan stochastic gradient descent sgd mungkin lebih stuck pada nilai minimum atau terjebak pada nilai minimum lokal ya ng disebabkan oleh kemungkinan bergantung pada seberapa tepat kecepatan pemelajaran dipilih kecepatan pemelajaran yang tetap dapat membuat model mencapai konvergensi terlalu cepat atau terlalu lambat. adapun melakukan pendekatan kedua penam bahan data keti ka masuk ke model building dan terjadi proses pemodelan setelah menggunakan epoch . augment asi data diterapkan setelah data melewati beberapa epoch selama proses pelatihan sehingga variasi data yang dihasilkan akan berbeda beda pada setiap epoch dan model dapat terus menerus terlatih dengan variasi data yang lebih besar . menggunakan 100 epoch sehingga total training data yang diproses menjadi 230.400 gambar dan validation data menjadi 6.400 gambar. sehingga jumlah data yang diproses selama pelatihan menjadi sangat besar dan pada akhirnya nanti akan menyiapkan m odel kompilasi dalam mengatur pengoptimal adam fungsi kerugian biner crossentropy dan metrik evaluasi akurasi. berikut merupakan gambar 3. 8 tahapan building model . model building define cnn model compile model gambar 3 .8 tahapan building model berdasarkan hasil analisis sebelumnya maka dapat diketahui untuk j umlah data asli training data adalah 1.121 jumlah data asli validation data adalah 279 jumlah data asli training data setelah augmentasi adalah 1152 jumlah data asli validation data setelah augmentasi adalah 320 jumlah epoch yang digunakan sebanyak 100 dan ukuran batch adalah 64. berikut merupakan perhitungan manualnya ketika masuk ke model building dan terjadi proses pemodelan setelah menggunakan epoch . 1. jumlah batch per epoch untuk training data . 𝑆𝑡𝑒𝑝𝑝𝑒𝑟𝑒𝑝𝑜𝑐ℎjumlahdatatrainjumlahdataaugmentasi train 𝐵𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒 11211152 64 2273 64 35515636𝑏𝑎𝑡𝑐ℎ 2. jumlah batch per epoch untuk validation data. 𝑆𝑡𝑒𝑝𝑝𝑒𝑟𝑒𝑝𝑜𝑐ℎjumlahdatavalidjumlahdataaugmentasi valid 𝐵𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒 279320 64 599 64 9359310𝑏𝑎𝑡𝑐ℎ 3. total jumlah data setelah augmentasi untuk semua epoch . a. training data total𝑇𝑟𝑎𝑖𝑛𝑖𝑛𝑔 datajumlah𝐵𝑎𝑡𝑐ℎx𝐵𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒xjumlah𝐸𝑝𝑜𝑐ℎ𝑠 36x64x100 230.400 b. validation data total𝑉𝑎𝑙𝑖𝑑𝑎𝑡𝑖𝑜𝑛 datajumlah𝐵𝑎𝑡𝑐ℎx𝐵𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒xjumlah𝐸𝑝𝑜𝑐ℎ𝑠 10x64x100 64.000 3.2.7 model evaluation testing tahap kedelapan adalah model evaluation testing digunakan sebagai bahan terusan pada model building yang dibuat untuk melakukan evaluasi performanya dengan menggunakan bagian pengujian dan parameter yang digunakan pada metrik evaluasi seperti akurasi presisi recall dan f1score . berikut merupakan gambar 3. 9 tahapan model evaluation testing . model evaluation testing accuracy precision recall f1score gambar 3. 9 tahapan model evaluation testing 3.3 arsitektur convolutional neural network cnn convolutional neural network cnn yang dibangun menggunakan model atau kerangka kerja yang pada dasarnya menggunakan keras dan juga tensorflow dengan menambahkan beberapa model lapisan lapisan seperti lapisan convolutional conv2d laposan pooling maxpooling 2d flatten dan lapisan fully connected dense . berikut merupakan gambar 3. 10 tahapan convolutional neural network cnn dengan model keras. conv2d filter 128 ukuran filter 3 atau 3x3 strides 2 input size 189x189 jumlah neuron 1280maxpooling2d pool size 2 strides 2 input size 94x94 jumlah neuron 1280conv2d 2nd filter 64 ukuran filter 3 atau 3x3 strides 2 input size 46x46 jumlah neuron 73792maxpooling2d 2nd pool size 2 strides 2 input size 23x23 jumlah neuron 73792 conv2d 3nd filter 32 ukuran filter 3 atau 3x3 strides 2 input size 11x11 jumlah neuron 18464maxpooling2d 2nd pool size 2 strides 2 input size 5x5 jumlah neuron 18464conv2d 4nd filter 16 ukuran filter 3 atau 3x3 strides 2 input size 2x2 jumlah neuron 4624maxpooling2d 4nd pool size 2 strides 2 input size 1x1 jumlah neuron 4624 flatten input size 1x1x16 jumlah neuron 16dense layer 1 dengan aktivasi relu jumlah neuron 128 jumlah parameter 2176dropout layer 1 rate 0.2 20dense layer 2 dengan aktivasi relu jumlah neuron 64 jumlah parameter 8256 dropout layer 2 rate 0.2 20dense layer 3 dengan aktivasi sigmoid jumlah neuron 1 biner sigmoid jumlah parameter 65 training fit callbacks optimizer adam evaluation confusion matrix report epochs 100 gambar 3. 10 tahapan convolutional neural network cnn dengan model keras berdasarkan gambar 3. 10 tahapan convolutional neural network cnn dengan model keras maka dapat dijelaskan mulai dari yang mencakup lapisan lapisan konvolusi yang telah dilatih pada dataset besar seperti imagenet untuk mengekstrak fitur dari gambar gambar penggunaan image size diatur dengan 379 379 batch size 64 kernel size 3 strides 2 untuk cov2d dan 2 untuk maxpooling2d dan pool size 2. selanjutnya conv2d yang merupakan convolutional layer pertama yang berfungsi untuk mengekstrak fitur fitur visual dari gambar. filter convolutional layer pertama yang berfungsi untuk mengekstrak fitur fitur visual diterapkan pada gambar untuk menghasilkan fitur fitur yang lebih abstrak formula untuk mengetahui jumlah training datanya dengan . selanjutnya max pooling 2d di mana tahap pooling digunakan untuk mengurangi dimensi spasial dari setiap feature map yang dihasilkan oleh layer sebelumnya. max pooling memilih nilai maksimum di dalam jendela pooling untuk m engurangi ukuran fitur dan mempertahankan informasi penting. selanjutnya conv2d dan max pooling 2d diulang sampai 4 layer karena untuk terus mengekstrak fitur fitur yang semakin kompleks dari gambar. selanjutnya flatten digunakan untuk mengubah tensor multi dimensi menjadi tensor satu dimensi di mana setelah serangkaian layer konvolusi dan pooling masukan dari layer terakhir perlu diubah menjadi vektor tunggal sebelum dimasukkan ke dalam layer dense . flatten layer melakukan hal ini dengan mengubah matriks output menjadi array satu dimensi. selanjutnya dense layers lapisan dense digunakan sebagai lapisan output dalam model klasifikasi di mana jumlah neuron dalam lapisan output sesuai dengan jumlah kelas yang harus diprediksi di mana ada tiga lapisan dense ditambahkan dengan fungsi pertama dan kedua menggunakan relu sebagai 0 f x max x yang artinya menunjukkan bahwa keluarannya nol jika masukannya negatif atau nol dan output x jika masukannya positif dengan 128 unit neuron dan pada dense kedua 64 unit neuron karena tugasnya mengurangi dimensi representasi pada lapisan dense pertama maka model dapat mempelajari pola yang lebih rumit dan mendalam dari data dengan menambahkan lapisan yang lebih padat yang dapat meningkatkan performa model dalam tugas klasifikasi gambar. lapisan dense ketiga dengan fungsi aktivasi sigmoid untuk output biner dengan menunjukan kelas prediksi dari gambar yaitu normal atau crack . di antara tig a lapisan dense di ikuti dengan lapisan dropout untuk mencega h overfitting di mana model pembelajaran mesin terlalu menghafal pola dari training data yang tersedia sehingga kinerjanya menurun secara signifikan saat diuji dengan data baru yang tidak dilihat sebelumnya juga dimasukkan setelah setiap lapisan dense untuk mencegah overfitting dengan secara acak menonaktifkan seba gian unit sebanyak 0.2 atau 20 dari neuron selama pelatihan. selanjutnya training di mana model diterapkan pada training data dengan menggunakan metode fit dan callback . model fit digunakan untuk melatih model dengan training data dan model callback menggunakan modelcheckpoint untuk menyimpan model terba ik selama pelatihan berkaitan dengan performa pada validation data mengontrol proses pelatihan. terakhir evaluation di mana performa model pada testing data dinilai menggunakan hasil klasifikasi dan confusion matrix untuk memahami kinerjanya testing data. banyaknya parameter atau bobot dan jumlah data yang harus dipelajari selama pelatihan bergantung pada jumlah neuron pada lapisan. jumlah data yang harus dipelajari model selama pelatihan tercermin dalam jumlah parameter ini. berikut merupakan perhitungan dalam mengetahui total neuron yang dikerjakan oleh setiap lapisan. 1. first conv2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x11x128 10x128 1280 kedalaman gambar yang diproses lapisan konvolusi sebenarnya ditunjukkan oleh jumlah saluran masukan. tiga saluran merah hijau dan biru membentuk sebuah gambar jika diwarnai artinya ada tiga saluran masukan. karena kata grayscale digunakan untuk mendeskripsikan gambar ini hanya ada satu saluran warna dan bernilai 1 . sehingga jumlah neuronnya 1280 yang berarti ada 1280 parameter yang harus dipelajari selama pelatihan dan akan mencerminkan jumlah data yang harus dipelajari ketika pelatihan . selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 379x379 menjadi 189x189 sebagai berikut. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝐾𝑒𝑟𝑛𝑒𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 3793 11 376 21 189 2. first maxpooling2d tidak ada parameter baru yang ditambahkan dan jumlah neuron dalam contoh ini lapisan konvolusi pertama tetap sama. setiap filter diubah menjadi setengah dari ukuran inputnya 189x189 menjadi 94x94 dan jumlah neuronnya 1280 mengikuti lapisan konvolusi pertama . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 1892 21 187 21 94 3. second cov2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x1281x64 1153x128 73792 jumlah channel input menggunakan jumlah filter dari convolutional layer sebelumnya bukan lagi channel input di awal. sehingga jumlah neuronnya 73792 yang berarti ada 73792 parameter yang harus dipelajari selama pelatihan dan akan mencerminkan jumlah data yang harus dipelajari ketika pelatihan . selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 94x94 menjadi 46x46 sebagai berikut. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝐾𝑒𝑟𝑛𝑒𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 943 21 91 21 46 4. second maxpooling2d tidak ada parameter baru yang ditambahkan dan jumlah neuron dalam contoh ini lapisan konvolusi kedua tetap sama. setiap filter diubah menjadi setengah dari ukuran inputnya 46x46 menjadi 23x23 dan jumlah neuronnya 73792 mengikuti lapisan konvolusi kedua . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 462 21 44 21 23 5. third cov2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x641x32 577x32 18464 jumlah channel input menggunakan jumlah filter dari convolutional layer sebelumnya bukan lagi channel input di awal. sehingga jumlah neuronnya 18464 yang berarti ada 18464 parameter yang harus dipelajari selama pelatihan dan akan mencerminkan jumlah data yang harus dipelajari ketika pelatihan . selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 23x23 menjadi 11x11 sebagai berikut. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝐾𝑒𝑟𝑛𝑒𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 233 21 20 21 11 6. third maxpooling2d tidak ada parameter baru yang ditambahkan dan jumlah neuron dalam contoh ini lapisan konvolusi ketiga tetap sama. setiap filter diubah menjadi setengah dari ukuran inputnya 11x11 menjadi 5x5 dan jumlah neuronnya 18464 mengikuti lapisan konvolusi ketiga . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 112 21 9 21 5 7. fourth cov2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x321x16 289x16 4624 jumlah channel input menggunakan jumlah filter dari convolutional layer sebelumnya bukan lagi channel input di awal. sehingga jumlah neuronnya 4624 yang berarti ada 4624 parameter yang harus dipelajari selama pelatihan dan akan mencerminkan jumlah data yang harus dipelajari ketika pelatihan . selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 5x5 menjadi 2x2 sebagai berikut. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝐾𝑒𝑟𝑛𝑒𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 53 21 1 21 1.52 8. fourth maxpooling2d tidak ada parameter baru yang ditambahkan dan jumlah neuron dalam contoh ini lapisan konvolusi keempat tetap sama. setiap filter diubah menjadi setengah dari ukuran inputnya 2x2 menjadi 1x1 dan jumlah neuronnya 4624 mengikuti lapisan konvolusi keempat . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 12 21 1 21 0.51 9. flatten tidak mengubah parameter yang ada karena fungsi flatten hanya mengubah matriks multidimensi menjadi vektor tunggal berdasarkan hasil dari jumlah filter pada lapisan lima cov2d yaitu 8 dan maxpooling2d dengan ukuran inputnya 1x1 sehingga menjadi matriks multidimensi 1 1 16 diubah menjadi nilai vektor tunggal dengan panjang 16 atau menjadi jumlah neuron sebanyak 16. 10. dense layer 1 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 161x128 17x128 2176 11. dropout layer 1 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 1 akan dinonaktifkan secara acak. 12. dense layer 2 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 1281x64 129x64 8256 13. dropout layer 2 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 2 akan dinonaktifkan secara acak. 14. dense layer 2 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 641x1 65x1 65 ketika dimensi spasial tinggi dan lebar dikurangi menggunakan operasi lapisan pooling seperti maxpooling jumlah neuron di setiap lapisan pooling akan menurun. misalnya dimensi spasial setiap filter tinggi dan lebar di lapisan maxpooling disesuaikan menjadi setengah dari dimensi masukannya. karena hanya separuh dari masukan yang diproses lebih lanjut hal ini juga menyebabkan berkurangnya jumlah neuron pada lapisan tersebut. sedangkan penurunan pada dense terjadi karena penentuan jumlah neuron.,3.1 gambaran umum penelitian penelitian ini digunakan untuk mengatasi sensitivitas terhadap cacat pada gambar ban dengan melibatkan penggunaan jaringan syaraf menggunakan algoritma convolutional neural network cnn dan membangun model atau kerangka kerja menggunakan keras. berikut adalah gambar 3.1 blok diagram gambaran umum penelitian. data preparation data augmentasi data splitting model training forward pass model evaluation backward passfinetuning if neededinput unit processing unit output unit model deployment inference12 gambar 3.1 blok diagram gambaran umum penelitian berdasarkan gambar 3.1 blok diagram gambaran umum penelitian maka dapat dijelaskan di blok tersebut terbagi menjadi 3 bagian yaitu bagian pertama adalah unit masukan berisikan data preparation di mana gambar ban dimuat diubah menjadi format yang sesuai dipersiapkan untuk pelatihan model convolutional neural network cnn seperti pemrosesan gambar ban selanjutnya data augmentation di mana data dibuat lebih ber variasi dari training data yang ada sehingga dapat meningkatkan keberagaman training data tanpa h arus mengambil data baru mencakup rotasi pergeseran horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel selanjutnya data di mana dataset yang telah di augmentasi dan disiapkan dibagi menjadi subset yang berbeda untuk training untuk melatih model validation untuk menyempurnakan model serta me mvalidasi performanya selama pelatihan dan testing untuk mengevaluasi kinerja model akhir . data set dibagi menjadi training data validation data dan testing data dalam proporsi tertentu. bagian kedua adalah unit pemrosesan yang bertindak adalah model training forward pass tahap di mana input diproses melalui model untuk menghasilkan prediksi tujuannya melatih model convolutional neural network cnn menggunakan dataset pelatihan di mana data dari unit masukan diteruskan melalui jaringan neural di lakukan transformasi linier konvulasi dan non linier fungsi aktivasi dilakukan pada data di setiap lapisan untuk menghasilkan output prediksi yang melibatkan komputasi di setiap neuron dan lapisan jaringan yang merupakan inti dari proses pembelajaran dalam jaringan saraf. selanjutnya unit pemrosesan finetuning tujuannya dilakukan untuk menyempurnakan model lebih lanjut setelah pelatihan awal dengan dataset yang lebih kecil atau lebih spesifik nantinya. proses di dalam finetuning menyesuaikan bobot menggunakan kumpulan data yang lebih kecil untuk menyesuaikan bobot model untuk performa yang lebih baik pelatihan khusus fokus pada fitur data yang lebih relevan dengan objek . bagian ketiga adalah unit keluaran yang bertindak ada proses model evaluatioan backward pass tahap di mana gradien memperbarui parameter model dalam arah yang akan mengurangi fungsi loss dari fungsi loss metrik yang mengukur seberapa baik atau buruk model melakukan prediksi dibandingkan nilai aktualnya dihitung dan digunakan untuk memperbarui parameter model selama pelatihan tujuannya mengevaluasi performa model yang dilatih dan model dievaluasi menggunakan metrik yang relevan accuracy precision recall dan f1 score berdasarkan prediksi yang dihasilkan dari model terhadap validasi atau uji data. output dari proses ini adalah tentang hasil evaluasi model yang memberikan informasi kinerja model. selanjutnya ada dua alur pilihan yang bisa dilakukan alur pertama jika hasil prediksi sudah sesuai dengan keinginan maka bisa langsung masuk ke model deployment inference dan alu r kedua jika hasil prediksi masih perlu diperbaiki pada bagian unit pemrosesan terlebih dahulu fine tuning untuk penggunaan data set lebih kecil jika menunjukan model belum mencapai performa yang diharapkan baru masuk ke model deployment inference tujuannya menerapkan model terlatih untuk membuat prediksi pada data baru yang belum terlihat. model deployment inference yang telah dilatih digunakan untuk membuat prediksi pada data baru atau dalam situasi dunia nyata tahap di mana model menerima input baru dan menghasilkan output berdasarkan pada pembelajaran yang dilakukan selama proses pelatihan dan merupakan output akhir dari keseluruhan proses di mana model mengambil keputusan atau membuat prediksi berdasarkan pada pengalaman yang telah diperoleh selama pelatihan. 3.2. tahapan penelitian penelitian ini di dalamnya terdapat tahapan tahapan yang dilakukan untuk membentuk satu kesatuan yang utuh dari awal sampai akhir dan membentuk kerangka penelitian mengenai klasifikasi pada produk ban menggunakan algoritma convolutional neural network cnn . 3.2.1 studi literatur tahap pertama adalah studi literatur di mana studi yang dilakukan berasal dari artikel ilmiah dan buku yang menunjang dalam menganalisis terkait dengan metode pen gukuran kualitas mengenai klasifikasi produk ban meninjau penggunaan pembelajaran mesin algoritma convolutional neural network cnn dari beberapa tahun ke belakang dalam konteks peng ukuran kualitas untuk klasifikasi terhadap kondisi kondisi produk ban . 3 tahapan study literature 3.2.2 data aquisition tahap k edua adalah data aquisition dengan mengumpulkan kumpulan data sesuai tujuan penelitian dengan target untuk kumpulan data gambar ban untuk training data validation data dan testing data memastikan bahwa kumpulan data tersebut memiliki varian yang secara akurat memang mewakili kondisi produk ban dan diperoleh dari sumber sumber terpercaya . 5 tahapan data preprocessing 3.2.4 data augmentation tahap keempat adalah data augmentation meningkatkan variasi dalam dataset dengan teknik augmentasi data menggunakan operasi seperti rotasi pergeserarn horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel untuk memperkaya dataset dan mengurangi overfitting saat disajikan dengan data baru yang belum pernah dilihat sebelumnya performa model akan menurun drastis karena model tersebut dapat menyesuaikan diri dengan kumpulan training data dengan sangat efektif. sebaliknya pada saat runtime hanya menghasilkan variasi dari gambar yang sudah ada dibuat secara dinami s dan cukup bagi model untuk berlatih dari berbagai kondisi gambar ban yang ada pada kenyataaanya. data asli pada dataset berjumlah 1 .028 data gambar ban setelah dilakukan augmentasi secara fisik menggunakan website roboflow ada data yang tidak dapat diidentifikasi ada 3 gambar sehingga total gambar asli yang berhasil di upload dan dijadikan data asli yang tetap berjumlah 1.025 data ga mbar dan setelah di augmentasi bertambah menjadi 2 .050 data gambar ban. 7 tahapan splitting data 3.2.6 model building tahap ke enam adalah model building membangun model convolutional neural network cnn dengan keras membangun arsitektur model convolutional neural network cnn menggunakan keras mengatur lapisan lapisan seperti convolutional maxpooling2d flatten dan dense untuk membangun model. learning rate dalam penggunaan algoritma optimasi menggunakan adaptive momentum adam untuk menghasilkan pembelajaran yang adaptif pemilihan penggunaan adaptive momentum adam jika dibandingkan dengan learning rate lain seperti stochastic gradient descent sgd karena kecepatan pembelajaran adaptif untuk adaptive momentum adam bisa secara otomatis menyesuaikan learning rate untuk setiap parameter dalam model klasifikasi ban sedangkan stochastic gradient descent sgd memiliki learning rate tetap selama pelatihan model klasifikasi ban yang penentuannya dari user dan tidak bisa menyesuaikan learning rate secara otomatis berdasarkan kondisi a ktual dari setiap parameter. selanjutnya secara kestabilan dan konvergensi adaptive momentum adam menyambung dari awal dapat mengubah kecepatan pembelajaran secara adaptif sehingga membuatnya lebih stabil dan kecil kemungkinannya terjebak pada tingkat minimum lokal nilai yang dianggap sebagai titik terendah dari loss function dalam model sehingga adaptive momentum adam cenderung mencapai konvergensi tingkat kinerja yang diharapkan lebih cepat dan andal dalam berbagai keadaan sedangkan stochastic gradient descent sgd mungkin lebih stuck pada nilai minimum atau terjebak pada nilai minimum lokal ya ng disebabkan oleh kemungkinan bergantung pada seberapa tepat kecepatan pemelajaran dipilih kecepatan pemelajaran yang tetap dapat membuat model mencapai konvergensi terlalu cepat atau terlalu lambat. augment asi data diterapkan setelah data melewati beberapa epoch selama proses pelatihan sehingga variasi data yang dihasilkan akan berbeda beda pada setiap epoch dan model dapat terus menerus terlatih dengan variasi data yang lebih besar . model building define cnn model compile model gambar 3 .8 tahapan building model berdasarkan hasil analisis sebelumnya maka dapat diketahui untuk j umlah data asli training data adalah 1.121 jumlah data asli validation data adalah 279 jumlah data asli training data setelah augmentasi adalah 1152 jumlah data asli validation data setelah augmentasi adalah 320 jumlah epoch yang digunakan sebanyak 100 dan ukuran batch adalah 64. 9 tahapan model evaluation testing 3.3 arsitektur convolutional neural network cnn convolutional neural network cnn yang dibangun menggunakan model atau kerangka kerja yang pada dasarnya menggunakan keras dan juga tensorflow dengan menambahkan beberapa model lapisan lapisan seperti lapisan convolutional conv2d laposan pooling maxpooling 2d flatten dan lapisan fully connected dense . filter convolutional layer pertama yang berfungsi untuk mengekstrak fitur fitur visual diterapkan pada gambar untuk menghasilkan fitur fitur yang lebih abstrak formula untuk mengetahui jumlah training datanya dengan . selanjutnya max pooling 2d di mana tahap pooling digunakan untuk mengurangi dimensi spasial dari setiap feature map yang dihasilkan oleh layer sebelumnya. max pooling memilih nilai maksimum di dalam jendela pooling untuk m engurangi ukuran fitur dan mempertahankan informasi penting. selanjutnya dense layers lapisan dense digunakan sebagai lapisan output dalam model klasifikasi di mana jumlah neuron dalam lapisan output sesuai dengan jumlah kelas yang harus diprediksi di mana ada tiga lapisan dense ditambahkan dengan fungsi pertama dan kedua menggunakan relu sebagai 0 f x max x yang artinya menunjukkan bahwa keluarannya nol jika masukannya negatif atau nol dan output x jika masukannya positif dengan 128 unit neuron dan pada dense kedua 64 unit neuron karena tugasnya mengurangi dimensi representasi pada lapisan dense pertama maka model dapat mempelajari pola yang lebih rumit dan mendalam dari data dengan menambahkan lapisan yang lebih padat yang dapat meningkatkan performa model dalam tugas klasifikasi gambar. terakhir evaluation di mana performa model pada testing data dinilai menggunakan hasil klasifikasi dan confusion matrix untuk memahami kinerjanya testing data. bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. fourth cov2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x321x16 289x16 4624 jumlah channel input menggunakan jumlah filter dari convolutional layer sebelumnya bukan lagi channel input di awal. selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 5x5 menjadi 2x2 sebagai berikut. setiap filter diubah menjadi setengah dari ukuran inputnya 2x2 menjadi 1x1 dan jumlah neuronnya 4624 mengikuti lapisan konvolusi keempat . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 12 21 1 21 0.51 9. flatten tidak mengubah parameter yang ada karena fungsi flatten hanya mengubah matriks multidimensi menjadi vektor tunggal berdasarkan hasil dari jumlah filter pada lapisan lima cov2d yaitu 8 dan maxpooling2d dengan ukuran inputnya 1x1 sehingga menjadi matriks multidimensi 1 1 16 diubah menjadi nilai vektor tunggal dengan panjang 16 atau menjadi jumlah neuron sebanyak 16. 10. dense layer 1 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 161x128 17x128 2176 11. dropout layer 1 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 1 akan dinonaktifkan secara acak. 12. dense layer 2 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 1281x64 129x64 8256 13. dropout layer 2 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 2 akan dinonaktifkan secara acak. 14. dense layer 2 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 641x1 65x1 65 ketika dimensi spasial tinggi dan lebar dikurangi menggunakan operasi lapisan pooling seperti maxpooling jumlah neuron di setiap lapisan pooling akan menurun. misalnya dimensi spasial setiap filter tinggi dan lebar di lapisan maxpooling disesuaikan menjadi setengah dari dimensi masukannya. karena hanya separuh dari masukan yang diproses lebih lanjut hal ini juga menyebabkan berkurangnya jumlah neuron pada lapisan tersebut. sedangkan penurunan pada dense terjadi karena penentuan jumlah neuron.
Robert_Kualifikasi.txt,3.1 alur penelitian gambar 3.1 menunjuk kan metode penelitian. terdapat 5 tahap utama yang akan dilakukan yang pertama adalah studi literatur untuk menyusun bab 1 dan bab 2. tahap kedua adalah pengumpulan citra ekspresi wajah data citra berupa data primer dan data sekunder. tahap ketiga adalah pembentukan dataset untuk tiap model svm cnn dan mnn skenario pembentukan dataset dilakukan berdasarkan pada penelitian robert 2023 . pada tahap keempat dilakukan pembentukan model khusus untuk svm dan cnn menggunakan model pada penelitian robert 2023 sedangkan mnn menggunakan usulan pada penelitian ini. tahap terakhir adalah pelatihan dan pengujian untuk semua model svm cnn mnn terdapat tahap parameter tuning untuk tiap model . kemudian semua performa dari tiap model akan dibandingkan satu sama lain dan juga dianalis is pada bab 4. gambar 3.1. metode penelitian 48 3.2 pengumpulan citra ekspresi wajah citra ekspresi wajah dikumpulkan secara langsung oleh peneliti data primer dan juga menggunakan data yang dikumpulkan oleh peneliti lain data sekunder. terdapat 7 ekspresi wajah yang akan digunakan dalam penelitian ini yaitu marah jijik menghina senang sedih kaget dan netral tanpa ekspresi. gambar 3.2 menunjukkan contoh 7 ekspresi wajah manusia yang digunakan penelitian ini. gambar 3.2. contoh 7 jenis ekspresi wajah dataset primer akan dilakukan pengambilan citra ekspresi wajah mahasiswa universitas gunadarma baik pria maupun wanita. pengambilan akan dilakukan dari beberapa sudut pandang guna menambah variasi dataset . gambar 3.3 menunjukan contoh dataset primer dari berbagai sudut pandang. gambar 3.3. contoh dataset primer 49 dataset sekunder digunakan dataset yang telah digunakan umum oleh peneliti lain terkait pengenalan ekspresi wajah. terdapat beberapa dataset yang umum digunakan dalam penelitian ekspresi wajah . pertama extended cohn kanade ck yang berisi citra ekspresi wajah pria dan wanita dari berbagai etnis dengan resolusi tinggi kanade cohn tian 2000 lucey et al. 2010 . kedua taiwanese facial expression image dataset tfeid yang berisi citra ekspresi wajah pria dan wanita dari etnis taiwan chen yen 2007 . ketiga japanese female facial expression jaffe yang terdiri dari citra ekspresi wajah wanita etnis j epang lyons 2021 lyons kamachi gyoba 2020 . gambar 3.4 menunjukan contoh citra dataset ck a jaffe b dan tfeid c. gambar 3.4. contoh dataset sekunder 50 tabel 3.1 menunjukkan detail dari tiap dataset mulai dari jumlah citra dari tiap kelas serta ruang warna dan ukuran citra. ck memiliki jumlah yang tidak seimbang pada kelas neutral dan memiliki ruang warna campur antara rgb dan gray dengan ukuran citra dikisaran 640 490. jaffe dataset memiliki jumlah citra pada tiap kelas yang seimbang dengan perbedaan diantara 0 hingga 2 citra ukuran citra 256 256 dan ruang warna grayscale . tfeid juga memiliki jumlah citra yang seimbang ditiap kelas ukuran citra diki saran 481 600 ruang warna rgb. tabel 3.1. detail dataset sekunder ekspresi dataset ck dataset jaffe dataset tfeid total anger 45 30 34 109 disgust 59 29 40 128 fear 25 32 40 97 happy 69 31 40 140 neutral 107 30 39 176 sad 28 31 39 98 surprise 83 30 36 149 ukuran citra 640490 256256 481600 warna citra rgb gray gray rgb 51 3.3 pembentukan dataset secara garis besar dalam pembuatan model ai khususnya ml dan dl terdapat proses yang berperan penting yaitu preprocessing dataset seperti ekstrasi fitur penyesuaian ukuran citra dan augmentasi deshmukh et al. 2016 franchi et al. 2020 mohammad ali 2011 ravi et al. 2020 sawardekar naik 2018 shan et al. 2009 . pada penelitian robert 2023 dilakukan sebuah skenario pembentukan dataset menggunakan beberapa metode pengolahan citra seperti konversi warna ke grayscale deteksi wajah dan e kstrasi fitur di mana preprocessing mempengaruhi performa dari model ml dan dl. selain itu pada penelitian alam yao 2019 juga dilakukan penelitian yang serupa di mana preprocessing mempengaruhi performa model machine learning . pada tahap ketiga dilakukan pembentukan dataset . gambar 3.5 menunjukkan alur pembentukan dataset untuk svm . pertama dilakukan pendeteksian wajah menggunakan vja proses ini berguna untuk mengurangi noise pada citra . hasil vja membuat ukuran citra bervariasi oleh karena itu dilakukan resizing citra untuk menyamakan semua ukuran citra dan juga menyesuaikan dengan dimensi input model . selanjutnya dilakukan konversi warna citra dari rgb ke grayscale dikarena fitur warna tidak dibutuhkan dan agar dapat diekstrasi fiturnya menggunakan lmp. terakhir terdapat dua proses ekstrasi fitur berbeda . proses ekstrasi fitur pertama menggunakan lmp robert 2023 . proses ekstrasi fitur kedua adalah usulan dari penelitian ini di mana pertama diaplikasikan gabor filter terlebih dahulu kemudian diekstrasi menggunakan lmp. gambar 3.5. pembentukan dataset untuk svm 52 gambar 3.6 menunjukkan alur pembentukan dataset untuk cnn dan mnn . terdapat 3 proses yang akan dilakukan . pertama dilakukan deteksi wajah menggunakan vja guna mengurangi noise . kemudian dilakukan konversi warna dari rgb ke grayscale karena fitur warna tidak dibutuhkan untuk mengenali ekspresi wajah. t erakhir mengubah ukuran citra untuk menyamakan semua ukuran citra dan sesuai dengan dimensi input model . skema pembentukan dataset ini berdasarkan performa terbaik dari penelitian robert 2023 . gambar 3.6. pembentukan dataset untuk cnn dan mnn dataset yang sudah melalui pembentukan dataset dilakukan augmentasi dari sisi geometris seperti membalikan flipping secara horizontal dan verti kal dan rotasi dari 0 hingga 45 . tujuan dari augmentasi dataset adalah memperbanyak dataset dan juga variasi dataset . dataset yang telah dibentuk kemudian dibagi menjadi dua jenis dataset . jenis pertama adalah training dataset dengan jumlah 90 dari total semua dataset . kedua adalah testing dataset yang terdiri dari 10 dari total semua dataset . gambar 3.7 menunjukkan visualisasi pembagian dataset . svm training dataset digunakan untuk melatih model sedangkan testing dataset digunakan untuk menguji dataset . cnn dan mnn terdapat pembagian lagi pada training di mana 90 dari training dataset digunakan untuk melatih model dan 10 dari training dataset digunakan untuk validasi dan testing dataset digunakan untuk menguji model. proses pembentukan dataset untuk svm cnn dan mnn menggunakan algoritma 3.1 hingga algoritma 3.6. 53 gambar 3.7. visualisasi pembagian dataset 3.3.1 deteksi wajah proses deteksi wajah menggunakan vja vja memanfaatkan dua komponen yaitu integral image dan haar basis function . algoritma 3.1 menunjukkan cara menghitung dari integral image . input merupakan citra dengan ruang warna grayscale dengan nama variab el img dengan ukruan 𝑤ℎ dan output berupa integral image yang disimpan pada nama variab el itg_img. algoritma integral image cukup sederhana baris 1 dan 2 dilakukan perulangan terhadap baris dan kolom citra yang digunakan untuk menentukan koordinat integral image yang sedang dihitung. b aris ketiga dilakukan perhitungan integral image untuk koordinat 𝑖𝑗 yang menghitung total nilai piksel citra asli mulai dari koordinat 00 hingga 𝑖𝑗 menggunakan persamaan 2.18. 54 algoritma 3.1. integral image 1 2 3 4 5 input citra grayscale wh img output citra integral wh itg_img for i 0 to w do for j 0 to h do itg_imgij sumimg_gry0i0j end for end for algoritma 3.2 menunjukkan cara kerja dari vja. input dari algoritma 3.2 adalah citra integral dengan ukuran 𝑤ℎ yang diproses menggunakan algoritma 3.1. terdapat beberapa parameter yang digunakan pada algoritma 3.2. parameter pertama adalah detection window dengan ukuran 𝑤2 ℎ2 yang digunakan untuk perhitungan haar . parameter kedua adalah haar yang menggunakan gambar 2.14. parameter ketiga adalah nilai threshold untuk masing masing haar yang digunakan untuk menentukan apakah haar tersebut merupakan fitur wajah atau bukan. output dari algoritma ini adalah berupa koordinat wajah yang dimulai pada koordinat 𝑥1𝑦1 dengan panjang dan lebar yaitu 𝑤2ℎ2. baris pertama dan kedua dilakukan perulangan terhadap baris dan kolom citra yang digunakan untuk menentukan koordinat detction window agar lebih mudah memahami dapat melihat gambar 3.8. setiap perulang an pada baris pertama dan kedua dilakukan komputasi tiap area haar mulai dari jenis haar a hingga d. pada baris 491317 terdapat tiga perhitungan. perhitungan pertama adalah area putih perhitungan kedua adalah area hitam perhitungan ketiga adalah fitur area putih area hitam untuk lebih mudah memahami perhitungan area putih area hitam dan fitur dapat melihat gambar 3.9. setiap perhitungan nilai fitur a hingga fitur d dilakukan pengecekan apakah nilai fitur yang dihitung merupakan fitur atau bukan dengan cara membandingkan nilai fitur dengan threshold masing masing th_a hingga th_d seperti baris 6101418. jika salah satu dari keempat nilai fitur lebih kecil dari threshold yang ditentukan maka haar tersebut bukan merupakan fitur wajah dan algoritma akan melakukan pergeseran detection window ke koordinat selanjutnya. selain itu jika semua nilai fitur lebih besar dari threshold maka detection window tersebut merupakan wajah dan algoritma akan memberikan 55 empat nilai yaitu 𝑖𝑗𝑑𝑤𝑑ℎ. 𝑖𝑗 merupakan koordinat dari deteksi terakhir. 𝑑𝑤𝑑ℎ merupakan luas dari detection window itu sendiri. algoritma 3.2. algoritma viola jones 1 2 3 4 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 input citra integral wh itg_gry parameter detection window dengan ukuran w2h2 dw haar pada gambar 2.14 a hingga d thershold tha hingga the output koordinat wajah x1y1w2h2 for i 0 to ww2 do for j 0 to hh2 do hitung fitur haar a pada gambar 2.14 hitung fitur_a area putih gambar 2.14 a area hitam gambar 2.14 a untuk detection window iiw2jjh2 if fitur_a th_a do continue hitung fitur haar b pada gambar 2.14 hitung fitur_b area putih gambar 2.14 b area hitam gambar 2.14 b untuk detection window iiw2jjh2 if fitur_b th_b do continue hitung fitur haar c pada gambar 2.14 hitung fitur_c area putih gambar 2.14 c area hitam gambar 2.14 c untuk detection window iiw2jjh2 if fitur_c th_c do continue hitung fitur haar d pada gambar 2.14 hitung fitur_d area putih gambar 2.14 d area hitam gambar 2.14 d untuk detection window iiw2jjh2 if fitur_d th_d do continue return ijdwdh 56 gambar 3.8. pergeseran detection window gambar 3.9. contoh perhitungan haar gambar 3.9 menunjukkan contoh perhitungan untuk fitur a dan b pada algoritma 3.2 baris 4 dan 9. pertama dilakukan perhitungan pada area hitam dan putih . untuk mendapatkan hanya luas 𝐷 dilakukan pengurangan dengan luas 𝐵 dan 𝐶 kemudian dilakukan pertambahan luas 𝐴. perhitungan dilakukan secara demikian dikarenakan pada integral image luas 𝐷𝐴𝐵𝐶𝐷 luas 𝐵𝐴𝐵 dan luas 𝐶𝐴𝐶. secara teknis pengurangan dengan luas 𝐴 dilakukan dua kali 57 dikarenakan luas 𝐵 dan 𝐶 oleh karena itu dilakukan pertambahan luas 𝐴 setelah pengurangan dengan 𝐵 dan 𝐶. perhitungan luas 𝐻 memiliki pola yang sama dengan perhitungan luas 𝐷. kemudian dilakukan pengurangan antara area putih dengan hitam untuk mendapatkan nilai fitur. fitur kemudian dibandingkan dengan nilai thershold untuk menentukan apakah haar tersebut fitur wajah atau bukan. pola untuk perhitungan area putih area hitam dan fitur untuk haar a b c d memiliki pola yang sama. gambar 3.10 menunjukkan hasil dari implementasi algoritma deteksi wajah pada sebuah citra. a b c gambar 3.10. a citra original b hasil deteksi c hasil cropping 58 3.3.2 image resize proses perubahan ukuran citra menggunakan metode bicubic interpolation . algoritma 3.3 menunjukkan cara kerja dari bicubic interpolation . input berupa citra yang ingin diubah ukurannya dan ra sio skala ukuran yang diinginkan. parameter berupa koefisien a yang dapat mempengaruhi koordinat tetangga umumnya nilai dikisaran 0.75 hingga 0.5. hasil dari algoritma ini adalah citra dengan ukuran 𝐻𝑟𝑊𝑟𝐶. pada baris 1 dilakukan perhitungan 𝑑𝐻 𝑑𝑊 yang digunakan untuk menentukan ukuran citra setelah diubah ukurannya dan kemudian dilakukan perhitungan ℎ yang digunakan untuk konstanta yang akan mempengaruhi koordinat tetangga pada piksel yang akan dihitung . baris 2 dilakukan pembuatan matri ks yang digunakan untuk menyimpan hasil. baris 456 dilakukan perulangan pada channel 𝑑𝐻 𝑑𝑊 matri ks yang dibuat pada baris 2 perulangan ini digunakan untuk menentukan koordinat matri ks hasil yang akan dihitung. baris 6 dan 7 dilakukan perhitungan 𝑥 dan 𝑦 yang merupakan konstanta yang mempengaruhi koordinat tetangga nilai berubah setiap perulangan berjalan pada baris 3 4 5. baris 8 hingga 15 dilakukan perhitungan 𝑥1 hingga 𝑥4 dan 𝑦1 hingga 𝑦4 variab el tersebut digunakan untuk menentukan bobot weight tiap tetangga dan koordinat tetangga pada piksel yang sedang dihitung. b aris 16 dan 17 dilakukan perhitungan menggunakan persamaan 2.19 di mana baris 16 perhitungan untuk bobot horizontal baris 17 untuk bobot vertikal yang masing masing disimpan pada matrix_l dan matrix_r. baris 19 dilakukan pembuatan matri ks berukuran 4 4 yang digunakan untuk menyimpan nilai piksel tetangga. baris 20 hingga 35 merupakan pengambilan nilai tetangga berdasarkan dari perhitungan sebelumnya. baris 36 merupakan perkalian antara matriks tetangga 4 4 dengan bobot horizontal kemudian dikalikan dengan bobot verti kal. hasil yang didapatkan kemudian disimpan pada variab el output . 59 algoritma 3.3. image resize menggunakan bicubic interpolation input citra ukuran 𝐻𝑊𝐶 img ratio antara 0 hingga r parameter koefisien a 0.5 a output citra ukuran 𝐻𝑟𝑊𝑟𝐶 output 1 calculate dh hr dw wr h 1ratio used for calculation 2 create matrix output dimension dhdwc to store result 3 for i 0 to c do 4 for j 0 to dh do 5 for k 0 to dw do 6 calculate x i h 2 7 calculate y j h 2 8 calculate x1 1 x floorx 9 calculate x2 x flootx 10 calculate x3 floorx 1 x 11 calculate x4 flootx 2 x 12 calculate y1 1 y floory 13 calculate y2 y flooty 14 calculate y3 floory 1 y 15 calculate y4 flooty 2 y 16 create matrix mat_l dimension 14 mat_r dimension 41 h menggunakan pers 2.19 17 calculate mat_l00 hx1 mat_l01 hx2 mat_l02 hx3 mat_l03 hx4 bobot horizontal 18 calculate mat_r00 hy1 mat_l01 hy2 mat_l02 hy3 mat_l03 hy4 bobot vertical 19 create matrix mat_m dimension 44 20 mat_l00 img yy1 xx1 21 mat_l10 img yy2xx1 22 mat_l20 img yy3xx1 23 mat_l30 img yy4xx1 24 mat_l01 img yy1 xx2 25 mat_l11 img yy2xx2 26 mat_l21 img yy3xx2 27 mat_l31 img yy4xx2 28 mat_l02 img yy1 xx3 29 mat_l12 img yy2xx3 30 mat_l22 img yy3xx3 31 mat_l32 img yy4xx3 32 mat_l03 img yy1 xx4 33 mat_l13 img yy2xx4 34 mat_l23 img yy3xx4 35 mat_l33 img yy4xx4 60 36 calculate output mat_m mat_l mat_r gambar 3.11 menunjukkan hasil perubahan ukuran citra wajah menggunakan algoritma 3.3. berdasarkan gambar 3.11 ukuran dari input citra adalah 600 480 dan ratio 05. ukuran menjadi 300 240 setelah melalui proses algoritma perubahan ukuran citra . a b gambar 3.11 a citra original b citra setelah diubah ukurannya 61 3.3.3 color conversion proses konversi warna dari rgb ke grayscale menggunakan persamaan 2.2. algoritma 3.4 menujukan proses konversi ruang warna citra dari rgb ke grayscale dengan cara mengambil nilai y dari yc bcr. input dari algoritma ini adalah citra rgb yang memiliki dimensi 𝑊𝐻𝐶 yang diberi nama variabel img_rgb. output dari algoritma ini adalah citra grayscale yang disimpan pada variable img_gry. baris 1 dan 2 dilakukan perulangan baris dan kolom citra yang digunakan untuk menentukan koordinat citra grayscale yang akan dihitung. baris 3 dilakukan konversi citra grayscale menggunakan persamaan 2.2 di mana dilakukan penjumlahan nilai dari ketiga channel citra rgb. tiap channel memiliki bobot masing masing untuk channel r memiliki bobot 0.299 channel g memiliki bobot 0.587 dan channel b memiliki bobot 0.114. gambar 3.12 menunjukkan contoh hasil implementasi algoritma konversi warna dari rgb ke grayscale dengan menggunakan nilai y dari yc bcr. algoritma 3.4. rgb to grays cale 1 2 3 4 5 input citra rgb whc img_rgb output citra grayscale wh img_gry for i 0 to w do for j 0 to h do img_gryij 0.299img_rgbij0 0.587img_rgbij1 0.114img_rgbij2 end for end for a b gambar 3.12. sebelum a dan sesudah b konversi warna 62 3.3.4 gabor filter pada proses svm terdapat proses gabor filter sebelum diekstra ksi menggunakan lmp. pertama dilakukan pembuatan filter terlebih dahulu. algoritma 3.5 menunjukkan cara pembuatan gabor filter. input dari algoritma ini adalah sebuah citra grayscale yang memiliki ukuran 𝐻𝑊. kemudian jumlah filter luas kernel lambda 𝜆 psi 𝜑 sigma 𝜎 dan gamma 𝛾 yang akan digunakan untuk pembuatan gabor filter . terakhir adalah threshold bawah dan threshold atas yang digunakan untuk deteksi tepi. pada baris 1 dilakukan perulangan untuk menentukan rotasi nilai theta gabor filter berdasarkan jumlah filter yang digunakan. baris 2 dilakukan pembuatan gabor filter berdasarkan persamaan 2.23 dan parameter yang di input . gambar 3.13 menunjukkan contoh gabor filter dengan total 16 filter. pada baris 4 dilakukan perulangan terhadap filter filter di mana filter filter tersebut digunakan untuk konvolusi citra pada baris 5. pada baris 7 dilakukan deteksi tepi menggunakan canny edge detection dengan param eter lower threshold dan upper threshold . algoritma 3.5. gabor filter input citra grayscale ukuran 𝐻𝑊 img jumlah filter dari 1 hingga num_filter kernel size n n ksize lambda 𝜆 lambd psi 𝜑 psi sigma 𝜎 sigma gamma 𝛾 gamma threshold bawah min_int threshold atas max_int output citra ukuran 𝐻𝑊 output 1 for i 0 to 180 with increment 180num_filter do 2 create gabor filter filter with kernel size ksize lambda lambd theta i psi psi sigma sigma gamma gamma 3 proses konvolusi 4 for i 0 to num_filter do 5 output img filteri 6 proses deteksi tepi 7 apply canny edge detection on output with lower threshold min_int upper threshold max_int 63 perubahan nilai parameter dilakukan pada 𝜆 𝛾 dan 𝜎 pada gambar 3.14 menunjukkan hasil dari pengaplikasian gabor filter di mana a menunjukkan hasil awal sebelum dilakukan parameter tuning dan b hasil akhir setelah parameter tuning . berdasarkan gambar 3.13 sebelum dilakukan perubahan nilai parameter citra memiliki banyak noise setelah dilakukan perubahan nilai parameter fitur wajah seperti alis mata hidung dan mulut terlihat. 77 𝜆10𝜃11.25𝜓0𝜎4𝛾 2 a 1111 𝜆19𝜃11.25𝜓0𝜎3𝛾 0.5 b gambar 3.13. gabor filter a sebelum dan b sesudah tuning parameter a b gambar 3.14. hasil algoritma gabor filter 64 3.3.5 ekstrasi fitur lmp proses ekstrasi fitur menggunakan metode lmp. algoritma 3.6 menunjukkan proses dari ekstrasi fitur lmp. input dari algoritma lmp adalah citra grayscale dengan ukuran 𝑤ℎ. parameter yang digunakan adalah pattern yang memiliki dimensi 82 yang digunakan untuk menentukan arah perhitungan tetangga. hasil dari algoritma 3.6 adalah citra lmp dengan ukuran 𝑤4ℎ 4 ukuran citra berkurang untuk menghindari perhitungan di luar dari ukuran citra. baris 2 dan 3 dilakukan perulangan baris dan kolom citra yang digunakan untuk menentukan koordinat citra lmp yang akan dihitung. baris 4 menyimpan nilai piksel berdasarkan koordinat baris 2 dan 3. baris 5 dilakukan perulangan untuk mengambil arah dari ptn secara berurutan. baris 6 dan 7 digunakan untuk megambil nilai piksel tetangga radius pertama disimpan pada variable cur_val1 dan nilai piksel tetangga radius kedua disi mpan pada variable cur_val2. baris 9 dilakukan perbandingan nilai tengah ctr_val dengan nilai tetangga radius pertama cur_val1 berdasarkan 2.22. baris 14 dilakukan perbandingan nilai tetangga radius pertama dengan nilai teta ngga radius kedua cur_val2 berdasarkan persamaan 2.21. kemudian dilakukan perhitungan nilai lmp menggunakan persamaan 2.20. gambar 3.15 menunjukkan contoh hasil implementasi algoritma lmp pada citra wajah. algoritma 3.6. local monotonic pattern input citra grayscale wh img_gry parameter pattern ptn 0111101 101111011 output citra lmp wh img_lmp 1 for i 2 to w2 do 2 for j 2 to h2 do 3 ctr_val img_gryij 4 for p 0 to 7 do 5 cur_val1 img_gryxptnp0yptnp1 6 cur_val2 img_gryxptnp02 yptnp12 7 pers 2.20 8 if cur_val1 ctr_val 0 do 9 s1 1 10 else 11 s1 0 65 12 pers 2.19 13 if cur_val2 cur_val1 0 do 14 s2 1 15 else 16 s2 0 17 pers 2.18 18 img_lmpij img_lmp s1 s2 2p 19 end for 20 end for 21 end for 22 return img_lmp a b gambar 3.15. sebelum a dan sesudah b ekstrasi fitur lmp 66 3.4 pembentukan model 3.4.1 pembentukan model svm dalam penelitian sebelumnya robert 2023 telah dilakukan pengenalan ekspresi wajah menggunakan svm dengan menggunakan 4 kernel yaitu linear polynomial sigmoid dan rbf. pada penelitian tersebut dataset tfeid yang digunakan untuk melatih dan menguji model. dataset tfeid memiliki keterbatasan dalam jumlah dan variasi etnis di mana hanya terdapat 1 etnis saja yaitu orang taiwan. berdasarkan dari penelitian robert 2023 didapatkan model terbaik untuk mengenal ekspresi wajah adalah menggunakan kernel sigmoid. pada penelitian ini akan dilakukan pengujian ulang svm dengan dataset gabungan berdasarkan usulan . terdapat 4 kernel yang akan digunakan untuk model svm dalam penelitian ini yaitu linear polynomial sigmoid dan rbf. persamaan 2.29 2.30 2.31 2.32menunjukkan persamaan dari keempat kernel yang digunakan secara berurutan. selain kernel terdapat parameter yang juga akan dikonfigurasi yaitu c. terdapat beberapa nilai c berada diantara 0 hingga 100. 3.4.2 pembentukan model cnn dalam penelitian sebelumnya robert 2023 model cnn yang digunakan adalah mobilenetv2 yang merupakan pretrained model . penelitian tersebut menggunakan dataset tfeid yang memiliki keterbatasan baik dalam jumlah maupun variasi dari etnis ekspresi wajah manusia. oleh karena itu dalam penelitian ini akan dilakukan pelatihan dan pengujian ulang menggunakan dataset gabungan sesuai dengan usulan yang telah diuraikan sebelumnya. tabel 3.2 menunjukkan arsitektur mobilenetv2 dari konvolusi layer pertama hingga output layer . kolom pertama menunjukkan tipe dari layer dan juga stride yang digunakan . kolom kedua menu njukan ukuran filter dan jumlah filter . kolom terakhir menunjukkan ukuran masukan citra dari layer sebelumnya. fungsi aktivasi activation function pada output layer adalah softmax selain itu model juga dilakukan parameter tuning pada learning rate batch size dan fungsi aktivasi pada fclayer saat d ilakukan proses pelatihan . 67 tabel 3.2. arsitektur mobilenetv2 typestride filter shape input size conv 2 33332 1601603 conv dw 1 3332 dw 11211232 conv 1 113264 11211232 conv dw 2 3364 dw 11211264 conv 1 1164128 565664 conv dw 1 33128 dw 5656128 conv 1 11128128 5656128 conv dw 2 33128 dw 56x56x128 conv 1 11128256 2828128 conv dw 1 33256 dw 2828256 conv 1 11256256 2828256 conv dw 2 33256 dw 2828256 5 conv dw 1 33512 dw 1414512 conv 1 11512512 1414512 conv dw 2 33512 dw 1414512 conv 1 115121024 77512 conv dw 2 331024 dw 771024 conv 1 111024 1024 771024 avg pool 1 pool 7 7 771024 fc 1 1024 7 111024 softmax 1 classifier 117 68 3.4.3 pembentukan model mnn gambar 3.16 menunjukan alur dari pembentukan mnn. p ertama dilakukan penentuan se yang digunakan. dalam penelitian ini akan digunakan bentuk se berdasarkan penelitian lain shen et al. 2019 dan se yang diusulkan pada penelitian ini. selanjutnya dilakukan penentuan operasi morfologi pertama akan digunakan operasi morfologi yang telah dilakukan peneliti lain dan juga operasi morfologi usulan pada penelitian ini. kemudian dilakukan uji coba analisis dan dibandingkan pada semua operasi morfologi dan se yang diusulkan pada penelitian ini. terakhir dilakukan perancangan arsitektur mnn berdasarkan dari analisis dari tahap ketiga. gambar 3.16. proses pembentukan model 3.4.3.1 ekstrasi fitur 3.4.3.1.1 penentuan structure element dalam penelitian ini digunakan dua se dan tiga operasi morfologi yang dibandingkan satu dengan yang lain. gambar 3.17 menunjukkan se bentuk beserta ukuran yang digunakan untuk operasi morfologi. terdapat dua bentuk se yang digunakan yaitu disk dan kotak. terdapat empat ukuran se yang digunakan yaitu 33 55 99 dan 15 15 ukuran digunakan untuk kedua bentuk. di mana kotak berwarna putih bernilai 1 dan hitam adalah 0. 69 disk 33 disk 55 disk 77 disk 99 disk 1515 kotak 33 kotak 55 kotak 77 kotak 99 kotak 1515 gambar 3.17. struktur element yang digunakan 3.4.3.1.2 penentuan operasi morfologi tahap setelah penentuan bentuk dan juga ukuran se yang akan digunakan adalah penentuan operasi morfologi yang digunakan. terdapat tiga operasi yang digunakan dalam penelitian ini. operasi p ertama adalah operasi morgologi opening pada citra original kemudian dilakukan pengurangan nilai piksel antara citra original dengan hasil opening operasi opening itu sendiri adalah operasi erosi yang dilanjutkan operasi dilasi. operasi k edua adalah erosi pada citra original kemudian dilakukan pengurangan citra original terhadap ha sil erosi. ketiga adalah dilasi pada citra original kemudian dilakukan pengurangan hasil dilasi terhadap citra original . ketiga operasi tersebut menggunakan algoritma 3.7 algoritma 3.8 dan algoritma 3.9 secara berurutan. 70 algoritma 3.7. gradien morfologi opening 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 input image grayscale image wh structure element se nn output feature image output w2h2 start for i 0 to w do for j 0 to h do create empty list arr for h 0 to z do for w 0 to z do if sehw 1 do arr appendimageih spacejh space end if end for end for outputispacejspace minarr end for end for for i 0 to w do for j 0 to h do create empty list arr for h 0 to z do for w 0 to z do if sehw 1 do arr appendimageih spacejh space end if end for end for outputispacejspace maxarr end for end for for i to w do for j to h do outputij imageij outputij end for end for pada algoritma 3.7. terdapat dua input yang digunakan pertama adalah citra original dengan ukuran 𝑊 𝐻. kedua adalah structure element dengan ukuran 𝑁 𝑁. hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran 𝑊 𝐻. pada baris pertama dilakukan perhitungan space yang digunakan untuk menentukan koordinat mulai operasi opening . baris 2 dan 3 dilakukan perulangan baris dan kolom citra yang digunakan untuk menentukan koordinat operasi opening . baris 4 digunakan untuk menyimpan kandidat nilai 71 piksel pada baris 5 hingga 11. baris 12 dilakukan pengambilan nilai terkecil yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan . kemudian baris 15 dan 16 dilakukan perulangan baris dan kolom citra untuk menentukan koordinat operasi opening . baris 17 digunakan untuk menyimpan kandidat nilai piksel pada baris 18 hingga 24. baris 25 dilakukan pengambilan nilai terbesar yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan 2.14. kemudian pada baris 28 dan 29 dilakukan perulangan kembali pada baris dan kolom citra untuk menentukan koordinat perhitungan. baris 30 dilakukan pengurangan antara citra original dengan citra opening . algoritma 3.8. gradien morfologi erosi 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 input image grayscale image w h structure element se n n output feature image output w2 h2 for i 0 to w do for j 0 to h do create empty list arr for h 0 to z do for w 0 to z do if sehw 1 do arr appendimageih spacejh space end if end for end for outputispacejspace minarr end for end for for i to w do for j to h do outputij imageij outputij end for end for 72 pada algoritma 3.8. terdapat dua input yang digunakan pertama adalah citra original dengan ukuran 𝑊 𝐻. kedua adalah structure element dengan ukuran 𝑁 𝑁. hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran 𝑊 𝐻. pada baris pertama dilakukan perhitungan space yang digunakan untuk menentukan koordinat mulai operasi opening . baris 1 dan 2 dilakukan perulangan baris dan kolom citra yang digunakan untuk menentukan koordinat operasi opening . baris 3 digunakan untuk menyimpan kandidat nilai piksel pada baris 4 hingga 10. baris 11 dilakukan pengambilan nilai terkecil yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan 2.10. kemudian pada baris 14 dan 15 dilakukan perulangan kembali pada baris dan kolom citra untuk menentukan koordinat perhitungan. baris 16 dilakukan pengurangan antara citra original dengan citra opening . algoritma 3.9. gradien morfologi dilasi 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 input image grayscale image w h structure element se n n output feature image output w2 h2 for i 0 to w do for j 0 to h do create empty list arr for h 0 to z do for w 0 to z do if sehw 1 do arr appendimageih spacejh space end if end for end for outputispacejspace maxarr end for end for for i to w do for j to h do outputij imageij outputij end for end for 73 pada algoritma 3.9. terdapat dua input yang digunakan pertama adalah citra original dengan ukuran 𝑊 𝐻. kedua adalah structure element dengan ukuran 𝑁 𝑁. hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran 𝑊 𝐻. baris 1 dan 2 dilakukan perulangan baris dan kolom citra yang digunakan untuk menentukan koordinat operasi dilasi. baris 3 digunakan untuk menyimpan kandidat nilai piksel pada baris 4 hingga 10. baris 11 dilakukan pengambilan nilai terbesar yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan 2.8. kemudian pada baris 14 dan 15 dilakukan perulangan kembali pada baris dan kolom citra untuk menentukan koordinat perhitungan. baris 16 dilakukan pengurangan antara citra dilasi dengan citra original. 74 3.4.3.1.3 percobaan dan perbandingan hasil operasi morfologi tabel 3.2 menunjukkan hasil operasi morfologi menggunakan se berdasarkan 3.4.3.1 dan 3.4.3.2. pada operasi morfologi tabel 3.2. digunakan citra yang memiliki objek persegi panjang berwarna putih . di mana putih pada citra bernilai 1 sedangkan hitam adalah 0. tabel 3.3. operasi morfologi dan structure element pada persegi panjang original image se operasi operasi dan hasil disk original opening 33 55 77 99 1515 75 disk original erosi 33 55 7x7 99 1515 disk dilasi original 33 55 77 99 1515 kotak original opening 33 55 77 99 1515 76 kotak original erosi 33 55 77 99 1515 kotak dilasi original 33 55 77 99 1515 berdasarkan dari tabel 3.3 dapat dilihat operasi gmo dengan se disk 33 menghasilkan corner pada persegi panjang. operasi gmd dengan se disk 33 memiliki hasil garis berbentuk persegi panjang dengan nilai tiap corner terdapat hilang . operasi gme dengan disk 33 mirip dengan gmd dengan se disk 33 namun corner dari gme utuh . operasi gm o menggunakan se kotak 3 3 tidak dapat mengekstrasi fitur dari persegi. operasi gmd dengan se kotak 33 menghasilkan garis yang berbentuk persegi panja ng. gme dengan se kotak 33 memiliki hasil yang mirip dengan gmd namun memiliki luas yang berbeda. pada gmd garis terlelak pada luar objek sedangkan gme berada pada dalam objek. 77 kemudian dilakukan operasi menggunakan 3 ukuran se lain yaitu 5 5 77 99 dan 1515. dari hasil yang didapatkan tiap ukuran memiliki hasil yang mirip dengan operasi yang digunakan. gmo mengekstrasi tiap sudut pada persegi dengan perbedaan pada ukuran sudut di mana semakin besar se semakin besar sudut yang didapatkan. gmd dapat mengkestrasi tepi dari persegi di mana semakin besar ukuran se semakin tebal garis yang didapatkan. gme dapat mengekstrasi tepi dari persegi di mana semakin besar ukuran se sem akin tebal garis yang didapatkan. operasi gmd dan gme memiliki hasil yang mirip dengan perbedaan tepi pada gmd menebal kearah luar persegi sedangkan tepi pada gme menebal kearah dalam. 78 tabel 3.4 merupakan hasil morfologi menggunakan citra wajah dengan warna grayscale . nilai intensitas piksel pada citra berkisaran antara 0 hingga 255. operasi morfologi dan se yang digunakan berdasarkan usulan pada subbab 3.4.3.1 dan 3.4.3.2. tabel 3.4. structure element dan operasi morfologi pada wajah citra original se operasi operasi dan hasil disk gmo 33 55 77 99 1515 79 disk gme 33 55 77 99 1515 disk gmd 33 55 77 99 1515 80 kotak gmo 33 55 77 99 1515 kotak gme 33 55 77 99 1515 berdasarkan tabel 3.4 dapat dilihat hasil ekstrasi fitur menggunakan berbagai kom binasi dua bentuk dan lima ukuran . pertama dilakukan ekstrasi fitur menggunakan se ukuran 3 3 terhadap semua bentuk se dan operasi. se disk 33 dengan operasi gmo fitur tidak terlihat. se disk 33 dengan operasi gme atau gmd fitur terlihat namun tidak jelas. se kotak 3 3 dengan operasi gmo fitur juga tidak terlihat. se kotak 3 3 dengan operasi gme atau gmd fitur sedikit terlihat dan tidak memiliki perbedaan secara kasat mata. 81 kemudian dilakukan menggunakan se ukuran 5 5. se disk 55 dengan operasi gmo terdapat sangat sedikit fitur yang didapatka n yaitu pada bagian mata . se disk 55 dengan operasi gme atau gmd fitur lebih jelas terlihat dan terdapat perbedaan di mana operasi gme tepi pada bagian mata dengan bola mata tergabun g sedangkan gmd tidak. selain itu luas lubang hidung dan mulut juga lebih besar pada operasi gme dibandingkan operasi gmd. se kotak 5 5 juga memiliki hasil yang sama dengan disk 55 dengan perbedaan yang tid ak dapat dilihat kasat mata. kemudian dilakukan operasi menggunakan se ukuran 7 7. se disk 77 dengan operasi gmo terdapat sangat sedikit fitur yang didapatka n yaitu pada bagian mata. se disk 77 dengan operasi gme atau gmd fitur lebih jelas terlihat dan terdapat perbedaan di mana operasi gme tepi pada bagian mata dengan bola mata tergabun g sedangkan gmd tidak. selain itu luas lubang hidung dan mulut juga lebih besar pada operasi gme dibandingkan operasi gmd. se kotak 7 7 juga memiliki hasil yang sama dengan disk 77 dengan perbedaan yang tidak dapat dilihat kasat mata. pada operasi menggunakan se ukuran 9 9. se disk 99 dengan operasi gmo fitur yang didapatkan tidak akurat karena tidak mengekstrasi tepi bentuk dari ekspresi wajah. se disk 99 dengan operasi gme dan gmd memiliki fitur yang mirip dengan se 5 5 di mana operasi gme tepi pada bagian mata tergabung sedangkan gmd tidak. selain itu luas pada lubang hidung dan mulut juga lebih luas dibandingkan dengan se 5 5 dan memiliki garis tepi yang lebih tebal. se kotak 9 9 dengan operasi gmo fitur yang didapatkan mirip dengan disk 99 dengan operasi gmo namun memiliki fitur yang lebih jelas terlihat. se kotak 9 9 dengan operasi 9 9 gme fitur yang didapatkan terlihat dengan jelas dan mirip dengan hasil yang menggunakan se disk 99 dengan operasi gme. namun terdapat perbedaan fitur yang signifikan pada bagian hidung di mana bentuk dari hidung sedikit berubah menjadi sedikit kotak. se kotak 9 9 dengan operasi gmd hasil yang didapatkan hampir sama dengan hasil yang menggunakan se disk 99 dengan operasi gmd hanya terdapat perbedaan pada tebal garis pada hidung. 82 operasi menggunakan se 15 15 hasil yang didapatkan memiliki pola yang sama dengan operasi yang menggunakan se 9 9. se disk atau kotak 15 15 dengan operasi gmo fitur lebih terlihat jelas dibandingkan dengan ukuran 9 9. se disk atau kotak 15 15 dengan operasi gme fitur lebih tebal namun untuk se kotak bagian hidung menjadi lebih kotak dari ukuran sebelumnya. berdasarkan dari hasil yang didapatkan dan analisis. se disk 55 atau kotak 55 dengan operasi gmd memiliki hasil terbaik. tepi pada bagian mata tergabung bagian mulut tidak menjadi lebih luas . namun pada bagian hidung menjadi lebih kecil dibandingkan citra original . selain itu operasi menggunakan gme dengan se disk 55 atau kotak 5 5 juga memberikan hasil yang baik. tepi dari tiap komponen wajah terlihat namun tepi pada mata dan bola mata tergabung namun memberikan hasil ekstrasi fitur bagian hidung lebih baik dibandingkan gmd. karena luas hidung lebih sesuai pada gme dibandingkan gmd. 83 3.4.3.2 pembentukan dan pelatihan model gambar 3.18 menunjukkan arsitektur dari mnn secara garis besar. di mana terdapat 5 layer utama yang memiliki tugas masing masing. di mana terdapat beberapa variasi arsitektur variasi pertama terdapat pada morphology layer di mana akan digunakan dua jenis ekstrasi fitur berdasarkan pada hasil subbab 3.4.3.3. variasi kedua terdaoat pada hidden layer di mana akan digunakan beberapa kombinasi fullyconnected layer . gambar 3.18. model mnn yang diusulkan input layer adalah layer pertama dari model mnn yang bertugas untuk menerima input berupa citra. di mana dimensi dari intput layer itu sendiri sesuai dengan ukuran citra pada dataset yaitu 160 160. kedua adalah morphology layer . menerima masukan dari input layer kemudian dilakukan proses morfologi. terdapat dua jenis morfologi layer yang akan digunakan. morfolog y layer pertama adalah dilation layer kemudian subtraction layer . di mana lapisan morfologi jenis pertama menggunakan hasil terbaik dari operasi morfologi dilasi pada subbab 3.4.3.3. morphology layer jenis kedua adalah erosion layer dilanjutkan subtraction layer . di mana lapisan morfologi jenis kedua ini menggunakan hasil terbaik dari operasi m orfologi erosi pada subab 3.4.3.3. 84 lapisan ketiga adalah flatten layer lapisan yang bertugas mengubah citra menajadi feature vector. masukan dari lapisan ini adalah hasil dari subtraction layer pada lapisan morfologi. di mana hasil dari subtraction layer adalah citra dengan ukuran 160160 yang kemudian diubah mnejadi satu dimensi yaitu 25600. lapisan keempat adalah fully connected layer fc layer yang bertugas untuk mempelajari dan menganalisa nilai feature vector dari flatten layer . pada lapisan ini dilakukan beberapa konfigurasi fc layer mulai dari jumlah fc layer dan jumlah neuron pada fc layer . konfigurasi pertama akan diuji coba 2 fc layer dengan masing masing neuron adalah 512 dan 25 6. konfigurasi kedua akan dicoba 1024 dan 512. kemudian dari situ akan dicoba analisis mana yang lebih baik sehingga dapat dikonfigurasi lebih lanjut. jika konfigurasi pertama memiliki hasil lebih baik artinya memungkinkan fc layer untuk dibuat lebih sederhana dengan mengurangi jumlah neuron . jika konfigurasi kedua lebih baik artinya terdapat kemungkinan untuk meninkatkan performa dari model karena dataset memiliki kompleksitas tinggi . beberapa lapisan akan dilakukan tuning paramter. tuning pertama terdapat pada bentuk se ukuran se jenis operasi pada morphological layer . tuning kedua terdapat pada fclayer yaitu fungsi aktivasi relusigmoidtanh dan jumlah neuron pada tiap hidden layer. selain arsitektur pada proses pelatihan juga dilakukan tuning pada learning rate jumlah epoch dan batch size. terakhir adalah output layer merupakan penentuan dari ekspresi berdasarkan dari bobot hidden layer . di mana fungsi aktivasi yang digunakan untuk output layer adalah softmax yang artinya output berupa probabilitas dari tiap ekspresi. kemudian untuk loss function yang akan digunakan adalah categorical crossentropy di mana fungsi loss ini digunakan jika model memprediksi multi kelas multi class prediction . 85 3.5 time table semester 1 aktivitas 1 2 3 4 5 6 studi literatur pembuatan proposal pengumpulan dataset sekunder saja semester 2 pengumpulan dataset primer sekunder pembentukan dataset pembentukan model pelatihan pengujian model beserta tuning model menuliskan hasil penelitian bab 4 semester 3 pelatihan pengujian model beserta tuning model menuliskan hasil penelitian bab 4 bab 5 pembuatan jurnal pertama semester 4 pembuatan jurnal pertama submit jurnal pembuatan jurnal kedua semester 5 pembuatan jurnal kedua submit jurnal,3.1 alur penelitian gambar 3.1 menunjuk kan metode penelitian. terdapat 5 tahap utama yang akan dilakukan yang pertama adalah studi literatur untuk menyusun bab 1 dan bab 2. tahap kedua adalah pengumpulan citra ekspresi wajah data citra berupa data primer dan data sekunder. tahap ketiga adalah pembentukan dataset untuk tiap model svm cnn dan mnn skenario pembentukan dataset dilakukan berdasarkan pada penelitian robert 2023 . pada tahap keempat dilakukan pembentukan model khusus untuk svm dan cnn menggunakan model pada penelitian robert 2023 sedangkan mnn menggunakan usulan pada penelitian ini. tahap terakhir adalah pelatihan dan pengujian untuk semua model svm cnn mnn terdapat tahap parameter tuning untuk tiap model . kemudian semua performa dari tiap model akan dibandingkan satu sama lain dan juga dianalis is pada bab 4. gambar 3.1. metode penelitian 48 3.2 pengumpulan citra ekspresi wajah citra ekspresi wajah dikumpulkan secara langsung oleh peneliti data primer dan juga menggunakan data yang dikumpulkan oleh peneliti lain data sekunder. terdapat 7 ekspresi wajah yang akan digunakan dalam penelitian ini yaitu marah jijik menghina senang sedih kaget dan netral tanpa ekspresi. gambar 3.2 menunjukkan contoh 7 ekspresi wajah manusia yang digunakan penelitian ini. gambar 3.2. contoh 7 jenis ekspresi wajah dataset primer akan dilakukan pengambilan citra ekspresi wajah mahasiswa universitas gunadarma baik pria maupun wanita. gambar 3.3. contoh dataset primer 49 dataset sekunder digunakan dataset yang telah digunakan umum oleh peneliti lain terkait pengenalan ekspresi wajah. terdapat beberapa dataset yang umum digunakan dalam penelitian ekspresi wajah . pertama extended cohn kanade ck yang berisi citra ekspresi wajah pria dan wanita dari berbagai etnis dengan resolusi tinggi kanade cohn tian 2000 lucey et al. kedua taiwanese facial expression image dataset tfeid yang berisi citra ekspresi wajah pria dan wanita dari etnis taiwan chen yen 2007 . ketiga japanese female facial expression jaffe yang terdiri dari citra ekspresi wajah wanita etnis j epang lyons 2021 lyons kamachi gyoba 2020 . tabel 3.1. detail dataset sekunder ekspresi dataset ck dataset jaffe dataset tfeid total anger 45 30 34 109 disgust 59 29 40 128 fear 25 32 40 97 happy 69 31 40 140 neutral 107 30 39 176 sad 28 31 39 98 surprise 83 30 36 149 ukuran citra 640490 256256 481600 warna citra rgb gray gray rgb 51 3.3 pembentukan dataset secara garis besar dalam pembuatan model ai khususnya ml dan dl terdapat proses yang berperan penting yaitu preprocessing dataset seperti ekstrasi fitur penyesuaian ukuran citra dan augmentasi deshmukh et al. pada penelitian robert 2023 dilakukan sebuah skenario pembentukan dataset menggunakan beberapa metode pengolahan citra seperti konversi warna ke grayscale deteksi wajah dan e kstrasi fitur di mana preprocessing mempengaruhi performa dari model ml dan dl. selain itu pada penelitian alam yao 2019 juga dilakukan penelitian yang serupa di mana preprocessing mempengaruhi performa model machine learning . pertama dilakukan pendeteksian wajah menggunakan vja proses ini berguna untuk mengurangi noise pada citra . hasil vja membuat ukuran citra bervariasi oleh karena itu dilakukan resizing citra untuk menyamakan semua ukuran citra dan juga menyesuaikan dengan dimensi input model . pertama dilakukan deteksi wajah menggunakan vja guna mengurangi noise . kemudian dilakukan konversi warna dari rgb ke grayscale karena fitur warna tidak dibutuhkan untuk mengenali ekspresi wajah. gambar 3.10 menunjukkan hasil dari implementasi algoritma deteksi wajah pada sebuah citra. a citra original b hasil deteksi c hasil cropping 58 3.3.2 image resize proses perubahan ukuran citra menggunakan metode bicubic interpolation . parameter berupa koefisien a yang dapat mempengaruhi koordinat tetangga umumnya nilai dikisaran 0.75 hingga 0.5. hasil dari algoritma ini adalah citra dengan ukuran 𝐻𝑟𝑊𝑟𝐶. baris 2 dilakukan pembuatan matri ks yang digunakan untuk menyimpan hasil. baris 456 dilakukan perulangan pada channel 𝑑𝐻 𝑑𝑊 matri ks yang dibuat pada baris 2 perulangan ini digunakan untuk menentukan koordinat matri ks hasil yang akan dihitung. baris 19 dilakukan pembuatan matri ks berukuran 4 4 yang digunakan untuk menyimpan nilai piksel tetangga. hasil yang didapatkan kemudian disimpan pada variab el output . 59 algoritma 3.3. image resize menggunakan bicubic interpolation input citra ukuran 𝐻𝑊𝐶 img ratio antara 0 hingga r parameter koefisien a 0.5 a output citra ukuran 𝐻𝑟𝑊𝑟𝐶 output 1 calculate dh hr dw wr h 1ratio used for calculation 2 create matrix output dimension dhdwc to store result 3 for i 0 to c do 4 for j 0 to dh do 5 for k 0 to dw do 6 calculate x i h 2 7 calculate y j h 2 8 calculate x1 1 x floorx 9 calculate x2 x flootx 10 calculate x3 floorx 1 x 11 calculate x4 flootx 2 x 12 calculate y1 1 y floory 13 calculate y2 y flooty 14 calculate y3 floory 1 y 15 calculate y4 flooty 2 y 16 create matrix mat_l dimension 14 mat_r dimension 41 h menggunakan pers 2.19 17 calculate mat_l00 hx1 mat_l01 hx2 mat_l02 hx3 mat_l03 hx4 bobot horizontal 18 calculate mat_r00 hy1 mat_l01 hy2 mat_l02 hy3 mat_l03 hy4 bobot vertical 19 create matrix mat_m dimension 44 20 mat_l00 img yy1 xx1 21 mat_l10 img yy2xx1 22 mat_l20 img yy3xx1 23 mat_l30 img yy4xx1 24 mat_l01 img yy1 xx2 25 mat_l11 img yy2xx2 26 mat_l21 img yy3xx2 27 mat_l31 img yy4xx2 28 mat_l02 img yy1 xx3 29 mat_l12 img yy2xx3 30 mat_l22 img yy3xx3 31 mat_l32 img yy4xx3 32 mat_l03 img yy1 xx4 33 mat_l13 img yy2xx4 34 mat_l23 img yy3xx4 35 mat_l33 img yy4xx4 60 36 calculate output mat_m mat_l mat_r gambar 3.11 menunjukkan hasil perubahan ukuran citra wajah menggunakan algoritma 3.3. berdasarkan gambar 3.11 ukuran dari input citra adalah 600 480 dan ratio 05. gambar 3.12 menunjukkan contoh hasil implementasi algoritma konversi warna dari rgb ke grayscale dengan menggunakan nilai y dari yc bcr. pertama dilakukan pembuatan filter terlebih dahulu. algoritma 3.5 menunjukkan cara pembuatan gabor filter. kemudian jumlah filter luas kernel lambda 𝜆 psi 𝜑 sigma 𝜎 dan gamma 𝛾 yang akan digunakan untuk pembuatan gabor filter . baris 2 dilakukan pembuatan gabor filter berdasarkan persamaan 2.23 dan parameter yang di input . algoritma 3.5. gabor filter input citra grayscale ukuran 𝐻𝑊 img jumlah filter dari 1 hingga num_filter kernel size n n ksize lambda 𝜆 lambd psi 𝜑 psi sigma 𝜎 sigma gamma 𝛾 gamma threshold bawah min_int threshold atas max_int output citra ukuran 𝐻𝑊 output 1 for i 0 to 180 with increment 180num_filter do 2 create gabor filter filter with kernel size ksize lambda lambd theta i psi psi sigma sigma gamma gamma 3 proses konvolusi 4 for i 0 to num_filter do 5 output img filteri 6 proses deteksi tepi 7 apply canny edge detection on output with lower threshold min_int upper threshold max_int 63 perubahan nilai parameter dilakukan pada 𝜆 𝛾 dan 𝜎 pada gambar 3.14 menunjukkan hasil dari pengaplikasian gabor filter di mana a menunjukkan hasil awal sebelum dilakukan parameter tuning dan b hasil akhir setelah parameter tuning . hasil algoritma gabor filter 64 3.3.5 ekstrasi fitur lmp proses ekstrasi fitur menggunakan metode lmp. hasil dari algoritma 3.6 adalah citra lmp dengan ukuran 𝑤4ℎ 4 ukuran citra berkurang untuk menghindari perhitungan di luar dari ukuran citra. gambar 3.15 menunjukkan contoh hasil implementasi algoritma lmp pada citra wajah. berdasarkan dari penelitian robert 2023 didapatkan model terbaik untuk mengenal ekspresi wajah adalah menggunakan kernel sigmoid. operasi p ertama adalah operasi morgologi opening pada citra original kemudian dilakukan pengurangan nilai piksel antara citra original dengan hasil opening operasi opening itu sendiri adalah operasi erosi yang dilanjutkan operasi dilasi. ketiga adalah dilasi pada citra original kemudian dilakukan pengurangan hasil dilasi terhadap citra original . hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran 𝑊 𝐻. baris 12 dilakukan pengambilan nilai terkecil yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan . baris 25 dilakukan pengambilan nilai terbesar yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan 2.14. hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran 𝑊 𝐻. baris 11 dilakukan pengambilan nilai terkecil yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan 2.10. hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran 𝑊 𝐻. baris 11 dilakukan pengambilan nilai terbesar yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan 2.8. kemudian pada baris 14 dan 15 dilakukan perulangan kembali pada baris dan kolom citra untuk menentukan koordinat perhitungan. 74 3.4.3.1.3 percobaan dan perbandingan hasil operasi morfologi tabel 3.2 menunjukkan hasil operasi morfologi menggunakan se berdasarkan 3.4.3.1 dan 3.4.3.2. pada operasi morfologi tabel 3.2. digunakan citra yang memiliki objek persegi panjang berwarna putih . tabel 3.3. operasi morfologi dan structure element pada persegi panjang original image se operasi operasi dan hasil disk original opening 33 55 77 99 1515 75 disk original erosi 33 55 7x7 99 1515 disk dilasi original 33 55 77 99 1515 kotak original opening 33 55 77 99 1515 76 kotak original erosi 33 55 77 99 1515 kotak dilasi original 33 55 77 99 1515 berdasarkan dari tabel 3.3 dapat dilihat operasi gmo dengan se disk 33 menghasilkan corner pada persegi panjang. operasi gmd dengan se disk 33 memiliki hasil garis berbentuk persegi panjang dengan nilai tiap corner terdapat hilang . operasi gmd dengan se kotak 33 menghasilkan garis yang berbentuk persegi panja ng. gme dengan se kotak 33 memiliki hasil yang mirip dengan gmd namun memiliki luas yang berbeda. dari hasil yang didapatkan tiap ukuran memiliki hasil yang mirip dengan operasi yang digunakan. operasi gmd dan gme memiliki hasil yang mirip dengan perbedaan tepi pada gmd menebal kearah luar persegi sedangkan tepi pada gme menebal kearah dalam. 78 tabel 3.4 merupakan hasil morfologi menggunakan citra wajah dengan warna grayscale . operasi morfologi dan se yang digunakan berdasarkan usulan pada subbab 3.4.3.1 dan 3.4.3.2. tabel 3.4. structure element dan operasi morfologi pada wajah citra original se operasi operasi dan hasil disk gmo 33 55 77 99 1515 79 disk gme 33 55 77 99 1515 disk gmd 33 55 77 99 1515 80 kotak gmo 33 55 77 99 1515 kotak gme 33 55 77 99 1515 berdasarkan tabel 3.4 dapat dilihat hasil ekstrasi fitur menggunakan berbagai kom binasi dua bentuk dan lima ukuran . se kotak 5 5 juga memiliki hasil yang sama dengan disk 55 dengan perbedaan yang tid ak dapat dilihat kasat mata. se kotak 7 7 juga memiliki hasil yang sama dengan disk 77 dengan perbedaan yang tidak dapat dilihat kasat mata. se disk 99 dengan operasi gmo fitur yang didapatkan tidak akurat karena tidak mengekstrasi tepi bentuk dari ekspresi wajah. se kotak 9 9 dengan operasi 9 9 gme fitur yang didapatkan terlihat dengan jelas dan mirip dengan hasil yang menggunakan se disk 99 dengan operasi gme. se kotak 9 9 dengan operasi gmd hasil yang didapatkan hampir sama dengan hasil yang menggunakan se disk 99 dengan operasi gmd hanya terdapat perbedaan pada tebal garis pada hidung. 82 operasi menggunakan se 15 15 hasil yang didapatkan memiliki pola yang sama dengan operasi yang menggunakan se 9 9. berdasarkan dari hasil yang didapatkan dan analisis. se disk 55 atau kotak 55 dengan operasi gmd memiliki hasil terbaik. selain itu operasi menggunakan gme dengan se disk 55 atau kotak 5 5 juga memberikan hasil yang baik. tepi dari tiap komponen wajah terlihat namun tepi pada mata dan bola mata tergabung namun memberikan hasil ekstrasi fitur bagian hidung lebih baik dibandingkan gmd. 83 3.4.3.2 pembentukan dan pelatihan model gambar 3.18 menunjukkan arsitektur dari mnn secara garis besar. di mana terdapat beberapa variasi arsitektur variasi pertama terdapat pada morphology layer di mana akan digunakan dua jenis ekstrasi fitur berdasarkan pada hasil subbab 3.4.3.3. variasi kedua terdaoat pada hidden layer di mana akan digunakan beberapa kombinasi fullyconnected layer . model mnn yang diusulkan input layer adalah layer pertama dari model mnn yang bertugas untuk menerima input berupa citra. di mana lapisan morfologi jenis pertama menggunakan hasil terbaik dari operasi morfologi dilasi pada subbab 3.4.3.3. morphology layer jenis kedua adalah erosion layer dilanjutkan subtraction layer . di mana lapisan morfologi jenis kedua ini menggunakan hasil terbaik dari operasi m orfologi erosi pada subab 3.4.3.3. 84 lapisan ketiga adalah flatten layer lapisan yang bertugas mengubah citra menajadi feature vector. masukan dari lapisan ini adalah hasil dari subtraction layer pada lapisan morfologi. di mana hasil dari subtraction layer adalah citra dengan ukuran 160160 yang kemudian diubah mnejadi satu dimensi yaitu 25600. jika konfigurasi pertama memiliki hasil lebih baik artinya memungkinkan fc layer untuk dibuat lebih sederhana dengan mengurangi jumlah neuron . jika konfigurasi kedua lebih baik artinya terdapat kemungkinan untuk meninkatkan performa dari model karena dataset memiliki kompleksitas tinggi . tuning pertama terdapat pada bentuk se ukuran se jenis operasi pada morphological layer . terakhir adalah output layer merupakan penentuan dari ekspresi berdasarkan dari bobot hidden layer . di mana fungsi aktivasi yang digunakan untuk output layer adalah softmax yang artinya output berupa probabilitas dari tiap ekspresi. kemudian untuk loss function yang akan digunakan adalah categorical crossentropy di mana fungsi loss ini digunakan jika model memprediksi multi kelas multi class prediction . 85 3.5 time table semester 1 aktivitas 1 2 3 4 5 6 studi literatur pembuatan proposal pengumpulan dataset sekunder saja semester 2 pengumpulan dataset primer sekunder pembentukan dataset pembentukan model pelatihan pengujian model beserta tuning model menuliskan hasil penelitian bab 4 semester 3 pelatihan pengujian model beserta tuning model menuliskan hasil penelitian bab 4 bab 5 pembuatan jurnal pertama semester 4 pembuatan jurnal pertama submit jurnal pembuatan jurnal kedua semester 5 pembuatan jurnal kedua submit jurnal
Tatya Atyanti Paramastri_Kualifikasi.txt,3.1. alur penelitian 1. identifikasi masalah gambar 3.1 alur penelitian identifikasi masalah dilakukan supaya permasalahan yang diangkat jelas. identifikasi masalah dilakukan dengan cara melihat permasalahan nyata melalui literatur seperti jurnal penelitian wawancara dengan ahli dan keresahan yang dirasakan oleh peneliti secara pribadi. permasalahan yang diangkat pada penelitian ini adalah motif batik indonesia sangat beragam dan memiliki maknanya masingmasing. namun tidak banyak masyarakat yang masih mengetahui nama makna dan pemakaian dari masingmasing motif batik. menurut dewan ahli ppbi paguyuban pecinta batik indonesia sekar jagad ibu mari s. condronegoro saat ini sering kali ditemukan kesalahan dalam pemakaian motif batik seperti mengenakan kain yang seharusnya digunakan pada upacara kematian ketika menghadiri acara pernikahan. solusi yang diusulkan adalah melakukan klasifikasi motif batik. metode klasifikas yang umum digunakan adalah cnn. namun cnn klasik memiliki kelemahan dalam memahami makna menyeluruh dari gambar terutama yang berkaitan dengan hubungan antar bagian gambar yang berbeda. selain itu cnn klasik juga rentan terhadap overfitting di mana model terlalu terlatih pada data pelatihan dan tidak dapat menggeneralisasi dengan baik ke data baru. 2. studi literatur studi literatur dilakukan supaya penelitian memiliki landasan yang jelas. studi literatur dilakukan dengan sumber jurnal penelitian terdahulu serta buku yang berisikan metode yang sesuai dengan penelitian. fokus studi literatur terbagi menjadi tiga topik yaitu klasifikasi motif batik komputasi kuantum dan deteksi tepi. 3. pengumpulan dataset pengumpulan data dilakukan berdasarkan keperluan penelitian. data yang dikumpulkan merupakan data primer yang akan dikumpulkan degan bantuan ahli yaitu dewan ahli ppbi sekar jagad ibu mari s. condronegoro. ppbi sekar jagad merupakan perkumpulan pecinta batik yang diawasi langsung penasehat utama oleh permaisuri gusti kanjeng ratu hemas istri dari sri sultan hamengku buwono x sehingga informasi yang didapatkan bisa dijamin kebenarannya. pengumpulan dataset primer ini dilakukan dengan diskusi wawancara serta bimbingan dewan ahli ppbi sekar jagad supaya dataset yang digunakan sesuai dengan kebenaran dan kebutuhan penelitian yang dilakukan. sehingga hasil yang didapatkan memuaskan dan akurat. dataset yang akan dikumpulkan merupakan citra motif batik daur hidup yogyakarta dari kain batik tradisional yang merupakan batik cap maupun batik tulis bukan printing. motif yang akan digunakan dalam penelitian akan didiskusikan terlebih dahulu dengan narasumber supaya dapat mewakili batik daur hidup yogyakarta yang sangat penting untuk diketahui dalam bersosialdi masyarakat. misalnya seperti motif batik yang memiliki makna khusus dan tak pantas untuk dikenakan pada berapa acara motif batik yang memiliki larangan dan lainnya. hal ini dilakukan karena batik daur hidup yogyakarta tercatat memiliki ratusan motif hingga tahun 2006 sekar jagad 2015. gambar 3.2 gawangan kain citra batik akan diambil dengan menggunakan kamera dimana kain akan dibentangkan pada gawangan untuk difoto di dalam ruangan dengan pecahayaan yang sama dan di luar ruangan dengan cuaca yang sama. citra batik akan diambil dari berbagai posisi supaya citra lebih beragam. kemudian motif batik yang akan diambil beragam namun akan dipisahkan terlebih dahulu berdasarkan jenisnya. hal ini dikarenakan untuk satu kelompok motif yang sama terkadang terdapat bentuk yang terlihat berbeda. sehingga dibutuhkan pengujian bertahap untuk melihat apakah model dapat mendeteksi motif dengan benar. a b c gambar 3.3. a motif parang gondosuli b motif batik parang barong c motif batik parang kusuma data primer digunakan karena terdapat kekurangan dari data sekunder yang dapat ditemukan. seperti motif batik yang terpotong sehingga tidak terlihat serta motif yang salah pada beberapa kelas. beberapa motif juga memiliki bentuk atau komponen serupa sehingga butuh dikonsultasikan lebih lanjut kepada ahli. a b gambar . a motif parang yang terpotong b motif batik ceplok namun memiliki konponen parang 4. prapengolahan data proses prapengolahan data dilakukan untuk menyiapkan data sebelum diimplementasikan dalam model klasifikasi citra. prapengolahan data meliputi resize mengubah ruang warna menjadi grayscale augmentasi dan split data. resize dilakukan untuk memperkecil ukuran gambar aslinya. hal ini dilakukan untuk memastikan semua citra memiliki ukuran yang sama sehingga algoritma dapat bekerja secara konsisten dan efisien. selain itu ukuran citra yang lebih kecil dapat mempercepat proses segmentasi dan klasifikasi tanpa kehilangan informasi penting. proses selanjutnya adalah mengubah ruang warna menjadi grayscale perubahan warna ini dilakukan karena dapat meningkatkan kontras meningkatkan efisiensi komputasi dan meningkatkan ketahanan terhadap variasi pencahayaan. citra grayscale memiliki rentang intensitas yang lebih kecil dibandingkan citra rgb sehingga kontras tepi lebih jelas. selain itu citra grayscale membutuhkan lebih sedikit memori dan sumber daya komputasi dibandingkan citra rgb. kemudian citra grayscale tidak terpengaruh oleh variasi pencahayaan sehingga tepi dapat dideteksi dengan lebih akurat. selanjutnya proses augmentasi digunakan untuk meningkatkan ukuran dataset dengan menambahkan data baru tanpa perlu melakukan pengumpulan data baru. hal ini bermanfaat untuk mengatasi masalah keterbatasan data. selain itudengan melakukan augmentasi data akan menjadi lebih bervariasi sehingga dapat mencegah terjadinya overfitting dan lebih stabil terhadap perubahan data. proses terakhir adalah melakukan pembagian data. data akan dibagi menjadi tiga dataset yaitu pelatihan pengujian dan validasi. 5. komputasi kuantum model komputasi kuantum merupakan usulan dalam penelitian ini. adapun kombinasi model pertama yang akan dilakukan meliputi segmentasi tepi berbasis kuantum dengan menggunakan metode canny dan klasifikasi dengan metode quantum convolutional neural network qcnn. komputasi kuantum diterapkan mulai dari proses segmentasi karena berdasarkan penelitian terdahulu deteksi tepi berbasis kuantum dapat mendeteksi lebih banyak tepi dibandingkan deteksi tepi klasik berdasarkan jumlah tepi yang dihasilkan sundani dkk. 2019. hal serupa juga berlaku pada metode qcnn yang memiliki hasil lebih baik dan akurat dibandingkan dengan metode cnn klasik. sehingga hipotesisnya hasil dari ekstraksi fitur dan klasifikasi akan menjadi lebih optimal. gambar 3.2 perbandingan hasil deteksi tepi berbasis kuantum dan klasik sundani dkk. 2019 6. komputasi kuatum dan klasik kombinasi model berikutnya adalah melakukan deteksi tepi berbasis kuatum dengan model canny. kemudian klasifikasi dilakukan dengan menggunakan cnn klasik. kombinasi ini dilakukan untuk mengetahui seberapa jauh pengaruh penggunaan komputasi kuantum pada deteksi tepi dengan model canny. 7. komputasi klasik dan kuantum komputasi klasik dan kuantum disini adalah kombinasi antara deteksi tepi klasik dengan model canny yang kemudian dilanjutkan dengan melakukan klasifikasi dengan menggunakan metode quantum convolutional neural network qcnn. hal ini dilakukan untuk melihat seberapa jauh pengaruh dari penerapan model qcnn yang menggunakan komputasi kuantum. 8. komputasi klasik pengolahan data dengan komputasi klasik dilakukan dengan menggunakan deteksi tepi canny kasik yang dikombinasikan dengan klasifikasi cnn klasik. pengolahan data ini dilakukan sebagai pembanding performa model segmentasi dan klasifikasi berbasis kuantum. pengolahan data kedua model komputasi kuantum dan komputasi klasik akan dilakukan dengan menggunakan komputer yang sama yaitu komputer klasik. 9. evaluasi performa tahap terakhir adalah melakukan evaluasi performa. performa akan dibandingkan dari akurasi yang dihasilkan. adapun akurasi akan dihitung menggunakan confusion matrix pada kedua model. evaluasi ini akan dilakukan pada keempat kombinasi model untuk mengetahui seberapa jauh perbedaan dan fungsi penerapan komputasi kuantup pada setiap model. 3.2. jadwal penelitian jadwal penelitian digunakan sebagai target supaya penelitian ini dapat selesai tepat waktu. penelitian ini menggunakan pendekatan kualitatif dan kuantitatif. penelitian kualitatif dilakukan dalam proses mengkaji studi literatur dan melakukan wawancara dengan dewan ahli ppbi sekar jagad ibu mari s. condronegoro untuk mempelajari batik daur hidup yogyakarta. sedangkanpenelitian kuantitatif dilakukan dalam pengolahan data. berikut tabel 3.1 jadwal penelitian. tabel 3.1 jadwal penelitian no. uraian kegiatan 2023 202 4 9 10 11 12 1 2 3 4 5 6 7 8 9 10 11 12 1. penyusunan proposal 2. uji kualifikasi 3. pematangan rencana penelitian 5. wawancara dan pengambilan dataset primer 6. evaluasi progres pertama 7. paper pertama literatur review 8. evaluasi progres kedua 9. paper kedua deteksi tepi berbasis kuantum no. uraian kegiatan 202 5 2026 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 9. paper ketiga klasifikasi citra berbasis kuantum 10. evaluasi rkp 11. sidang tertutup 12. sidang terbuka,3.1. alur penelitian 1. identifikasi masalah gambar 3.1 alur penelitian identifikasi masalah dilakukan supaya permasalahan yang diangkat jelas. identifikasi masalah dilakukan dengan cara melihat permasalahan nyata melalui literatur seperti jurnal penelitian wawancara dengan ahli dan keresahan yang dirasakan oleh peneliti secara pribadi. permasalahan yang diangkat pada penelitian ini adalah motif batik indonesia sangat beragam dan memiliki maknanya masingmasing. namun tidak banyak masyarakat yang masih mengetahui nama makna dan pemakaian dari masingmasing motif batik. menurut dewan ahli ppbi paguyuban pecinta batik indonesia sekar jagad ibu mari s. condronegoro saat ini sering kali ditemukan kesalahan dalam pemakaian motif batik seperti mengenakan kain yang seharusnya digunakan pada upacara kematian ketika menghadiri acara pernikahan. solusi yang diusulkan adalah melakukan klasifikasi motif batik. fokus studi literatur terbagi menjadi tiga topik yaitu klasifikasi motif batik komputasi kuantum dan deteksi tepi. sehingga hasil yang didapatkan memuaskan dan akurat. dataset yang akan dikumpulkan merupakan citra motif batik daur hidup yogyakarta dari kain batik tradisional yang merupakan batik cap maupun batik tulis bukan printing. motif yang akan digunakan dalam penelitian akan didiskusikan terlebih dahulu dengan narasumber supaya dapat mewakili batik daur hidup yogyakarta yang sangat penting untuk diketahui dalam bersosialdi masyarakat. hal ini dilakukan karena batik daur hidup yogyakarta tercatat memiliki ratusan motif hingga tahun 2006 sekar jagad 2015. selain itu ukuran citra yang lebih kecil dapat mempercepat proses segmentasi dan klasifikasi tanpa kehilangan informasi penting. proses selanjutnya adalah mengubah ruang warna menjadi grayscale perubahan warna ini dilakukan karena dapat meningkatkan kontras meningkatkan efisiensi komputasi dan meningkatkan ketahanan terhadap variasi pencahayaan. selanjutnya proses augmentasi digunakan untuk meningkatkan ukuran dataset dengan menambahkan data baru tanpa perlu melakukan pengumpulan data baru. komputasi kuantum diterapkan mulai dari proses segmentasi karena berdasarkan penelitian terdahulu deteksi tepi berbasis kuantum dapat mendeteksi lebih banyak tepi dibandingkan deteksi tepi klasik berdasarkan jumlah tepi yang dihasilkan sundani dkk. hal serupa juga berlaku pada metode qcnn yang memiliki hasil lebih baik dan akurat dibandingkan dengan metode cnn klasik. sehingga hipotesisnya hasil dari ekstraksi fitur dan klasifikasi akan menjadi lebih optimal. gambar 3.2 perbandingan hasil deteksi tepi berbasis kuantum dan klasik sundani dkk. pengolahan data ini dilakukan sebagai pembanding performa model segmentasi dan klasifikasi berbasis kuantum. performa akan dibandingkan dari akurasi yang dihasilkan. condronegoro untuk mempelajari batik daur hidup yogyakarta. paper kedua deteksi tepi berbasis kuantum no. paper ketiga klasifikasi citra berbasis kuantum 10. evaluasi rkp 11. sidang tertutup 12. sidang terbuka
Tia Haryanti_Kualifikasi.txt,3.1 kerangka umum penelitian ini bertujuan untuk mengembangkan sistem deteksi dini kantuk sebelum berkendara dengan menggunakan kombinasi data visual berupa data citra wajah dan data fisiologis. kondisi predriving mengacu pada kondisi sebelum pengemudi memulai perjalanan sehingga sistem ini sangat penting untuk mencegah risiko kecelakaan di jalan . sistem ini mengintegrasikan teknologi pengenalan wajah dan analisis data fisiologis untuk memberikan deteksi yang lebih akurat. blok d iagram secara umum yang digunakan pada penelitian ini dapat dilihat pada gambar 3.1 blok diagram. objek preprocessing data fisiologis ekstrasi fiturpenggabungan fitur klasifikasi data image data visual kantuk ya tidak gambar 3.1 blok diagram model ini terdiri dari tiga tahapan yaitu input proses dan output . penelitian deteksi dini kantuk untuk kondisi predriving menggabungkan data visual yaitu pengumpulan data citra wajah pengemudi yang diambil menggunakan kamera serta data fisiologis yang diukur berupa data ekg menggunakan perangkat wearable yaitu smartwatch dan pulse oximeter untuk mengukur saturasi oksigen spo2 . tahapan preprocessing dan ekstraksi fitur dilakukan pada kedua jenis data yaitu data citra gambar dan data fisiologis. model convolutional neural network cnn digunakan untuk mengekst raksi fitur dari data citra wajah yang merupakan data visual sementara long short term memory lstm digunakan untuk memproses data fisiologis yang bersifat timeseries. fitur fitur yang diekstraksi dari kedua model ini digabungkan untuk menghasilkan vect or fitur gabungan. vektor fitur ini kemudian digunakan sebagai input untuk model support vector machine 43 svm yang melakukan klasifikasi akhir untuk mendeteksi kantuk. hasil deteksi kemudian digunakan untuk memberikan peringatan kepada pengemudi layak tidak nya pengemudi untuk berkendara. 3.2 tahapan peneletian tahapan penelitian merupakan urutan atau langkah langkah yang dilakukan secara terstruktur dan sistematis pada penelitian ini secara garis besar terbagi menjadi empat tahapan. berikut adalah gambar 3.2 tahapan penelitian yang dilakukan pada penelitian ini. pengumpulan data data visualdata fisiologis pemilihan dan persiapan dataset preprocessing data pembuatan modelekstraksi fitur penggabungan fitur evaluasi pemisahan dataset pembangunan model pelatihan model evaluasi model implementasi gambar 3. 2 tahapan penelitian 44 3.3. pemilihan dan persiapan dataset tahapan ini merupakan tahapan identifikasi awal dari penelitian meliputi identifikasi masalah penelitian yang berfokus pada masalah utama yaitu mendeteksi kantuk pada pengemudi menggunakan pemrosesan citra dan fisiologis . tahapan ini dilakukan untuk memasikan bahwa hanya data yang relevan berkualitas tinggi dan siap untuk dip roses lebih lanjut yang digunakan. pemilihan dataset memastikan bahwa dataset yang dikumpulkan relevan dengan tujuan penelitian yaitu hanya menggunakan data yang berkaitan dengan kondisi predriving serta memastikan bahwa data visual dan data fisiologis diambil pada waktu yang sama. tahapan pengumpulan data dan preprocessing data merupakan tahap awal untuk mempersiapkan dataset yang akan digunakan. 3.3.1 pengumpulan data data dibagi menjadi dua kategori utama yaitu data primer dan data sekunder . data primer diperoleh berdasarkan pengumpulan dan pengamatan langsung oleh peneliti berdasarkan kondisi subjek penelitian dan rekaman aktivitas fisik atau ekspresi wajah menggunakan kamera serta pengukuran fisiologis yang menggunakan perangkat wearable . data primer ini berupa data objektif dengan mengumpulkan data citra wajah dan pengukuran fisiologis . berikut merupakan gambar 3. 3 pengumpulan data. matapengumpulan data data visual citra wajahdata fisiologis ekgsaturasi oksigen spo2kamera smartwatch pulse oximetry gambar 3 .3 pengumpulan data dataset visual berupa citra wajah yang berfokus pada wajah pengemudi yang diambil menggunakan kamera dengan spesifikasi 12 mp. data visual dan fisiologis berupa data yang diambil dari partisipan dalam kondisi terjaga dan mengantuk . data fisiologis mencakup pengukuran langsung dari respons tubuh berupa sinyal 45 ekg elektrokardiogram yang merekam detak jantung hr variabilitas detak jantung atau heart rate variability hrv menggunakan perangkat wearable dan pengukuran saturasi oksigen dalam darah spo2 yang diukur menggunakan pulse oximeter. 3.3.2 preprocessing data melakukan analisis eksploratif data untuk memahami karakteristik dataset sehingga meningkatkan kualitas deteksi . preprocessing yang dilakukan yaitu pre processing citra dan preprocessing data fisiologis. preprocessing citra yaitu dengan mendeteksi wajah dan mata normalisasi pencahayaan pemotongan area wajah yang relevan. ektraksi frame dari video menggunakan opencv . pre processing data fisiologis yaitu dengan normalisasi data dan segmentasi. berikut merupakan gambar 3. 4 preprocessing data. data acquisitionfacial landmark detectionroi extraction gambar dari kameraeye detection data fisiologis ekg spo2 noise removal normalizationsave processed datasegmentationresize imagesnormalize pixel value data augmentation gambar 3. 4 preprocessing data data set yang dikumpulkan kemudian diolah yang meliputi normalisasi penghilangan noise dan teknik pra pemrosesan lainnya untuk membuat data siap digunakan dalam ekstraksi fitur. langkah ini melibatkan pembersihan dan penyiapan data untuk analisis. proses preprocessing untuk data visual atau data gambar yaitu 1. pengumpulan data visual dengan mengambil gambar wajah pengemudi menggunakan kamera berfo kus pada mata. 2. deteksi wajah dan deteksi mata menggunakan algoritma deteksi wajah seperti haar cascades atau dlib untuk mendetekasi dan melokalisasi wajah dalam gambar. 3. deteksi mata yaitu mendeteksi mata daam area wajah yang terdeteksi. 46 4. ekstraksi roi region of interest dengan mengambil area mata dari gambar. 5. teknik normalisasi untuk mengubah ukuran gambar mata menjadi dimensi yang konsisten missal nya 64x64 pixel serta menormalisasi nilai pixel gambar dalam rentang 0 1 atau 1 1. 6. augmentasi gambar dilakukan untuk meningkatkan variasi data seperti rotasi flipping horizontal atau vertikal zooming dan perubahan cahaya 7. penyimpanan data yang diproses dengan menyimpan gambar yang telah diproses dan fitur yang diekstraski dalam format terstruktur csv atau database . proses preprocessing untuk data fisiologis yaitu 1. pengumpulan data fisiologis menggunakan wearable untuk merekam detak jantung hr variabilitas detak jantung hrv dan saturasi oksigen spo2. 2. pembersihan data dengan menghilangkan noise dengan menggunakan teknik filtering dan imputasi data hilang dengan mengisi data yang hilang menggunakan metode seperti mean median atau interpolasi. 3. normalisasi data dengan min max sehingga menyesuaikan denga n skala data ke rentang yang konsisten 0 1. 4. segmentasi data dilakukan dengan membagi data menjadi segmen dengan ukuran waktu tetap yaitu 30 detik. 5. normalisasi data untuk memastikan konsistensi skala antar subjek dan pengukuran. 6. penyimpanan data yang d iproses yaitu data fisiologis dalam format terstruktur. langkah selanjutnya yaitu sinkronisasi data dengan menggabungkan data visual serta data fisiologis berdasarkan timestamp. selanjutnya memastikan bahwa data visual dan fisiologis yang telah disinkronk an mencerminkan kondisi yang sama pada waktu yang sama. selanjutnya yaitu menyimpan data yang telah disinkronkan dalam format yang mudah diakses untuk dianalisis lebih lanjut. 3.4. pembuatan model pembuatan model merupakan proses implementasi dari desain arsitektur yang telah direncanakan . langkah dari pembuatan model yaitu penulisan kode untuk membangun model sesuai dengan desain arsitektur yaitu cnn lstm dan svm. 47 selanjutnya mengonfigurasi model dengan optimizer fungsi loss dan metrik evaluasi. kemu dian melakukan pelatihan model menggunakan dataset yang telah dibagi menjadi training set dan validation set pada tahapan preprocessing . selanjutnya dilakukan validasi serta tuning hyperparameters untuk mengoptimalkan kinerja model. 3.4.1 ekstraksi fitur ekstraksi fitur dilakukan untuk menangkap karakteristik penting dari data yang telah diproses. fitur ini akan digunakan sebagai input untuk model pembelajaran mesin. ektraksi fitur dilakukan pada data visual berupa data gambar dan data fisiologis. 1. data v isual a. eye aspect ratio ear digunakan untuk mendeteksi apakah mata terbuka atau tertutup. di mana pi adalah titik titik landmark mata. b. pupil dilation digunakan untuk mengukur perubahan ukuran pupil. c. redness of eyes mengukur tingkat kemerahan pada ma ta. d. eye openess mengukur bukaan mata berdasarkan jarak vertikal antara kelopak mata atas dan bawah. 2. data fisiologis a. heart rate hr mengukur detak jantung per menit. b. heart rate variability hrv mengukur variabilitas detak jantung. c. respiratory rate rr mengukur laju pernapasan. d. spo2 saturasi oksigen dalam darah ekstraksi fitur dengan convolutional neural network cnn adalah proses yang menggunakan lapisan konvolusi dan pooling untuk menangkap fitur penting dari data gambar. langkah langkah ekstraksi fitur dengan cnn 1. convolutional layer menggunakan filter untuk menangkap fitur spasial dari gambar. 48 2. pooling layer mengurangi dimensi peta fitur sambil mempertahankan fitur penting. 3. fully connected layer menghubungkan peta fitur yang telah diratakan untuk melakukan klasifikasi atau ekstraksi fitur. 4. pelatihan model menyesuaikan bobot filter melalui backpropagation dengan data latih. 5. ekstraksi fitur menggunakan model yang telah dilatih untuk mengekstraksi fitur dari gambar baru. ekstraksi fitur dengan long short term memory lstm adalah proses yang menggunakan jaringan lstm untuk menangkap pola temporal dan hubungan jangka panjang dalam data sekuensial seperti data fisiologis ekg hr hrv rr dan spo2. lstm sangat efektif dal am menangani data yang memiliki ketergantungan waktu. ekstraksi fitur dengan lstm melibatkan beberapa langkah penting 1. menyiapkan data menyiapkan data sekuensial dalam bentuk yang sesuai untuk input ke lstm. 2. membangun model lstm membangun model lstm dengan lapisan lstm dan dense untuk ekstraksi fitur. 3. melatih model lstm melatih model menggunakan data sekuensial untuk menyesuaikan bobot jaringan. 4. ekstraksi fitur menggunakan model yang telah dilatih untuk mengekstraksi fitur dari data seku ensial baru. 3.4.2 penggabungan fitur fitur fitur yang telah diekstraksi dari ekstraksi fitur dengan model cnn yaitu dari gambar visul dengan mengekstraksi bagian mata dan ektraksi fitur dari data sekuensial dengan menggunakan lstm berupa data fisiologis . selanju tnya penggabungan fitur visual dan fitur sekuensial menggunakan metode penggabungan concatenation digabungkan membentuk satu set fitur komprehensif yang akan digunakan untuk pelatihan model yaitu klasifikasi akhir menggunakan model svm. 49 3.4.3 pemisahan dataset pembagian dataset merupakan langkah penting dalam proses pelatihan dan evaluasi model. merujuk pada penelitian li k. gong y. ren z. 2020 untuk pembagian dataset dibagi menjadi tiga bagian yaitu training set 40 validation set 10 dan test set 50 namun pada penelitian ini pembagian dataset yang terdiri dari data gambar dan data fisiologis dibagi menjadi berikut 1. training set 75 data yang digunakan untuk melatih melatih model . 2. validation set 15 digu nakan untuk tuning hyperparameters dan memilih model terbaik . 3. test set 15 digunakan untuk mengevaluasi kinerja akhir model . 3.4.4 desain arsitektur desain a rsitektur merupakan proses menentukan struktur dan komponen model yang akan dibangun yang terdiri dari jenis model jumlah dan jenis layer fungsi aktivasi teknik regularisasi dan konfigurasi model. jenis model penelitian ini melibatkan dua model utama yaitu convolutional neural network cnn untuk data visual dan long short term memory lstm untuk data fisiologis. hasil dari kedua model digabungkan dan diklasifikasikan menggunakan support vector machine svm. model ini terdiri dari tiga tahapan yaitu akuisisi data pre processing data ekstraksi fitur penggabungan fitur dan klasifikasi dengan svm dan output sistem . berikut merupakan gambar 3. 5 arsitektur model. ear pupil dilation redness of eyes eye openesspreprocessing alignmentmata akuisisi databehavioral fisiologis ekstraksi fiturklasifikasidriver mengantuk alarm atau notifikasi tidak layak alarm atau notifikasi layak yatidak perangkat sensor wearablemembaca hrv hr dan spo2object cnn lstmpenggabungan fitur ekstraksi gambar 3. 5 arsitektur model tahap ini mencakup perancangan arsitektur cnn yang akan digunakan termasuk pemilihan jumlah dan jenis layer fungsi aktivasi dan teknik regularisasi. 50 digunakan untuk mengolah data visual seperti mengenali mata tertutup atau mulut menguap sebagai indikator kantuk. lstm digunakan untuk menga nalisis data fisiologis yang berurutan seperti pola detak jantung yang m enunjukkan kelelahan atau penurunan kewaspadaan. menggabungkan fitur yang diekstrak dari cnn dan lstm untuk mendapatkan representasi data yang komprehensif memastikan bahwa model dapat mengidentifikasi kantuk berdasarkan kombinasi indikator visual dan fis iologis. selanjutnya yaitu menggunakan support vector machines svm untuk mengklasifikasikan data sebagai kantuk atau tidak kantuk. svm dipilih karena kemampuannya dalam mengklasifikasikan data yang kompleks dan memberikan batas keputusan yang jelas layak atau tidak layak pengemudi untuk berkendara. jika pengklasifikasi mendeteksi keadaan mengantuk maka pengklasifikasi menghasilkan alarm atau notifikasi pemberitahuan untuk memberi tahu bahwa pengemudi tidak layak untuk berkendara atau kembali ke f ase pertama dan memulai ulang prosedur. 3.4.5 pelatihan model dengan dataset pelatihan m odel dilakukan dengan menggunakan training set dengan tuning hyperparamaters berdasarkan kinerja pada validation set. pelatihan model dilakukan dengan model svm menggunakan training set. 3.5 evaluasi model gabungan ini dievaluasi menggunakan metrik seperti akurasi presisi recall dan f1score untuk memastikan performa dan keandalannya. implementasi sistem ini diharapkan dapat memberikan notifikasi atau peringatan kepada pengemudi jika tanda tanda kantuk terdeteksi selama kondisi predriving sehingga dapat meningkatkan keselamatan berkendara secara signifikan. berdasarkan hasil validasi model dapat ditune atau dioptimalkan untuk meningkatkan performa misalnya dengan mengubah arsitektur parameter atau teknik training . 3.6 implementasi setelah penyempurnaan model dianggap siap untuk digunakan. model ini harus dapat secara akurat mendeteksi kantuk pengemudi dalam berbagai kondisi dengan minimal kesalahan. langkah selanjutnya yaitu penerapan model dalam sistem nyata dan pemantauan efektivitasnya dalam kondisi pengemudi pada 51 lingkungan predriving. model yang telah dioptimalkan diintegrasikan ke dalam sistem deteksi dini kantuk untuk pengujian awal. selanjutn ya yaitu m elakukan uji coba lapangan untuk mengevaluasi efektivitas sistem dalam kondisi nyata memungkinkan pengumpulan feedback untuk perbaikan lebih lanjut. 3.7 rencana kegiatan tabel 3.1 rencana kegiatan no nama kegiatan bulan 1 2 3 4 5 6 7 8 9 10 11 12 1 kajian literatur 2 perencanaan penelitian 3. pengumpulan data 4. prapemrosesan data 5. pembuatan model 6. pelatihan dan evaluasi model 7. penyusunan laporan akhir 8. presentasi laporan akhir 9. publikasi jurnal ilmiah internasional 10. pengajuan hki,3.1 kerangka umum penelitian ini bertujuan untuk mengembangkan sistem deteksi dini kantuk sebelum berkendara dengan menggunakan kombinasi data visual berupa data citra wajah dan data fisiologis. kondisi predriving mengacu pada kondisi sebelum pengemudi memulai perjalanan sehingga sistem ini sangat penting untuk mencegah risiko kecelakaan di jalan . sistem ini mengintegrasikan teknologi pengenalan wajah dan analisis data fisiologis untuk memberikan deteksi yang lebih akurat. blok d iagram secara umum yang digunakan pada penelitian ini dapat dilihat pada gambar 3.1 blok diagram. objek preprocessing data fisiologis ekstrasi fiturpenggabungan fitur klasifikasi data image data visual kantuk ya tidak gambar 3.1 blok diagram model ini terdiri dari tiga tahapan yaitu input proses dan output . penelitian deteksi dini kantuk untuk kondisi predriving menggabungkan data visual yaitu pengumpulan data citra wajah pengemudi yang diambil menggunakan kamera serta data fisiologis yang diukur berupa data ekg menggunakan perangkat wearable yaitu smartwatch dan pulse oximeter untuk mengukur saturasi oksigen spo2 . tahapan preprocessing dan ekstraksi fitur dilakukan pada kedua jenis data yaitu data citra gambar dan data fisiologis. model convolutional neural network cnn digunakan untuk mengekst raksi fitur dari data citra wajah yang merupakan data visual sementara long short term memory lstm digunakan untuk memproses data fisiologis yang bersifat timeseries. fitur fitur yang diekstraksi dari kedua model ini digabungkan untuk menghasilkan vect or fitur gabungan. vektor fitur ini kemudian digunakan sebagai input untuk model support vector machine 43 svm yang melakukan klasifikasi akhir untuk mendeteksi kantuk. hasil deteksi kemudian digunakan untuk memberikan peringatan kepada pengemudi layak tidak nya pengemudi untuk berkendara. 3.2 tahapan peneletian tahapan penelitian merupakan urutan atau langkah langkah yang dilakukan secara terstruktur dan sistematis pada penelitian ini secara garis besar terbagi menjadi empat tahapan. pengumpulan data data visualdata fisiologis pemilihan dan persiapan dataset preprocessing data pembuatan modelekstraksi fitur penggabungan fitur evaluasi pemisahan dataset pembangunan model pelatihan model evaluasi model implementasi gambar 3. 2 tahapan penelitian 44 3.3. pemilihan dan persiapan dataset tahapan ini merupakan tahapan identifikasi awal dari penelitian meliputi identifikasi masalah penelitian yang berfokus pada masalah utama yaitu mendeteksi kantuk pada pengemudi menggunakan pemrosesan citra dan fisiologis . pemilihan dataset memastikan bahwa dataset yang dikumpulkan relevan dengan tujuan penelitian yaitu hanya menggunakan data yang berkaitan dengan kondisi predriving serta memastikan bahwa data visual dan data fisiologis diambil pada waktu yang sama. data primer diperoleh berdasarkan pengumpulan dan pengamatan langsung oleh peneliti berdasarkan kondisi subjek penelitian dan rekaman aktivitas fisik atau ekspresi wajah menggunakan kamera serta pengukuran fisiologis yang menggunakan perangkat wearable . data visual dan fisiologis berupa data yang diambil dari partisipan dalam kondisi terjaga dan mengantuk . 3.3.2 preprocessing data melakukan analisis eksploratif data untuk memahami karakteristik dataset sehingga meningkatkan kualitas deteksi . augmentasi gambar dilakukan untuk meningkatkan variasi data seperti rotasi flipping horizontal atau vertikal zooming dan perubahan cahaya 7. 3.4. pembuatan model pembuatan model merupakan proses implementasi dari desain arsitektur yang telah direncanakan . langkah dari pembuatan model yaitu penulisan kode untuk membangun model sesuai dengan desain arsitektur yaitu cnn lstm dan svm. redness of eyes mengukur tingkat kemerahan pada ma ta. pooling layer mengurangi dimensi peta fitur sambil mempertahankan fitur penting. membangun model lstm membangun model lstm dengan lapisan lstm dan dense untuk ekstraksi fitur. 3.4.4 desain arsitektur desain a rsitektur merupakan proses menentukan struktur dan komponen model yang akan dibangun yang terdiri dari jenis model jumlah dan jenis layer fungsi aktivasi teknik regularisasi dan konfigurasi model. hasil dari kedua model digabungkan dan diklasifikasikan menggunakan support vector machine svm. 50 digunakan untuk mengolah data visual seperti mengenali mata tertutup atau mulut menguap sebagai indikator kantuk. selanjutnya yaitu menggunakan support vector machines svm untuk mengklasifikasikan data sebagai kantuk atau tidak kantuk. svm dipilih karena kemampuannya dalam mengklasifikasikan data yang kompleks dan memberikan batas keputusan yang jelas layak atau tidak layak pengemudi untuk berkendara. jika pengklasifikasi mendeteksi keadaan mengantuk maka pengklasifikasi menghasilkan alarm atau notifikasi pemberitahuan untuk memberi tahu bahwa pengemudi tidak layak untuk berkendara atau kembali ke f ase pertama dan memulai ulang prosedur. implementasi sistem ini diharapkan dapat memberikan notifikasi atau peringatan kepada pengemudi jika tanda tanda kantuk terdeteksi selama kondisi predriving sehingga dapat meningkatkan keselamatan berkendara secara signifikan. berdasarkan hasil validasi model dapat ditune atau dioptimalkan untuk meningkatkan performa misalnya dengan mengubah arsitektur parameter atau teknik training . 3.6 implementasi setelah penyempurnaan model dianggap siap untuk digunakan. model ini harus dapat secara akurat mendeteksi kantuk pengemudi dalam berbagai kondisi dengan minimal kesalahan. langkah selanjutnya yaitu penerapan model dalam sistem nyata dan pemantauan efektivitasnya dalam kondisi pengemudi pada 51 lingkungan predriving. model yang telah dioptimalkan diintegrasikan ke dalam sistem deteksi dini kantuk untuk pengujian awal. selanjutn ya yaitu m elakukan uji coba lapangan untuk mengevaluasi efektivitas sistem dalam kondisi nyata memungkinkan pengumpulan feedback untuk perbaikan lebih lanjut. 3.7 rencana kegiatan tabel 3.1 rencana kegiatan no nama kegiatan bulan 1 2 3 4 5 6 7 8 9 10 11 12 1 kajian literatur 2 perencanaan penelitian 3. pengumpulan data 4. prapemrosesan data 5. pembuatan model 6. pelatihan dan evaluasi model 7. penyusunan laporan akhir 8. presentasi laporan akhir 9. publikasi jurnal ilmiah internasional 10. pengajuan hki
Utami Lestari_Kualifikasi.txt,3.1 gambaran umum penelitian ini bertujuan untuk mengembangkan aplikasi berbasis large language model llm dengan arsitektur gpt 4 yang mampu melakukan telaah sejawatpeer review secara otomatis pada artikel ilmiah dari jurnal komputer. data utama yang digunakan adalah ar tikel ilmiah berbahasa indonesia dalam bidang ilmu komputer dari berbagai jurnal akademik. sebelum digunakan data akan diperiksa untuk menghilangkan informasi pribadi yang dapat mengidentifikasi penulis atau reviewer. aplikasi ini diharapkan dapat membant u para peneliti dan editor jurnal dalam menganalisis dan memperoleh wawasan dari artikel yang seringkali bersifat kompleks dan teknis. untuk melakukan penelitian ini perlu dilakukan beberapa tahapan hingga penelitian selesai tahapan yang dilaukan mulai dari pengumpulan data preprocessing data melakukan pemodelan untuk telaah sejawat mengevaluasi model dan validasi ahli . untuk tahapan penelitian dapat dilihat pada gambar 3.1. gambar 3. 1tahapan penelitian 3.1.1 pengumpulan data proses pengumpulan data dilakukan dengan cara mengumpulkan artikel ilmiah dari be rbagai sumber terbuka dengan topik artikel ilmu computer. pengumpulan data menggunakan teknik webscraping a rtikel yang telah dikumpulkan akan diproses melalui tahap preprocessing. 3.1.2 preprocessing data proses preprocessing data merupakan langkah yang sangat penting dalam persiapan data untuk pemodelan llm. proses ini melibatkan beberapa tahap penting yang bertujuan untuk membersihkan dan menyiapkan data teks agar sesuai dengan kebutuhan model serta menin gkatkan kualitas dan konsistensi representasi teks. proses preprocessing dilakukan melalui beberapa tahap seperti tokenisasi pembersihan teks normalisasi token encoding penghapusan stopword stemming segmentasi kalimat dan pemisahan dataset. gambar 3. 2 tahapan preprocessing tahap pertama adalah tokenisasi di mana teks dipecah menjadi unit unit yang lebih kecil yang dikenal sebagai token memungkinkan model untuk menganalisis teks pada tingkat yang lebih granular. selanjutnya dilakukan pembersihan teks untuk menghilangkan karakter atau simbol yang tidak diinginkan seperti tanda baca angka dan karakter khusus lainnya serta penghapusan spasi berlebih dan karakter yang tidak relevan. no rmalisasi juga dilakukan untuk mengubah teks menjadi bentuk standar termasuk mengubah semua huruf menjadi huruf kecil menghapus aksen dari huruf dan menangani variasi penulisan yang berbeda untuk kata yang sama. setelah itu token yang dihasilkan dari tokenisasi perlu diubah menjadi representasi numerik melalui token encoding menggunakan teknik embeddings dari model transformer. penghapusan stopword yaitu kata kata umum yang sering muncul dalam teks tetapi tidak memiliki makna khusus yang penting untuk analisis juga dilakukan untuk mengurangi di mensi data dan fokus pada kata kata yang lebih bermakna. proses selanjutnya adalah stemming dan lemmatisasi yang bertujuan untuk mengurangi kata kata ke bentuk dasar atau akar katanya dengan stemming memotong akhiran kata dan lemmatisasi menggunakan kamus bahasa untuk mengembalikan kata ke bentuk dasar yang benar secara gramatikal. selanjutnya s egmentasi kalimat dilakukan untuk memisahkan teks menjadi kalimat kalimat individu yang bisa dianalisis lebih lanjut secara terpisah. tahap terakhir dalam preproces sing adalah pemisahan dataset menjadi bagian bagian yang berbeda seperti data latih data validasi dan data uji yang penting untuk mengevaluasi kinerja model secara adil dan menghindari overfitting. melalui proses preprocessing yang cermat dan terstrukt ur data teks menjadi lebih bersih terorganisir dan siap digunakan dalam pemodelan sehingga tidak hanya meningkatkan efisiensi pemrosesan data tetapi juga memungkinkan model untuk belajar dan melakukan prediksi dengan lebih akurat. 3.1.3 pembuatan model llm setelah dataset yang di kumpulkan dan melalui proses preprocessing maka dilanjutkan tahap pemodelan dengan menggunakan llm. pada tahap ini dilakukan pemodelan dengan arsitektur gpt4 untuk platform tinjauan artikel ilmiah . proses pemodelan dimulai dengan fine tuning gpt 4 menggunakan dataset yang telah dipreproccesing sebelumnya. fine tuning dilakukan untuk menyesuaikan model dengan gaya penulisan dan terminologi spesifik yang digunakan dalam artikel ilmiah. selama fase pela tihan model dievaluasi secara be rkala untuk memastikan kinerjanya sesuai dengan harapan dan parameter model dioptimalkan untuk meningkatkan kualitas output. penggunaan gpt 4 untuk platform tinjauan artikel ilmiah dapat menyediakan analisis yang mendalam dan komprehensif membantu reviewer untuk lebih cepat dan efisien dalam menilai kualitas dan kontribusi sebuah artikel. hal ini tidak hanya meningkatkan produktivitas tetapi juga memastikan bahwa artikel yang dipublikasikan memenuhi standar ilmiah yang tinggi. 3.1.4 evaluasi model llm evaluasi model merupakan langkah yang penting dalam pengembangan sistem kecerdasan buatan karena memungkinkan untuk menilai kinerja dan efektivitas model dalam menyelesaikan tugas tertentu. proses evaluasi membantu mengidentifikasi kelemahan dan kekuatan model serta memberikan wawasan tentang seber apa baik model dapat digunakan. tanpa evaluasi yang tepat model yang dikembangkan dapat menghasilkan prediksi yang tidak akurat atau tidak dapat diandalkan yang berpotensi menyebabkan kinerja sistem yang buruk secara keseluruhan. pada penelitian ini dilakukan evaluasi model dengan melihat nilai akurasi presisi recall dan f1 score . 1. akurasi memberikan gambaran umum tentang seberapa baik model klasifikasi melakukan prediksi secara keseluruhan. 2. presisi memberikan informasi tentang seberapa banyak prediksi positif yang sebenarnya benar dari semua prediksi positif yang dilakukan oleh model. 3. recall memberikan informasi tentang seberapa banyak instance positif yang berhasil diidentifikasi oleh model dari semua instance positif yang 4. sebenarnya dalam dataset. 5. f1score berguna ketika kelas target tidak seimbang dalam dataset karena mencakup baik presisi maupun recall dalam perhitungannya. 3.1.5 validasi ahli proses validasi ahli ini memastikan bahwa model gpt 4 yang digunakan untuk telaah sejawat mampu memberikan evaluasi yang akurat relevan dan sesuai dengan standar akademik dengan masukan berharga dari para ahli di bidangnya. 3.2 jadwal penelitian jadwal penelitian bertujuan untuk mengatasi target waktu penelitian memastikan bahwa penelitian ini dapat diselesaikan sesuai dengan batas waktu yang telah ditetapkan. adanya jadwal penelitian diharapkan penelitian dapat berjalan secara efisien dan sesuai rencana sehingga memberikan kepastian bahwa semua tahapan penelitian dapat diselesaikan tepat pada waktunya. table jadwal penelitian dapat dilihat pada table 3.1 table 3. 1 jadwal penelitian no uraian kegiatan 2023 2024 9 10 11 12 1 2 3 4 5 6 7 8 9 10 11 12 1 penyusunan proposal 2 uji kualifikasi 3 evaluasi progres pertama 4 paper pertama 5 evaluasi progres kedua no uraian kegiatan 2025 2026 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 1 paper ke dua 2 evaluasi rkp 3 sidang tertutup 4 sidang terbuka,3.1 gambaran umum penelitian ini bertujuan untuk mengembangkan aplikasi berbasis large language model llm dengan arsitektur gpt 4 yang mampu melakukan telaah sejawatpeer review secara otomatis pada artikel ilmiah dari jurnal komputer. data utama yang digunakan adalah ar tikel ilmiah berbahasa indonesia dalam bidang ilmu komputer dari berbagai jurnal akademik. 2 tahapan preprocessing tahap pertama adalah tokenisasi di mana teks dipecah menjadi unit unit yang lebih kecil yang dikenal sebagai token memungkinkan model untuk menganalisis teks pada tingkat yang lebih granular. setelah itu token yang dihasilkan dari tokenisasi perlu diubah menjadi representasi numerik melalui token encoding menggunakan teknik embeddings dari model transformer. melalui proses preprocessing yang cermat dan terstrukt ur data teks menjadi lebih bersih terorganisir dan siap digunakan dalam pemodelan sehingga tidak hanya meningkatkan efisiensi pemrosesan data tetapi juga memungkinkan model untuk belajar dan melakukan prediksi dengan lebih akurat. 3.1.3 pembuatan model llm setelah dataset yang di kumpulkan dan melalui proses preprocessing maka dilanjutkan tahap pemodelan dengan menggunakan llm. selama fase pela tihan model dievaluasi secara be rkala untuk memastikan kinerjanya sesuai dengan harapan dan parameter model dioptimalkan untuk meningkatkan kualitas output. hal ini tidak hanya meningkatkan produktivitas tetapi juga memastikan bahwa artikel yang dipublikasikan memenuhi standar ilmiah yang tinggi. 3.1.4 evaluasi model llm evaluasi model merupakan langkah yang penting dalam pengembangan sistem kecerdasan buatan karena memungkinkan untuk menilai kinerja dan efektivitas model dalam menyelesaikan tugas tertentu. tanpa evaluasi yang tepat model yang dikembangkan dapat menghasilkan prediksi yang tidak akurat atau tidak dapat diandalkan yang berpotensi menyebabkan kinerja sistem yang buruk secara keseluruhan. recall memberikan informasi tentang seberapa banyak instance positif yang berhasil diidentifikasi oleh model dari semua instance positif yang 4. table jadwal penelitian dapat dilihat pada table 3.1 table 3. 1 jadwal penelitian no uraian kegiatan 2023 2024 9 10 11 12 1 2 3 4 5 6 7 8 9 10 11 12 1 penyusunan proposal 2 uji kualifikasi 3 evaluasi progres pertama 4 paper pertama 5 evaluasi progres kedua no uraian kegiatan 2025 2026 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 1 paper ke dua 2 evaluasi rkp 3 sidang tertutup 4 sidang terbuka
Yoga Panji Perdana Nugraha_Kualifikasi.txt,3.1 motivasi industri manufaktur memiliki berbagai macam produk yang ada di dalamnya. dalam upaya pemenuhan kualitas yang tinggi serta menjaga kepuasan pelanggan dan reputasi perusahaan maka mendeteksi produk yang cacat sedini mungkin merupakan aspek yang penting. sehingga motivasi dari disertasi ini adalah sebagai berikut. 1. pengembangan aplikasi pendeteksi cacat pada produk ini didasari keinginan peneliti untuk meningkatkan kinerja pengendalian kualitas pada industri manufaktur sehingga dapat membantu menjaga kualitas produk serta efisien si dalam kegiatan pengendalian kualitas. 2. untuk meminimalisir pemborosan waktu bahan baku biaya dan sumber daya lainnya karena deteksi cacat pada produk dilakukan sedini dan secepat mungkin. 3. meningkatkan efisiensi pada kegiatan inspeksi produk d engan mene rapkan otomatisasi mel alui aplikasi yang dikembangkan. 4. mengintegrasikan teknologi yang sedang berkembang seperti artificial intelligence dengan industri manufaktur sehingga tercipta manufaktur cerdas yang akan berakibat pendapatan profit perusahaan yang op timal. 5. memberikan kontribusi pemahaman dan pengembangan teknologi baru dalam deteksi objek sehingga bisa menjadi referensi untuk pembaca serta penelitian selanjutnya. 3.2 alur kerja riset alur kerja riset digambarkan melalui diagram alir. tujuannya agar penel itian dapat terstruktur sehingga tidak ada tah apan penelitian yang terlewat. secara umum b erikut ini merupakan diagram alir penelitian ini. tahap awal tahap pengembanganperancangan dan pembuatan prototype alat deteksi cacatpengumpulan data cacat objek uji coba prototype alat deketsi cacat objekperancangan model deteksi cacat objek menggunakan deep learning implementasi dan pelatihan model deteksi cacat objek evaluasi dan penyempurnaan model deteksi cacat objek pengujian model deteksi objek menggunakan deep learning pembuatan aplikasi pendeteksi objek cacattahap optimasi pengajuan hki dan jurnal internasional q 1 gambar 3. 1 diagram alir penelitian diagram alir penelitian di atas menggambarkan alur penelitian yang akan dilakukan. berikut ini adalah penjelasan dari diagram alir penelitian di atas. 1. tahap awal kegiatan yang dilakukan pada tahap awal ini adalah merancang dan membuat prototype alat deteksi cacat dan pengumpulan data cacat objek. prototype alat ini menggunakan ban berjalan dengan motor listrik sebagai penggeraknya dengan alat pencahayaan yang cukup. alat ini nantinya digunakan untuk mengumpulkan data yang akan digunakan untuk melakukan perancangan dan pelatihan m odel deteksi cacat objek. pengumpulan data dilakukan untuk memperoleh data yang dibutuhkan pada penelitian ini. data bisa berupa data primer dan data sekunder ataupun keduanya bergantung pada kebutuhan penelitian yang akan dilakukan. data primer dikumpulan dengan memotret objek pada ban berjalan menjadi citra baik citra bergerak maupun citra tak bergerak yang akan menjadi satu kesatuan yaitu dataset . data primer dikumpulkan menggunakan alat yang dirancang seperti di bawah ini. gambar 3. 2 rancangan prototipe alat gambar 3.2 di atas menggambarkan rancangan alat yang akan dikembangkan. alat tersebut pertama digunakan sebagai media untuk pengambilan data primer yaitu data citra dari objek yang akan dideteksi. objek berupa sekrup akan berjalan melalui ban berjalan conveyor yang nantinya akan ditangkap gambarnya oleh webcam atau kamera yang terhubung dengan komputer untuk menyimpan gambar tersebut untuk kebutuhan pelatihan model. sedangkan data sekunder dikumpulkan melalui website kaggle maupun website atau jurnal lain yang sejenis. hasil dari akuisisi citra ini akan digunakan untuk pelatihan dan pengujian data. sampel yang diambil adalah objek berupa sekrup yang terdapat kecacatan. data tersebut kemudian dikumpulkan menjadi sebuah da taset yang akan digunakan untuk melatih model. data data yang diambil kemudian dikelompokkan menjadi beberapa kelas sesuai dengan jenis cacat yang ada pada sekrup tersebut. luaran pada tahap ini adalah pengajuan hki untuk prototype alat pendeteksi cacat ob jek yang dirancang. 2. tahap pengembangan tahap ini terdapat beberapa kegiatan yang dilakukan. pertama adalah melakukan uji coba prototype alat deteksi cacat objek yang digambarkan pada gambar 3.2 di atas . uji coba dilakukan dengan menyesuaikan tinggi kamera tingkat pencahayaan kecepatan ban berjalan serta pengaturan tempat ban berjalan untuk menjaga efektivitas dan efisiensi dalam mendeteksi objek. kedua adalah merancang model untuk mendeteksi cacat objek dengan menggunakan deep learning . sebelum melatih da ta dilakukan preprocessing terlebih dahulu. kegiatan ini dilakukan dengan menggunakan website roboflow. preprocessing dilakukan mengoptimalkan pelatihan dengan menganotasi citra untuk menandai bagian penting dari citra region of interest menyamakan orie ntasi citra mengubah ukuran citra agar sama memperbanyak variasi data dengan augmentasi dan generalisir data sehingga menjadi satu kesatuan dataset yang lebih siap untuk dilatih. setelah preprocessing dilakukan maka diharapkan pelatihan data yang dilaku kan lebih optimal. pelatihan data dilakukan untuk melatih model mengenali citra yang akan dideteksi sehingga pada penerapannya mendapatkan hasil deteksi yang akurat dan optimal. pelatihan data dilakukan dengan menggunakan salah satu algoritma dari teknolog i kecerdasan artifisial yaitu deep learning dengan bahasa pemrograman yang digunakan adalah python. pada pelatihan data ini juga akan mendapatkan nilai pengukuran evaluasi measurment evaluation berupa accuracy recall and precision dan mean average prec ision map. pada umumnya pelatihan harus memiliki jumlah data dalam hal ini adalah citra yang lebih banyak dibandingkan pengujian. 3. tahap optimasi tahap pengembangan telah dilakukan kemudian masuk ke tahap optimasi. tahap ini terdapat kegiatan yaitu eval uasi dan penyempurnaan model deteksi cacat objek. evaluasi dan penyempurnaan dilakukan agar fitur yang ada pada aplikasi yang akan dikembangkan dapat ditampilkan dengan maksimal. fitur yang akan ditambahkan pada model pendeteksi objek berupa kemampuan komp uter untuk secara otomatis menyimpan hasil deteksi menjadi sebuah basis data. sehingga nantinya data tersebut dapat menjadi acuan bagi departemen terkait untuk inovasi ke depannya. setelah pelatihan data dilakukan maka selanjutnya adalah pengujian data. p engujian data dilakukan untuk menguji model sejauh mana dapat mendeteksi cacat dari suatu produk. pada pengujian data dilakukan dengan mengunggah data secara acak selain data yang digunakan pada pelatihan. pada akhirnya akan menampilkan output model dalam mendeteksi cacat pada produk. setelah itu maka dibangun aplikasi yang mampu mendeteksi cacat produk pada industri secara real time. aplikasi ini nantinya akan menampilkan hasil deteksi dari produk yang bergerak. informasi yang disampaikan antara lain kondi si dari produk cacat atau tidak serta bagian mana yang cacat akan ditandai oleh bounding box . hal ini akan dengan cepat membantu operator mengetahui cacat jenis apa yang terjadi. sehingga dapat ditindaklanjuti sesegera mungkin yang secara tidak langsung ju ga membantu dalam pengambilan keputusan. target penelitian ini adalah pengajuan hki serta publikasi artikeljurnal ilmiah internasional bereputasi q1 ieee access . 3.3 pendekatan pendekatan yang dilakukan adalah dengan menggunakan teknologi artificial int elligence dalam mengadopsi kemampuan manusia dalam mendeteksi objek. pendekatan ini menggabungkan antara pengolahan citra dan deep learning dengan memanfaatkan salah satu arsitektur yang dimilikinya. selain itu diterapkan juga pengukuran evaluasi seperti precision recall dan mean average precision map untuk memastikan model yang dikembangkan dapat digunakan dengan optimal. nantinya akan dikembangkan sebuah aplikasi yang kemungkinan berbasis web untuk mempermudah pengguna untuk mengambil gambar bergerak maupun tak bergerak yang kemudian mengirimnya ke sistem pendeteksi cacat dan menerima hasil deteksi secara real time. hasil deteksi secara real time dikehendaki agar produk dapat diperiksa selama proses produksi berlangsung sehingga cacat dapat dideteksi secepat dan seakurat mungkin. hal ini akan membantu operator untuk melakukan kegiatan inspeksi produk dengan efisien.,3.1 motivasi industri manufaktur memiliki berbagai macam produk yang ada di dalamnya. dalam upaya pemenuhan kualitas yang tinggi serta menjaga kepuasan pelanggan dan reputasi perusahaan maka mendeteksi produk yang cacat sedini mungkin merupakan aspek yang penting. pengembangan aplikasi pendeteksi cacat pada produk ini didasari keinginan peneliti untuk meningkatkan kinerja pengendalian kualitas pada industri manufaktur sehingga dapat membantu menjaga kualitas produk serta efisien si dalam kegiatan pengendalian kualitas. meningkatkan efisiensi pada kegiatan inspeksi produk d engan mene rapkan otomatisasi mel alui aplikasi yang dikembangkan. mengintegrasikan teknologi yang sedang berkembang seperti artificial intelligence dengan industri manufaktur sehingga tercipta manufaktur cerdas yang akan berakibat pendapatan profit perusahaan yang op timal. memberikan kontribusi pemahaman dan pengembangan teknologi baru dalam deteksi objek sehingga bisa menjadi referensi untuk pembaca serta penelitian selanjutnya. tahap awal tahap pengembanganperancangan dan pembuatan prototype alat deteksi cacatpengumpulan data cacat objek uji coba prototype alat deketsi cacat objekperancangan model deteksi cacat objek menggunakan deep learning implementasi dan pelatihan model deteksi cacat objek evaluasi dan penyempurnaan model deteksi cacat objek pengujian model deteksi objek menggunakan deep learning pembuatan aplikasi pendeteksi objek cacattahap optimasi pengajuan hki dan jurnal internasional q 1 gambar 3. tahap awal kegiatan yang dilakukan pada tahap awal ini adalah merancang dan membuat prototype alat deteksi cacat dan pengumpulan data cacat objek. luaran pada tahap ini adalah pengajuan hki untuk prototype alat pendeteksi cacat ob jek yang dirancang. kedua adalah merancang model untuk mendeteksi cacat objek dengan menggunakan deep learning . pelatihan data dilakukan untuk melatih model mengenali citra yang akan dideteksi sehingga pada penerapannya mendapatkan hasil deteksi yang akurat dan optimal. tahap optimasi tahap pengembangan telah dilakukan kemudian masuk ke tahap optimasi. tahap ini terdapat kegiatan yaitu eval uasi dan penyempurnaan model deteksi cacat objek. evaluasi dan penyempurnaan dilakukan agar fitur yang ada pada aplikasi yang akan dikembangkan dapat ditampilkan dengan maksimal. fitur yang akan ditambahkan pada model pendeteksi objek berupa kemampuan komp uter untuk secara otomatis menyimpan hasil deteksi menjadi sebuah basis data. pada akhirnya akan menampilkan output model dalam mendeteksi cacat pada produk. setelah itu maka dibangun aplikasi yang mampu mendeteksi cacat produk pada industri secara real time. aplikasi ini nantinya akan menampilkan hasil deteksi dari produk yang bergerak. selain itu diterapkan juga pengukuran evaluasi seperti precision recall dan mean average precision map untuk memastikan model yang dikembangkan dapat digunakan dengan optimal. nantinya akan dikembangkan sebuah aplikasi yang kemungkinan berbasis web untuk mempermudah pengguna untuk mengambil gambar bergerak maupun tak bergerak yang kemudian mengirimnya ke sistem pendeteksi cacat dan menerima hasil deteksi secara real time. hasil deteksi secara real time dikehendaki agar produk dapat diperiksa selama proses produksi berlangsung sehingga cacat dapat dideteksi secepat dan seakurat mungkin.
