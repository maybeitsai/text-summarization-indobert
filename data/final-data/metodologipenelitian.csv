nama_dokumen,kalimat,summary
Alfharizky Fauzi_Kualifikasi.txt,pada metodologi penelitian ini menjelaskan mengenai bagaimana proses dari analisis system perancangan dan analisis program yang dilakukan pada penelitian ini. berikut analisis dan perancangan pada penelitian ini. 3.1 tahapan penelitian gambar 3. 1 tahapan penelitian dokumentasi peneliti tahapan penelitian dapat dilihat pada gambar 3.1. tahapan penelitian yang dilakukan terdiri dari 9 tahapan yaitu dimulai dari studi literatur sebagai dasar penelitian analisis kebutuhan pada system yang akan dibangun pengumpulan dataset preprocessing data membangun model training model evaluasi model deployme nt model dan implementasi model yang telah dibuat ke dalam smartphone. saat program telah dijalankan program akan mengakuisisi dataset kemudian dataset akan melalui tahap preprocessing untuk m enormalkan data kemudian setelah melalui tahap preprocessing selanjutnya mentraining dataset yang sudah didapatkan jika dataset berhasil dilatih dan juga divalidasi maka berlanjut ke tahap berikutnya yaitu tahapan test ing dengan menerapkan model yang dibuat kedalam mobile phone atau smartphone. tahap selanjutnya jika camera telah menyala maka artinya sudah siap untuk mendeteksi objek jenis penyakit kulit . pada tahap terakhir yaitu saat ada objek jenis penyakit kulit yang masuk atau terdeteksi oleh camera m aka citra tersebut sudah dapat dilakukan proses klasifikasi kemudian divalidasikan bahwa data tersebut sama dengan yang ada pada database untuk memunculkan label nama pada dataset serta memunculkan nilai confidence pada citra jenis penyakit kulit yang terdete ksi. 3.2 analisis kebutuhan analisis kebutuhan merupakan menganalisis komponen yang diperlukan dalam pembuatan dan menjalankan program proses ini mencakup evaluasi identifikasi dan pemetaan kebutuhan dari berbagai perangkat yang terlibat dalam pembuatan system dan program pada penelitian ini. berikut analisis kebutuhan dari penelitian yang dibuat . 3.2.1. analisis kebutuhan perangkat keras perangkat keras yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan laptop acer predator helios neo 16 dan mobile phone atau smartphone xiaomi redmi note 7 dengan bahasa pemrograman python dengan spesifikasi yang dapat dilihat pada tabel 3.1. tabel 3. 1 daftar perangkat keras no perangkat qty spesifikasi 1 laptop acer predator helios neo 16 1 13th gen intelr core tm i7 13700hx 24 cpus 2.1ghz. random acces memory 8gb. graphics card nvidia geforce rtx 4060 8gb solid state drive 2tb. 2 mobile phone smartphone 1 camera hd 48mp 169 1280x720 f1.8 wide dual led flash hdr panorama rgb red green blue 3.2.2. analisis kebutuhan perangkat lunak perangkat lunak yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan operating system windows jupyter lab dengan bahasa pemrograman python dan visual studio sebagai text editor yang dapat dilihat pada tabel 3.2. tabel 3. 2 daftar perangkat keras no perangkat lunak version 1 operating system windows 11 pro single language 64 bit 10.0 build 22631 2 python 3.7.0 3 jupyter notebook labs 7.2.1 4.2.2 4 visual studio code may 2024 version 1.90 3.2.3. analisis objek program dengan menggunakan metode bidirectional image text matching deep learning ini mempunyai beberapa objek yang diterapkan pada penelitian ini yaitu 1. identifikasi berbagai macam jenis penyakit kulit dengan memunculkan citra gambar yang didapat dan deskripsi mengenai penyakit kulit yang teridentifikasi dibawah citra gambar untuk setiap objek penyakit kulit yang terdeteksi data yang digunakan memiliki variasi jenis penyakit kulit dengan kategori 2 penyakit kulit menular candidiasis dan molluscum dan 2 penyakit kulit tidak menular eczhema dan melanoma dengan masing masing kelas memiliki 1000 citra penyakit kulit yang di dapat pada website international dermnet nz dermnetnz.org 2024 dan the international skin imaging collaboration isic isicarchive.com 2024 . 2. program identifikasi berbagai macam objek penyakit kulit pada manusia ditampilkan secara real time menggunakan file upload kamera mobile phone. 3.3 akuisisi data set proses akuisisi citra dilakukan dengan melakukan pengunduhan data dari berbagai sumber online international skin disease seperti pada website dermnetnz.org dan www.isic archive.com yang merupakan referensi gratis berbasis website untuk informasi tentang berbagai kondisi kulit. website ini menyediakan gambar gambar resolusi tinggi dari berbagai penyakit kulit baik yang menular maupun tidak menular serta memberikan deskripsi lengkap tentang penyakti tersebut meliputi gejala dan pengobatan. citra yang diperoleh kemudian diseleksi berdasarkan fokus penelitian yaitu identifikasi penyakit kulit menular candidiasis dan molluscum dan tidak menular eczhema dan melanoma . data citra yang digunakan berasal dari pasien dewasa dan anak anak dengan kondisi kulit yang jelas menunjukkan ge jala atau kelainan seperti lesi atau ruam. contoh citra yang akan digunakan pada penelitian seperti terlihat pada gambar 3. 2 gambar 3. 2 citra penyakit kulit yang berasal dari website isic isicarchive.com 2024 3.3.1. dataset penyakit kulit dataset pada penelitian ini dibagi menjadi 2 bagian yaitu 80 data training dan 20 data testing objek jenis penyakit kulit . dataset bersumber dari citra data image dan deskripsi data teks beberapa jenis penyakit kulit sejumlah 4000 citra dengan 4 jenis penyakit kulit yang terdiri dari echzema melanoma candidiasis dan molluscum dengan memiliki 1000 citra berbeda setiap jenis penyakit kulit . dari keempat jenis penyakit kulit tersebut dibagi menjadi 2 kelompok sebagai penyakit kulit menular dan tidak menular. 3.3.1.1. data gambar data image ini mencakup berbagai jenis gambar yang menampilkan gejala dan karakteristik penyakit kulit yang digunakan pada peneltian ini eczhema melanoma candidiasis dan molluscum seperti ruam bintik bintik lepuhan atau lesi kulit lainnya . ukuran citra asli yang didapat berukuran 294 x 222 yang akan diproses menjadi 256 x 256 sehingga ukuran gambar menjadi presisi dan pengambilan gambar diambil dari berbagai posisi yang berbeda sehingga posisi dalam proses training data akan mendapat banyak posisi p engenalan 1 jenis penyakit kulit dengan format citra jpeg joint photographic experts group serta pengambilan gambar dengan kamera . penggunaan data gambar sangat penting dalam penelitian ini untuk membandingkan dan mempelajari pola visual yang terkait dengan berbagai penyakit kulit. data image pada penelitian ini terdiri 4000 gambar dari 4 jenis penyakit kulit yaitu eczhema melanoma candidiasis dan molluscum yang dibagi menjadi 2 kelompok menular dan tidak menular. data gambar dapat dilihat pada gambar 3.3 . gambar 3. 3 data gambar penyakit kulit 3.3.1.2. data teks data teks penyakit kulit merujuk kepada informasi tertulis yang berisi deskripsi dan karakteristik berbagai kondisi dermatologis. data pada penelitian ini meliputi penjelasan tentang gejala gejala khas seperti gatal gatal perubahan warna kulit tekstur dan lokasi lesi serta penjelasan mengenai cara penanganan maupun pengobatan yang dapat dilakukan pasien . informasi ini penting untuk diagnosis dan pemahaman lebih lanjut tentang berbagai penyakit kulit seperti dermatitis eksim psoriasis dan infeksi jamur kulit. pada penelitian ini data teks diproses menggunakan teknik pengolahan bahasa alami atau natural language processing nlp untuk mengidentifikasi kata kunci dan pola yang terkait dengan setiap kondisi kulit. berikut data teks yang digunakan pada penelitian ini dapat dilihat pada tabel 3.3 tabel 3.,berikut analisis kebutuhan dari penelitian yang dibuat . graphics card nvidia geforce rtx 4060 8gb solid state drive 2tb. 2. program identifikasi berbagai macam objek penyakit kulit pada manusia ditampilkan secara real time menggunakan file upload kamera mobile phone. 3.3 akuisisi data set proses akuisisi citra dilakukan dengan melakukan pengunduhan data dari berbagai sumber online international skin disease seperti pada website dermnetnz.org dan www.isic archive.com yang merupakan referensi gratis berbasis website untuk informasi tentang berbagai kondisi kulit. website ini menyediakan gambar gambar resolusi tinggi dari berbagai penyakit kulit baik yang menular maupun tidak menular serta memberikan deskripsi lengkap tentang penyakti tersebut meliputi gejala dan pengobatan. data citra yang digunakan berasal dari pasien dewasa dan anak anak dengan kondisi kulit yang jelas menunjukkan ge jala atau kelainan seperti lesi atau ruam. contoh citra yang akan digunakan pada penelitian seperti terlihat pada gambar 3. dataset bersumber dari citra data image dan deskripsi data teks beberapa jenis penyakit kulit sejumlah 4000 citra dengan 4 jenis penyakit kulit yang terdiri dari echzema melanoma candidiasis dan molluscum dengan memiliki 1000 citra berbeda setiap jenis penyakit kulit . dari keempat jenis penyakit kulit tersebut dibagi menjadi 2 kelompok sebagai penyakit kulit menular dan tidak menular. data image pada penelitian ini terdiri 4000 gambar dari 4 jenis penyakit kulit yaitu eczhema melanoma candidiasis dan molluscum yang dibagi menjadi 2 kelompok menular dan tidak menular.
Alifurrohman_Kualifikasi.txt,"3.1 Kerangka Umum Penelitian
     Berikut ini merupakan kerangka penelitian yang menjelaskan tahapan yang dilakukan dalam penelitan ini. Berikut gambar 3.1 diagram alir penelitian

Persiapan Data
Definisikan Ukuran Input dan Parameter
Definisikan Multi-Head Attention
Desain Model
Definisikan DQN dengan Lapisan Tersembunyi
Output Layer untuk Q-values
Fungsi untuk Memilih Tindakan menggunakan
Strategi e-greedy
Fungsi untuk Memperbarui Model dengan
Pengalaman dari Replay Buffer
Gambar 3.1 Diagram Alir Penelitian


3.2 Pengumpulan Data
     Langkah awal adalah mengumpulkan dataset yang akurat dan relevan. Dataset didapatkan dari data sekunder, dataset ini merupakan hal yang penting dari simulasi dan eksperimen, mencakup koordinat lokasi yang mungkin meliputi lokasi depot dan titik pengiriman, jendela waktu untuk setiap pengiriman yang menentukan batas awal dan akhir kapan pengiriman harus dilakukan, serta jumlah kendaraan. Data ini harus mencerminkan situasi dunia nyata untuk memastikan bahwa model yang dikembangkan dapat diaplikasikan secara praktis. 3.3 Persiapan Data
     Langkah berikutnya adalah persiapan data. Pada persiapan data dilakukan normalisasi data. Normalisasi merupakan proses penting untuk menyamakan skala data, memastikan bahwa model dapat memprosesnya dengan efisien. Normalisasi min-max digunakan pada penelitian ini. Min-max adalah teknik yang mengubah skala nilai data ke dalam rentang baru seperti 0 hingga 1 atau -1 hingga 1. Teknik ini memastikan bahwa setiap fitur atau kolom data memberikan kontribusi yang seimbang dalam analisis tanpa membiarkan fitur dengan skala besar mendominasi. Pengecekan matriks korelasi dilakukan untuk memahami hubungan antara variabel-variabel dalam dataset. Korelasi membantu mengidentifikasi fitur-fitur yang saling terkait dan memberikan wawasan tentang bagaimana setiap fitur dapat mempengaruhi model prediksi rute. Koefisien Korelasi Pearson digunakan untuk
mengukur hubungan linear antara fitur. 3.4 Desain model
     Implementasi Deep Q-Network (DQN) dengan mekanisme attention untuk Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) melibatkan beberapa langkah utama, mulai dari pemilihan kerangka kerja hingga pembuatan lingkungan simulasi. 1. Pemilihan Kerangka Kerja
     Kerangka kerja yang digunakan yaitu TensorFlow, dimana kerangka kerja ini menawarkan lingkungan yang komprehensif dengan TensorBoard untuk visualisasi, serta dukungan terhadap TPU untuk akselerasi komputasi. TensorFlow mungkin lebih cocok untuk produksi dan skala besar. 2. Desain model DQN dan Multi header-attention
     DQN adalah algoritma pembelajaran penguatan yang menggunakan jaringan saraf tiruan untuk memperkirakan fungsi nilai Q, yang merepresentasikan nilai maksimum hadiah kumulatif yang diharapkan, diberikan sebuah state dan semua strategi yang mungkin diambil. Implementasi DQN melibatkan beberapa komponen utama:
Jaringan Q: Jaringan ini memperkirakan nilai Q untuk setiap aksi dari state tertentu. Dalam kasus DVRPTW, input bisa berupa representasi dari state saat ini (misalnya, lokasi kendaraan, status pengiriman) dan output adalah nilai Q untuk setiap kemungkinan aksi (misalnya, memilih lokasi pengiriman berikutnya). Memory Replay: Untuk meningkatkan stabilitas dan efisiensi pembelajaran, DQN menggunakan teknik memory replay, di mana transisi (state, aksi, reward, state baru) disimpan dalam sebuah buffer. Batch transisi ini kemudian digunakan untuk melatih jaringan Q, memungkinkan pengalaman dari masa lalu digunakan kembali. Strategi Eksplorasi: Seperti e-greedy, di mana aksi acak dipilih dengan probabilitas e untuk mendorong eksplorasi lingkungan. Mekanisme attention terdiri dari tiga matriks utama: Query (Q), Key (K), dan Value (V) untuk setiap head i. Adapun langkah-langkahnya implementasinya sebagai berikut:
a. Definisikan Ukuran Input dan Parameter
      Mentukan jumlah fitur input, dimensi embedding, jumlah heads untuk mekanisme attention, dan jumlah unit dalam lapisan tersembunyi DQN. Serta jumlah tindakan yang mungkin dilakukan oleh agen.","Berikut gambar 3.1 diagram alir penelitian

Persiapan Data
Definisikan Ukuran Input dan Parameter
Definisikan Multi-Head Attention
Desain Model
Definisikan DQN dengan Lapisan Tersembunyi
Output Layer untuk Q-values
Fungsi untuk Memilih Tindakan menggunakan
Strategi e-greedy
Fungsi untuk Memperbarui Model dengan
Pengalaman dari Replay Buffer
Gambar 3.1 Diagram Alir Penelitian


3.2 Pengumpulan Data
     Langkah awal adalah mengumpulkan dataset yang akurat dan relevan. Min-max adalah teknik yang mengubah skala nilai data ke dalam rentang baru seperti 0 hingga 1 atau -1 hingga 1. 3.4 Desain model
     Implementasi Deep Q-Network (DQN) dengan mekanisme attention untuk Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) melibatkan beberapa langkah utama, mulai dari pemilihan kerangka kerja hingga pembuatan lingkungan simulasi. 1. Implementasi DQN melibatkan beberapa komponen utama:
Jaringan Q: Jaringan ini memperkirakan nilai Q untuk setiap aksi dari state tertentu. Batch transisi ini kemudian digunakan untuk melatih jaringan Q, memungkinkan pengalaman dari masa lalu digunakan kembali. Serta jumlah tindakan yang mungkin dilakukan oleh agen."
Armando Tirta Dwilaga_Kualifikasi.txt,3.1 gambaran umum penelitian penelitian ini digunakan untuk mengatasi sensitivitas terhadap cacat pada gambar ban dengan melibatkan penggunaan jaringan syaraf menggunakan algoritma convolutional neural network cnn dan membangun model atau kerangka kerja menggunakan keras. berikut adalah gambar 3.1 blok diagram gambaran umum penelitian. data preparation data augmentasi data splitting model training forward pass model evaluation backward passfinetuning if neededinput unit processing unit output unit model deployment inference12 gambar 3.1 blok diagram gambaran umum penelitian berdasarkan gambar 3.1 blok diagram gambaran umum penelitian maka dapat dijelaskan di blok tersebut terbagi menjadi 3 bagian yaitu bagian pertama adalah unit masukan berisikan data preparation di mana gambar ban dimuat diubah menjadi format yang sesuai dipersiapkan untuk pelatihan model convolutional neural network cnn seperti pemrosesan gambar ban selanjutnya data augmentation di mana data dibuat lebih ber variasi dari training data yang ada sehingga dapat meningkatkan keberagaman training data tanpa h arus mengambil data baru mencakup rotasi pergeseran horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel selanjutnya data di mana dataset yang telah di augmentasi dan disiapkan dibagi menjadi subset yang berbeda untuk training untuk melatih model validation untuk menyempurnakan model serta me mvalidasi performanya selama pelatihan dan testing untuk mengevaluasi kinerja model akhir . data set dibagi menjadi training data validation data dan testing data dalam proporsi tertentu. bagian kedua adalah unit pemrosesan yang bertindak adalah model training forward pass tahap di mana input diproses melalui model untuk menghasilkan prediksi tujuannya melatih model convolutional neural network cnn menggunakan dataset pelatihan di mana data dari unit masukan diteruskan melalui jaringan neural di lakukan transformasi linier konvulasi dan non linier fungsi aktivasi dilakukan pada data di setiap lapisan untuk menghasilkan output prediksi yang melibatkan komputasi di setiap neuron dan lapisan jaringan yang merupakan inti dari proses pembelajaran dalam jaringan saraf. selanjutnya unit pemrosesan finetuning tujuannya dilakukan untuk menyempurnakan model lebih lanjut setelah pelatihan awal dengan dataset yang lebih kecil atau lebih spesifik nantinya. proses di dalam finetuning menyesuaikan bobot menggunakan kumpulan data yang lebih kecil untuk menyesuaikan bobot model untuk performa yang lebih baik pelatihan khusus fokus pada fitur data yang lebih relevan dengan objek . bagian ketiga adalah unit keluaran yang bertindak ada proses model evaluatioan backward pass tahap di mana gradien memperbarui parameter model dalam arah yang akan mengurangi fungsi loss dari fungsi loss metrik yang mengukur seberapa baik atau buruk model melakukan prediksi dibandingkan nilai aktualnya dihitung dan digunakan untuk memperbarui parameter model selama pelatihan tujuannya mengevaluasi performa model yang dilatih dan model dievaluasi menggunakan metrik yang relevan accuracy precision recall dan f1 score berdasarkan prediksi yang dihasilkan dari model terhadap validasi atau uji data. output dari proses ini adalah tentang hasil evaluasi model yang memberikan informasi kinerja model. selanjutnya ada dua alur pilihan yang bisa dilakukan alur pertama jika hasil prediksi sudah sesuai dengan keinginan maka bisa langsung masuk ke model deployment inference dan alu r kedua jika hasil prediksi masih perlu diperbaiki pada bagian unit pemrosesan terlebih dahulu fine tuning untuk penggunaan data set lebih kecil jika menunjukan model belum mencapai performa yang diharapkan baru masuk ke model deployment inference tujuannya menerapkan model terlatih untuk membuat prediksi pada data baru yang belum terlihat. model deployment inference yang telah dilatih digunakan untuk membuat prediksi pada data baru atau dalam situasi dunia nyata tahap di mana model menerima input baru dan menghasilkan output berdasarkan pada pembelajaran yang dilakukan selama proses pelatihan dan merupakan output akhir dari keseluruhan proses di mana model mengambil keputusan atau membuat prediksi berdasarkan pada pengalaman yang telah diperoleh selama pelatihan. 3.2. tahapan penelitian penelitian ini di dalamnya terdapat tahapan tahapan yang dilakukan untuk membentuk satu kesatuan yang utuh dari awal sampai akhir dan membentuk kerangka penelitian mengenai klasifikasi pada produk ban menggunakan algoritma convolutional neural network cnn . berikut gambar 3.2 tahapan penelitian. study of literature data acquisition data augmentation data splitting model buildingdata preprocessing model evaluation testing gambar 3.2 tahapan penelitian berdasarkan gambar 3.2 tahapan penelitian maka dapat dijelaskan proses yang terlibat di dalamnya ada 8 yaitu studi literatur data aquisition data preprocessing data augmentation texture feature extraction data splitting model building dan model evaluation testing di mana tahap ke dua sampai lima merupakan tahap proses menyiapkan sebuah data sebelum dilakukan pemodelan. 3.2.1 studi literatur tahap pertama adalah studi literatur di mana studi yang dilakukan berasal dari artikel ilmiah dan buku yang menunjang dalam menganalisis terkait dengan metode pen gukuran kualitas mengenai klasifikasi produk ban meninjau penggunaan pembelajaran mesin algoritma convolutional neural network cnn dari beberapa tahun ke belakang dalam konteks peng ukuran kualitas untuk klasifikasi terhadap kondisi kondisi produk ban . sehingga dapat menemukan teknik terbaik yang dapat diaplikasikan pada masalah yang ada. berikut merupakan gambar 3. 3 tahapan study literature . study of literature load libraries initialize imagedatagenerator set image directory and parameters create test training and validation dataset gambar 3. 3 tahapan study literature 3.2.2 data aquisition tahap k edua adalah data aquisition dengan mengumpulkan kumpulan data sesuai tujuan penelitian dengan target untuk kumpulan data gambar ban untuk training data validation data dan testing data memastikan bahwa kumpulan data tersebut memiliki varian yang secara akurat memang mewakili kondisi produk ban dan diperoleh dari sumber sumber terpercaya . berikut merupakan gambar 3. 4 tahapan data aquisition . data acquisition normal defecttire dataset gambar 3. 4 tahapan data aquisition 3.2.3 data preprocessing tahap ketiga adalah data preprocessing melakukan pra pemrosesan data untuk menyiapkan gambar untuk model pelatihan dan pengujian proses ini meliputi normalisasi dan penskalaan dengan fitur dalam program image data generator . bermaksud merapikan menata dan menyiapkan data untuk pemeriksaan tambahan. normalisasi data pengkodean variabel mengatasi nilai yang hilang menghapus data yang tidak relevan atau hilang dan modifikasi data lainnya untuk memenuhi persyaratan analisis a dalah persiapan data. berikut merupakan gambar 3.5 tahapan data preprocessing . data preprocessing data normalization data scalinginitiation split data into training and validation sets rescale target_size gambar 3. 5 tahapan data preprocessing 3.2.4 data augmentation tahap keempat adalah data augmentation meningkatkan variasi dalam dataset dengan teknik augmentasi data menggunakan operasi seperti rotasi pergeserarn horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel untuk memperkaya dataset dan mengurangi overfitting saat disajikan dengan data baru yang belum pernah dilihat sebelumnya performa model akan menurun drastis karena model tersebut dapat menyesuaikan diri dengan kumpulan training data dengan sangat efektif. augmentasi data dilakukan dengan dua cara secara statis dan dinamis yang artinya secara statis yaitu menambah data secara fisiknya dan dinamis tidak menambah secara fisik tetapi secara k uantitas dataset yang dapat diakses secara fisik di komputer tidak bertambah ketika image data generator digunakan pada dataset. sebaliknya pada saat runtime hanya menghasilkan variasi dari gambar yang sudah ada dibuat secara dinami s dan cukup bagi model untuk berlatih dari berbagai kondisi gambar ban yang ada pada kenyataaanya.,data preparation data augmentasi data splitting model training forward pass model evaluation backward passfinetuning if neededinput unit processing unit output unit model deployment inference12 gambar 3.1 blok diagram gambaran umum penelitian berdasarkan gambar 3.1 blok diagram gambaran umum penelitian maka dapat dijelaskan di blok tersebut terbagi menjadi 3 bagian yaitu bagian pertama adalah unit masukan berisikan data preparation di mana gambar ban dimuat diubah menjadi format yang sesuai dipersiapkan untuk pelatihan model convolutional neural network cnn seperti pemrosesan gambar ban selanjutnya data augmentation di mana data dibuat lebih ber variasi dari training data yang ada sehingga dapat meningkatkan keberagaman training data tanpa h arus mengambil data baru mencakup rotasi pergeseran horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel selanjutnya data di mana dataset yang telah di augmentasi dan disiapkan dibagi menjadi subset yang berbeda untuk training untuk melatih model validation untuk menyempurnakan model serta me mvalidasi performanya selama pelatihan dan testing untuk mengevaluasi kinerja model akhir . selanjutnya ada dua alur pilihan yang bisa dilakukan alur pertama jika hasil prediksi sudah sesuai dengan keinginan maka bisa langsung masuk ke model deployment inference dan alu r kedua jika hasil prediksi masih perlu diperbaiki pada bagian unit pemrosesan terlebih dahulu fine tuning untuk penggunaan data set lebih kecil jika menunjukan model belum mencapai performa yang diharapkan baru masuk ke model deployment inference tujuannya menerapkan model terlatih untuk membuat prediksi pada data baru yang belum terlihat. model deployment inference yang telah dilatih digunakan untuk membuat prediksi pada data baru atau dalam situasi dunia nyata tahap di mana model menerima input baru dan menghasilkan output berdasarkan pada pembelajaran yang dilakukan selama proses pelatihan dan merupakan output akhir dari keseluruhan proses di mana model mengambil keputusan atau membuat prediksi berdasarkan pada pengalaman yang telah diperoleh selama pelatihan. 3.2. tahapan penelitian penelitian ini di dalamnya terdapat tahapan tahapan yang dilakukan untuk membentuk satu kesatuan yang utuh dari awal sampai akhir dan membentuk kerangka penelitian mengenai klasifikasi pada produk ban menggunakan algoritma convolutional neural network cnn . berikut gambar 3.2 tahapan penelitian. 3.2.1 studi literatur tahap pertama adalah studi literatur di mana studi yang dilakukan berasal dari artikel ilmiah dan buku yang menunjang dalam menganalisis terkait dengan metode pen gukuran kualitas mengenai klasifikasi produk ban meninjau penggunaan pembelajaran mesin algoritma convolutional neural network cnn dari beberapa tahun ke belakang dalam konteks peng ukuran kualitas untuk klasifikasi terhadap kondisi kondisi produk ban . sehingga dapat menemukan teknik terbaik yang dapat diaplikasikan pada masalah yang ada. berikut merupakan gambar 3. 3 tahapan study literature .
Devi Resviani_KUALIFIKASI.txt,3.1 tahapan penelitian tahapan penelitian merupakan serangkaian langkah langkah yang dilakukan dalam penelitian. gambaran mengenai tahapan penelitian ini dapat dilihat pada gambar 3.1. studi literatur pengumpulan dan analisis data preprocessing data pemilihan algoritma yang efektif pengembangan model machine learning sistem peringatan pemeliharaan prediktif evaluasi identifikasi permasalahan integrasi model dengan sistem peringatan pemeliharaan prediktif gambar 3.1 tahapan penelitian gambar 3.1 menunjukkan tahapan penelitian sebagai dasar untuk pengembangan sistem pemeliharaan prediktif menggunakan teknik machine 45 learning. tahapan penelitian ini terdiri dari studi literatur untuk memahami keadaan yang terfokus terhadap tentang mesin kompresor reciprocating metode prediksi pemeliharaan mesin predictive maintenance dan machine learning. identifikasi permasalahan secara spesifik yang akan diatasi oleh penelitian termasuk mendefinisikan ruang lingkup serta tujuan dari penelitian. pengumpulan data yang relevan dan melakukan analisis awal untuk memahami karakteristik dan pola dalam data. preprocessing data melibatkan pembersihan data normalisasi dan transformasi data agar siap digunakan dalam model machine learning. tahap ini bertujuan untuk mengatasi masalah data yang hilang outliers dan memastikan data berada dalam format yang sesuai. pemilihan algoritma machine learning yang efektif untuk membantu mencapai akurasi yang lebih tinggi dan efisiensi dalam prediksi. pengembangan dan melatih model machine learning menggunakan algoritma yang telah dipilih dengan data yang telah diperoses tahap ini melibatkan pembagian data menjadi set pelatihan dan set pengujian serta termasuk mengatur parameter model untuk mencapai kinerja terbaik. s istem peringatan pemeliharaan prediktif menggunakan model machine learning untuk memprediksi kegagalan mesin sistem ini bertujuan untuk memberikan peringatan dini sebelum terjadinya kerusakan atau kegagalan mesin. i ntegrasi model dengan sistem peringatan pemeliharaan prediktif tahap ini memastikan bahwa model dapat bekerja secara realtime dan memberikan peringatan yang akurat kepada pengguna. serta tahapan terakhir adalah evaluasi kinerja sistem secara keseluruhan untuk memastikan bahwa sistem peringatan pemeliharaan prediktif berfungsi dengan baik dan mencapai tujuan yang diinginkan. 3.2 pengumpulan dan analisis data observasi data dilakukan pada platform terpercaya yang menyediakan berbagai dataset publik yaitu kaggle .,3.1 tahapan penelitian tahapan penelitian merupakan serangkaian langkah langkah yang dilakukan dalam penelitian. gambaran mengenai tahapan penelitian ini dapat dilihat pada gambar 3.1. studi literatur pengumpulan dan analisis data preprocessing data pemilihan algoritma yang efektif pengembangan model machine learning sistem peringatan pemeliharaan prediktif evaluasi identifikasi permasalahan integrasi model dengan sistem peringatan pemeliharaan prediktif gambar 3.1 tahapan penelitian gambar 3.1 menunjukkan tahapan penelitian sebagai dasar untuk pengembangan sistem pemeliharaan prediktif menggunakan teknik machine 45 learning. tahapan penelitian ini terdiri dari studi literatur untuk memahami keadaan yang terfokus terhadap tentang mesin kompresor reciprocating metode prediksi pemeliharaan mesin predictive maintenance dan machine learning.
Erfiana Wahyuningsih_UK.txt,3.1 konsep penelitian untuk mempermudah dalam melakukan penelitian maka dibuat sebuah flowchart agar penelitian tidak menyimpang dan salah. berikut flowchart penelitian untuk rangkaian sram 6t low power dan high read stability dengan metode m gdi. gambar 10. alur penelitian sram 6t dengan metode m gdi dalam me mulai desain sram 6t dengan menggunakan metode m gdi diperlukan studi literatur terkait bebera pa penelitian dengan metode atau hasil serupa . setelah me mpelajari se luruh penelitian terkait maka di lakukan desain rangkaian sram dengan metode konvensional sebagai referensi untuk dilakukan proses m gdi.,3.1 konsep penelitian untuk mempermudah dalam melakukan penelitian maka dibuat sebuah flowchart agar penelitian tidak menyimpang dan salah. berikut flowchart penelitian untuk rangkaian sram 6t low power dan high read stability dengan metode m gdi.
Fitriana Indah Pramitasari_Kualifikasi.txt,3.1 alur penelitian alur penelitian menggambarkan alur dari awal hingga akhir penelitian dilaksanakan. alur penelitian ini diuraikan pada gambar 3.1 di bawah ini. gambar 3.1 alur penelitian 27 3.2 identifikasi masalah identifikasi masalah adalah salah satu langkah pertama yang dilakukan sebelum melakukan penelitian. identifikasi masalah merupakan suatu proses mencari dan mengetahui masalah yang ingin diselesaikan. identifikasi masalah ini membantu penelitian untuk memah ami tantangan yang dihadapi oleh petani kentang skala nasional dan merancang solusi yang tepat sesuai dengan kebutuhan mereka. identifikasi masalah pada penelitian ini berfokus pada mengidentifikasi proses perancangan model koperasi petani mengidentifikas i metode prediksi permintaan dengan ann di dalam blockchain yang digunakan untuk mengoptimalkan permintaan pelanggan di masa depan selama periode tertentu dan mengidentifikasi metode safety stock di dalam blockchain yang digunakan agar dapat mengoptimalkan stok dan permintaan. identifikasi masalah pada penelitian ini peneliti dapat lebih memahami kendala dan kebutuhan petani kentang skala nasional. perancangan model platform koperasi untuk meningkatkan efisiensi dan kerjasama antarpetani dengan koperasi sebagai mitranya. sement ara itu metode prediksi permintaan dengan menggunakan artificial neural network ann diharapkan dapat membantu petani mengelola produksi secara lebih tepat sesuai dengan kebutuhan pasar dan koperasi dapat menyesuaikan persediaan stok dan permintaan secar a dinamis dari hasil prediksi permintaan. selain itu identifikasi masalah juga mencakup penerapan metode safety stock untuk mengoptimalkan manajemen stok memastikan ketersediaan barang dan meningkatkan responsibilitas terhadap fluktuasi permintaan pasar. dengan penerapan ann dan metode safety stock di dalam blockchain semua prediksi dan manajemen stok dapat dicatat di dlaam buku besar yang tidak dapat diubah sehingga meningkatkan transparansi dan keamanan data dalam rantai pasok. sehingga koperasi ini dapat melakukan perencanaan yang lebih akurat meminimalkan pemborosan dan meningkatkan ketersediaan kentang sesuai dengan kebutuhan pelanggan. dengan demikian platform koperasi menjadi responsif terhadap perubahan permintaan pasar mendukung pertumbuhan ekonomi para petani memperkuat kolaborasi antar anggota koperasi serta memiliki transparansi dan keamanan pada rantai pasok. 28 3.3 studi literatur studi literatur yang dilakukan pada penelitian engembangan platform koperasi petani ini dimulai dari pencarian dan review literatur literatur terbaru dan relevan yang telah diterbitkan. studi literatur juga dapat dari teori teori buku yang relevan dengan metode yang digunakan. analisis literatur membantu untuk mengidentifikasi kerangka kerja metode dan teknologi yang telah digunakan pada penelitian sebelumnya. studi literatur dapat digunakan sebagai mencari solusi dan menganalisa penelitian yang dilakukan . studi literatur juga membantu dalam mengetahui tantangan dan peluang yang mungkin dihadapi dalam pengembangan platform koperasi petani kentang. sehingga informasi tersebut dapat memberikan sebuah wawasan terkait dengan penelitian yang dilakukan. 3.4 pengumpulan data pengumpulan data yang digunakan sebagai bahan dalam mengolah data. sehingga penelitian ini akan menghasilkan data yang sesuai dengan tujuan penelitian. penelitian ini mengumpulkan data sekunder dan data primer. pengumpulan data pada penelitian ini terdiri dari beberapa proses sebagai berikut. pengumpulan data sekunder memanfaatkan sumber informasi yang sudah ada seperti literatur ilmiah dokumen resmi dan data statistik yang relevan. proses ini memungkinkan peneliti untuk memahami konteks yang telah ada sebelumnya dan memanfaatkan pengetahua n serta data yang telah dihasilkan sebelumnya. berdasarkan data yang diperoleh dari badan pusat statistik bps tahun 2022 menjelaskan data produksi kentang di berbagai wilayah indonesia. beberapa wilayah indonesia berhasil dalam produksi kentang dan beberapa wilayah indonesia yang tidak dapat mempro duksi kentang. data tersebut memberikan gambaran lengkap mengenai kegiatan pertanian kentang di berbagai wilayah indonesia pada tahun 2022. berikut data bps tahun 2022 produksi kentang di berbagai wilayah indonesia. 29 tabel 3.1 data lokasi produksi kentang 2022 sumber badan pusat statistik 2023 pengumpulan data primer yaitu melakukan pencarian secara langsung untuk mengumpulkan data serta informasi baru sesuai dengan tujuan penelitian. metode ini seperti pengambilan data survei wawancara observasi atau eksperimen dengan tujuan untuk kebutuha n penelitian. data primer yang akan digunakan pada penelitian ini adalah kebutuhan pengguna aliran data dari petani dengan koperasi sebagai mitranya data musim data historis penjualan data produksi kentang dan data harga kentang. pengambilan data primer dilakukan di wonosobo jawa tengah. berdasarkan informasi yang didapatkan dari salah satu petani di wonosobo jawa tengah disana terdapat banyak petani kentang dan sayuran lainnya. menurut bps kabupaten wonosobo jawa tengah adalah wilayah yang terbanyak memproduksi kentang di provinsi jawa tengah. pola distribusi kentang di wonosobo jawa tengah terdiri dari 3 pola sebagai berikut zaenuri et al 2023. 30 gambar 3.2 pola distribusi kentang 3.5 blockchain pada penelitian ini untuk meningkatkan keamanan dan transparansi maka menggunakan teknologi blockchain untuk rantai pasok kentang. berikut flowchart kecerdasan buatan safety stock yang dikombinasikan di dalam blockchain. gambar 3.3 flowchart blockchain berdasarkan gambar di atas menggambarkan kombinasi ann dan safety stock di dalam blockchain. data rantai pasok yang telah dikumpulkan kemudian 31 dimasukkan ke dalam database. data tersebut diverifikasi dalam blockchain dengan proses pembuatan blok baru yang melibatkan perhitungan hash blok sebelumnya menyusun blok baru menghitung hash blok baru dan mencapai konsensus untuk menambahkan blok ke ra ntai. data yang diverifikasi kemudian diproses menggunakan model artificial neural network ann. tahapan dalam ann meliputi praproses data inisialisasi model pelatihan model validasi model dan evaluasi kinerja. hasil prediksi permintaan disimpan dalam blockchain dengan proses pembuatan blok baru yang sama seperti langkah sebelumnya. selanjutnya permintaan data diverifikasi dan jika valid safety stock dihitung menggunakan rumus safety stock yang sudah ada. hasil perhitungan safety stock disimpan dalam database dan dicatat dalam blockchain dengan pembuatan blok baru. semua data dari proses tersebut dicatat dalam blockchain untuk memastikan transparansi dan keamanan. proses validasi memastikan bahwa data permintaan dan pengelolaan stok selalu diperbarui dan valid sebelum digunakan untuk pengambilan keputusan. 3.6 design sistem dengan uml pengembangan platform koperasi petani kentang menggunakan metode unified modeling language uml untuk menggambarkan struktur fungsi dan interaksi komponen sistem secara visual. dimana proses metode uml ini diawali dengan identifikasi kebutuhan sistem dan pemahaman terhadap fungsionalitas yang terkait dengan economic sharing dan prinsip prinsip perkoperasian. 3.6.1 analisis kebutuhan sistem analisis kebutuhan sistem bertujuan untuk mengidentifikasi kebutuhan dari pengguna dan stakeholder sistem. pengumpulan informasi pada proses ini mengenai detail cara kerja sistem dan batasan batasan yang ada. pengumpulan data dilakukan melalui wawancara a tau survei. analisis kebutuhan sistem dapat menentukan arah dan ruang lingkup proyek pengembang sistem serta memastikan bahwa produk akhir akan memenuhi harapan dan memecahkan masalah yang dihadapi oleh pengguna. 32 gambar 3. 4 multi stakeholder cooperative gambar 3. 4 menjelaskan proses multi stakeholder cooperative dimana anggota koperasi termasuk dari workers community producers dan consumers . mereka memilih board of director dari para anggotanya. board of director merupakan struktur organisasi yang bertanggung jawab dalam mengawasi manajemen yang dijalankan oleh koperasi dengan setiap anggotanya memiliki tugas khusus sesuai dengan tujuan koperasi. dewan direksi berperan penting dalam menjaga keberlanjutan dan kese imbangan antara berbagai kepentingan dalam konteks multi stakeholder cooperative . gambar 3. 5 pengguna platform gambar 3. 5 mendeskripsikan pengguna platform koperasi petani yang melibatkan sejumlah pihak. pengguna platform ini terdiri dari consumers yang dapat mengakses produk pertanian secara langsung farmers yang memanfaatkan platform untuk memasarkan hasil panen companies yang terlibat dalam dukungan pengembangan teknologi dan partner cooperatives yang menjadi bagian dari 33 kolaborasi kerjasama antar koperasi untuk meningkatkan kesejahteraan bersama. keterlibatan seluruh pihak ini diharapkan platform koperasi petani menciptakan lingkungan yang saling mendukung dan berkelanjutan memperkuat konektivitas antar anggota untuk me ncapai tujuan bersama dalam dunia pertanian. 3.6.2 use case diagram model pertama uml adalah pemodelan use case diagram dimana menggambarkan skenario skenario utama pengguna platform koperasi. use case diagram digunakan untuk menunjukkan hubungan dan struktur kelas kelas yang terlibat dalam sistem termasuk entitas entitas seperti data permintaan stok kentang dan pengguna. gambar 3. 6 use case diagram gambar 3. 6 adalah diagram use case untuk platform koperasi petani yang menunjukkan berbagai interaksi antara pengguna dan sistem. pada diagram use 34 case terdapat aktor yang terdiri dari petani konsumen anggota koperasi dan admin. registrasi dilakukan oleh petani anggota koperasi dan konsumen.,dengan penerapan ann dan metode safety stock di dalam blockchain semua prediksi dan manajemen stok dapat dicatat di dlaam buku besar yang tidak dapat diubah sehingga meningkatkan transparansi dan keamanan data dalam rantai pasok. 28 3.3 studi literatur studi literatur yang dilakukan pada penelitian engembangan platform koperasi petani ini dimulai dari pencarian dan review literatur literatur terbaru dan relevan yang telah diterbitkan. sehingga informasi tersebut dapat memberikan sebuah wawasan terkait dengan penelitian yang dilakukan. 3.4 pengumpulan data pengumpulan data yang digunakan sebagai bahan dalam mengolah data. penelitian ini mengumpulkan data sekunder dan data primer. pengumpulan data pada penelitian ini terdiri dari beberapa proses sebagai berikut. berdasarkan data yang diperoleh dari badan pusat statistik bps tahun 2022 menjelaskan data produksi kentang di berbagai wilayah indonesia. data tersebut memberikan gambaran lengkap mengenai kegiatan pertanian kentang di berbagai wilayah indonesia pada tahun 2022. berikut data bps tahun 2022 produksi kentang di berbagai wilayah indonesia. pengambilan data primer dilakukan di wonosobo jawa tengah. 30 gambar 3.2 pola distribusi kentang 3.5 blockchain pada penelitian ini untuk meningkatkan keamanan dan transparansi maka menggunakan teknologi blockchain untuk rantai pasok kentang. berikut flowchart kecerdasan buatan safety stock yang dikombinasikan di dalam blockchain. gambar 3.3 flowchart blockchain berdasarkan gambar di atas menggambarkan kombinasi ann dan safety stock di dalam blockchain. data tersebut diverifikasi dalam blockchain dengan proses pembuatan blok baru yang melibatkan perhitungan hash blok sebelumnya menyusun blok baru menghitung hash blok baru dan mencapai konsensus untuk menambahkan blok ke ra ntai. data yang diverifikasi kemudian diproses menggunakan model artificial neural network ann. selanjutnya permintaan data diverifikasi dan jika valid safety stock dihitung menggunakan rumus safety stock yang sudah ada. hasil perhitungan safety stock disimpan dalam database dan dicatat dalam blockchain dengan pembuatan blok baru. dimana proses metode uml ini diawali dengan identifikasi kebutuhan sistem dan pemahaman terhadap fungsionalitas yang terkait dengan economic sharing dan prinsip prinsip perkoperasian. 32 gambar 3. board of director merupakan struktur organisasi yang bertanggung jawab dalam mengawasi manajemen yang dijalankan oleh koperasi dengan setiap anggotanya memiliki tugas khusus sesuai dengan tujuan koperasi. pengguna platform ini terdiri dari consumers yang dapat mengakses produk pertanian secara langsung farmers yang memanfaatkan platform untuk memasarkan hasil panen companies yang terlibat dalam dukungan pengembangan teknologi dan partner cooperatives yang menjadi bagian dari 33 kolaborasi kerjasama antar koperasi untuk meningkatkan kesejahteraan bersama. gambar 3.
KUALIFIKASI_Riya Widayanti.txt,bab ini menyajikan desain yang digunakan dalam penelitian ini. desain penelitian adalah rencana umum bagaimana penelitian akan dilakukan untuk menjawab pertanyaan dan pernyataan dalam penelitian. hal ini menentukan sumber dari mana data akan dikumpulkan dan bagaimana mengumpulkan dan menganalisis data ini. selanjutnya membahas masalah etika dan beberapa kendala yang dapat ditemui peneliti. ini menunjukkan bahwa peneliti telah memikirkan elemenelemen desain penelitian tertentu saunders lewis thornhill 2011. pada bab ini akan dibahas mengenai filosofi keilmuan dari data governance konsep teknolgi blockchain dan penerapan data governance dalam teknologi blockchain di bidang pendidikan yang akan memberikan pandangan utama saat melakukan penelitian. selanjutnya akan dijelaskan pendekatan yang digunakan penelitian dalam pengumpulan data menganalisis data yang digunakan serta etika lain yang akan dipatuhi terutama terkait kerahasiaan data yang digunakan. jadi metodologi penelitian memberikan gambaran jelas mengenai strategi penelitian pengambilan data pengumpulan pengolahan dan analisis dan serta keterbatasan penelitian. 3.1 filosofi keilmuan pengkajian ilmiah penelitian menurut aliran positivistik banyak dianut peneliti ilmu komputer merupakan upaya sistematis investigatif objektif logis hatihati dan terencana dengan selalu berusaha mencari kebenaran. penelitian dengan pendekatan positivistik adalah memiliki karakteristik analitik nomotetik dedikatif laboratorik pembuktian dengan logika kebenaran universal dan bersifat bebas nilainya.,desain penelitian adalah rencana umum bagaimana penelitian akan dilakukan untuk menjawab pertanyaan dan pernyataan dalam penelitian. 3.1 filosofi keilmuan pengkajian ilmiah penelitian menurut aliran positivistik banyak dianut peneliti ilmu komputer merupakan upaya sistematis investigatif objektif logis hatihati dan terencana dengan selalu berusaha mencari kebenaran.
Kualifikasi Witta Listiya Ningrum.txt,bab ini akan menjelaskan tentang metodologi penelitian yang digunakan sebagai gambaran dari langkah langkah yang akan dilakukan untuk menyelesaikan penelitian ini. 3.1 tahapan penelitian penelitian ini melakukan pengembangan model klasifikasi toksisitas pada platform sosial media. tahapan penelitian yang digunakan dapat dilihat pada gambar 3.1. gambar 3.1 tahapan metode penelitian literatur review pengumpulan data large language model llm platform twitter representasi teks representasi gambar platform instagram representasi video platform t iktok model klasifikasi toksisitas evaluasi model hasil generate caption llm multi modal 30 tahapan metode penelitian pada gambar 3.1 terdiri dari beberapa langkah yaitu 1. tahap literature review pada tahap ini dimulai dengan melakukan kajian dari berbagai sumber tertulis dalam bentuk buku artikel dan jurnal serta penelitian peneltiian terkait guna memahami dan mengidentifikasi kesenjangan dalam topik penelitian serta menemukan kelemahan dan keleb ihan dalam penelitian. selain itu juga untuk menentukan dan membandingkan metode serta algoritma yang sudah digunakan pada penelitian sebelumnya yang nantinya akan mengembangkan atau menciptakan suatu metode atau algoritma terbaru.,3.1 tahapan penelitian penelitian ini melakukan pengembangan model klasifikasi toksisitas pada platform sosial media. tahapan penelitian yang digunakan dapat dilihat pada gambar 3.1. gambar 3.1 tahapan metode penelitian literatur review pengumpulan data large language model llm platform twitter representasi teks representasi gambar platform instagram representasi video platform t iktok model klasifikasi toksisitas evaluasi model hasil generate caption llm multi modal 30 tahapan metode penelitian pada gambar 3.1 terdiri dari beberapa langkah yaitu 1. tahap literature review pada tahap ini dimulai dengan melakukan kajian dari berbagai sumber tertulis dalam bentuk buku artikel dan jurnal serta penelitian peneltiian terkait guna memahami dan mengidentifikasi kesenjangan dalam topik penelitian serta menemukan kelemahan dan keleb ihan dalam penelitian.
Kualifikasi_Aris Gunaryati.txt,3.1 gambaran umum penelitian motivasi dari metodologi yang diusulkan adalah membu at suatu metode peramalan yang sesuai dengan data runtun waktu yang ada serta meni ngkatkan akurasinya dengan tetap memp erhatikan efisiensi w aktu ko mputasi nya. langkahlangkah yang dilakuk an dalam p enelitian ini adalah m enganalisis data jum lah kasus h arian covid 19 di jakarta berdasarkan dataset dari situs ht tpscorona.jakarta.go.id tangg al 6 maret 2020 sampai 30 juni 2021 sebagai data training dan nanti akan diprediksi untuk tanggal 1 juli 2021 sampai dengan 31 juli 2021 sebagai data uji dengan tahapan sebagai berikut 1. mempersiapk an data runtun w aktu yang akan dia nalisis 2. menganalisis data runtun waktu yang ada meng gunakan metode statistika arima 3. menganalisis data runtun waktu yang ada menggunakan metode quantum neural network 4. mengembangkan model hybrid arimaquantum neural network 5. menentukan mod el yang cocok untuk s etiap variabel 6. menguji kecocokan masingmasing model 7. melakuk an peramalan dengan menggunakan mo del yang cocok 8. melakuk an perbandingan tingkat aku rasi hasil peramalan dengan tiap model untuk mend apatkan model peramalan yang diharapkan sesuai dengan data runtun waktu yang ada maka perlu dilakukan pendekatan ilmiah yaitu dengan melihat pola d ata runtun waktu yang ada terlebih dahulu. dengan melihat pola data awal yang di miliki maka akan memud ahkan dalam memi lih model yang sesuai untuk data tersebut. pendekatan lainnya adalah me nggunakan too ls untuk m enentukan secara otomatis bentuk model statistik arima yang sesuai dengan runtun waktu yang ada lalu model tersebut dilatih menggunakan quantum neural network agar diket ahui polapola d ata yang sudah ada d an d apat d iuji akurasinya.17 tipe model pola tipikal acf pola tipikal pacf ar p menurun secara ekspon ensial sinusoidal terputus s etelah lag p ma q terputus s etelah lag q menurun secara ekspon ensial sinusoidal arma p q menurun secara ekspon ensial sinusoidal menurun secara ekspon ensial sinusoidal 3.2 model arima bentuk u mum model ar ima dapat dinyatakan dalam p ersamaan berikut ............................... ................................ ................................. 1 operator ar adalah ............................................................2 operator ma adalah ............................................................ ............. .3 1. autore gressive integrated moving average arima not asi model arima p d q p orde untuk pros es autoregressive ar d orde yang menyatakan banyaknya proses dife rensi d ilakuk an pada data time series yang tidak stasione r q orde yang menyatakan proses moving a verage ma. pola teoretis acf dan pacf dari proses yang stasio ner sumber aswi dan sukarna 2006 2. tahapan analisis time series arima a. membuat plot time series identifikasi asumsi s tasione ritas data runtun waktu. suatu de ret pengamatan dikat akan stasioner apabila proses tidak berubah seiring dengan perubahan waktu tidak stasioner dalam mean jika trend tidak datar tidak sejajar smbu waktu tidak stasioner dalam varian jika trend datar atau hampir datar tetapi data tersebar membangun pola m elebar atau m enyempit pola t eromp et18 tidak stasioner dalam mean varians j ika trend tidak datar dan data memb entuk po la terompet. augmented di ckey fuller uji formal untuk stasion eritas hipotesis h0 terdapat akar unit dan data tidak st asioner 0 h1 tid ak terdapat akar unit dan data stasioner 0 span taraf signifik ansi α statistik uji ............................................................... ...4 ............................................................................................... .5 ............................................................................................... .......... .6 kriteria uji h0 ditolak jika nilai mu tlak dari augmented di ckey fuller nilai kritis mackinnon atau nilai prob . α. b. menghitung membu at plot acf dan pacf mengidentifikasi model runtun w aktu yang mungkin mengestimasi p arameter model c. uji signifik ansi parameter hipotesis h0 danatau parameter tidak signifik an terhadap model h1 danatau parameter signifik an terhadap model taraf signifik ansi α statistik uji danatau 19 kriteria uji tolak h 0 jika atau p value alpha d. verifikasi mo del independensi residual hipotesis h0 tidak ada korelasi antarlag h1 paling sedikit ada satu dengan k12 24 36 48 ada ko relasi antarlag statistik uji kriteria uji tolak h 0 jika atau p value alpha dengan m l ag maksim um s jumlah p arameter yang diesti masi dan taraf signifik ans normalitas residual hipotesis h0 residual berdistriusi norm al h1 residual t idak berdistribusi norm al statistik uji fungsi peluang kumulatif r esidual distribusi ku mulatif yang diobs ervasi dari suatu sampel acak sebanyak n o servasi kriteria uji tolak h 0 jika atau p value alpha ukuran ketepatan ra malan mod el dengan uku ran ketepatan p eramalan yang baik ad alah model yang menghasilkan error yang kecil. nilai teng ah kesalahan kuadrat mean square er ror 20 berikut flo wchart langkahlangkah membu at model arima gambar 1. flowch art analisis runtun waktu arima 3.3 model neural network dalam buku jaringan syaraf tiruan dan pemrogramannya menggunakan matlab drs. jong jek siang m.sc menyebutkan bahwa jaringan syaraf tiruan adalah system pemroses informasi yang memiliki karakteristik mirip dengan jaringan syaraf biologi. jaringan syaraf t iruan dibentuk sebagai generalisasi model matematika dari jaringan syaraf biologi dengan asumsi bahwa pemrosesan informasi terjadi pada banyak elemen sederhana neuron a. sinyal dikirimkan di antara neuron neuron melalui penghubung penghubung b. penghubung ant ar neuron memiliki bobot yang akan memperkuat atau memperlemah sinyal c. untuk menentukan output setiap neuron menggunakan fungsi aktivasi biasanya bukan fungsi linier yang dikenakan pada jumlahan input yang diterima. besarnya output ini selanjutnya diband ingkan dengan suatu batas ambang treshhold 21 jaringan syaraf tiruan ditentukan oleh tiga hal a. pola hubungan antar neuron disebut arsitektur jaringan b. metode untuk menentukan bobot penghubung disebut metode traininglearning algoritma c. fungsi aktivasi gambar skematik tipikal neuron dapat dilihat pada gambar 2 gambar 2 syaraf biologis pemrosesan informasi dalam jaringan syaraf tiruan dapat disingkat sebagai berikut sinyal baik berupa aksi ataupun potensial muncul sebagai masukan unit sinapsis efek dari tiap sinyal ini dinyatakan sebagai bentuk perkalian dengan sebuah nilai bobot untuk mengindikasikan kekuatan dari sinapsis. semua sinyal yang diberi pengali bobo t ini kemudian dijumlahkan satu sama lain untuk menghasilkan unit aktivasi. jika aktivasi ini melampaui sebuah batas ambang tertentu maka unit tersebut akan memberikan keluaran dalam bentuk respon terhadap masukan. unit aktivasi ini kemudian dibandingkan d engan sebuah nilai ambang dan hasilnya dimasukkan kedalam fungsi transfer fungsi non linier yang akan menghasilkan sebuah keluaran. secara ringkas proses tersebut dapat digambarkan dalam gambar 3 gambar 3 neuron buatan mcculloch pitts sebagai operator matematis 22 aktivasi dari unit masukan diatur dan diteruskan melalui jaring hingga nilai dari keluaran dapat ditentukan. jaring berperan sebagai fungsi vektor yang mengambil satu vektor pada masukan dan mengeluarkan satu vektor lain pada keluaran. model jaringan syaraf tiruan dapat memiliki sebuah lapisan bobot dimana masukan dihubungkan langsung dengan keluaran atau beberapa lapisan yang didalamnya terdapat beberapa lapisan tersembunyi karena berada t ersembunyi diantara neuron masukan dan keluaran. jaring syaraf menggunakan unit tersembunyi untuk menghasilkan representasi pola masukan secara internal didalam jaring syaraf. fungsi transfer nonlinier yang digunakan dalam tiap neuron baik dilapisan masukan keluaran atau lapisan tersembunyi dapat berupa fungsi nilai ambang fungsi linier fungsi sigmoid ataupun fungsi gaussian tergantung dari karakter neuron sesuai keinginan kita. hal ini dapat dilihat pada gambar 4 gambar 4 tipikal sebuah jaringan syaraf tiruan 3.3.1 komponen jaringan syaraf terdapat beberapa tipe jaringan syaraf hampir semuanya memiliki komponen komponen yang sama. seperti halnya otak manusia jaringan syaraf juga terdiri atas beberapa neuron dan ada hubungan antar neu ron tersebut. neuron neuron tersebut akan mentransformasikan informasi yang diterima melalui sambungan keluarnya menuju ke neuron neuron yang lain. pada jaringan syaraf hubungan ini dikenal dengan nama bobot. informasi tersebut disimpan pada suatu nilai t ertentu pada bobot tersebut. neuron ini sebenarnya mirip dengan sel neuron biologis. neuron neuron buatan tersebut bekerja dengan cara yang sama pula dengan neuron biologis. informasi disebut dengan input akan dikirim ke neuron dengan bobot kedatangan t ertentu.,pendekatan lainnya adalah me nggunakan too ls untuk m enentukan secara otomatis bentuk model statistik arima yang sesuai dengan runtun waktu yang ada lalu model tersebut dilatih menggunakan quantum neural network agar diket ahui polapola d ata yang sudah ada d an d apat d iuji akurasinya.17 tipe model pola tipikal acf pola tipikal pacf ar p menurun secara ekspon ensial sinusoidal terputus s etelah lag p ma q terputus s etelah lag q menurun secara ekspon ensial sinusoidal arma p q menurun secara ekspon ensial sinusoidal menurun secara ekspon ensial sinusoidal 3.2 model arima bentuk u mum model ar ima dapat dinyatakan dalam p ersamaan berikut ............................... ................................ ................................. 1 operator ar adalah ............................................................2 operator ma adalah ............................................................ ............. .3 1. autore gressive integrated moving average arima not asi model arima p d q p orde untuk pros es autoregressive ar d orde yang menyatakan banyaknya proses dife rensi d ilakuk an pada data time series yang tidak stasione r q orde yang menyatakan proses moving a verage ma. pola teoretis acf dan pacf dari proses yang stasio ner sumber aswi dan sukarna 2006 2. tahapan analisis time series arima a. membuat plot time series identifikasi asumsi s tasione ritas data runtun waktu. jaringan syaraf t iruan dibentuk sebagai generalisasi model matematika dari jaringan syaraf biologi dengan asumsi bahwa pemrosesan informasi terjadi pada banyak elemen sederhana neuron a. sinyal dikirimkan di antara neuron neuron melalui penghubung penghubung b. penghubung ant ar neuron memiliki bobot yang akan memperkuat atau memperlemah sinyal c. untuk menentukan output setiap neuron menggunakan fungsi aktivasi biasanya bukan fungsi linier yang dikenakan pada jumlahan input yang diterima. jika aktivasi ini melampaui sebuah batas ambang tertentu maka unit tersebut akan memberikan keluaran dalam bentuk respon terhadap masukan. jaring berperan sebagai fungsi vektor yang mengambil satu vektor pada masukan dan mengeluarkan satu vektor lain pada keluaran. neuron neuron tersebut akan mentransformasikan informasi yang diterima melalui sambungan keluarnya menuju ke neuron neuron yang lain. pada jaringan syaraf hubungan ini dikenal dengan nama bobot. informasi disebut dengan input akan dikirim ke neuron dengan bobot kedatangan t ertentu.
Kualifikasi_Rama Dian Syah.txt,3.1 tahapan penelitian tahapan penelitian dibagi atas beberapa tahapan yang dilakukan dari awal sampai akhir. tahapan dimulai dari studi literatur sampai analisis yang membentuk alur secara sistematis. tahapan penelitian ini terpada pada gambar 3.1 gambar 3.1 tahapan penelitian tahapan penelitian pada gambar 3.1 menjelaskan tahapan yang dilakukan pada penelitian ini. tahapan pertama yaitu studi literatur dengan membaca dan memahami beberapa penelitian yang dilakukan oleh peneliti sebel umnya kemudian desain algoritma dilakukan pada matlab pengujian dilakukan dengan beberapa parameter pengujian dan analisis dilakukan dari beberapa pengujian yang telah dilakukan. 3.2 desain algoritma penelitian yang terdahulu menggunakan metode yang memiliki ke amanan tinggi yang dibuktikan dengan beberapa parameter pengujian. pada penelitian ini mengajukan pengembangan algoritma kriptografi citra digital dengan mengkombinasi teknik konfusi dengan algoritma cat map dan henon map serta teknik difusi dengan algoritma logistic map . pengembangan pada algoritma ini diharapkan dapat memiliki keamanan yang lebih tinggi dengan melalui beberapa parameter pengujian. diagram alur proses enkripsi dapat dilihat pada 3.2. 18 gambar 3.2 diagram alur proses enkripsi gambar 3.2 merupakan diagram alur proses enkripsi yang diusulkan pada penelitian ini. citra asli dan kunci enkripsi menjadi input pada proses enkripsi. langkah pertama yaitu p engacakan piksel dilakukan dengan algoritma cat map menggu nakan persamaan 2.1 dan algoritma henon map menggunakan persamaan 2.5 dan 2.6. kemudian pembangkitan keystream dengan algoritma logistic map menggunakan persamaan 2.9. keystream yang dibangkitkan akan dilakukan operasi xor dengan piksel citra asli sehingga menghasilkan citra terenkripsi. diagram alur proses dekripsi dapat dilihat pada gambar 3.3 gambar 3.3 diagram alur proses dekripsi 19 gambar 3.3 merupakan diagram alur proses dekripsi yang diusulkan pada penelitian ini. proses dekripsi merupakan k ebalikan dari proses enkripsi. citra terenkripsi dan kunci dekripsi menjadi input pada proses dekripsi. kunci enkripsi dan dekripsi merupakan kunci yang sama. langkah pertama yaitu pembangkitan keystream menggunakan logistic map . kemudian pengembalian nila i piksel dengan operasi xor. pengembalian posisi piksel dengan algoritma henon map menggunakan persamaan 2.7 dan 2.8 serta algoritma cat map menggunakan persamaan 2.2 sehingga menghasilkan citra asli kembali. 3.3 pengujian tahapan pengujian dilakukan unt uk mengetahui hasil pada proses enkripsi dan dekripsi beberapa pengujian yang dilakukan yaitu 1. histogram histogram merupakan analisis statistik yang menunjukkan penyebaran atau distribusi piksel pada citra. histogram sering digunakan untuk pada pengolahan citra untuk melihat kualitas citra. kriptografi pada citra digital yang ideal memiliki distribusi nilai p iksel yang beragam benlashram et al. 2020 . 2. psnr peak signal noise to ratio psnr digunakan untuk pengukuran kualitas citra antara citra asli dan noise yang terjadi pada citra terenkripsi. nilai psnr 30 db membuktikan kualitas yang ba ik pada citra asli atau citra terdekripsi lone et al. 2021 .,tahapan penelitian ini terpada pada gambar 3.1 gambar 3.1 tahapan penelitian tahapan penelitian pada gambar 3.1 menjelaskan tahapan yang dilakukan pada penelitian ini. diagram alur proses enkripsi dapat dilihat pada 3.2. citra asli dan kunci enkripsi menjadi input pada proses enkripsi. langkah pertama yaitu p engacakan piksel dilakukan dengan algoritma cat map menggu nakan persamaan 2.1 dan algoritma henon map menggunakan persamaan 2.5 dan 2.6. kemudian pembangkitan keystream dengan algoritma logistic map menggunakan persamaan 2.9. keystream yang dibangkitkan akan dilakukan operasi xor dengan piksel citra asli sehingga menghasilkan citra terenkripsi. kunci enkripsi dan dekripsi merupakan kunci yang sama. langkah pertama yaitu pembangkitan keystream menggunakan logistic map . 3.3 pengujian tahapan pengujian dilakukan unt uk mengetahui hasil pada proses enkripsi dan dekripsi beberapa pengujian yang dilakukan yaitu 1. histogram histogram merupakan analisis statistik yang menunjukkan penyebaran atau distribusi piksel pada citra.
Kualifikasi_Remigius.txt,3.1 motivasi penelitian penelitian ini dilakukan dengan motivasi mengenalkan pentingnya sistem pembelajaran bidang arsitektur menggunakan teknologi metaverse. dalam proses pengembangan sistem pembelajaran arsitektur berbasis metaverse ini peneliti juga ingin menunjukkan perlunya keterlibatan komunitas dan persepsi pengguna bidang arsitektur agar si stem pembelajaran yang dihasilkan sesuai dengan kebutuhan dan harapan mereka dalam meningkatkan efektivitas pembelajaran arsitektur itu sendiri. diharapkan sistem pembelajaran arsitektur berbasis metaverse ini dapat memberi kemudahan kepada komunitas dose n dan mahasiswa dalam mempelajari berbagai sisi arsitektur dengan memasuki dunia virtual dan mereka dapat memahami materi yang diajarkan serta memecahkan permasalahan arsitektur yang dihadapi secara interaktif kolaboratif dan imersif dengan solusi tepat tanpa harus mencari berbagai referensi wujud nyata arsitektur di dunia fisik atau dunia nyata. studi literatur yose indarta ambiyar agariadne dwinggo samala ronal watrianthos 2022 berjudul metaverse tantangan dan peluang dalam pendidikan menyimpu lkan bahwa implementasi metaverse di dunia pendidikan memiliki peluang besar dalam menunjang proses pelaksanaan pendidikan menjadi lebih baik. pendidikan berbasis audiovisual merupakan aplikasi metaverse paling popular dan banyak digunakan dalam pembelajar an. berdasar penelitian pendidikan berbasis pengalaman menjadi lebih baik apakah melalui belajar secara langsung maupun simulasi didukung teknologi. dengan konsep pembelajaran matakuliah perkembangan arsitektur 1 yang dilakukan dengan metode metaverse p embelajaran secara online ini dapat dilakukan dengan lebih interaktif. dalam proses metaverse menyediakan banyak dukungan dukungan pada proses pembelajaran online dengan tidak menghilangkan pengalaman belajar di kampus. metode belajar di mana saja dan kapan saja menjadi konsep menarik yang disenangi banyak pihak. seharusnya 30 waktu ruang dan biaya dan lainnya dapat dipangkas dengan kehadiran teknologi metaverse. 3.2 kerangka penelitian penelitian ini dilakukan dalam mencapai tujuan utama yaitu pengembangan sistem pembelajaran arsitektur berbasis metaverse terutama terkait perkembangan arsitektur. penelitian ini dilakukan melalui beberapa tahap antara lain tabel 3.2 tahapan pengembangan sistem pembelajaran perkembangan arsitektur 1 berbasis me taverse no. tahapan proses hasil 1. identifikasi topik pembelajaran menghimpun materi pembelajaran perkembangan arsitektur selama satu semester himpunan materi pembelajaran perkembangan arsitektur selama satu semester 2. konstruksi dunia visual melakukan konstruksi visual konstruksi fisik dan desain dunia fisik dan desain visual menyiapkan latar arsitektur dan tata letak dunia digital konstruksi avatar dan konten pembelajaran perkembangan arsitektur di dunia digital dunia virtual berbasis konten pembelajaran perkembangan arsitektur 3. penggunaan dunia nyata koneksi dunia virtual persistensi interaksi interaksi dunia virtual keterlibatan komunitas 31 4. efektivitas pembelajaran kolaboratif presensi imersi kehadiran dalam realitas yang disimulasi kapabilitas metaverse dalam membentuk lingkungan pengguna untuk memahami realitas pemahaman materi pembelajaran kemampuan memahami materi pembelajaran perkembangan arsitektur berbasis metaverse penelitian mengenai pengembangan sistem pembelajaran perkembangan arsitektur 1 berbasis metaverse ini dilakukan dengan melibatkan komunitas yang terdiri dari dosen dan mahasiswa di program studi s1 arsitektur jurusan teknik arsitektur.,studi literatur yose indarta ambiyar agariadne dwinggo samala ronal watrianthos 2022 berjudul metaverse tantangan dan peluang dalam pendidikan menyimpu lkan bahwa implementasi metaverse di dunia pendidikan memiliki peluang besar dalam menunjang proses pelaksanaan pendidikan menjadi lebih baik. 3.2 kerangka penelitian penelitian ini dilakukan dalam mencapai tujuan utama yaitu pengembangan sistem pembelajaran arsitektur berbasis metaverse terutama terkait perkembangan arsitektur. penelitian ini dilakukan melalui beberapa tahap antara lain tabel 3.2 tahapan pengembangan sistem pembelajaran perkembangan arsitektur 1 berbasis me taverse no.
Miftakhul Zaen_KUALIFIKASI.txt,3.1 tahapan penel itian dalam penelitian mengenai pengembangan algoritma dbscan dengan kuantum terdapat langkahlangkah yang dilakukan seperti pada gambar 3.1. langkah langkah yang dilaukan d iantaranya yaitu pengumpulan data definisi qubits kriteria inisialis asi sistem kuantum hingga evaluasi klaster. data definisi qubits kriteria inisialisasi sistem kuantum penentuan eps dan minpts kuantum identifikasi core supplier dengan kuantum sirkuitidentifikasi noise supplier dengan kuantum sirkuit penanganan noise dengan kuantum stateformasi klaster supplier dengan kuantum measurementimplementasi quantum distance measure identifikasi core supplier dengan kuantum sirkuit evaluasi klaster1 2 3 4 5 6 9 10 117 8 gamb ar 3.1 tahapan penel itian 1. data tahap awal dalam penelitian di awali dengan pembuatan data dimana data yang digunakan pada penel itian ini adalah data s intetik. data sintetik digunakan untuk mendapatkan jumlah data yang besar sela in itu data sintetik juga b ersifat fleksibel kar ena ju mlah data yang digunakan dapat ditentukan sesuai dengan kebutuhan pengujian algo ritma yang dikembang kan. data sintetik yang dibuat berisikan nama supplier harga kualitas dan waktu pengiriman. 2. definis i qubits kriteria pada taha p ini kriteria yang digunak an untuk pengelompokan supplier diubah menjadi representasi kuantum menggunakan qubits. setia p kriteria mungkin diwakili ol eh satu atau lebih qubits tergantung pada kompleksitas yang diperlukan. kriteri a yang digunakan dalam peng elompokan supplier yaitu harga kualitas dan waktu pengiri man. 3. inisialisasi sistem kuantum pada tahapan ini melakukan p ersiapan awal dari komputer k uantum yaitu mengatur qubits ke state awal dan memas tikan semua qubits berada dalam keadaan awal sebelum operasi kuantum dijalankan. pada tahapan ini juga menentuk kan jumlah qubits yan g digunakan. 4. implementasi quantum distance measure pada tahapan ini melakukan p enerapan metode untuk mengukur jarak antar supplier dalam ruang kuantum dengan menggunakan prins ipprinsip mekanika kuantum .,3.1 tahapan penel itian dalam penelitian mengenai pengembangan algoritma dbscan dengan kuantum terdapat langkahlangkah yang dilakukan seperti pada gambar 3.1. langkah langkah yang dilaukan d iantaranya yaitu pengumpulan data definisi qubits kriteria inisialis asi sistem kuantum hingga evaluasi klaster. setia p kriteria mungkin diwakili ol eh satu atau lebih qubits tergantung pada kompleksitas yang diperlukan.
Ragmar Faikar Eka_Kualifikasi.txt,bab metode penelitian menjelaskan mengenai tahapan yang dilakukan dalam penelitian beserta menjelaskan mengenai jadwal dan estimasi waktu tahapan yang dilakukan pada penelitian ini serta menjelaskan mengenai kegiatan yang dilakukan selama penelitian . tahapan penelitian dijelaskan dalam bentuk flowchart sehingga dapat menjelaskan proses yang dilakukan mulai dari studi literatur sampai dengan kesimpulan jadwal dan estimasi penelitian digambarkan dalam bentuk time table untuk menjadwalkan dan melakukan estimasi waktu dari tiap tahap yang dilakuk an. 3.1 tahapan penelitian terdapat beberapa tahapan yang dilakukan untuk melakukan penelitian ini beberapa tahapan yang dilakukan dapat dilihat pada gambar 3.1 . gambar 3.1 tahapan penelitian 31 3.1.1 studi literatur tahap pertama yang dilakukan yaitu studi literature yang bertujuan untuk mencari informasi atau pengetahuan dari paper atau buku sebagai teori pendukung untuk melakukan penelitian dan mencari novelty atau gap peneltian yang sudah dilakukan. paper dan buku yang digunakan dalam penelitian ini merupakan paper atau buku 5 tah un terakhir. 3.1.2 pengumpulan data tahap kedua yaitu pengumpulan data data yang digunakan pada penelitian ini adalah data citra digital kelapa sawit dengan tingkat kematangan belum matang setengah matang matang terlalu matang dan tandan buah yang kosong . data diambil dari beberapa sumber melalui website kaggle dan roboflow lalu dilakukan pemilihan gambar yang sesuai untuk dijadikan sebagai dataset. gambar 3.2 contoh data kelapa sawit dari masing masing kelas 3.1.3 preprocessing data sebelum data digunakan pada model machine learning yang dibuat data tersebut akan dilakukan preprocessing data agar data yang akan dilatih sesuai dengan keperluan yang dibutuhkan.,gambar 3.1 tahapan penelitian 31 3.1.1 studi literatur tahap pertama yang dilakukan yaitu studi literature yang bertujuan untuk mencari informasi atau pengetahuan dari paper atau buku sebagai teori pendukung untuk melakukan penelitian dan mencari novelty atau gap peneltian yang sudah dilakukan. paper dan buku yang digunakan dalam penelitian ini merupakan paper atau buku 5 tah un terakhir.
Reviana Siti Mardiah_Kualifikasi.txt,3.1 tahapan penelitian tahapan penelitian merupakan gambaran dari langkah langkah atau proses yang akan dilakukan dalam suatu penelitian. penelitian ini terdiri dari lima tahap an. tahap pertama adalah mengidentifikasi permasalahan pihak terkait interaksi tujuan dan tinjauan pustaka . tahap an kedua adalah membuat model manajemen persediaan beras perum bulog berdasarkan hasil wawancara awal dengan pihak terkait. tahap ketiga adalah melakukan analisis terhadap model manajemen persediaan beras perum bulog untuk mengidentifikasi area yang perlu ditingkatkan . hasil analisis ini akan digunakan untuk merumuskan solusi terhadap permasalahan yang ada . tahap keempat adalah pengembangan solusi berbasis teknologi yang terdiri dari pengembangan be rbagai model dan prototype sistem yang akan diuji . usulan yang pertama adalah model generative ai untuk menghasilkan data sintetis yang realistis yang dapat digunakan sebagai data pelatihan untuk model prediksi . model ini kemudian diintegrasikan ke dalam model ml prediksi produksi hasil panen . usulan yang kedua adalah model prediksi permintaan beras yang merupakan model yang mirip dengan model prediksi produksi hasil panen beras dengan beberapa penyesuaian agar sesuai dengan karakteristik data untuk prediksi permintaan beras. usulan yang ketiga adalah pengembangan prototype decision support system yang mengintegrasikan model prediksi dan optimasi untuk mendukung kebijakan terkait pengadaan cadangan beras . tahap kelima adalah uji coba terhadap prototype decision support system . gambar 3. 1 adalah tahapan pada penelitian ini. 59 gambar 3. 1 tahapan penelitian 3.2 pemodelan manajemen persediaan beras perum bulog manajemen persediaan cadangan beras nasional telah menjadi perhatian penting dalam beberapa tahun terakhir karena meningkatnya permintaan pangan global perubahan iklim dan ketidakstabilan ekonomi. cadangan ini merupakan stok strategis yang diawasi oleh pemerintah untuk menstabilkan persediaan dan harga beras memberikan bantuan saat terjadi kekurangan pangan dan mendukung tujuan ketahanan pangan nasional . manajemen persed iaan cadangan beras yang efektif sangat penting untuk memitigasi risiko yang terkait dengan gangguan persediaan dan fluktuasi harga beras yulianis rachman 2021 yang pada akhirnya akan menjamin ketahanan pangan dan stabilitas ekonomi octania 2021 usdianto setiyowati 2023 . 60 para pemangku kepentingan yang terlibat dalam manajemen cadangan beras ini termasuk kementerian pertanian kementerian perdagangan kem enteri an keuangan dan kem enteri badan usaha milik negara sebagai regulator serta perum bulog yang bertanggung jawab untuk mengelola persediaan beras pemerintah dan stabilisasi harga di tingkat produsen dan konsumen octania 2021 . perum bulog bertanggung jawab untuk menjaga stabilitas harga dengan membeli gabah dan beras dari petani dengan harga yang ditentukan pemerintah ketika harga beli gabah turun sehingga melindungi petani dari kerugian dan menjual beras dengan harga yang lebih rendah daripada harga pasar ketika terjadi kenaikan harga beras untuk memastikan keterjangkauan harga beras bagi masyarakat octania 2021 . lembaga ini bertanggung jawab atas manajemen salah satu komponen cadangan beras nasional yaitu cadangan beras pemerintah cbp termasuk pada pengadaan dalam negeri dan impor penyimpanan dan penyaluran beras untuk kebutuhan stabilisasi harga bantuan pangan dan keadaan darurat fang chen zhang pei gao wang 2020 octania 2021 . beberapa penelitian telah menekankan peran penting perum bulog dalam manajemen persediaan cadangan beras di indonesia . melalui manajemen cbp perum bulog memainkan peran penting dalam menjaga ketahanan pangan nasional terutama saat terjadi fluktuasi harga atau gangguan p ersediaan . keberadaan cbp yang dikelola perum bulog tidak hanya menstabilkan harga beras di pasar tetapi juga menjamin ketersediaan beras bagi masyarakat sehingga berkontribusi terhadap stabilitas ekonomi nasional octania 2021 putro purwaningsih sensuse suryono 2022 silalahi et al. 2019 . mengingat peran penting ini penerapan teknologi ai dapat membantu perum bulog dalam mengoptimalkan berbagai aspek dalam manajemen cadangan beras pemerintah seperti prediksi permintaan dan produksi hasil panen optimasi cadangan beras dan pengambilan keputusan yang lebih baik. ai dapat digunakan untuk menganalisis data historis dan realtime guna menghasilkan prediksi yang akurat mengenai permintaan dan produksi hasil panen beras mehmood et al. 2023 rai et al. 2021 sehingga memungkinkan 61 perum bulog untuk mengoptimalkan cadangan beras menghindari kelebihan atau kekurangan cadangan beras dan mengambil keputusan yang lebih baik dalam manajemen cadangan beras pemerintah h. qin 2023 . berdasarkan kajian model manajemen persediaan beras perum bulog maka penelitian ini berfokus pada pemanfaatan teknologi ai untuk efektivitas manajemen cadangan beras pemerintah terutama pada proses pengadaan . gambar 3.1 menggambarkan model manajemen persediaan beras perum bulog . gambar 3. 2 model manajemen persediaan perum bulog 3.3. analisis analisis ini bertujuan untuk mengungkap kelemahan dan proses yang kompleks dalam manajemen persediaan cadangan beras pemerintah di perum bulog . penelitian ini menggunakan metode analisis swot untuk mengidentifikasi titik titik lemah yang krusial dalam manajemen persediaan cadangan beras pemerintah dan mengembangkan strategi untuk meningkatkan efisiensi dan efektivitas pengelolaan persediaan cadangan beras di indonesia analisis swot bertujuan untuk mengetahui kekuatan kelemahan peluang dan ancaman bisnis. analisis lingkungan internal di fokuskan untuk mengetahui kekuatan dan kelemahan sedangkan analisis lingkungan eksternal difokuskan untuk mengetahui peluang dan ancaman putra pujangkoro situmorang 2022 . 62 1. analisis swot 1. strengths kekuatan s1 dukungan pemerintah perum bulog didukung oleh berbagai kebijakan pemerintah yang bertujuan menjaga stabilitas harga dan ketersediaan beras seperti yang diatur dalam uu no. 18 tahun 2012 tentang pangan dan perpres no. 48 tahun 2016 tentang penugasan kepada perum bulog . hal ini memberikan akses terhadap dukun gan kebijakan dan finansial yang kuat termasuk alokasi anggaran khusus untuk pengadaan cbp anggraini faqih sangadji kadarisman revany 2021 octania 2021 utomo 2020 . s2 infrastruktur logistik yang memadai perum bulog memiliki infrastruktur logistik yang cukup baik termasuk gudang penyimpanan yang tersebar di berbagai daerah yang berperan penting dalam menjaga kecukupan persediaan cadangan beras octania 2021 utomo 2020 s3 pengalaman dan keahlian perum bulog memiliki pengalaman puluhan tahun dalam manajemen persediaan beras mulai dari pengadaan hingga distribusi yang menjadi keunggulan dalam menjaga stabilitas harga dan persediaan beras anggraini et al. 2021 utomo 2020 . 2. weaknesses kelemahan w1 ketidakmampuan untuk bersaing dengan sektor swasta perum bulog sering menghadapi tantangan dalam bersaing dengan sektor swasta yang mampu menawarkan harga lebih tinggi kepada petan i octania 2021 . gambar 3.3 menggambarkan perbedaan yang signifikan antara harga gabah di tingkat petani dengan harga beli yang ditetapkan pemerintah. kon disi ini menyebabkan petani lebih memilih menjual hasil panennya ke sektor swasta. 63 gambar 3. 3 perbandingan harga gabah bps 2023 w2 ketergantungan pada impor meskipun perum bulog memprioritaskan pengadaan dalam negeri untuk memenuhi cbp tetapi masih terdapat ketergantungan pada impor beras terutama selama periode penurunan produksi dalam negeri yang membuat persediaan cbp rentan terhadap fluktuasi harga dan kebijakan perdagangan internasional octania 2021 utomo 2020 . tabel 3.1 dan gambar 3.4 menunjukkan banyaknya jumlah impor beras yang dilakukan perum bulog setiap tahunnya. tabel 3. 1 jumlah impor beras bps 2024 negara asal 2017 2018 2019 2020 2021 2022 2023 berat bersih ton india 32209.7 337999 7973.3 10594.4 215386.46 178533.57 69715.7 thailand 108944.8 795600.1 53278 88593.1 69360.037 80182.506 1381921.2 vietnam 16599.9 767180.9 33133.1 88716.4 65692.874 81828.039 1147705.3 pakistan 87500 310990 182564.9 110516.5 52479.011 84407 309309.7 myanmar 57475 41820 166700.6 57841.4 3790 3830 141204 jepang 72.1 0.2 90 0.3 230.291 56.087 61.5 tiongkok 2419 227.7 24.3 23.8 42.601 6 7 lainnya 54.3 6.5ssss 744.6 0.3 760.146 364.065 12933.3 total 305274.8 2253824.4 444508.8 356286.2 407741.42 429207.27 3062857.6 02000400060008000 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024perbandingan harga rata rata gkp di tingkat petani dan harga pembelian pemerintah tingkat petani kelompok kualitas gkp gabah kering panen tingkat petani hpp harga pembelian pemerintah gkp gkp gabah kering panen64 gambar 3. 4 jumlah impor beras bps 2024 w3 manajemen persediaan yang tidak efisien terdapat ketidakmampuan dalam memprediksi permintaan dan persediaan secara akurat dan realtime yang menyebabkan kelebihan dan kekurangan persediaan anggraini et al. 2021 utomo 2020 . w4 keterbatasan teknologi dan transparansi sistem yang ada saat ini tidak memiliki kapasitas untuk mencatat transaksi secara transparan yang mengakibatkan meningkatnya risiko kebocoran dan penipuan di sepanjang rantai pasok anggraini et al. 2021 utomo 2020 . w5 koordinasi antar lembaga koordinasi antara perum bulog dan lembaga pemerintah lainnya seperti kementerian pertanian dan kementerian perdagangan terkadang menghadapi tantangan karena adanya perbedaan data sehingga berdampak pada kelancaran pengambilan keputusan kebijakan impor siahaan 2023 . 3. opportunities peluang o1 memanfaatkan teknologi canggih integrasi teknologi canggih seperti blockchain dan ai berpotensi meningkatkan presisi transparansi dan efisiensi dalam mengelola persediaan cbp anggraini et al. 2021 putro et al. 2022 utomo 2020 . 0500000100000015000002000000250000030000003500000 2017 2018 2019 2020 2021 2022 2023berat bersih tonimpor beras tahun 2017 2023 impor beras65 o2 pengembangan sistem yang terintegrasi terdapat peluang untuk mengembangkan sistem yang lebih terintegrasi dan canggih yang dapat memfasilitasi pengelolaan cbp yang lebih baik anggraini et al. 2021 putro et al. 2022 utomo 2020 . 4. threats ancaman t1 ketidakstabilan harga dan persediaan global ketidakstabilan harga dan persediaan beras di pasar global dapat mempengaruhi kemampuan perum bulog untuk mengimpor beras dalam jumlah yang cukup dan dengan harga yang stabil octania 2021 . t2 dampak perubahan iklim perubahan iklim yang ekstrim dapat mengganggu produksi beras dalam negeri sehingga meningkatkan risiko ketidakcukupan cbp dan fluktuasi harga beras di tingkat konsumen octania 2021 saud wang fahad alharby bamagoos mjrashi alabdallah alzahrani abdelgawad adnan 2022 . 2. strategi setelah dilakukan analisis swot maka dapat dirumuskan strategi yang dapat digunakan perum bulog untuk meningkatkan kekuatan mengatasi kelemahan memanfaatkan peluang dan meminimalkan potensi ancaman . berikut adalah rincian strategi strategi tersebut . a. strategi s o leveraging strengths to optimize opportunities so1 pemanfaatan teknologi blockchain untuk transparansi dan efisiensi memanfaatkan dukungan pemerintah untuk mengadopsi teknologi blockchain dalam manajemen pangan yang dapat meningkatkan transparansi efisiensi dan keamanan dalam transaksi dan pencatatan. teknologi ini membantu dalam pencatatan mengotomatisasi kontrak memverifikasi transaksi dan melacak keaslian produk dari produsen ke konsumen s1 o1. 66 so2 pengembangan sistem terintegrasi meningkatkan infrastruktur yang sudah ada dengan mengembangkan sistem manajemen data yang terintegrasi dan canggih untuk memperkuat pengelolaan cbp secara lebih efektif s2 o2. so3 pengembangan model prediksi permintaan dan produksi hasil panen memanfaatkan ai untuk mengembangkan model prediksi permintaan dan produksi hasil panen beras yang akurat sehingga memungkinkan pengambilan keputusan pengadaan yang lebih tepat untuk menghindari kelebihan atau kekurangan persediaan s3 o1 o2. so4 optimalisasi program peningkatan produksi pangan memanfaatkan tenaga ahli dan infrastruktur yang ada untuk mendukung program pemerintah dalam meningkatkan produksi pangan lokal mengurangi ketergantungan impor serta memperkuat stabilitas harga dan persediaan beras s1 s3 o3. b. strategi s t using strengths to counter threats st1 pengembangan alat pendukung keputusan untuk pengadaan impor mengembangkan decision support tool dst dengan menggunakan input dari model prediksi untuk membantu menentukan kebijakan impo r beras. ds t akan membantu mengidentifikasi jumlah impor yang optimal berdasarkan analisis kebutuhan dan persediaan beras dalam negeri sehingga mengurangi risiko ketidakstabilan persediaan dan harga beras s2 t1. st2 optimalisasi manajemen krisis dengan prediksi produksi hasil panen menerapkan model prediksi hasil panen untuk mempersiapkan dan merespons secara efektif dampak perubahan iklim pada produksi beras . model prediksi ini dimanfaatkan untuk meningkatkan ketahanan pangan dan kesiapan dalam menghadapi fluktuasi hasil panen yang tidak terduga s3 t2. 67 c. strategi wo minimizing weaknesses by seizing opportunities wo1 mengadopsi teknologi blockchain untuk meningkatkan kepercayaan dan efisiensi mengadopsi teknologi blockchain untuk mengatasi keterbatasan teknologi saat ini seperti sistem yang kurang transparan . blockchain akan meningkatkan kepercayaan dan kredibilitas dalam operasi perum bulog memfasilitasi transaksi yang lebih aman dan audit yang dapat diverifikasi w1 w4 o1. wo2 peningkatan koordinasi antar lembaga melalui sistem terintegrasi membangun sistem terintegrasi yang melibatkan semua lembaga terkait untuk mengatasi masalah kurangnya koordinasi dan perbedaan data serta memfasilitasi pengambilan keputusan yang lebih cepat dan akurat w5 o2. d. strategi wt minimizing weaknesses and avoiding threats wt1 mengoptimalkan kebijakan impor dengan model prediksi menggunakan model prediksi untuk mengurangi ketergantungan pada impor dengan mengidentifikasi jumlah produksi hasil panen dalam negeri yang dapat memenuhi permintaan sekaligus mengetahui perlu atau tidaknya dilakukan impor w2 w3 t1. wt2 peningkatan manajemen persediaan melalui analisis tingkat lanjut meningkatkan sistem manajemen persediaan dengan model prediksi agar lebih responsif terhadap perubahan permintaan dan kondisi darurat serta mengurangi risiko kekurangan persediaan dan mengatasi fluktuasi harga w3 t2. setelah melakukan analisis swot da n merumuskan strategi maka hasilnya akan dirangkum dalam bentuk matriks swot yang terlampir pada gambar 3.5. 68 gambar 3.,usulan yang kedua adalah model prediksi permintaan beras yang merupakan model yang mirip dengan model prediksi produksi hasil panen beras dengan beberapa penyesuaian agar sesuai dengan karakteristik data untuk prediksi permintaan beras. cadangan ini merupakan stok strategis yang diawasi oleh pemerintah untuk menstabilkan persediaan dan harga beras memberikan bantuan saat terjadi kekurangan pangan dan mendukung tujuan ketahanan pangan nasional . melalui manajemen cbp perum bulog memainkan peran penting dalam menjaga ketahanan pangan nasional terutama saat terjadi fluktuasi harga atau gangguan p ersediaan . 2023 rai et al. 2021 sehingga memungkinkan 61 perum bulog untuk mengoptimalkan cadangan beras menghindari kelebihan atau kekurangan cadangan beras dan mengambil keputusan yang lebih baik dalam manajemen cadangan beras pemerintah h. qin 2023 . gambar 3. 2 model manajemen persediaan perum bulog 3.3. analisis analisis ini bertujuan untuk mengungkap kelemahan dan proses yang kompleks dalam manajemen persediaan cadangan beras pemerintah di perum bulog . analisis lingkungan internal di fokuskan untuk mengetahui kekuatan dan kelemahan sedangkan analisis lingkungan eksternal difokuskan untuk mengetahui peluang dan ancaman putra pujangkoro situmorang 2022 . hal ini memberikan akses terhadap dukun gan kebijakan dan finansial yang kuat termasuk alokasi anggaran khusus untuk pengadaan cbp anggraini faqih sangadji kadarisman revany 2021 octania 2021 utomo 2020 . gambar 3.3 menggambarkan perbedaan yang signifikan antara harga gabah di tingkat petani dengan harga beli yang ditetapkan pemerintah. tabel 3. w4 keterbatasan teknologi dan transparansi sistem yang ada saat ini tidak memiliki kapasitas untuk mencatat transaksi secara transparan yang mengakibatkan meningkatnya risiko kebocoran dan penipuan di sepanjang rantai pasok anggraini et al. 2021 utomo 2020 . w5 koordinasi antar lembaga koordinasi antara perum bulog dan lembaga pemerintah lainnya seperti kementerian pertanian dan kementerian perdagangan terkadang menghadapi tantangan karena adanya perbedaan data sehingga berdampak pada kelancaran pengambilan keputusan kebijakan impor siahaan 2023 . 3. opportunities peluang o1 memanfaatkan teknologi canggih integrasi teknologi canggih seperti blockchain dan ai berpotensi meningkatkan presisi transparansi dan efisiensi dalam mengelola persediaan cbp anggraini et al. 2021 putro et al. 2022 utomo 2020 . 0500000100000015000002000000250000030000003500000 2017 2018 2019 2020 2021 2022 2023berat bersih tonimpor beras tahun 2017 2023 impor beras65 o2 pengembangan sistem yang terintegrasi terdapat peluang untuk mengembangkan sistem yang lebih terintegrasi dan canggih yang dapat memfasilitasi pengelolaan cbp yang lebih baik anggraini et al. 2021 putro et al. 2022 utomo 2020 . t2 dampak perubahan iklim perubahan iklim yang ekstrim dapat mengganggu produksi beras dalam negeri sehingga meningkatkan risiko ketidakcukupan cbp dan fluktuasi harga beras di tingkat konsumen octania 2021 saud wang fahad alharby bamagoos mjrashi alabdallah alzahrani abdelgawad adnan 2022 . 2. strategi setelah dilakukan analisis swot maka dapat dirumuskan strategi yang dapat digunakan perum bulog untuk meningkatkan kekuatan mengatasi kelemahan memanfaatkan peluang dan meminimalkan potensi ancaman . so3 pengembangan model prediksi permintaan dan produksi hasil panen memanfaatkan ai untuk mengembangkan model prediksi permintaan dan produksi hasil panen beras yang akurat sehingga memungkinkan pengambilan keputusan pengadaan yang lebih tepat untuk menghindari kelebihan atau kekurangan persediaan s3 o1 o2. so4 optimalisasi program peningkatan produksi pangan memanfaatkan tenaga ahli dan infrastruktur yang ada untuk mendukung program pemerintah dalam meningkatkan produksi pangan lokal mengurangi ketergantungan impor serta memperkuat stabilitas harga dan persediaan beras s1 s3 o3.
Reza Al Husna_Kualifikasi.txt,3.1 tahapan penelitian secara garis besar penelitian ini terdiri dari beberapa tahapan yaitu akuisisi data preprocessing data pengembangan dan pelatihan model pengujian dan evaluasi model serta pengembangan system deteksi penyakit daun kakao ditunjukkan pada gambar 3.1. gambar 3.1 tahapan penelitian 3.2 akuisisi data penyakit daun tanaman kakao pengumpulan citra penyakit daun tanaman kakao dikumpulkan secara langsung oleh peneliti data primer dan juga menggunakan data yang dikumpulkan oleh peneliti lain data sekunder. terdapat 4 kelas penyakit dan satu kelas daun sehat yang akan digunakan dalam penelitian ini yaitu daun sehat penyakit antraknosa colletotrichum gloeosporioides penyakit vascular streak dieback vsd penyakit leaf blotch dan penyakit cocoa swollen shoot virus disease cssvd. 46 gambar 3.2 contoh 4 jenis penyakit daun tanaman kakao dataset primer akan dilakukan pengambilan foto penyakit daun tanaman kakao yang terdapat pada kebun kakao di daerah kabupaten solok provinsi sumatra barat. pengambilan akan dilakukan dari jarak 20cm dari kamera yang bertujuan menangkap detail kecil seperti bercak kecil atau lesi pada daun perubahan warna serta tekstur permukaan daun. dataset sekunder meng gunakan dataset yang telah digunakan u mum oleh para peneliti lain terkait penyakit daun tanaman kakao. 3.3 preprocessing 3.3.1 resiz e dataset perubahan ukuran citra dilakukan menggunakan metode nearest neighbor interpolation . cara kerja dari metode ini dengan cara mengambil nilai piksel terdekat dari citra asli untuk menentukan nilai piksel baru dalam citra yang akan diubah ukurannya. citra diubah ukurannya menjadi seragam 224x224 piksel . faktor skala dihitung dengan membandingkan dimensi citra asli dimana 𝑊𝐻 dengan dimensi baru 𝑊𝐻 yang akan diubah. untuk setiap piksel dalam citra baru dengan koordinat 𝑖𝑗 hitung koordinat terdekat di citra asli 𝑖𝑗. selanjutnya map nilai piksel yaitu mengambil nilai piksel dari citra asli pada koordinat 𝑖𝑗 dan menetapkan nilai ke piksel baru di koordinat 𝑖𝑗 dalam citra yang diubah ukurannya. 3.3.2 grayscale pada tahap ini citra rgb dikonversi ke grayscale untuk membantu menyederhanakan dan.memfokuskan informasi intensitas cahaya yang lebih relevan.,3.1 tahapan penelitian secara garis besar penelitian ini terdiri dari beberapa tahapan yaitu akuisisi data preprocessing data pengembangan dan pelatihan model pengujian dan evaluasi model serta pengembangan system deteksi penyakit daun kakao ditunjukkan pada gambar 3.1. gambar 3.1 tahapan penelitian 3.2 akuisisi data penyakit daun tanaman kakao pengumpulan citra penyakit daun tanaman kakao dikumpulkan secara langsung oleh peneliti data primer dan juga menggunakan data yang dikumpulkan oleh peneliti lain data sekunder. terdapat 4 kelas penyakit dan satu kelas daun sehat yang akan digunakan dalam penelitian ini yaitu daun sehat penyakit antraknosa colletotrichum gloeosporioides penyakit vascular streak dieback vsd penyakit leaf blotch dan penyakit cocoa swollen shoot virus disease cssvd. 46 gambar 3.2 contoh 4 jenis penyakit daun tanaman kakao dataset primer akan dilakukan pengambilan foto penyakit daun tanaman kakao yang terdapat pada kebun kakao di daerah kabupaten solok provinsi sumatra barat.
Robert_Kualifikasi.txt,3.1 alur penelitian gambar 3.1 menunjuk kan metode penelitian. terdapat 5 tahap utama yang akan dilakukan yang pertama adalah studi literatur untuk menyusun bab 1 dan bab 2. tahap kedua adalah pengumpulan citra ekspresi wajah data citra berupa data primer dan data sekunder. tahap ketiga adalah pembentukan dataset untuk tiap model svm cnn dan mnn skenario pembentukan dataset dilakukan berdasarkan pada penelitian robert 2023 . pada tahap keempat dilakukan pembentukan model khusus untuk svm dan cnn menggunakan model pada penelitian robert 2023 sedangkan mnn menggunakan usulan pada penelitian ini. tahap terakhir adalah pelatihan dan pengujian untuk semua model svm cnn mnn terdapat tahap parameter tuning untuk tiap model . kemudian semua performa dari tiap model akan dibandingkan satu sama lain dan juga dianalisis pada bab 4. gambar 3.1. metode penelitian 48 3.2 pengumpulan citra ekspresi wajah citra ekspresi wajah dikumpulkan secara langsung oleh peneliti data primer dan juga menggunakan data yang dikumpulkan oleh peneliti lain data sekunder. terdapat 7 ekspresi wajah yang akan digunakan dalam penelitian ini yaitu marah jijik menghina senang sedih kaget dan netral tanpa ekspresi. gambar 3.2 menunjukkan contoh 7 ekspresi wajah manusia yang digunakan penelitian ini. gambar 3.2. contoh 7 jenis ekspresi wajah dataset primer akan dilakukan pengambilan citra ekspresi wajah mahasiswa universitas gunadarma baik pria maupun wanita. pengambilan akan dilakukan dari beberapa sudut pandang guna menambah variasi dataset . gambar 3.3 menunjukan contoh dataset primer dari berbagai sudut pandang. gambar 3.3. contoh dataset primer 49 dataset sekunder digunakan dataset yang telah digunakan umum oleh peneliti lain terkait pengenalan ekspresi wajah. terdapat beberapa dataset yang umum digunakan dalam penelitian ekspresi wajah . pertama extended cohn kanade ck yang berisi citra ekspresi wajah pria dan wanita dari berbagai etnis dengan resolusi tinggi kanade cohn tian 2000 lucey et al. 2010 . kedua taiwanese facial expression image dataset tfeid yang berisi citra ekspresi wajah pria dan wanita dari etnis taiwan chen yen 2007 . ketiga japanese female facial expression jaffe yang terdiri dari citra ekspresi wajah wanita etnis j epang lyons 2021 lyons kamachi gyoba 2020 . gambar 3.4 menunjukan contoh citra dataset ck a jaffe b dan tfeid c. gambar 3.4. contoh dataset sekunder 50 tabel 3.1 menunjukkan detail dari tiap dataset mulai dari jumlah citra dari tiap kelas serta ruang warna dan ukuran citra. ck memiliki jumlah yang tidak seimbang pada kelas neutral dan memiliki ruang warna campur antara rgb dan gray dengan ukuran citra dikisaran 640 490. jaffe dataset memiliki jumlah citra pada tiap kelas yang seimbang dengan perbedaan diantara 0 hingga 2 citra ukuran citra 256 256 dan ruang warna grayscale . tfeid juga memiliki jumlah citra yang seimbang ditiap kelas ukuran citra diki saran 481 600 ruang warna rgb. tabel 3.1. detail dataset sekunder ekspresi dataset ck dataset jaffe dataset tfeid total anger 45 30 34 109 disgust 59 29 40 128 fear 25 32 40 97 happy 69 31 40 140 neutral 107 30 39 176 sad 28 31 39 98 surprise 83 30 36 149 ukuran citra 640490 256256 481600 warna citra rgb gray gray rgb 51 3.3 pembentukan dataset secara garis besar dalam pembuatan model ai khususnya ml dan dl terdapat proses yang berperan penting yaitu preprocessing dataset seperti ekstrasi fitur penyesuaian ukuran citra dan augmentasi deshmukh et al. 2016 franchi et al. 2020 mohammad ali 2011 ravi et al. 2020 sawardekar naik 2018 shan et al. 2009 . pada penelitian robert 2023 dilakukan sebuah skenario pembentukan dataset menggunakan beberapa metode pengolahan citra seperti konversi warna ke grayscale deteksi wajah dan e kstrasi fitur di mana preprocessing mempengaruhi performa dari model ml dan dl. selain itu pada penelitian alam yao 2019 juga dilakukan penelitian yang serupa di mana preprocessing mempengaruhi performa model machine learning . pada tahap ketiga dilakukan pembentukan dataset . gambar 3.5 menunjukkan alur pembentukan dataset untuk svm . pertama dilakukan pendeteksian wajah menggunakan vja proses ini berguna untuk mengurangi noise pada citra . hasil vja membuat ukuran citra bervariasi oleh karena itu dilakukan resizing citra untuk menyamakan semua ukuran citra dan juga menyesuaikan dengan dimensi input model . selanjutnya dilakukan konversi warna citra dari rgb ke grayscale dikarena fitur warna tidak dibutuhkan dan agar dapat diekstrasi fiturnya menggunakan lmp. terakhir terdapat dua proses ekstrasi fitur berbeda . proses ekstrasi fitur pertama menggunakan lmp robert 2023 . proses ekstrasi fitur kedua adalah usulan dari penelitian ini di mana pertama diaplikasikan gabor filter terlebih dahulu kemudian diekstrasi menggunakan lmp. gambar 3.5. pembentukan dataset untuk svm 52 gambar 3.6 menunjukkan alur pembentukan dataset untuk cnn dan mnn . terdapat 3 proses yang akan dilakukan . pertama dilakukan deteksi wajah menggunakan vja guna mengurangi noise . kemudian dilakukan konversi warna dari rgb ke grayscale karena fitur warna tidak dibutuhkan untuk mengenali ekspresi wajah. t erakhir mengubah ukuran citra untuk menyamakan semua ukuran citra dan sesuai dengan dimensi input model . skema pembentukan dataset ini berdasarkan performa terbaik dari penelitian robert 2023 . gambar 3.6. pembentukan dataset untuk cnn dan mnn dataset yang sudah melalui pembentukan dataset dilakukan augmentasi dari sisi geometris seperti membalikan flipping secara horizontal dan verti kal dan rotasi dari 0 hingga 45 . tujuan dari augmentasi dataset adalah memperbanyak dataset dan juga variasi dataset . dataset yang telah dibentuk kemudian dibagi menjadi dua jenis dataset . jenis pertama adalah training dataset dengan jumlah 90 dari total semua dataset . kedua adalah testing dataset yang terdiri dari 10 dari total semua dataset . gambar 3.7 menunjukkan visualisasi pembagian dataset . svm training dataset digunakan untuk melatih model sedangkan testing dataset digunakan untuk menguji dataset . cnn dan mnn terdapat pembagian lagi pada training di mana 90 dari training dataset digunakan untuk melatih model dan 10 dari training dataset digunakan untuk validasi dan testing dataset digunakan untuk menguji model. proses pembentukan dataset untuk svm cnn dan mnn menggunakan algoritma 3.1 hingga algoritma 3.6. 53 gambar 3.7. visualisasi pembagian dataset 3.3.1 deteksi wajah proses deteksi wajah menggunakan vja vja memanfaatkan dua komponen yaitu integral image dan haar basis function . algoritma 3.1 menunjukkan cara menghitung dari integral image . input merupakan citra dengan ruang warna grayscale dengan nama variab el img dengan ukruan 𝑤ℎ dan output berupa integral image yang disimpan pada nama variab el itg_img. algoritma integral image cukup sederhana baris 1 dan 2 dilakukan perulangan terhadap baris dan kolom citra yang digunakan untuk menentukan koordinat integral image yang sedang dihitung. b aris ketiga dilakukan perhitungan integral image untuk koordinat 𝑖𝑗 yang menghitung total nilai piksel citra asli mulai dari koordinat 00 hingga 𝑖𝑗 menggunakan persamaan 2.18. 54 algoritma 3.1. integral image 1 2 3 4 5 input citra grayscale wh img output citra integral wh itg_img for i 0 to w do for j 0 to h do itg_imgij sumimg_gry0i0j end for end for algoritma 3.2 menunjukkan cara kerja dari vja. input dari algoritma 3.2 adalah citra integral dengan ukuran 𝑤ℎ yang diproses menggunakan algoritma 3.1. terdapat beberapa parameter yang digunakan pada algoritma 3.2. parameter pertama adalah detection window dengan ukuran 𝑤2 ℎ2 yang digunakan untuk perhitungan haar . parameter kedua adalah haar yang menggunakan gambar 2.14. parameter ketiga adalah nilai threshold untuk masing masing haar yang digunakan untuk menentukan apakah haar tersebut merupakan fitur wajah atau bukan. output dari algoritma ini adalah berupa koordinat wajah yang dimulai pada koordinat 𝑥1𝑦1 dengan panjang dan lebar yaitu 𝑤2ℎ2. baris pertama dan kedua dilakukan perulangan terhadap baris dan kolom citra yang digunakan untuk menentukan koordinat detction window agar lebih mudah memahami dapat melihat gambar 3.8. setiap perulang an pada baris pertama dan kedua dilakukan komputasi tiap area haar mulai dari jenis haar a hingga d. pada baris 491317 terdapat tiga perhitungan. perhitungan pertama adalah area putih perhitungan kedua adalah area hitam perhitungan ketiga adalah fitur area putih area hitam untuk lebih mudah memahami perhitungan area putih area hitam dan fitur dapat melihat gambar 3.9. setiap perhitungan nilai fitur a hingga fitur d dilakukan pengecekan apakah nilai fitur yang dihitung merupakan fitur atau bukan dengan cara membandingkan nilai fitur dengan threshold masing masing th_a hingga th_d seperti baris 6101418. jika salah satu dari keempat nilai fitur lebih kecil dari threshold yang ditentukan maka haar tersebut bukan merupakan fitur wajah dan algoritma akan melakukan pergeseran detection window ke koordinat selanjutnya. selain itu jika semua nilai fitur lebih besar dari threshold maka detection window tersebut merupakan wajah dan algoritma akan memberikan 55 empat nilai yaitu 𝑖𝑗𝑑𝑤𝑑ℎ. 𝑖𝑗 merupakan koordinat dari deteksi terakhir. 𝑑𝑤𝑑ℎ merupakan luas dari detection window itu sendiri. algoritma 3.2. algoritma viola jones 1 2 3 4 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 input citra integral wh itg_gry parameter detection window dengan ukuran w2h2 dw haar pada gambar 2.14 a hingga d thershold tha hingga the output koordinat wajah x1y1w2h2 for i 0 to ww2 do for j 0 to hh2 do hitung fitur haar a pada gambar 2.14 hitung fitur_a area putih gambar 2.14 a area hitam gambar 2.14 a untuk detection window iiw2jjh2 if fitur_a th_a do continue hitung fitur haar b pada gambar 2.14 hitung fitur_b area putih gambar 2.14 b area hitam gambar 2.14 b untuk detection window iiw2jjh2 if fitur_b th_b do continue hitung fitur haar c pada gambar 2.14 hitung fitur_c area putih gambar 2.14 c area hitam gambar 2.14 c untuk detection window iiw2jjh2 if fitur_c th_c do continue hitung fitur haar d pada gambar 2.14 hitung fitur_d area putih gambar 2.14 d area hitam gambar 2.14 d untuk detection window iiw2jjh2 if fitur_d th_d do continue return ijdwdh 56 gambar 3.8. pergeseran detection window gambar 3.9. contoh perhitungan haar gambar 3.9 menunjukkan contoh perhitungan untuk fitur a dan b pada algoritma 3.2 baris 4 dan 9. pertama dilakukan perhitungan pada area hitam dan putih . untuk mendapatkan hanya luas 𝐷 dilakukan pengurangan dengan luas 𝐵 dan 𝐶 kemudian dilakukan pertambahan luas 𝐴. perhitungan dilakukan secara demikian dikarenakan pada integral image luas 𝐷𝐴𝐵𝐶𝐷 luas 𝐵𝐴𝐵 dan luas 𝐶𝐴𝐶. secara teknis pengurangan dengan luas 𝐴 dilakukan dua kali 57 dikarenakan luas 𝐵 dan 𝐶 oleh karena itu dilakukan pertambahan luas 𝐴 setelah pengurangan dengan 𝐵 dan 𝐶. perhitungan luas 𝐻 memiliki pola yang sama dengan perhitungan luas 𝐷. kemudian dilakukan pengurangan antara area putih dengan hitam untuk mendapatkan nilai fitur. fitur kemudian dibandingkan dengan nilai thershold untuk menentukan apakah haar tersebut fitur wajah atau bukan. pola untuk perhitungan area putih area hitam dan fitur untuk haar a b c d memiliki pola yang sama. gambar 3.10 menunjukkan hasil dari implementasi algoritma deteksi wajah pada sebuah citra. a b c gambar 3.10. a citra original b hasil deteksi c hasil cropping 58 3.3.2 image resize proses perubahan ukuran citra menggunakan metode bicubic interpolation . algoritma 3.3 menunjukkan cara kerja dari bicubic interpolation . input berupa citra yang ingin diubah ukurannya dan ra sio skala ukuran yang diinginkan. parameter berupa koefisien a yang dapat mempengaruhi koordinat tetangga umumnya nilai dikisaran 0.75 hingga 0.5. hasil dari algoritma ini adalah citra dengan ukuran 𝐻𝑟𝑊𝑟𝐶. pada baris 1 dilakukan perhitungan 𝑑𝐻 𝑑𝑊 yang digunakan untuk menentukan ukuran citra setelah diubah ukurannya dan kemudian dilakukan perhitungan ℎ yang digunakan untuk konstanta yang akan mempengaruhi koordinat tetangga pada piksel yang akan dihitung . baris 2 dilakukan pembuatan matri ks yang digunakan untuk menyimpan hasil. baris 456 dilakukan perulangan pada channel 𝑑𝐻 𝑑𝑊 matri ks yang dibuat pada baris 2 perulangan ini digunakan untuk menentukan koordinat matri ks hasil yang akan dihitung. baris 6 dan 7 dilakukan perhitungan 𝑥 dan 𝑦 yang merupakan konstanta yang mempengaruhi koordinat tetangga nilai berubah setiap perulangan berjalan pada baris 3 4 5. baris 8 hingga 15 dilakukan perhitungan 𝑥1 hingga 𝑥4 dan 𝑦1 hingga 𝑦4 variab el tersebut digunakan untuk menentukan bobot weight tiap tetangga dan koordinat tetangga pada piksel yang sedang dihitung. b aris 16 dan 17 dilakukan perhitungan menggunakan persamaan 2.19 di mana baris 16 perhitungan untuk bobot horizontal baris 17 untuk bobot vertikal yang masing masing disimpan pada matrix_l dan matrix_r. baris 19 dilakukan pembuatan matri ks berukuran 4 4 yang digunakan untuk menyimpan nilai piksel tetangga. baris 20 hingga 35 merupakan pengambilan nilai tetangga berdasarkan dari perhitungan sebelumnya. baris 36 merupakan perkalian antara matriks tetangga 4 4 dengan bobot horizontal kemudian dikalikan dengan bobot verti kal. hasil yang didapatkan kemudian disimpan pada variab el output . 59 algoritma 3.3. image resize menggunakan bicubic interpolation input citra ukuran 𝐻𝑊𝐶 img ratio antara 0 hingga r parameter koefisien a 0.5 a output citra ukuran 𝐻𝑟𝑊𝑟𝐶 output 1 calculate dh hr dw wr h 1ratio used for calculation 2 create matrix output dimension dhdwc to store result 3 for i 0 to c do 4 for j 0 to dh do 5 for k 0 to dw do 6 calculate x i h 2 7 calculate y j h 2 8 calculate x1 1 x floorx 9 calculate x2 x flootx 10 calculate x3 floorx 1 x 11 calculate x4 flootx 2 x 12 calculate y1 1 y floory 13 calculate y2 y flooty 14 calculate y3 floory 1 y 15 calculate y4 flooty 2 y 16 create matrix mat_l dimension 14 mat_r dimension 41 h menggunakan pers 2.19 17 calculate mat_l00 hx1 mat_l01 hx2 mat_l02 hx3 mat_l03 hx4 bobot horizontal 18 calculate mat_r00 hy1 mat_l01 hy2 mat_l02 hy3 mat_l03 hy4 bobot vertical 19 create matrix mat_m dimension 44 20 mat_l00 img yy1 xx1 21 mat_l10 img yy2xx1 22 mat_l20 img yy3xx1 23 mat_l30 img yy4xx1 24 mat_l01 img yy1 xx2 25 mat_l11 img yy2xx2 26 mat_l21 img yy3xx2 27 mat_l31 img yy4xx2 28 mat_l02 img yy1 xx3 29 mat_l12 img yy2xx3 30 mat_l22 img yy3xx3 31 mat_l32 img yy4xx3 32 mat_l03 img yy1 xx4 33 mat_l13 img yy2xx4 34 mat_l23 img yy3xx4 35 mat_l33 img yy4xx4 60 36 calculate output mat_m mat_l mat_r gambar 3.11 menunjukkan hasil perubahan ukuran citra wajah menggunakan algoritma 3.3. berdasarkan gambar 3.11 ukuran dari input citra adalah 600 480 dan ratio 05. ukuran menjadi 300 240 setelah melalui proses algoritma perubahan ukuran citra . a b gambar 3.11 a citra original b citra setelah diubah ukurannya 61 3.3.3 color conversion proses konversi warna dari rgb ke grayscale menggunakan persamaan 2.2. algoritma 3.4 menujukan proses konversi ruang warna citra dari rgb ke grayscale dengan cara mengambil nilai y dari yc bcr. input dari algoritma ini adalah citra rgb yang memiliki dimensi 𝑊𝐻𝐶 yang diberi nama variabel img_rgb. output dari algoritma ini adalah citra grayscale yang disimpan pada variable img_gry. baris 1 dan 2 dilakukan perulangan baris dan kolom citra yang digunakan untuk menentukan koordinat citra grayscale yang akan dihitung. baris 3 dilakukan konversi citra grayscale menggunakan persamaan 2.2 di mana dilakukan penjumlahan nilai dari ketiga channel citra rgb. tiap channel memiliki bobot masing masing untuk channel r memiliki bobot 0.299 channel g memiliki bobot 0.587 dan channel b memiliki bobot 0.114. gambar 3.12 menunjukkan contoh hasil implementasi algoritma konversi warna dari rgb ke grayscale dengan menggunakan nilai y dari yc bcr. algoritma 3.4. rgb to grays cale 1 2 3 4 5 input citra rgb whc img_rgb output citra grayscale wh img_gry for i 0 to w do for j 0 to h do img_gryij 0.299img_rgbij0 0.587img_rgbij1 0.114img_rgbij2 end for end for a b gambar 3.12. sebelum a dan sesudah b konversi warna 62 3.3.4 gabor filter pada proses svm terdapat proses gabor filter sebelum diekstra ksi menggunakan lmp. pertama dilakukan pembuatan filter terlebih dahulu. algoritma 3.5 menunjukkan cara pembuatan gabor filter. input dari algoritma ini adalah sebuah citra grayscale yang memiliki ukuran 𝐻𝑊. kemudian jumlah filter luas kernel lambda 𝜆 psi 𝜑 sigma 𝜎 dan gamma 𝛾 yang akan digunakan untuk pembuatan gabor filter . terakhir adalah threshold bawah dan threshold atas yang digunakan untuk deteksi tepi. pada baris 1 dilakukan perulangan untuk menentukan rotasi nilai theta gabor filter berdasarkan jumlah filter yang digunakan. baris 2 dilakukan pembuatan gabor filter berdasarkan persamaan 2.23 dan parameter yang di input .,pada tahap ketiga dilakukan pembentukan dataset . gambar 3.5 menunjukkan alur pembentukan dataset untuk svm . hasil vja membuat ukuran citra bervariasi oleh karena itu dilakukan resizing citra untuk menyamakan semua ukuran citra dan juga menyesuaikan dengan dimensi input model . selanjutnya dilakukan konversi warna citra dari rgb ke grayscale dikarena fitur warna tidak dibutuhkan dan agar dapat diekstrasi fiturnya menggunakan lmp. terakhir terdapat dua proses ekstrasi fitur berbeda . proses ekstrasi fitur pertama menggunakan lmp robert 2023 . terdapat 3 proses yang akan dilakukan . skema pembentukan dataset ini berdasarkan performa terbaik dari penelitian robert 2023 . gambar 3.6. pembentukan dataset untuk cnn dan mnn dataset yang sudah melalui pembentukan dataset dilakukan augmentasi dari sisi geometris seperti membalikan flipping secara horizontal dan verti kal dan rotasi dari 0 hingga 45 . jenis pertama adalah training dataset dengan jumlah 90 dari total semua dataset . kedua adalah testing dataset yang terdiri dari 10 dari total semua dataset . gambar 3.7 menunjukkan visualisasi pembagian dataset . svm training dataset digunakan untuk melatih model sedangkan testing dataset digunakan untuk menguji dataset . cnn dan mnn terdapat pembagian lagi pada training di mana 90 dari training dataset digunakan untuk melatih model dan 10 dari training dataset digunakan untuk validasi dan testing dataset digunakan untuk menguji model. proses pembentukan dataset untuk svm cnn dan mnn menggunakan algoritma 3.1 hingga algoritma 3.6. 53 gambar 3.7. visualisasi pembagian dataset 3.3.1 deteksi wajah proses deteksi wajah menggunakan vja vja memanfaatkan dua komponen yaitu integral image dan haar basis function . algoritma 3.1 menunjukkan cara menghitung dari integral image . input merupakan citra dengan ruang warna grayscale dengan nama variab el img dengan ukruan 𝑤ℎ dan output berupa integral image yang disimpan pada nama variab el itg_img. 54 algoritma 3.1. integral image 1 2 3 4 5 input citra grayscale wh img output citra integral wh itg_img for i 0 to w do for j 0 to h do itg_imgij sumimg_gry0i0j end for end for algoritma 3.2 menunjukkan cara kerja dari vja. selain itu jika semua nilai fitur lebih besar dari threshold maka detection window tersebut merupakan wajah dan algoritma akan memberikan 55 empat nilai yaitu 𝑖𝑗𝑑𝑤𝑑ℎ. 𝑑𝑤𝑑ℎ merupakan luas dari detection window itu sendiri. algoritma 3.2. algoritma viola jones 1 2 3 4 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 input citra integral wh itg_gry parameter detection window dengan ukuran w2h2 dw haar pada gambar 2.14 a hingga d thershold tha hingga the output koordinat wajah x1y1w2h2 for i 0 to ww2 do for j 0 to hh2 do hitung fitur haar a pada gambar 2.14 hitung fitur_a area putih gambar 2.14 a area hitam gambar 2.14 a untuk detection window iiw2jjh2 if fitur_a th_a do continue hitung fitur haar b pada gambar 2.14 hitung fitur_b area putih gambar 2.14 b area hitam gambar 2.14 b untuk detection window iiw2jjh2 if fitur_b th_b do continue hitung fitur haar c pada gambar 2.14 hitung fitur_c area putih gambar 2.14 c area hitam gambar 2.14 c untuk detection window iiw2jjh2 if fitur_c th_c do continue hitung fitur haar d pada gambar 2.14 hitung fitur_d area putih gambar 2.14 d area hitam gambar 2.14 d untuk detection window iiw2jjh2 if fitur_d th_d do continue return ijdwdh 56 gambar 3.8. pergeseran detection window gambar 3.9. contoh perhitungan haar gambar 3.9 menunjukkan contoh perhitungan untuk fitur a dan b pada algoritma 3.2 baris 4 dan 9. pertama dilakukan perhitungan pada area hitam dan putih . untuk mendapatkan hanya luas 𝐷 dilakukan pengurangan dengan luas 𝐵 dan 𝐶 kemudian dilakukan pertambahan luas 𝐴. perhitungan dilakukan secara demikian dikarenakan pada integral image luas 𝐷𝐴𝐵𝐶𝐷 luas 𝐵𝐴𝐵 dan luas 𝐶𝐴𝐶. fitur kemudian dibandingkan dengan nilai thershold untuk menentukan apakah haar tersebut fitur wajah atau bukan. a b c gambar 3.10. a citra original b hasil deteksi c hasil cropping 58 3.3.2 image resize proses perubahan ukuran citra menggunakan metode bicubic interpolation . input berupa citra yang ingin diubah ukurannya dan ra sio skala ukuran yang diinginkan. pada baris 1 dilakukan perhitungan 𝑑𝐻 𝑑𝑊 yang digunakan untuk menentukan ukuran citra setelah diubah ukurannya dan kemudian dilakukan perhitungan ℎ yang digunakan untuk konstanta yang akan mempengaruhi koordinat tetangga pada piksel yang akan dihitung . b aris 16 dan 17 dilakukan perhitungan menggunakan persamaan 2.19 di mana baris 16 perhitungan untuk bobot horizontal baris 17 untuk bobot vertikal yang masing masing disimpan pada matrix_l dan matrix_r. baris 20 hingga 35 merupakan pengambilan nilai tetangga berdasarkan dari perhitungan sebelumnya.
Tatya Atyanti Paramastri_Kualifikasi.txt,3.1. alur penelitian 1. identifikasi masalah gambar 3.1 alur penelitian identifikasi masalah dilakukan supaya permasalahan yang diangkat jelas. identifikasi masalah dilakukan dengan cara melihat permasalahan nyata melalui literatur seperti jurnal penelitian wawancara dengan ahli dan keresahan yang dirasakan oleh peneliti secara pribadi. permasalahan yang diangkat pada penelitian ini adalah motif batik indonesia sangat beragam dan memiliki maknanya masingmasing. namun tidak banyak masyarakat yang masih mengetahui nama makna dan pemakaian dari masingmasing motif batik. menurut dewan ahli ppbi paguyuban pecinta batik indonesia sekar jagad ibu mari s. condronegoro saat ini sering kali ditemukan kesalahan dalam pemakaian motif batik seperti mengenakan kain yang seharusnya digunakan pada upacara kematian ketika menghadiri acara pernikahan. solusi yang diusulkan adalah melakukan klasifikasi motif batik. metode klasifikas yang umum digunakan adalah cnn. namun cnn klasik memiliki kelemahan dalam memahami makna menyeluruh dari gambar terutama yang berkaitan dengan hubungan antar bagian gambar yang berbeda. selain itu cnn klasik juga rentan terhadap overfitting di mana model terlalu terlatih pada data pelatihan dan tidak dapat menggeneralisasi dengan baik ke data baru. 2. studi literatur studi literatur dilakukan supaya penelitian memiliki landasan yang jelas. studi literatur dilakukan dengan sumber jurnal penelitian terdahulu serta buku yang berisikan metode yang sesuai dengan penelitian. fokus studi literatur terbagi menjadi tiga topik yaitu klasifikasi motif batik komputasi kuantum dan deteksi tepi. 3. pengumpulan dataset pengumpulan data dilakukan berdasarkan keperluan penelitian. data yang dikumpulkan merupakan data primer yang akan dikumpulkan degan bantuan ahli yaitu dewan ahli ppbi sekar jagad ibu mari s. condronegoro. ppbi sekar jagad merupakan perkumpulan pecinta batik yang diawasi langsung penasehat utama oleh permaisuri gusti kanjeng ratu hemas istri dari sri sultan hamengku buwono x sehingga informasi yang didapatkan bisa dijamin kebenarannya. pengumpulan dataset primer ini dilakukan dengan diskusi wawancara serta bimbingan dewan ahli ppbi sekar jagad supaya dataset yang digunakan sesuai dengan kebenaran dan kebutuhan penelitian yang dilakukan. sehingga hasil yang didapatkan memuaskan dan akurat.,3.1. alur penelitian 1. identifikasi masalah gambar 3.1 alur penelitian identifikasi masalah dilakukan supaya permasalahan yang diangkat jelas. menurut dewan ahli ppbi paguyuban pecinta batik indonesia sekar jagad ibu mari s. condronegoro saat ini sering kali ditemukan kesalahan dalam pemakaian motif batik seperti mengenakan kain yang seharusnya digunakan pada upacara kematian ketika menghadiri acara pernikahan. metode klasifikas yang umum digunakan adalah cnn. 2. studi literatur studi literatur dilakukan supaya penelitian memiliki landasan yang jelas. pengumpulan dataset primer ini dilakukan dengan diskusi wawancara serta bimbingan dewan ahli ppbi sekar jagad supaya dataset yang digunakan sesuai dengan kebenaran dan kebutuhan penelitian yang dilakukan.
Tia Haryanti_Kualifikasi.txt,3.1 kerangka umum penelitian ini bertujuan untuk mengembangkan sistem deteksi dini kantuk sebelum berkendara dengan menggunakan kombinasi data visual berupa data citra wajah dan data fisiologis. kondisi predriving mengacu pada kondisi sebelum pengemudi memulai perjalanan sehingga sistem ini sangat penting untuk mencegah risiko kecelakaan di jalan . sistem ini mengintegrasikan teknologi pengenalan wajah dan analisis data fisiologis untuk memberikan deteksi yang lebih akurat. blok d iagram secara umum yang digunakan pada penelitian ini dapat dilihat pada gambar 3.1 blok diagram. objek preprocessing data fisiologis ekstrasi fiturpenggabungan fitur klasifikasi data image data visual kantuk ya tidak gambar 3.1 blok diagram model ini terdiri dari tiga tahapan yaitu input proses dan output . penelitian deteksi dini kantuk untuk kondisi predriving menggabungkan data visual yaitu pengumpulan data citra wajah pengemudi yang diambil menggunakan kamera serta data fisiologis yang diukur berupa data ekg menggunakan perangkat wearable yaitu smartwatch dan pulse oximeter untuk mengukur saturasi oksigen spo2 . tahapan preprocessing dan ekstraksi fitur dilakukan pada kedua jenis data yaitu data citra gambar dan data fisiologis. model convolutional neural network cnn digunakan untuk mengekst raksi fitur dari data citra wajah yang merupakan data visual sementara long short term memory lstm digunakan untuk memproses data fisiologis yang bersifat timeseries. fitur fitur yang diekstraksi dari kedua model ini digabungkan untuk menghasilkan vect or fitur gabungan. vektor fitur ini kemudian digunakan sebagai input untuk model support vector machine 43 svm yang melakukan klasifikasi akhir untuk mendeteksi kantuk. hasil deteksi kemudian digunakan untuk memberikan peringatan kepada pengemudi layak tidak nya pengemudi untuk berkendara. 3.2 tahapan peneletian tahapan penelitian merupakan urutan atau langkah langkah yang dilakukan secara terstruktur dan sistematis pada penelitian ini secara garis besar terbagi menjadi empat tahapan. berikut adalah gambar 3.2 tahapan penelitian yang dilakukan pada penelitian ini. pengumpulan data data visualdata fisiologis pemilihan dan persiapan dataset preprocessing data pembuatan modelekstraksi fitur penggabungan fitur evaluasi pemisahan dataset pembangunan model pelatihan model evaluasi model implementasi gambar 3. 2 tahapan penelitian 44 3.3. pemilihan dan persiapan dataset tahapan ini merupakan tahapan identifikasi awal dari penelitian meliputi identifikasi masalah penelitian yang berfokus pada masalah utama yaitu mendeteksi kantuk pada pengemudi menggunakan pemrosesan citra dan fisiologis . tahapan ini dilakukan untuk memasikan bahwa hanya data yang relevan berkualitas tinggi dan siap untuk dip roses lebih lanjut yang digunakan. pemilihan dataset memastikan bahwa dataset yang dikumpulkan relevan dengan tujuan penelitian yaitu hanya menggunakan data yang berkaitan dengan kondisi predriving serta memastikan bahwa data visual dan data fisiologis diambil pada waktu yang sama. tahapan pengumpulan data dan preprocessing data merupakan tahap awal untuk mempersiapkan dataset yang akan digunakan. 3.3.1 pengumpulan data data dibagi menjadi dua kategori utama yaitu data primer dan data sekunder . data primer diperoleh berdasarkan pengumpulan dan pengamatan langsung oleh peneliti berdasarkan kondisi subjek penelitian dan rekaman aktivitas fisik atau ekspresi wajah menggunakan kamera serta pengukuran fisiologis yang menggunakan perangkat wearable . data primer ini berupa data objektif dengan mengumpulkan data citra wajah dan pengukuran fisiologis . berikut merupakan gambar 3. 3 pengumpulan data. matapengumpulan data data visual citra wajahdata fisiologis ekgsaturasi oksigen spo2kamera smartwatch pulse oximetry gambar 3 .3 pengumpulan data dataset visual berupa citra wajah yang berfokus pada wajah pengemudi yang diambil menggunakan kamera dengan spesifikasi 12 mp. data visual dan fisiologis berupa data yang diambil dari partisipan dalam kondisi terjaga dan mengantuk . data fisiologis mencakup pengukuran langsung dari respons tubuh berupa sinyal 45 ekg elektrokardiogram yang merekam detak jantung hr variabilitas detak jantung atau heart rate variability hrv menggunakan perangkat wearable dan pengukuran saturasi oksigen dalam darah spo2 yang diukur menggunakan pulse oximeter. 3.3.2 preprocessing data melakukan analisis eksploratif data untuk memahami karakteristik dataset sehingga meningkatkan kualitas deteksi . preprocessing yang dilakukan yaitu pre processing citra dan preprocessing data fisiologis. preprocessing citra yaitu dengan mendeteksi wajah dan mata normalisasi pencahayaan pemotongan area wajah yang relevan. ektraksi frame dari video menggunakan opencv . pre processing data fisiologis yaitu dengan normalisasi data dan segmentasi. berikut merupakan gambar 3. 4 preprocessing data. data acquisitionfacial landmark detectionroi extraction gambar dari kameraeye detection data fisiologis ekg spo2 noise removal normalizationsave processed datasegmentationresize imagesnormalize pixel value data augmentation gambar 3. 4 preprocessing data data set yang dikumpulkan kemudian diolah yang meliputi normalisasi penghilangan noise dan teknik pra pemrosesan lainnya untuk membuat data siap digunakan dalam ekstraksi fitur. langkah ini melibatkan pembersihan dan penyiapan data untuk analisis. proses preprocessing untuk data visual atau data gambar yaitu 1. pengumpulan data visual dengan mengambil gambar wajah pengemudi menggunakan kamera berfo kus pada mata.,kondisi predriving mengacu pada kondisi sebelum pengemudi memulai perjalanan sehingga sistem ini sangat penting untuk mencegah risiko kecelakaan di jalan . blok d iagram secara umum yang digunakan pada penelitian ini dapat dilihat pada gambar 3.1 blok diagram. fitur fitur yang diekstraksi dari kedua model ini digabungkan untuk menghasilkan vect or fitur gabungan. berikut adalah gambar 3.2 tahapan penelitian yang dilakukan pada penelitian ini. pengumpulan data data visualdata fisiologis pemilihan dan persiapan dataset preprocessing data pembuatan modelekstraksi fitur penggabungan fitur evaluasi pemisahan dataset pembangunan model pelatihan model evaluasi model implementasi gambar 3. 2 tahapan penelitian 44 3.3. pemilihan dan persiapan dataset tahapan ini merupakan tahapan identifikasi awal dari penelitian meliputi identifikasi masalah penelitian yang berfokus pada masalah utama yaitu mendeteksi kantuk pada pengemudi menggunakan pemrosesan citra dan fisiologis . tahapan ini dilakukan untuk memasikan bahwa hanya data yang relevan berkualitas tinggi dan siap untuk dip roses lebih lanjut yang digunakan. pemilihan dataset memastikan bahwa dataset yang dikumpulkan relevan dengan tujuan penelitian yaitu hanya menggunakan data yang berkaitan dengan kondisi predriving serta memastikan bahwa data visual dan data fisiologis diambil pada waktu yang sama. 3.3.1 pengumpulan data data dibagi menjadi dua kategori utama yaitu data primer dan data sekunder . matapengumpulan data data visual citra wajahdata fisiologis ekgsaturasi oksigen spo2kamera smartwatch pulse oximetry gambar 3 .3 pengumpulan data dataset visual berupa citra wajah yang berfokus pada wajah pengemudi yang diambil menggunakan kamera dengan spesifikasi 12 mp. 4 preprocessing data data set yang dikumpulkan kemudian diolah yang meliputi normalisasi penghilangan noise dan teknik pra pemrosesan lainnya untuk membuat data siap digunakan dalam ekstraksi fitur.
Utami Lestari_Kualifikasi.txt,3.1 gambaran umum penelitian ini bertujuan untuk mengembangkan aplikasi berbasis large language model llm dengan arsitektur gpt 4 yang mampu melakukan telaah sejawatpeer review secara otomatis pada artikel ilmiah dari jurnal komputer. data utama yang digunakan adalah ar tikel ilmiah berbahasa indonesia dalam bidang ilmu komputer dari berbagai jurnal akademik. sebelum digunakan data akan diperiksa untuk menghilangkan informasi pribadi yang dapat mengidentifikasi penulis atau reviewer. aplikasi ini diharapkan dapat membant u para peneliti dan editor jurnal dalam menganalisis dan memperoleh wawasan dari artikel yang seringkali bersifat kompleks dan teknis. untuk melakukan penelitian ini perlu dilakukan beberapa tahapan hingga penelitian selesai tahapan yang dilaukan mulai dari pengumpulan data preprocessing data melakukan pemodelan untuk telaah sejawat mengevaluasi model dan validasi ahli . untuk tahapan penelitian dapat dilihat pada gambar 3.1. gambar 3. 1tahapan penelitian 3.1.1 pengumpulan data proses pengumpulan data dilakukan dengan cara mengumpulkan artikel ilmiah dari be rbagai sumber terbuka dengan topik artikel ilmu computer. pengumpulan data menggunakan teknik webscraping a rtikel yang telah dikumpulkan akan diproses melalui tahap preprocessing. 3.1.2 preprocessing data proses preprocessing data merupakan langkah yang sangat penting dalam persiapan data untuk pemodelan llm. proses ini melibatkan beberapa tahap penting yang bertujuan untuk membersihkan dan menyiapkan data teks agar sesuai dengan kebutuhan model serta menin gkatkan kualitas dan konsistensi representasi teks. proses preprocessing dilakukan melalui beberapa tahap seperti tokenisasi pembersihan teks normalisasi token encoding penghapusan stopword stemming segmentasi kalimat dan pemisahan dataset. gambar 3. 2 tahapan preprocessing tahap pertama adalah tokenisasi di mana teks dipecah menjadi unit unit yang lebih kecil yang dikenal sebagai token memungkinkan model untuk menganalisis teks pada tingkat yang lebih granular. selanjutnya dilakukan pembersihan teks untuk menghilangkan karakter atau simbol yang tidak diinginkan seperti tanda baca angka dan karakter khusus lainnya serta penghapusan spasi berlebih dan karakter yang tidak relevan. no rmalisasi juga dilakukan untuk mengubah teks menjadi bentuk standar termasuk mengubah semua huruf menjadi huruf kecil menghapus aksen dari huruf dan menangani variasi penulisan yang berbeda untuk kata yang sama. setelah itu token yang dihasilkan dari tokenisasi perlu diubah menjadi representasi numerik melalui token encoding menggunakan teknik embeddings dari model transformer.,3.1 gambaran umum penelitian ini bertujuan untuk mengembangkan aplikasi berbasis large language model llm dengan arsitektur gpt 4 yang mampu melakukan telaah sejawatpeer review secara otomatis pada artikel ilmiah dari jurnal komputer. 1tahapan penelitian 3.1.1 pengumpulan data proses pengumpulan data dilakukan dengan cara mengumpulkan artikel ilmiah dari be rbagai sumber terbuka dengan topik artikel ilmu computer. 3.1.2 preprocessing data proses preprocessing data merupakan langkah yang sangat penting dalam persiapan data untuk pemodelan llm. 2 tahapan preprocessing tahap pertama adalah tokenisasi di mana teks dipecah menjadi unit unit yang lebih kecil yang dikenal sebagai token memungkinkan model untuk menganalisis teks pada tingkat yang lebih granular.
Yoga Panji Perdana Nugraha_Kualifikasi.txt,3.1 motivasi industri manufaktur memiliki berbagai macam produk yang ada di dalamnya. dalam upaya pemenuhan kualitas yang tinggi serta menjaga kepuasan pelanggan dan reputasi perusahaan maka mendeteksi produk yang cacat sedini mungkin merupakan aspek yang penting. sehingga motivasi dari disertasi ini adalah sebagai berikut. 1. pengembangan aplikasi pendeteksi cacat pada produk ini didasari keinginan peneliti untuk meningkatkan kinerja pengendalian kualitas pada industri manufaktur sehingga dapat membantu menjaga kualitas produk serta efisien si dalam kegiatan pengendalian kualitas. 2. untuk meminimalisir pemborosan waktu bahan baku biaya dan sumber daya lainnya karena deteksi cacat pada produk dilakukan sedini dan secepat mungkin. 3. meningkatkan efisiensi pada kegiatan inspeksi produk d engan mene rapkan otomatisasi mel alui aplikasi yang dikembangkan. 4. mengintegrasikan teknologi yang sedang berkembang seperti artificial intelligence dengan industri manufaktur sehingga tercipta manufaktur cerdas yang akan berakibat pendapatan profit perusahaan yang op timal. 5. memberikan kontribusi pemahaman dan pengembangan teknologi baru dalam deteksi objek sehingga bisa menjadi referensi untuk pembaca serta penelitian selanjutnya. 3.2 alur kerja riset alur kerja riset digambarkan melalui diagram alir. tujuannya agar penel itian dapat terstruktur sehingga tidak ada tah apan penelitian yang terlewat. secara umum b erikut ini merupakan diagram alir penelitian ini. tahap awal tahap pengembanganperancangan dan pembuatan prototype alat deteksi cacatpengumpulan data cacat objek uji coba prototype alat deketsi cacat objekperancangan model deteksi cacat objek menggunakan deep learning implementasi dan pelatihan model deteksi cacat objek evaluasi dan penyempurnaan model deteksi cacat objek pengujian model deteksi objek menggunakan deep learning pembuatan aplikasi pendeteksi objek cacattahap optimasi pengajuan hki dan jurnal internasional q 1 gambar 3. 1 diagram alir penelitian diagram alir penelitian di atas menggambarkan alur penelitian yang akan dilakukan. berikut ini adalah penjelasan dari diagram alir penelitian di atas. 1. tahap awal kegiatan yang dilakukan pada tahap awal ini adalah merancang dan membuat prototype alat deteksi cacat dan pengumpulan data cacat objek. prototype alat ini menggunakan ban berjalan dengan motor listrik sebagai penggeraknya dengan alat pencahayaan yang cukup. alat ini nantinya digunakan untuk mengumpulkan data yang akan digunakan untuk melakukan perancangan dan pelatihan m odel deteksi cacat objek. pengumpulan data dilakukan untuk memperoleh data yang dibutuhkan pada penelitian ini. data bisa berupa data primer dan data sekunder ataupun keduanya bergantung pada kebutuhan penelitian yang akan dilakukan. data primer dikumpulan dengan memotret objek pada ban berjalan menjadi citra baik citra bergerak maupun citra tak bergerak yang akan menjadi satu kesatuan yaitu dataset . data primer dikumpulkan menggunakan alat yang dirancang seperti di bawah ini. gambar 3. 2 rancangan prototipe alat gambar 3.2 di atas menggambarkan rancangan alat yang akan dikembangkan. alat tersebut pertama digunakan sebagai media untuk pengambilan data primer yaitu data citra dari objek yang akan dideteksi. objek berupa sekrup akan berjalan melalui ban berjalan conveyor yang nantinya akan ditangkap gambarnya oleh webcam atau kamera yang terhubung dengan komputer untuk menyimpan gambar tersebut untuk kebutuhan pelatihan model. sedangkan data sekunder dikumpulkan melalui website kaggle maupun website atau jurnal lain yang sejenis. hasil dari akuisisi citra ini akan digunakan untuk pelatihan dan pengujian data. sampel yang diambil adalah objek berupa sekrup yang terdapat kecacatan. data tersebut kemudian dikumpulkan menjadi sebuah da taset yang akan digunakan untuk melatih model. data data yang diambil kemudian dikelompokkan menjadi beberapa kelas sesuai dengan jenis cacat yang ada pada sekrup tersebut.,dalam upaya pemenuhan kualitas yang tinggi serta menjaga kepuasan pelanggan dan reputasi perusahaan maka mendeteksi produk yang cacat sedini mungkin merupakan aspek yang penting. tujuannya agar penel itian dapat terstruktur sehingga tidak ada tah apan penelitian yang terlewat. tahap awal tahap pengembanganperancangan dan pembuatan prototype alat deteksi cacatpengumpulan data cacat objek uji coba prototype alat deketsi cacat objekperancangan model deteksi cacat objek menggunakan deep learning implementasi dan pelatihan model deteksi cacat objek evaluasi dan penyempurnaan model deteksi cacat objek pengujian model deteksi objek menggunakan deep learning pembuatan aplikasi pendeteksi objek cacattahap optimasi pengajuan hki dan jurnal internasional q 1 gambar 3. 1. tahap awal kegiatan yang dilakukan pada tahap awal ini adalah merancang dan membuat prototype alat deteksi cacat dan pengumpulan data cacat objek. prototype alat ini menggunakan ban berjalan dengan motor listrik sebagai penggeraknya dengan alat pencahayaan yang cukup. pengumpulan data dilakukan untuk memperoleh data yang dibutuhkan pada penelitian ini. 2 rancangan prototipe alat gambar 3.2 di atas menggambarkan rancangan alat yang akan dikembangkan. sedangkan data sekunder dikumpulkan melalui website kaggle maupun website atau jurnal lain yang sejenis. hasil dari akuisisi citra ini akan digunakan untuk pelatihan dan pengujian data.
