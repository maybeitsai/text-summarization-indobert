kalimat,summary
"Pada metodologi penelitian ini menjelaskan mengenai bagaimana proses dari analisis system, perancangan, dan analisis program yang dilakukan pada penelitian ini. Berikut analisis dan perancangan pada penelitian ini. 3.1 Tahapan Penelitian
       Tahapan penelitian dapat dilihat pada gambar 3.1. Tahapan penelitian yang dilakukan terdiri dari 9 tahapan, yaitu dimulai dari studi literatur sebagai dasar penelitian, analisis kebutuhan pada system yang akan dibangun, Pengumpulan dataset, preprocessing data, membangun model, training model, evaluasi model, deployment model, dan implementasi model yang telah dibuat ke dalam smartphone. Saat program telah dijalankan, program akan mengakuisisi dataset kemudian dataset akan melalui tahap 
preprocessing untuk menormalkan data kemudian setelah melalui tahap preprocessing selanjutnya mentraining dataset yang sudah didapatkan jika dataset berhasil dilatih dan 
juga divalidasi maka berlanjut ke tahap berikutnya yaitu tahapan testing dengan menerapkan model yang dibuat kedalam mobile phone atau smartphone. tahap selanjutnya 
jika camera telah menyala maka artinya sudah siap untuk mendeteksi objek jenis penyakit kulit. Pada tahap terakhir yaitu saat ada objek jenis penyakit kulit yang masuk atau terdeteksi oleh camera, maka citra tersebut sudah dapat dilakukan proses klasifikasi kemudian divalidasikan bahwa data tersebut sama dengan yang ada pada database untuk memunculkan label nama pada dataset serta memunculkan nilai confidence pada citra jenis penyakit kulit yang terdeteksi. 3.2 Analisis Kebutuhan
       Analisis kebutuhan merupakan menganalisis komponen yang diperlukan dalam pembuatan dan menjalankan program, Proses ini mencakup evaluasi, identifikasi, dan pemetaan kebutuhan dari berbagai perangkat yang terlibat dalam pembuatan system dan program pada penelitian ini. berikut analisis kebutuhan dari penelitian yang dibuat. 3.2.1. Analisis Kebutuhan Perangkat Keras
       Perangkat keras yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan laptop Acer Predator Helios Neo 16 dan mobile phone atau 
smartphone Xiaomi Redmi Note 7 dengan bahasa pemrograman python, dengan spesifikasi yang dapat dilihat pada Tabel 3.1. 3.2.2. Analisis Kebutuhan Perangkat Lunak
       Perangkat lunak yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan Operating System Windows Jupyter Lab dengan bahasa pemrograman python, dan Visual Studio sebagai text editor, yang dapat dilihat pada tabel 3.2. 3.2.3. Analisis Objek
       Program dengan menggunakan Metode Bi-Directional Image-Text Matching Deep Learning ini mempunyai beberapa objek yang diterapkan pada penelitian ini, yaitu:
1. Identifikasi berbagai macam jenis penyakit kulit dengan memunculkan citra gambar yang didapat dan deskripsi mengenai penyakit kulit yang teridentifikasi dibawah citra gambar untuk setiap objek penyakit kulit yang terdeteksi, data yang digunakan memiliki variasi jenis penyakit kulit dengan kategori 2 penyakit kulit menular (Candidiasis dan Molluscum) dan 2 penyakit kulit tidak menular (Eczhema dan Melanoma) dengan masing masing kelas memiliki 1000 citra penyakit kulit yang di dapat pada website international Dermnet NZ (dermnetnz.org, 2024) dan The International Skin Imaging Collaboration (ISIC) (isic-archive.com, 2024). 2. Program identifikasi berbagai macam objek penyakit kulit pada manusia ditampilkan secara real-time menggunakan file upload kamera mobile phone. 3.3 Akuisisi Dataset
       Proses akuisisi citra dilakukan dengan melakukan pengunduhan data dari berbagai sumber online international skin disease, seperti pada website dermnetnz.org dan 
www.isic-archive.com yang merupakan referensi gratis berbasis website untuk informasi tentang berbagai kondisi kulit. Website ini menyediakan gambar-gambar resolusi tinggi dari berbagai penyakit kulit, baik yang menular maupun tidak menular, serta memberikan deskripsi lengkap tentang penyakti tersebut meliputi gejala dan pengobatan. Citra yang diperoleh kemudian diseleksi berdasarkan fokus penelitian, yaitu identifikasi penyakit kulit menular (Candidiasis dan Molluscum) dan tidak menular (Eczhema dan Melanoma). Data citra yang digunakan berasal dari pasien dewasa dan anak-anak dengan kondisi kulit yang jelas menunjukkan gejala atau kelainan, seperti lesi atau ruam. Contoh citra yang akan digunakan pada penelitian seperti terlihat pada Gambar 3.2. 3.3.1. Dataset Penyakit Kulit
       Dataset pada penelitian ini dibagi menjadi 2 bagian yaitu 80% data training, dan 20% data testing objek jenis penyakit kulit. Dataset bersumber dari citra (data image) dan deskripsi (data teks) beberapa jenis penyakit kulit sejumlah 4000 citra dengan 4 jenis penyakit kulit yang terdiri dari Echzema, Melanoma, Candidiasis, dan Molluscum dengan memiliki 1000 citra berbeda setiap jenis penyakit kulit. Dari keempat jenis penyakit kulit tersebut dibagi menjadi 2 kelompok sebagai penyakit kulit menular dan tidak menular. 3.3.1.1. Data Gambar
       Data image ini mencakup berbagai jenis gambar yang menampilkan gejala dan karakteristik penyakit kulit yang digunakan pada peneltian ini (Eczhema, Melanoma, 
Candidiasis, dan Molluscum) seperti ruam, bintik-bintik, lepuhan, atau lesi kulit lainnya. Ukuran citra asli yang didapat berukuran 294 x 222 yang akan diproses menjadi 256 x 256 sehingga ukuran gambar menjadi presisi dan pengambilan gambar diambil dari berbagai posisi yang berbeda sehingga posisi dalam proses training data akan mendapat banyak posisi pengenalan 1 jenis penyakit kulit dengan format citra JPEG (Joint Photographic Experts Group) serta pengambilan gambar dengan kamera. Penggunaan data gambar 
sangat penting dalam penelitian ini untuk membandingkan dan mempelajari pola visual yang terkait dengan berbagai penyakit kulit. Data image pada penelitian ini terdiri 4000 gambar dari 4 jenis penyakit kulit yaitu Eczhema, Melanoma, Candidiasis, dan Molluscum yang dibagi menjadi 2 kelompok menular dan tidak menular. Data gambar dapat dilihat pada Gambar 3.3. 3.3.I.2. Data Teks
       Data teks penyakit kulit merujuk kepada informasi tertulis yang berisi deskripsi dan karakteristik berbagai kondisi dermatologis. Data pada penelitian ini meliputi 
penjelasan tentang gejala-gejala khas seperti gatal-gatal, perubahan warna kulit, tekstur, dan lokasi lesi serta penjelasan mengenai cara penanganan maupun pengobatan yang dapat dilakukan pasien. Informasi ini penting untuk diagnosis dan pemahaman lebih lanjut tentang berbagai penyakit kulit seperti dermatitis, eksim, psoriasis, dan infeksi jamur kulit. Pada penelitian ini data teks diproses menggunakan teknik pengolahan bahasa alami atau natural language processing (NLP) untuk mengidentifikasi kata kunci dan pola yang terkait dengan setiap kondisi kulit. Berikut data teks yang digunakan pada penelitian ini dapat dilihat pada Tabel 3.3
       
3.4 Pre-Processing Data
       Pada tahapan ini data gambar penyakit kulit, preprocessing mencakup berbagai teknik seperti pengubahan ukuran gambar, normalisasi piksel, peningkatan kontras, 
penghapusan noise serta melakukan segmentasi dan fitur ekstraksi. Teknik ini bertujuan untuk meningkatkan kualitas gambar dan memastikan konsistensi data, sehingga fitur-fitur penting dapat diekstraksi dengan lebih efektif oleh algoritma analisis atau model kecerdasan buatan. Sedangkan pada data teks penyakit kulit, preprocessing melibatkan beberapa tahap seperti tokenisasi, penghapusan stop words, stemming, lemmatization, dan tagging. Langkah-langkah ini membantu dalam menyederhanakan teks, mengurangi dimensionalitas, dan meningkatkan efisiensi analisis teks. Dengan preprocessing yang tepat, data gambar dan teks menjadi lebih bersih dan terstruktur, memungkinkan model machine learning untuk menghasilkan prediksi yang lebih akurat dan andal. Tahapan preprocessing dapat dilihat pada Gambar 3.4. 3.4.1. Preprocessing Data Gambar
       Proses ini melibatkan beberapa teknik utama. Pertama, pengubahan ukuran (resizing) gambar dilakukan untuk memastikan bahwa semua gambar memiliki dimensi yang seragam yaitu 256 x 256, yang penting untuk pengolahan batch dan integrasi dalam model. Kedua, normalisasi piksel diterapkan untuk mengatur nilai piksel dalam rentang 
tertentu, biasanya antara 0 dan 1, guna meningkatkan stabilitas dan kecepatan konvergensi model. Ketiga, peningkatan kontras (contrast enhancement) dan penghapusan noise 
bertujuan untuk memperjelas fitur-fitur penting dalam gambar, seperti tepi atau tekstur, yang mungkin relevan untuk diagnosis penyakit kulit. Keempat, segmentasi data untuk memisahkan area kulit yang terkena penyakit dari bagian yang sehat. Kelima, fitur ekstraksi memungkinkan identifikasi karakteristik spesifik dari kondisi kulit, seperti ukuran dan bentuk lesi, distribusi warna, dan tekstur permukaan kulit. Preprocessing data gambar dapat dilihat pada Gambar 3.5. 3.4.1.1. Resizing Data
       Pada tahap resize data ini betujuan untuk mengubah ukuran citra penyakit kulit menjadi resolusi tetap 256x256 piksel. Langkah ini penting untuk memastikan bahwa 
semua citra memiliki ukuran yang konsisten sebelum digunakan dalam proses analisis data atau pelatihan model pembelajaran mesin. Skrip ini menggunakan pustaka OpenCV 
untuk memuat, mengubah ukuran, dan menyimpan citra. Dapat dilihat pada Algoritma 3.1. Ukuran dan bentuk citra hasil resizing disimpan pada folder output masing-masing penyakit kulit, yang selanjutnya akan diproses pada tahap berikutnya. Algoritma 3.1 diatas dapat dikonversi kedalam Pseudo-code 1 yang dapat diimplementasikan pada pemrograman Python. Sehingga tampilan hasil program terlihat pada gambar 3.6 berikut. Seperti terlihat pada gambar, proses resize ditujukan pada ukuran gambar yang terlihat presisi dan sama yaitu 256x256. 3.4.1.2. Normalisasi Data
       Pada tahapan ini data yang telah di resize pada tahap sebelumya dinormalisasi. Melalui tahap normalisasi data bertujuan untuk mengubah nilai piksel citra ke dalam 
rentang yang konsisten, biasanya antara 0 dan 1 atau -1 dan 1. proses ini membantu dalam mengurangi variasi yang tidak diinginkan antar citra, seperti perbedaan pencahayaan dan kontras, sehingga fitur yang relevan menjadi lebih menonjol. Normalisasi dilakukan dengan membagi nilai piksel setiap citra dengan nilai maksimum piksel (biasanya 255 untuk citra 8-bit), sehingga setiap piksel memiliki nilai yang proporsional dalam rentang yang diinginkan. Langkah- langkah normalisasi data dapat di lihat pada Algoritma 3.2.Citra hasil normalisasi disimpan, yang selanjutnya akan diproses pada tahap berikutnya. Algoritma 3.2 diatas dapat dikonversi kedalam Pseudo-code 2 yang dapat diimplementasikan pada pemrograman Python. Sehingga tampilan hasil program terlihat pada gambar 3.7 berikut. Seperti terlihat pada gambar, proses normalisasi ditujukan mengubah nilai piksel citra ke dalam rentang yang konsisten, biasanya antara 0 dan 1 atau -1 dan 1. 3.4.1.3. Peningkatan Kontras Data
       Pada tahap ini dilakuakn peningkatan kontras pada data citra yang telah di normalisasi bertujuan untuk meningkatkan perbedaan antara nilai intensitas piksel yang 
berdekatan. Dengan meningkatkan perbedaan antara nilai intensitas piksel, proses ini membantu dalam meningkatkan ketajaman citra dan membuatnya lebih mudah untuk dianalisis. Proses ini tidak hanya membuat citra lebih tajam dan lebih jelas, tetapi juga dapat meningkatkan kemampuan sistem analisis citra, seperti deteksi objek atau 
segmentasi yang lebih baik. Langkah-langkah peningkatan kontras dapat dilihat pada Algoritma 3.3. Citra hasil peningkatan kontras disimpan, yang selanjutnya akan diproses pada tahap berikutnya. Algoritma 3.3 diatas dapat dikonversi kedalam Pseudo-code 3 yang dapat diimplementasikan pada pemrograman Python. Sehingga tampilan hasil program terlihat pada gambar 3.8 berikut. Seperti terlihat pada gambar, proses peningkatan kontras ditujukan untuk meningkatkan perbedaan antara nilai intensitas piksel yang berdekatan. Dengan meningkatkan perbedaan antara nilai intensitas piksel, proses ini membantu dalam meningkatkan ketajaman citra dan membuatnya lebih mudah untuk dianalisis. 3.4.1.4. Penghapusan Noise Data
       Pada tahap ini dilakukan penghapusan noise yang bertujuan untuk menghilangkan noise pada citra. Noise pada citra kulit dapat muncul karena berbagai alasan, seperti 
kualitas kamera yang rendah, kondisi pencahayaan yang buruk, atau bahkan gangguan selama pengambilan gambar. Untuk membersihkan gambar dari gangguan ini, digunakan 
berbagai teknik penghapusan noise. Filter median, misalnya, sangat baik untuk mengatasi noise jenis salt-and-pepper dengan menggantikan nilai setiap piksel dengan median dari piksel-piksel sekitarnya, sementara filter Gaussian menghaluskan gambar dengan mempertahankan tepi dan detail penting. Dengan menghilangkan noise, gambar kulit 
menjadi lebih bersih dan detail penting seperti warna, bentuk, dan tekstur lesi menjadi lebih jelas. Ini sangat membantu dokter atau sistem analisis otomatis untuk 
mengidentifikasi dan mengevaluasi kondisi kulit dengan lebih akurat, memastikan diagnosis dan rencana perawatan yang lebih efektif. Langkah-langkah penghapusan noise 
menggunakan median dan gaussian filter dapat dilihat pada Algoritma 3.4. Citra hasil penghapusan noise menggunakan median filter dan gaussian filter disimpan, 
yang selanjutnya akan diproses pada tahap berikutnya. Algoritma 3.4 diatas dapat dikonversi kedalam Pseudo-code 4 yang dapat diimplementasikan pada pemrograman 
Python. Sehingga tampilan hasil program terlihat pada gambar 3.9 berikut. Seperti terlihat pada gambar, proses penghapusan noise menggunakan gabungan median filter dan gaussian filter ditujukan untuk menghilangkan objek-objek yang tidak terpakai dengan menggunakan kernel rendah citra yang dihasilkan tidak terlalu mendapatkan blur yang 
sangat singnifikan, sehingga objek suatu penyakit kulit masih dapat terlihat jelas tanpa adanya noise yang tidak terpakai. Dengan menghapus noise maka citra yang dihasilkan menjadi lebih bersih, proses ini membantu dalam meningkatkan fokus citra terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 3.4.1.5. Segmentasi Data
       Pada tahap ini dilakukan Segmentasi dengan thresholding atau penghapusan bagian yang tidak diperlukan seperti background untuk mendapatkan objek penyakit kulit 
yang digunakan pada penelitian serta menambahkan active contour untuk mendapatkan objek yang ditandai sebagai penyakit kulit. Proses ini melibatkan beberapa tahapan 
penting. Pertama, citra awal dimuat dan mungkin diubah menjadi citra skala abu-abu untuk mempermudah analisis intensitas piksel. Selanjutnya, nilai ambang dipilih atau 
dihitung berdasarkan karakteristik citra seperti histogram intensitas piksel. Pada tahap thresholding, piksel dalam citra yang melebihi nilai ambang akan diberi warna atau nilai putih (255), sementara piksel yang lebih rendah akan diberi warna atau nilai hitam (0), menghasilkan citra biner. Langkah-langkah segmentasi menggunakan thresholding atau penghapusan bagian yang tidah dibutuhkan dapat dilihat pada Algoritma 3.5. Citra hasil segmentasi menggunakan thresholding disimpan, yang selanjutnya akan diproses pada tahap berikutnya. Algoritma 3.5 diatas dapat dikonversi kedalam Pseudo-code 5 yang dapat diimplementasikan pada pemrograman Python. Sehingga tampilan hasil program terlihat pada gambar 3.10 berikut. Seperti terlihat pada gambar, proses segmentasi menggunakan thresholding dan active contour 
ditujukan untuk menghilangkan objek-objek yang tidak digunakan dan memberi tanda pada objek yang digunakan untuk proses selanjutnya. Dengan menghapus nilai-nilai pada 
citra yang tidak terpakai maka citra yang dihasilkan menjadi lebih bersih, proses ini membantu dalam menentukan focus objek terhadap penyakit kulit dan membuatnya lebih 
mudah untuk dianalisis. 3.4.1.6. Ekstraksi Fitur
       Tahapan ini melibatkan pengambilan informasi relevan dari citra yang dapat digunakan untuk mengklasifikasikan dan mendiagnosis kondisi kulit. Setelah citra 
tersegmentasi dengan baik, langkah berikutnya yaitu mengekstraksi fitur-fitur yang relevan dari setiap area tersegmentasi. Fitur-fitur ini berupa tekstur, bentuk, dan warna yang dapat membedakan antara lesi kulit yang berbeda. Dalam beberapa kasus, tidak semua fitur yang diekstraksi diperlukan. Proses seleksi fitur membantu dalam memilih subset fitur terbaik yang paling bermakna untuk klasifikasi atau diagnosa yang akurat. 3.4.1.6.1. Ekstraksi Fitur Warna
       Tahap ini dimulai dengan memuat citra dalam format yang sesuai, seperti JPEG atau PNG, dan memisahkan informasi warna menjadi tiga kanal utama: merah (Red), hijau 
(Green), dan biru (Blue). Setiap kanal ini mewakili intensitas cahaya pada panjang gelombang yang berbeda dan memiliki rentang nilai dari 0 hingga 255 dalam skala 8-bit. Langkah-langkah ekstraksi fitur warna dapat dilihat pada Algoritma 3.6.Nilai hasil Ektraksi fitur warna menggunakan RGB disimpan, yang selanjutnya akan diproses pada tahap berikutnya. Algoritma 3.6 diatas dapat dikonversi kedalam Pseudo-code 6 yang dapat diimplementasikan pada pemrograman Python. Sehingga tampilan hasil program terlihat pada gambar 3.11 berikut. Seperti terlihat pada gambar, proses ektraksi fitur menggunakan RGB dan menunjukan hasil 
histogram ditujukan untuk memisahkan informasi warna menjadi tiga kanal utama: merah (Red), hijau (Green), dan biru (Blue). Dengan mendapatkan nilai-nilai pada setiap kanal RGB maka informasi yang didapat akan semakin kompleks, proses ini membantu dalam menentukan setiap warna yang paling dominan pada objek terhadap penyakit kulit dan 
membuatnya lebih mudah untuk dianalisis. 3.4.1.6.2. Ektraksi Fitur Bentuk
      Tahapan ini dimulai dengan pra-pemrosesan citra untuk meningkatkan kualitas dan mempersiapkannya untuk ekstraksi fitur. Langkah pertama biasanya melibatkan 
segmentasi objek dari latar belakang, yang dapat dilakukan dengan metode seperti thresholding atau deteksi tepi. Setelah objek tersegmentasi, berbagai fitur geometris 
seperti luas, keliling, bentuk, dan orientasi dapat diekstraksi. Langkah-langkah ekstraksi fitur bentuk dapat dilihat pada Algoritma 3.7. Nilai hasil Ektraksi fitur bentuk menggunakan Contour dan Geometris disimpan, yang selanjutnya akan diproses pada tahap berikutnya. Algoritma 3.7 diatas dapat 
dikonversi kedalam Pseudo-code 7 yang dapat diimplementasikan pada pemrograman Python. Sehingga tampilan hasil program terlihat pada gambar 3.12 berikut. Seperti terlihat pada gambar, proses ektraksi fitur menggunakan bentuk contour dan geometris 
menunjukan hasil nilai untuk setiap citra ditujukan untuk memisahkan informasi bentuk menjadi area, perimeter, circularity, dan exccentricity. Dengan mendapatkan nilai-nilai bentuk maka informasi yang didapat akan semakin kompleks, proses ini membantu dalam menentukan setiap bentuk yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 3.4.1.6.3. Ektraksi Fitur Tekstur
       Pada Tahapan ekstraksi fitur tekstur melibatkan beberapa langkah kunci untuk menggambarkan dan menganalisis tekstur citra secara sistematis. Tahap awal mencakup 
pemilihan GLCM sebagai metode utama untuk mengekstraksi fitur tekstur. Setelah GLCM terbentuk, tahap selanjutnya adalah ekstraksi fitur-fitur statistik dari matriks 
GLCM. Fitur-fitur ini mungkin mencakup energi, kontras, homogenitas, dan korelasi, yang masing-masing memberikan informasi tentang struktur dan pola tekstur dalam citra 
yang dianalisis. Langkah-langkah ekstraksi fitur tekstur dengan menggunakan metode GLCM sebagai acuan tekstur dapat dilihat pada Algoritma 3.8. Nilai hasil Ektraksi fitur tekstur menggunakan GLCM disimpan, yang selanjutnya akan diproses pada tahap berikutnya. Algoritma 3.8 diatas dapat dikonversi kedalam Pseudo-
code 8 yang dapat diimplementasikan pada pemrograman Python. Sehingga tampilan hasil program terlihat pada gambar 3.13 berikut. Seperti terlihat pada gambar, proses ektraksi fitur menggunakan GLCM menunjukan hasil nilai untuk setiap 
citra ditujukan untuk memisahkan informasi tekstur menjadi contrast, dissimilarity, homogeneity, energy dan correlation. Dengan mendapatkan nilai-nilai tekstur maka 
informasi yang didapat akan semakin kompleks, proses ini membantu dalam menentukan setiap tekstur yang paling dominan pada objek terhadap penyakit kulit dan membuatnya 
lebih mudah untuk dianalisis. 3.4.2. Preprocessing Data Teks
       Tahap pre-processing data teks dilakukan serangkaian langkah penting dalam pengolahan informasi teks yang bertujuan untuk membersihkan, merapihkan, dan 
mempersiapkan data sebelum dilakukan analisis lebih lanjut. Proses ini krusial karena data teks sering kali tidak terstruktur dan dapat mengandung berbagai jenis noise atau informasi yang tidak relevan yang dapat mempengaruhi hasil analisis. Beberapa tahap yang dilakukan pada preprocessing data teks ini meliputi Pertama, Tokenisasi dilakukan untuk memecah teks menjadi unit-unit yang lebih kecil seperti kata-kata atau kalimat. Setelah itu, langkah Pembersihan (cleaning) dilakukan untuk menghilangkan elemen-elemen yang tidak relevan seperti, karakter khusus, atau token seperti stopwords yang 
tidak memberikan banyak informasi. Selanjutnya, Stemming atau Lemmatisasi Proses ini mengubah kata-kata menjadi bentuk dasarnya (lemmas) atau akar kata (stems) untuk 
mengurangi variasi kata yang memiliki arti yang sama. Contohnya, mengubah kata-kata seperti ""berlari"", ""berlari"", dan ""berlari"" menjadi bentuk dasar ""lari"". Terakhir Tagging proses ini menandai atau menempatkan label pada kata- kata atau token dalam teks untuk mengidentifikasi informasi tertentu atau untuk mempersiapkan 
data untuk analisis lebih lanjut. Preprocessing data teks dapat dilihat pada Gambar 3.14. 3.5 Training Model
       Sebelum memulai pelatihan model, data yang telah diproses melalui tahap preprocessing, seperti segmentasi dan ekstraksi fitur, menjadi input yang sangat penting. Segmentasi membantu dalam memisahkan area lesi kulit dari bagian yang tidak relevan, sedangkan ekstraksi fitur membantu dalam mengidentifikasi karakteristik spesifik dari lesi kulit tersebut. Data yang telah dipreproses ini kemudian digunakan untuk melatih model pembelajaran mesin, khususnya deep learning dengan arsitektur Convolutional Neural Networks (CNNs), yang terkenal mampu mengenali pola kompleks dalam data citra dan dengan menggunakan Char- CNN-RNN untuk mengenali pola kompleks pada text untuk 
mengenali citra menggunakan kata per kata. Setelah melakukan 2 pemodelan antara modelling gambar dan modelling teks, maka tahapan selanjutnya menggabungkan ke 2 
model tersebut dengan metode Bi-Directional Image-Text Matching untuk menghasilkan algoritma yang dapat mengindentifikasi melalui kedua jenis objek data. Gambaran Bi-
Directional Image-Text Matching dapat dilihat pada gambar berikut
       
3.7 Evaluasi Model
       Evaluasi terhadap model dilakukan untuk melihat akurasi model saat mengidentifikasi penyakit. Proses evaluasi dimulai dengan penerapan model pada set uji, yang terdiri dari data yang belum pernah dilihat oleh model selama fase pelatihan. Set uji ini dirancang untuk mensimulasikan kondisi dunia nyata, di mana model harus membuat 
prediksi tanpa bias dari data pelatihan. 3.8 Implenientasi Model
       Tahap ini melibatkan integrasi model yang telah dilatih ke dalam lingkungan klinis atau aplikasi yang akan digunakan oleh para profesional medis untuk mendukung 
diagnosis dan pengobatan penyakit kulit. Implementasi model membutuhkan pemikiran yang cermat dan strategi yang terkoordinasi untuk memastikan keberhasilannya dalam 
praktik medis.","Pada metodologi penelitian ini menjelaskan mengenai bagaimana proses dari analisis system, perancangan, dan analisis program yang dilakukan pada penelitian ini. Berikut analisis dan perancangan pada penelitian ini. Tahapan penelitian yang dilakukan terdiri dari 9 tahapan, yaitu dimulai dari studi literatur sebagai dasar penelitian, analisis kebutuhan pada system yang akan dibangun, Pengumpulan dataset, preprocessing data, membangun model, training model, evaluasi model, deployment model, dan implementasi model yang telah dibuat ke dalam smartphone. Saat program telah dijalankan, program akan mengakuisisi dataset kemudian dataset akan melalui tahap 
preprocessing untuk menormalkan data kemudian setelah melalui tahap preprocessing selanjutnya mentraining dataset yang sudah didapatkan jika dataset berhasil dilatih dan 
juga divalidasi maka berlanjut ke tahap berikutnya yaitu tahapan testing dengan menerapkan model yang dibuat kedalam mobile phone atau smartphone. tahap selanjutnya 
jika camera telah menyala maka artinya sudah siap untuk mendeteksi objek jenis penyakit kulit. Pada tahap terakhir yaitu saat ada objek jenis penyakit kulit yang masuk atau terdeteksi oleh camera, maka citra tersebut sudah dapat dilakukan proses klasifikasi kemudian divalidasikan bahwa data tersebut sama dengan yang ada pada database untuk memunculkan label nama pada dataset serta memunculkan nilai confidence pada citra jenis penyakit kulit yang terdeteksi. 3.2 Analisis Kebutuhan
       Analisis kebutuhan merupakan menganalisis komponen yang diperlukan dalam pembuatan dan menjalankan program, Proses ini mencakup evaluasi, identifikasi, dan pemetaan kebutuhan dari berbagai perangkat yang terlibat dalam pembuatan system dan program pada penelitian ini. berikut analisis kebutuhan dari penelitian yang dibuat. Analisis Kebutuhan Perangkat Keras
       Perangkat keras yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan laptop Acer Predator Helios Neo 16 dan mobile phone atau 
smartphone Xiaomi Redmi Note 7 dengan bahasa pemrograman python, dengan spesifikasi yang dapat dilihat pada Tabel 3.1. Analisis Kebutuhan Perangkat Lunak
       Perangkat lunak yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan Operating System Windows Jupyter Lab dengan bahasa pemrograman python, dan Visual Studio sebagai text editor, yang dapat dilihat pada tabel 3.2. Analisis Objek
       Program dengan menggunakan Metode Bi-Directional Image-Text Matching Deep Learning ini mempunyai beberapa objek yang diterapkan pada penelitian ini, yaitu:
1. Identifikasi berbagai macam jenis penyakit kulit dengan memunculkan citra gambar yang didapat dan deskripsi mengenai penyakit kulit yang teridentifikasi dibawah citra gambar untuk setiap objek penyakit kulit yang terdeteksi, data yang digunakan memiliki variasi jenis penyakit kulit dengan kategori 2 penyakit kulit menular (Candidiasis dan Molluscum) dan 2 penyakit kulit tidak menular (Eczhema dan Melanoma) dengan masing masing kelas memiliki 1000 citra penyakit kulit yang di dapat pada website international Dermnet NZ (dermnetnz.org, 2024) dan The International Skin Imaging Collaboration (ISIC) (isic-archive.com, 2024). Program identifikasi berbagai macam objek penyakit kulit pada manusia ditampilkan secara real-time menggunakan file upload kamera mobile phone. Website ini menyediakan gambar-gambar resolusi tinggi dari berbagai penyakit kulit, baik yang menular maupun tidak menular, serta memberikan deskripsi lengkap tentang penyakti tersebut meliputi gejala dan pengobatan. Citra yang diperoleh kemudian diseleksi berdasarkan fokus penelitian, yaitu identifikasi penyakit kulit menular (Candidiasis dan Molluscum) dan tidak menular (Eczhema dan Melanoma). Dataset Penyakit Kulit
       Dataset pada penelitian ini dibagi menjadi 2 bagian yaitu 80% data training, dan 20% data testing objek jenis penyakit kulit. Dataset bersumber dari citra (data image) dan deskripsi (data teks) beberapa jenis penyakit kulit sejumlah 4000 citra dengan 4 jenis penyakit kulit yang terdiri dari Echzema, Melanoma, Candidiasis, dan Molluscum dengan memiliki 1000 citra berbeda setiap jenis penyakit kulit. Dari keempat jenis penyakit kulit tersebut dibagi menjadi 2 kelompok sebagai penyakit kulit menular dan tidak menular. Data Gambar
       Data image ini mencakup berbagai jenis gambar yang menampilkan gejala dan karakteristik penyakit kulit yang digunakan pada peneltian ini (Eczhema, Melanoma, 
Candidiasis, dan Molluscum) seperti ruam, bintik-bintik, lepuhan, atau lesi kulit lainnya. Penggunaan data gambar 
sangat penting dalam penelitian ini untuk membandingkan dan mempelajari pola visual yang terkait dengan berbagai penyakit kulit. Data image pada penelitian ini terdiri 4000 gambar dari 4 jenis penyakit kulit yaitu Eczhema, Melanoma, Candidiasis, dan Molluscum yang dibagi menjadi 2 kelompok menular dan tidak menular. Data Teks
       Data teks penyakit kulit merujuk kepada informasi tertulis yang berisi deskripsi dan karakteristik berbagai kondisi dermatologis. Informasi ini penting untuk diagnosis dan pemahaman lebih lanjut tentang berbagai penyakit kulit seperti dermatitis, eksim, psoriasis, dan infeksi jamur kulit. Berikut data teks yang digunakan pada penelitian ini dapat dilihat pada Tabel 3.3
       
3.4 Pre-Processing Data
       Pada tahapan ini data gambar penyakit kulit, preprocessing mencakup berbagai teknik seperti pengubahan ukuran gambar, normalisasi piksel, peningkatan kontras, 
penghapusan noise serta melakukan segmentasi dan fitur ekstraksi. Teknik ini bertujuan untuk meningkatkan kualitas gambar dan memastikan konsistensi data, sehingga fitur-fitur penting dapat diekstraksi dengan lebih efektif oleh algoritma analisis atau model kecerdasan buatan. Ketiga, peningkatan kontras (contrast enhancement) dan penghapusan noise 
bertujuan untuk memperjelas fitur-fitur penting dalam gambar, seperti tepi atau tekstur, yang mungkin relevan untuk diagnosis penyakit kulit. Ukuran dan bentuk citra hasil resizing disimpan pada folder output masing-masing penyakit kulit, yang selanjutnya akan diproses pada tahap berikutnya. Dengan meningkatkan perbedaan antara nilai intensitas piksel, proses ini membantu dalam meningkatkan ketajaman citra dan membuatnya lebih mudah untuk dianalisis. Dengan menghapus noise maka citra yang dihasilkan menjadi lebih bersih, proses ini membantu dalam meningkatkan fokus citra terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. Dengan menghapus nilai-nilai pada 
citra yang tidak terpakai maka citra yang dihasilkan menjadi lebih bersih, proses ini membantu dalam menentukan focus objek terhadap penyakit kulit dan membuatnya lebih 
mudah untuk dianalisis. Langkah-langkah ekstraksi fitur warna dapat dilihat pada Algoritma 3.6.Nilai hasil Ektraksi fitur warna menggunakan RGB disimpan, yang selanjutnya akan diproses pada tahap berikutnya. Dengan mendapatkan nilai-nilai pada setiap kanal RGB maka informasi yang didapat akan semakin kompleks, proses ini membantu dalam menentukan setiap warna yang paling dominan pada objek terhadap penyakit kulit dan 
membuatnya lebih mudah untuk dianalisis. Dengan mendapatkan nilai-nilai bentuk maka informasi yang didapat akan semakin kompleks, proses ini membantu dalam menentukan setiap bentuk yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. Langkah-langkah ekstraksi fitur tekstur dengan menggunakan metode GLCM sebagai acuan tekstur dapat dilihat pada Algoritma 3.8. Nilai hasil Ektraksi fitur tekstur menggunakan GLCM disimpan, yang selanjutnya akan diproses pada tahap berikutnya. Sehingga tampilan hasil program terlihat pada gambar 3.13 berikut. Seperti terlihat pada gambar, proses ektraksi fitur menggunakan GLCM menunjukan hasil nilai untuk setiap 
citra ditujukan untuk memisahkan informasi tekstur menjadi contrast, dissimilarity, homogeneity, energy dan correlation. Dengan mendapatkan nilai-nilai tekstur maka 
informasi yang didapat akan semakin kompleks, proses ini membantu dalam menentukan setiap tekstur yang paling dominan pada objek terhadap penyakit kulit dan membuatnya 
lebih mudah untuk dianalisis. Proses ini krusial karena data teks sering kali tidak terstruktur dan dapat mengandung berbagai jenis noise atau informasi yang tidak relevan yang dapat mempengaruhi hasil analisis. Terakhir Tagging proses ini menandai atau menempatkan label pada kata- kata atau token dalam teks untuk mengidentifikasi informasi tertentu atau untuk mempersiapkan 
data untuk analisis lebih lanjut. 3.5 Training Model
       Sebelum memulai pelatihan model, data yang telah diproses melalui tahap preprocessing, seperti segmentasi dan ekstraksi fitur, menjadi input yang sangat penting. Segmentasi membantu dalam memisahkan area lesi kulit dari bagian yang tidak relevan, sedangkan ekstraksi fitur membantu dalam mengidentifikasi karakteristik spesifik dari lesi kulit tersebut. Setelah melakukan 2 pemodelan antara modelling gambar dan modelling teks, maka tahapan selanjutnya menggabungkan ke 2 
model tersebut dengan metode Bi-Directional Image-Text Matching untuk menghasilkan algoritma yang dapat mengindentifikasi melalui kedua jenis objek data. Gambaran Bi-
Directional Image-Text Matching dapat dilihat pada gambar berikut
       
3.7 Evaluasi Model
       Evaluasi terhadap model dilakukan untuk melihat akurasi model saat mengidentifikasi penyakit. Set uji ini dirancang untuk mensimulasikan kondisi dunia nyata, di mana model harus membuat 
prediksi tanpa bias dari data pelatihan. 3.8 Implenientasi Model
       Tahap ini melibatkan integrasi model yang telah dilatih ke dalam lingkungan klinis atau aplikasi yang akan digunakan oleh para profesional medis untuk mendukung 
diagnosis dan pengobatan penyakit kulit. Implementasi model membutuhkan pemikiran yang cermat dan strategi yang terkoordinasi untuk memastikan keberhasilannya dalam 
praktik medis."
"3.1. Alur Penelitian
1. Identifikasi Masalah
Identifikasi masalah dilakukan supaya permasalahan yang diangkat jelas. Identifikasi masalah dilakukan dengan cara melihat permasalahan nyata melalui literatur seperti jurnal penelitian, wawancara dengan ahli, dan keresahan yang dirasakan oleh peneliti secara pribadi. Permasalahan yang diangkat pada penelitian ini adalah motif batik Indonesia sangat beragam dan memiliki maknanya masing-masing. Namun tidak banyak masyarakat yang masih mengetahui nama, makna dan pemakaian dari masing-masing motif batik. Menurut Dewan Ahli PPBI (Paguyuban Pecinta Batik Indonesia) Sekar Jagad, Ibu Mari S. Condronegoro saat ini sering kali ditemukan kesalahan dalam pemakaian motif batik, seperti mengenakan kain yang seharusnya digunakan pada upacara kematian ketika menghadiri acara pernikahan. Solusi yang diusulkan adalah melakukan klasifikasi motif batik. Metode klasifikas yang umum digunakan adalah CNN. Namun, CNN klasik memiliki kelemahan dalam memahami makna menyeluruh dari gambar, terutama yang berkaitan dengan hubungan antar bagian gambar yang berbeda. Selain itu, CNN klasik juga rentan terhadap overfitting, di mana model terlalu terlatih pada data pelatihan dan tidak dapat menggeneralisasi dengan baik ke data baru. 2. Studi Literatur
Studi literatur dilakukan supaya penelitian memiliki landasan yang jelas. Studi literatur dilakukan dengan sumber jurnal, penelitian terdahulu, serta buku yang berisikan metode yang sesuai dengan penelitian. Fokus studi literatur terbagi menjadi tiga topik, yaitu klasifikasi motif batik, komputasi kuantum, dan deteksi tepi. 3. Pengumpulan Dataset
Pengumpulan data dilakukan berdasarkan keperluan penelitian. Data yang dikumpulkan merupakan data primer yang akan dikumpulkan degan bantuan ahli, yaitu Dewan Ahli PPBI Sekar Jagad, Ibu Mari S. Condronegoro. PPBI Sekar Jagad merupakan perkumpulan pecinta batik yang diawasi langsung (penasehat utama) oleh Permaisuri Gusti Kanjeng Ratu Hemas (istri dari Sri Sultan Hamengku Buwono X) sehingga informasi yang didapatkan, bisa dijamin kebenarannya. Pengumpulan dataset primer ini dilakukan dengan diskusi, wawancara, serta bimbingan Dewan Ahli PPBI Sekar Jagad supaya dataset yang digunakan sesuai dengan kebenaran dan kebutuhan penelitian yang dilakukan. Sehingga hasil yang didapatkan memuaskan dan akurat. Dataset yang akan dikumpulkan merupakan citra motif ""batik daur hidup"" Yogyakarta dari kain batik tradisional yang merupakan batik cap maupun batik tulis (bukan printing). Motif yang akan digunakan dalam penelitian akan didiskusikan terlebih dahulu dengan narasumber supaya dapat mewakili ""batik daur hidup"" Yogyakarta yang sangat penting untuk diketahui dalam bersosialdi masyarakat. Misalnya seperti motif batik yang memiliki makna khusus dan tak pantas untuk dikenakan pada berapa acara, motif batik yang memiliki larangan dan lainnya. Hal ini dilakukan karena ""batik daur hidup"" Yogyakarta tercatat memiliki ratusan motif hingga tahun 2006 (Sekar Jagad, 2015). Citra batik akan diambil dengan menggunakan kamera, dimana kain akan dibentangkan pada gawangan untuk difoto di dalam ruangan (dengan pecahayaan yang sama) dan di luar ruangan (dengan cuaca yang sama). Citra batik akan diambil dari berbagai posisi supaya citra lebih beragam. Kemudian motif batik yang akan diambil beragam, namun akan dipisahkan terlebih dahulu berdasarkan jenisnya. Hal ini dikarenakan untuk satu kelompok motif yang sama, terkadang terdapat bentuk yang terlihat berbeda. Sehingga dibutuhkan pengujian bertahap untuk melihat apakah model dapat mendeteksi motif dengan benar.Data primer digunakan karena terdapat kekurangan dari data sekunder yang dapat ditemukan. Seperti motif batik yang terpotong sehingga tidak terlihat, serta motif yang salah pada beberapa kelas. Beberapa motif juga memilikibentuk atau komponen serupa sehingga butuh dikonsultasikan lebih lanjut kepada ahli. 4. Pra-pengolahan Data
Proses pra-pengolahan data dilakukan untuk menyiapkan data sebelum diimplementasikan dalam model klasifikasi citra. Pra-pengolahan data meliputi resize, mengubah ruang warna menjadi grayscale, augmentasi, dan split data. Resize dilakukan untuk memperkecil ukuran gambar aslinya. Hal ini dilakukan untuk memastikan semua citra memiliki ukuran yang sama, sehingga algoritma dapat bekerja secara konsisten dan efisien. Selain itu ukuran citra yang lebih kecil dapat mempercepat proses segmentasi dan klasifikasi tanpa kehilangan informasi penting. Proses selanjutnya adalah mengubah ruang warna menjadi grayscale, perubahan warna ini dilakukan karena dapat meningkatkan kontras, meningkatkan efisiensi komputasi, dan meningkatkan ketahanan terhadap variasi pencahayaan. Citra grayscale memiliki rentang intensitas yang lebih kecil dibandingkan citra RGB, sehingga kontras tepi lebih jelas. Selain itu citra grayscale membutuhkan lebih sedikit memori dan sumber daya komputasi dibandingkan citra RGB. Kemudian citra grayscale tidak terpengaruh oleh variasi pencahayaan, sehingga tepi dapat dideteksi dengan lebih akurat. Selanjutnya proses augmentasi digunakan untuk meningkatkan ukuran dataset dengan menambahkan data baru tanpa perlu melakukan pengumpulan data baru. Hal ini bermanfaat untuk mengatasi masalah keterbatasan data. Selain itu dengan melakukan augmentasi, data akan menjadi lebih bervariasi, sehingga dapat mencegah terjadinya overfitting dan lebih stabil terhadap perubahan data. Proses terakhir adalah melakukan pembagian data. Data akan dibagi menjadi tiga dataset, yaitu pelatihan, pengujian dan validasi. 5. Komputasi Kuantum
Model komputasi kuantum merupakan usulan dalam penelitian ini. Adapun kombinasi model pertama yang akan dilakukan meliputi segmentasi tepi berbasis kuantum dengan menggunakan metode canny, dan klasifikasi dengan metode Quantum Convolutional Neural Network (QCNN). Komputasi kuantum diterapkan mulai dari proses segmentasi karena berdasarkan penelitian terdahulu, deteksi tepi berbasis kuantum dapat mendeteksi lebih banyak tepi dibandingkan deteksi tepi klasik berdasarkan jumlah tepi yang dihasilkan (Sundani, dkk., 2019). Hal serupa juga berlaku pada metode QCNN yang memiliki hasil lebih baik dan akurat dibandingkan dengan metode CNN klasik. Sehingga hipotesisnya, hasil dari ekstraksi fitur dan klasifikasi akan menjadi lebih optimal. 6. Komputasi Kuatum dan Klasik
Kombinasi model berikutnya adalah melakukan deteksi tepi berbasis kuatum dengan model canny. Kemudian klasifikasi dilakukan dengan menggunakan CNN klasik. Kombinasi ini dilakukan untuk mengetahui seberapa jauh pengaruh penggunaan komputasi kuantum pada deteksi tepi dengan model canny. 7. Komputasi Klasik dan Kuantum
Komputasi klasik dan kuantum disini adalah kombinasi antara deteksi tepi klasik dengan model canny, yang kemudian dilanjutkan dengan melakukan klasifikasi dengan menggunakan metode Quantum Convolutional Neural Network (QCNN). Hal ini dilakukan untuk melihat seberapa jauh pengaruh dari penerapan model QCNN yang menggunakan komputasi kuantum. 8. Komputasi Klasik
Pengolahan data dengan komputasi klasik dilakukan dengan menggunakan deteksi tepi canny kasik, yang dikombinasikan dengan klasifikasi CNN klasik. Pengolahan data ini dilakukan sebagai pembanding performa model segmentasi dan klasifikasi berbasis kuantum. Pengolahan data kedua model (komputasi kuantum dan komputasi klasik) akan dilakukan dengan menggunakan komputer yang sama, yaitu komputer klasik. 9. Evaluasi Performa
Tahap terakhir adalah melakukan evaluasi performa. Performa akan dibandingkan dari akurasi yang dihasilkan. Adapun akurasi akan dihitung menggunakan confusion matrix pada kedua model. Evaluasi ini akan dilakukan pada ke-empat kombinasi model untuk mengetahui seberapa jauh perbedaan dan fungsi penerapan komputasi kuantup pada setiap model. 3.2. Jadwal Penelitian
        Jadwal penelitian digunakan sebagai target supaya penelitian ini dapat selesai tepat waktu. Penelitian ini menggunakan pendekatan kualitatif dan kuantitatif. Penelitian kualitatif dilakukan dalam proses mengkaji studi literatur dan melakukan wawancara dengan Dewan Ahli PPBI Sekar Jagad, Ibu Mari S. Condronegoro untuk mempelajari batik daur hidup Yogyakarta.","3.1. Alur Penelitian
1. Permasalahan yang diangkat pada penelitian ini adalah motif batik Indonesia sangat beragam dan memiliki maknanya masing-masing. Namun tidak banyak masyarakat yang masih mengetahui nama, makna dan pemakaian dari masing-masing motif batik. Menurut Dewan Ahli PPBI (Paguyuban Pecinta Batik Indonesia) Sekar Jagad, Ibu Mari S. Condronegoro saat ini sering kali ditemukan kesalahan dalam pemakaian motif batik, seperti mengenakan kain yang seharusnya digunakan pada upacara kematian ketika menghadiri acara pernikahan. Solusi yang diusulkan adalah melakukan klasifikasi motif batik. Fokus studi literatur terbagi menjadi tiga topik, yaitu klasifikasi motif batik, komputasi kuantum, dan deteksi tepi. Sehingga hasil yang didapatkan memuaskan dan akurat. Dataset yang akan dikumpulkan merupakan citra motif ""batik daur hidup"" Yogyakarta dari kain batik tradisional yang merupakan batik cap maupun batik tulis (bukan printing). Motif yang akan digunakan dalam penelitian akan didiskusikan terlebih dahulu dengan narasumber supaya dapat mewakili ""batik daur hidup"" Yogyakarta yang sangat penting untuk diketahui dalam bersosialdi masyarakat. Hal ini dilakukan karena ""batik daur hidup"" Yogyakarta tercatat memiliki ratusan motif hingga tahun 2006 (Sekar Jagad, 2015). Selain itu ukuran citra yang lebih kecil dapat mempercepat proses segmentasi dan klasifikasi tanpa kehilangan informasi penting. Proses selanjutnya adalah mengubah ruang warna menjadi grayscale, perubahan warna ini dilakukan karena dapat meningkatkan kontras, meningkatkan efisiensi komputasi, dan meningkatkan ketahanan terhadap variasi pencahayaan. Selanjutnya proses augmentasi digunakan untuk meningkatkan ukuran dataset dengan menambahkan data baru tanpa perlu melakukan pengumpulan data baru. Komputasi kuantum diterapkan mulai dari proses segmentasi karena berdasarkan penelitian terdahulu, deteksi tepi berbasis kuantum dapat mendeteksi lebih banyak tepi dibandingkan deteksi tepi klasik berdasarkan jumlah tepi yang dihasilkan (Sundani, dkk., 2019). Hal serupa juga berlaku pada metode QCNN yang memiliki hasil lebih baik dan akurat dibandingkan dengan metode CNN klasik. Sehingga hipotesisnya, hasil dari ekstraksi fitur dan klasifikasi akan menjadi lebih optimal. Pengolahan data ini dilakukan sebagai pembanding performa model segmentasi dan klasifikasi berbasis kuantum. Performa akan dibandingkan dari akurasi yang dihasilkan. Penelitian ini menggunakan pendekatan kualitatif dan kuantitatif. Penelitian kualitatif dilakukan dalam proses mengkaji studi literatur dan melakukan wawancara dengan Dewan Ahli PPBI Sekar Jagad, Ibu Mari S. Condronegoro untuk mempelajari batik daur hidup Yogyakarta."
"3.1 Tahapan Penelitian
      Secara garis besar penelitian ini terdiri dari beberapa tahapan, yaitu Akuisisi data, pre-processing data, pengembangan dan pelatihan model, pengujian dan evaluasi model, serta pengembangan system deteksi penyakit daun kakao, ditunjukkan pada Gambar 3.1. 3.2 Akuisisi Data Penyakit Daun Tanaman Kakao
      Pengumpulan citra Penyakit Daun tanaman kakao dikumpulkan secara langsung oleh peneliti (data primer) dan juga menggunakan data yang dikumpulkan oleh peneliti lain (data sekunder). Terdapat 4 kelas penyakit dan satu kelas daun sehat yang akan digunakan dalam penelitian ini, yaitu:	Daun sehat, penyakit antraknosa(Colletotrichum gloeosporioides), penyakit vascular streak dieback (VSD), penyakit Leaf Blotch dan penyakit cocoa swollen shoot virus disease (CSSVD). Dataset primer akan dilakukan pengambilan foto penyakit daun tanaman kakao yang terdapat pada kebun kakao di daerah Kabupaten Solok, Provinsi Sumatra Barat. Pengambilan akan dilakukan dari jarak 20cm dari kamera yang bertujuan menangkap detail kecil seperti bercak kecil atau lesi pada daun, perubahan warna serta tekstur permukaan daun. Dataset sekunder menggunakan dataset yang telah digunakan umum oleh para peneliti lain terkait penyakit daun tanaman kakao. 3.3 Pre-Processing
3.3.1 Resize Dataset
      Perubahan ukuran citra dilakukan menggunakan metode nearest neighbor interpolation. Cara kerja dari metode ini dengan cara mengambil nilai piksel terdekat dari citra asli untuk menentukan nilai piksel baru dalam citra yang akan diubah ukurannya. Citra diubah ukurannya menjadi seragam (224x224 piksel). Faktor skala dihitung dengan membandingkan dimensi citra asli, dimana (W, H) dengan dimensi baru (W1, H') yang akan diubah. Untuk setiap piksel dalam citra baru dengan koordinat (ir,jr), hitung koordinat terdekat di citra asli (i,j). Selanjutnya map nilai piksel yaitu mengambil nilai piksel dari citra asli pada koordinat (i,j) dan menetapkan nilai ke piksel baru di koordinat (i',jr) dalam citra yang diubah ukurannya. 3.3.2 Grayscale
       Pada tahap ini citra RGB dikonversi ke Grayscale untuk membantu menyederhanakan dan.memfokuskan informasi intensitas cahaya yang lebih relevan. Gejala penyakit pada daun tanaman kakao seperti perubahan warna, bintik-bintik atau nekrosis dapat lebih mudah diindetifikasi melalui variasi intensitas Cahaya. Grayscale dapat mempertahankan informasi penting dengan lebih sederhana. 3.3.3 Augmentasi Dataset
       Augmentasi data dilakukan untuk meningkatkan variasi pada dataset yang akan digunakan serta untuk mencegah terjadinya overfitting. Teknik augmentasi yang diterapkan penelitian ini seperti rotasi, flipping, zooming, dan cropping. 3.3.4	Ekstraksi Fitur
3.3.4.1	Histogram Oriented of Gradients (HoG)
       Ekstraksi fitur HoG digunakan dalam penelitian ini untuk menangkap bentuk dan tekstur. HoG berfokus pada gradien intensitas lokal dan arah tepi yang menggambarkan struktur dan tekstur dari daun yang terkena penyakit pada tanaman kakao, HoG dapat menangani perubahan dalam rotasi dan skala yang memungkinkan pendeteksian penyakit yang konsisten pada pengambilan gambar dari sudut atau jarak yang berbeda. 3.3.4.2	Local Binary Pattern (LBP)
       Penerapan ekstraksi fitur LBP pada penelitian ini untuk menangkap tekstur lokal dalam citra. LBP membantu dalam menangkap informasi tekstur seperti bercak- bercak, lubang kecil yang terdapat pada daun, perubahan warna daun yang tidak merata dan perubahan permukaan lainnya. 3.3.5 Splitting Data 3.3.5.1 Data Training
       Data training digunakan untu melatih model untuk mengenali pola maupun karakteristik visual yang membedakan daun sehat dengan daun yang terinfeksi penyakit. Melalui proses pelatihan ini model mengoptimalkan parameter untuk meminimalkan kesalahan dalam memprediksi. 3.3.5.2	Data Testing
        Data testing digunakan untuk melakukan pengujian pada model yang telah dilatih sebelumnya untuk mengevaluasi kinerja model. 3.4 Pengembangan dan Pelatihan Model
        Data citra daun kakao yang telah melalui preprocessing dan ekstraksi fitur, kemudian digunakan untuk pelatihan dan pembuatan model deep learning menggunakan pendekatan feature fusion berbasis attention yaitu fitur ekstraksi HoG dan LBP digabungkan ke dalam vision transformer yang menggunakan attention mechanism. Attention mechanism dalam vision transformer memberikan fokus yang berbeda pada fitur HoG dan LBP. Penggunaan attention mechanism dapat meningkatkan akurasi model dengan mengurangi pengaruh noise atau informasi yang tidak relevan dalam gambar. 3.5 Pengujian dan Evaluasi Model
       Pengujian dan Evaluasi model dilakukan untuk melihat akurasi model saat mengidentifikasi penyakit daun tanaman kakao. Proses evaluasi dimulai dengan pengujian yang terdiri dari data yang belum pernah dilihat oleh model selama melakukan fase pelatihan. Matrik evaluasi digunakan untuk mengukur kinerja model secara menyeluruh. matrik evaluasi yang digunakan seperti akurasi, presisi, recall, dan Fl-score. 3.6 Pengembangan Sistem Deteksi Penyakit Daun Kakao
       Setelah melakukan pelatihan dan pengembangan model, serta tahap pengujian dan evaluasi model, system deteksi untuk penyakit daun kakao diimplemetasikan dengan melibatkan pengintegrasian model ke dalam aplikasi atau perangkat keras. Pengembangan system menciptakan Solusi yang efektif dan efisien dalam mengidentifikasi penyakit daun kakao. 3.7 Jadwal Penelitian
       Jadwal penelitian merupakan rancanagan kegiatan yang dilakukan selama penelitian beserta estimasi waktu tiap kegiatan seperti yang ditunjukkan tabal 3.1","3.1 Tahapan Penelitian
      Secara garis besar penelitian ini terdiri dari beberapa tahapan, yaitu Akuisisi data, pre-processing data, pengembangan dan pelatihan model, pengujian dan evaluasi model, serta pengembangan system deteksi penyakit daun kakao, ditunjukkan pada Gambar 3.1. 3.2 Akuisisi Data Penyakit Daun Tanaman Kakao
      Pengumpulan citra Penyakit Daun tanaman kakao dikumpulkan secara langsung oleh peneliti (data primer) dan juga menggunakan data yang dikumpulkan oleh peneliti lain (data sekunder). Dataset primer akan dilakukan pengambilan foto penyakit daun tanaman kakao yang terdapat pada kebun kakao di daerah Kabupaten Solok, Provinsi Sumatra Barat. Dataset sekunder menggunakan dataset yang telah digunakan umum oleh para peneliti lain terkait penyakit daun tanaman kakao. 3.4 Pengembangan dan Pelatihan Model
        Data citra daun kakao yang telah melalui preprocessing dan ekstraksi fitur, kemudian digunakan untuk pelatihan dan pembuatan model deep learning menggunakan pendekatan feature fusion berbasis attention yaitu fitur ekstraksi HoG dan LBP digabungkan ke dalam vision transformer yang menggunakan attention mechanism. Attention mechanism dalam vision transformer memberikan fokus yang berbeda pada fitur HoG dan LBP. Penggunaan attention mechanism dapat meningkatkan akurasi model dengan mengurangi pengaruh noise atau informasi yang tidak relevan dalam gambar. 3.5 Pengujian dan Evaluasi Model
       Pengujian dan Evaluasi model dilakukan untuk melihat akurasi model saat mengidentifikasi penyakit daun tanaman kakao. 3.6 Pengembangan Sistem Deteksi Penyakit Daun Kakao
       Setelah melakukan pelatihan dan pengembangan model, serta tahap pengujian dan evaluasi model, system deteksi untuk penyakit daun kakao diimplemetasikan dengan melibatkan pengintegrasian model ke dalam aplikasi atau perangkat keras. Pengembangan system menciptakan Solusi yang efektif dan efisien dalam mengidentifikasi penyakit daun kakao."
"3.1 Kerangka Umum Penelitian
     Berikut ini merupakan kerangka penelitian yang menjelaskan tahapan yang dilakukan dalam penelitan ini. Berikut gambar 3.1 diagram alir penelitian

Persiapan Data
Definisikan Ukuran Input dan Parameter
Definisikan Multi-Head Attention
Desain Model
Definisikan DQN dengan Lapisan Tersembunyi
Output Layer untuk Q-values
Fungsi untuk Memilih Tindakan menggunakan
Strategi e-greedy
Fungsi untuk Memperbarui Model dengan
Pengalaman dari Replay Buffer
Gambar 3.1 Diagram Alir Penelitian


3.2 Pengumpulan Data
     Langkah awal adalah mengumpulkan dataset yang akurat dan relevan. Dataset didapatkan dari data sekunder, dataset ini merupakan hal yang penting dari simulasi dan eksperimen, mencakup koordinat lokasi yang mungkin meliputi lokasi depot dan titik pengiriman, jendela waktu untuk setiap pengiriman yang menentukan batas awal dan akhir kapan pengiriman harus dilakukan, serta jumlah kendaraan. Data ini harus mencerminkan situasi dunia nyata untuk memastikan bahwa model yang dikembangkan dapat diaplikasikan secara praktis. 3.3 Persiapan Data
     Langkah berikutnya adalah persiapan data. Pada persiapan data dilakukan normalisasi data. Normalisasi merupakan proses penting untuk menyamakan skala data, memastikan bahwa model dapat memprosesnya dengan efisien. Normalisasi min-max digunakan pada penelitian ini. Min-max adalah teknik yang mengubah skala nilai data ke dalam rentang baru seperti 0 hingga 1 atau -1 hingga 1. Teknik ini memastikan bahwa setiap fitur atau kolom data memberikan kontribusi yang seimbang dalam analisis tanpa membiarkan fitur dengan skala besar mendominasi. Pengecekan matriks korelasi dilakukan untuk memahami hubungan antara variabel-variabel dalam dataset. Korelasi membantu mengidentifikasi fitur-fitur yang saling terkait dan memberikan wawasan tentang bagaimana setiap fitur dapat mempengaruhi model prediksi rute. Koefisien Korelasi Pearson digunakan untuk
mengukur hubungan linear antara fitur. 3.4 Desain model
     Implementasi Deep Q-Network (DQN) dengan mekanisme attention untuk Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) melibatkan beberapa langkah utama, mulai dari pemilihan kerangka kerja hingga pembuatan lingkungan simulasi. 1. Pemilihan Kerangka Kerja
     Kerangka kerja yang digunakan yaitu TensorFlow, dimana kerangka kerja ini menawarkan lingkungan yang komprehensif dengan TensorBoard untuk visualisasi, serta dukungan terhadap TPU untuk akselerasi komputasi. TensorFlow mungkin lebih cocok untuk produksi dan skala besar. 2. Desain model DQN dan Multi header-attention
     DQN adalah algoritma pembelajaran penguatan yang menggunakan jaringan saraf tiruan untuk memperkirakan fungsi nilai Q, yang merepresentasikan nilai maksimum hadiah kumulatif yang diharapkan, diberikan sebuah state dan semua strategi yang mungkin diambil. Implementasi DQN melibatkan beberapa komponen utama:
Jaringan Q: Jaringan ini memperkirakan nilai Q untuk setiap aksi dari state tertentu. Dalam kasus DVRPTW, input bisa berupa representasi dari state saat ini (misalnya, lokasi kendaraan, status pengiriman) dan output adalah nilai Q untuk setiap kemungkinan aksi (misalnya, memilih lokasi pengiriman berikutnya). Memory Replay: Untuk meningkatkan stabilitas dan efisiensi pembelajaran, DQN menggunakan teknik memory replay, di mana transisi (state, aksi, reward, state baru) disimpan dalam sebuah buffer. Batch transisi ini kemudian digunakan untuk melatih jaringan Q, memungkinkan pengalaman dari masa lalu digunakan kembali. Strategi Eksplorasi: Seperti e-greedy, di mana aksi acak dipilih dengan probabilitas e untuk mendorong eksplorasi lingkungan. Mekanisme attention terdiri dari tiga matriks utama: Query (Q), Key (K), dan Value (V) untuk setiap head i. Adapun langkah-langkahnya implementasinya sebagai berikut:
a. Definisikan Ukuran Input dan Parameter
      Mentukan jumlah fitur input, dimensi embedding, jumlah heads untuk mekanisme attention, dan jumlah unit dalam lapisan tersembunyi DQN. Serta jumlah tindakan yang mungkin dilakukan oleh agen. b. Definisikan Multi-Header Attention
      Menerapkan mekanisme Multi-Header Attention pada representasi vektor dari embedding layer. Multi-Header Attention menggunakan Query (Q), Key (K), dan Value (V) untuk menangkap hubungan kontekstual dalam data. Proses ini membantu model untuk fokus pada aspek-aspek penting dari data input. Attention Score dihitung dengan mengalikan Query dengan Key, kemudian membaginya dengan skala (biasanya akar dari dimensi Key) dan menerapkan fungsi softmax untuk mendapatkan bobot attention. Output Attention diperoleh dengan mengalikan bobot perhatian dengan Value. Multi-Header Attention melakukan proses ini beberapa kali secara paralel (dengan beberapa ""heads"") dan hasilnya digabungkan untuk data input. c. Definisikan DQN dengan Lapisan Tersembunyi
      Membuat beberapa lapisan tersembunyi (hidden layers) menggunakan fungsi aktivasi ReLU. Lapisan tersembunyi ini memungkinkan jaringan untuk belajar representasi yang kompleks dari data input. Output dari mekanisme attention diberikan sebagai input ke DQN. DQN memperkirakan Q-values untuk setiap tindakan yang mungkin dilakukan oleh agen berdasarkan representasi state yang telah diperkaya. d. Output Layer untuk Q-values
      Lapisan output menghasilkan Q-values untuk setiap tindakan yang mungkin dilakukan oleh agen. Q-values ini menunjukkan seberapa baik setiap tindakan dalam memaksimalkan reward di masa depan. Misalnya, jika agen memiliki 5 kemungkinan tindakan, lapisan output akan menghasilkan 5 Q-values, satu untuk setiap tindakan. e. Memilih Tindakan menggunakan Strategi e-greedy
      Implementasikan strategi e-greedy untuk memastikan agen mengeksplorasi lingkungan sekaligus mengeksploitasi pengetahuan yang ada. Dengan probabilitas e, agen memilih tindakan secara acak untuk eksplorasi, dan dengan probabilitas 1- e, agen memilih tindakan dengan Q-value tertinggi untuk eksploitasi. f. Memperbarui Model dengan Pengalaman dari Replay Buffer
      Menggunakan replay buffer untuk menyimpan transisi (state, action, reward, next state) dan menggunakannya untuk melatih model. Batch transisi diambil secara acak dari replay buffer untuk mengurangi korelasi antara sampel pelatihan dan meningkatkan stabilitas pelatihan. 3.5 Pelatihan Model
     Selama fase pelatihan, model secara berulang kali dihadapkan pada berbagai skenario dari masalah rute kendaraan. Untuk setiap episode, model mengambil serangkaian aksi berdasarkan policy atau kebijakan saat ini yang awalnya adalah kebijakan acak dengan tujuan meminimalkan jarak total dan memenuhi jendela waktu pengiriman. Setelah mengambil aksi, model menerima feedback dari lingkungan berupa reward yang merupakan ukuran dari performa aksi tersebut dan state baru yang mencerminkan kondisi terkini dari lingkungan setelah aksi diambil. Informasi ini digunakan untuk memperbarui kebijakan model dengan cara mengoptimalkan parameter jaringan sehingga meningkatkan estimasi nilai Q, yang merepresentasikan hadiah kumulatif yang diharapkan. Untuk meningkatkan stabilitas dan efisiensi pelatihan, teknik seperti experience replay dan target networks digunakan. Experience replay memungkinkan model untuk belajar dari pengalaman masa lalu yang disimpan dalam memory replay, sedangkan target networks membantu mengurangi pergeseran target yang bergerak selama proses pembelajaran. Melalui interaksi yang berulang dan proses optimisasi ini, model secara bertahap belajar untuk memprediksi nilai Q yang lebih akurat untuk setiap kombinasi state dan aksi, yang mengarah pada pembentukan kebijakan rute yang lebih optimal. Selain itu pada tahap pelatihan model ini juga dilakukan penyetelan hyperparameter untuk menemukan nilai optimal hyperparameter guna meningkatkan kinerja model. Ini merupakan langkah penting dalam machine learning karena dapat menghasilkan peningkatan akurasi, efisiensi, dan generalizability model. Penyetelan hyperparameter menggunakan teknik random search, yaitu teknik yang digunakan untuk penyetelan hyperparameter yang melibatkan pemilihan acak dari ruang yang ditentukan untuk menemukan kombinasi terbaik yang mengoptimalkan kinerja model. Teknik ini lebih efektif dan efisien untuk penyetelan hyperparameter terutama pada kasus dengan ruang pencarian yang besar, serta dapat menemukan solusi yang baik dalam waktu yang lebih singkat. 3.6 Evaluasi Model
     Setelah fase pelatihan model Deep Q-Network (DQN) dengan multi-header attention untuk Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) selesai, langkah evaluasi menjadi penting untuk memahami seberapa efektif model dalam menyelesaikan masalah yang ditargetkan. Evaluasi dilakukan dengan menguji model terhadap kumpulan data pengujian yang tidak terlibat selama proses pelatihan, memberikan masukan penting tentang kemampuan generalisasi model terhadap skenario baru dan belum pernah dilihat. Dalam konteks DVRPTW, metrik yang relevan seperti total jarak tempuh oleh semua kendaraan dan kepatuhan terhadap jendela waktu pengiriman menjadi fokus utama. Total jarak tempuh mencerminkan efisiensi rute yang dihasilkan, sementara kepatuhan terhadap jendela waktu mencerminkan kualitas layanan yang dapat dijamin oleh model. 3.7 Analisis dan Penyempurnaan
     Langkah terakhir yaitu analisis secara mendalam kinerja model pada dataset pengujian. Penyempurnaan dilakukan untuk mengatasi kelemahan yang telah dianalisis sebelumnya seperti penyempurnaan pada tuning hyperparameter untuk peningkatan kinerja, modifikasi arsitektur dan pelatihan ulang model. 3.8 Jadwal Penelitian
     Jadwal penelitian digunakan untuk meningkatkan efektivitas dalam proses penelitian. Adanya jadwal penelitian ini setiap proses penelitian sudah terjadwal dalam tabel 3.1 sehingga penelitian lebih efektif dan optimal. Tabel 3.1 Jadwal Penelitian","3.1 Kerangka Umum Penelitian
     Berikut ini merupakan kerangka penelitian yang menjelaskan tahapan yang dilakukan dalam penelitan ini. Berikut gambar 3.1 diagram alir penelitian

Persiapan Data
Definisikan Ukuran Input dan Parameter
Definisikan Multi-Head Attention
Desain Model
Definisikan DQN dengan Lapisan Tersembunyi
Output Layer untuk Q-values
Fungsi untuk Memilih Tindakan menggunakan
Strategi e-greedy
Fungsi untuk Memperbarui Model dengan
Pengalaman dari Replay Buffer
Gambar 3.1 Diagram Alir Penelitian


3.2 Pengumpulan Data
     Langkah awal adalah mengumpulkan dataset yang akurat dan relevan. Dataset didapatkan dari data sekunder, dataset ini merupakan hal yang penting dari simulasi dan eksperimen, mencakup koordinat lokasi yang mungkin meliputi lokasi depot dan titik pengiriman, jendela waktu untuk setiap pengiriman yang menentukan batas awal dan akhir kapan pengiriman harus dilakukan, serta jumlah kendaraan. Data ini harus mencerminkan situasi dunia nyata untuk memastikan bahwa model yang dikembangkan dapat diaplikasikan secara praktis. Normalisasi merupakan proses penting untuk menyamakan skala data, memastikan bahwa model dapat memprosesnya dengan efisien. 3.4 Desain model
     Implementasi Deep Q-Network (DQN) dengan mekanisme attention untuk Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) melibatkan beberapa langkah utama, mulai dari pemilihan kerangka kerja hingga pembuatan lingkungan simulasi. Informasi ini digunakan untuk memperbarui kebijakan model dengan cara mengoptimalkan parameter jaringan sehingga meningkatkan estimasi nilai Q, yang merepresentasikan hadiah kumulatif yang diharapkan. Untuk meningkatkan stabilitas dan efisiensi pelatihan, teknik seperti experience replay dan target networks digunakan. Selain itu pada tahap pelatihan model ini juga dilakukan penyetelan hyperparameter untuk menemukan nilai optimal hyperparameter guna meningkatkan kinerja model. Ini merupakan langkah penting dalam machine learning karena dapat menghasilkan peningkatan akurasi, efisiensi, dan generalizability model. 3.6 Evaluasi Model
     Setelah fase pelatihan model Deep Q-Network (DQN) dengan multi-header attention untuk Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) selesai, langkah evaluasi menjadi penting untuk memahami seberapa efektif model dalam menyelesaikan masalah yang ditargetkan. Dalam konteks DVRPTW, metrik yang relevan seperti total jarak tempuh oleh semua kendaraan dan kepatuhan terhadap jendela waktu pengiriman menjadi fokus utama. Total jarak tempuh mencerminkan efisiensi rute yang dihasilkan, sementara kepatuhan terhadap jendela waktu mencerminkan kualitas layanan yang dapat dijamin oleh model. 3.7 Analisis dan Penyempurnaan
     Langkah terakhir yaitu analisis secara mendalam kinerja model pada dataset pengujian. Penyempurnaan dilakukan untuk mengatasi kelemahan yang telah dianalisis sebelumnya seperti penyempurnaan pada tuning hyperparameter untuk peningkatan kinerja, modifikasi arsitektur dan pelatihan ulang model. 3.8 Jadwal Penelitian
     Jadwal penelitian digunakan untuk meningkatkan efektivitas dalam proses penelitian. Adanya jadwal penelitian ini setiap proses penelitian sudah terjadwal dalam tabel 3.1 sehingga penelitian lebih efektif dan optimal. Tabel 3.1 Jadwal Penelitian"
"3.1 Tahapan Penelitian
     Metode penelitian ini dilakukan berdasarkan kerangka pemikiran dan kajian pustaka. Secara umum penelitian ini berupa studi kualitatif dengan pendekatan deskriptif, untuk teknik pengambilan sampel melalui observasi, wawancara, kuisioner, dan dokumentasi. Untuk tahapan penelitian secara garis besar, dapat dilihat pada gambar 3.1. digunakan untuk mengetahui output yang dibutuhkan oleh pihak-pihak yang terlibat di proyek konstruksi. 3.3.2 Data Sekunder
     Data sekunder dikumpulkan dari hasil studi literatur, review penelitian terdahulu, pencarian perangkat lunak dan beberapa template perangkat lunak yang banyak tersedia di internet. Data sekunder ini juga akan mengumpulkan mengenai informasi proyek, sumber dana, jenis laporan baik dari pemilik (pengguna jasa), konsultan dan kontraktor, serta jadwal pelaksanaan dan kemajuan fisik, termin pembayaran serta informasi orang-orang yang berkepentingan dalam proyek konstruksi. 3.3.3 Pengumpulan Data
     Teknik pengumpulan data yang dilakukan antara lain sebagai berikut :
a. Observasi dilakukan untuk mengetahui kebutuhan sistem informasi manajemen proyek yang dibutuhkan oleh para pihak-pihak yang terlibat pada proyek konstruksi. b. Wawancara dilakukan untuk mengetahui output mengenai sistem informasi manajemen yang dibutuhkan oleh para pihak-pihak yang terlibat pada proyek kosntruksi. c. Kuesioner dilakukan untuk menanyakan kembali kepada para pihak-pihak yang terlibat pada proyek konstruksi mengenai pembobotan atas atribut- atribut yang sudah dikelompokkan atas jawaban setiap atribut untuk dijadikan bobot kebutuhan dari para pihak-pihak yang terlibat pada proyek konstruksi. d. Dokumentasi dilakukan untuk mendapatkan data dengan cara membaca dan mengambil kesimpulan dari berkas-berkas proyek. 3.4 Pengembangan Sistem
     Untuk pengembangan sistem, sesuai yang telah disampaikan pada latar belakang bahwa metode yang digunakan dalam memodelkan sistem informasi manajemen proyek konstruksi adalah Rapid Application Development (RAD). Metode RAD digunakan karena modul yang terlalu banyak sehingga untuk fleksibilitas dalam pengembangan sistem dapat dikendalikan serta jika ada perubahan pada setiap modul, maka pengembang secara fleksibel dapat merubah modul tersebut dan modul yang berkaitan. RAD pada pengembangan sistem yang membuat terbagi dalam beberapa tahap, sedangkan tools yang digunakan untuk memodelkan beriorientasi objek adalah notasi Unified Modelling Language (UML). Metode RAD terdiri dari tiga tahap pengembangan, yaitu :
a. Requirement Planning Phase
     Pada tahap ini, akan dilakukan obeservasi untuk mengumpulkan informasi-informasi mengenai gambaran umum dari suatu perusahaan, termasuk logo perusahaan, visi dan misi, serta struktur perusahaannya. Tahap selanjutnya, akan dilakukan analisi pada sistem yang berjalan proses monitoring manajemen proyek serta bagaimana work breakdown structures yang sedang berlangsung, kemudian mengindentifikasi masalah dari sistem yang berjalan. Setelah itu, akan dibuat sistem usulan yang akan dijadikan sebagai rekomendasi untuk sistem tersebut. b. RAD Design Workshop
     Pada tahap ini, tahap perancangan proses sistem, basis data dan user interface yang akan dikerjakan untuk prototype sistem, kemudian menganalisis dan mengembangkan modul-modul yang dirancang. 1)	Perancangan Proses Sistem
     Pada tahap ini akan membuat use case diagram, activity diagram, class diagram, sequence diagram, component diagram, dan deployment diagram. 2)	Perancangan Basis Data
     Pada tahap ini, akan dirancang basis data yang berupa tabel-tabel serta hubungan antar label yang berdasarkan kebutuhan sistem informasi manajemen proyek. 3)	Perancangan User Interface
     Pada tahap ini, akan dirancang tampilan antar muka yang akan dibuat sesuai dengan kebutuhan pengembangan sistem. c. Implementation Phase
     Pada tahap ini, akan dilakukan implementasi pada sistem sehingga yang sudah dirancang dapat dilihat prosesnya ke dalam bentuk aplikasi. Tahap ini akan terdiri dari dua tahap, yaitu :
     1)	Tahap Pembangunan Sistem
     Jika perancangan siap dan sudah disetujui, maka proses sistem akan dibangun dengan menggunakan bahasa Laravel Framework sesuai dengan rancangan yang sudah dibuat. 2)	Tahap Pengujian Sistem
     Tahap ini akan memeriksa seluruh proses yang telah dibangun apakah dapat berjalan sesuai rancangan dan optimal. 3.4.1 Gambaran Umum Perusahaan
     Pada tahapan ini, akan dikumpukan informasi mengenai gambaran umum perusahaan seperti profil perusahaan, visi misi perusahaan, struktur organisasi perusahaan. 3.4.2 Analisis Sistem Berjalan
     Pada tahapan ini, akan dikumpulkan informasi mengenai sistem yang berj alan pada perusahaan, seperti informasi aktor-aktor yang menggunakan sistem tersebut. Untuk mengetahui tanggung jawab dari masing-masing Admin, User, dan Client yang menggunakan sistem tersebut. Dari sistem yang digunakan, akan dikumpulkan juga mengenai informasi kelebihan dan kekurangan sistem yang berjalan dari masing-masing aktor-aktor yang menggunakan sistem tersebut. 3.4.3 Identifikasi Masalah
     Berdasarkan hasil pengumpulan informasi pada tahap analisis sistem berjalan, yaitu mengetahui kelemahan sistem yang berjalan, maka peneliti akan mengindentifikasi permasalahan tersebut. 3.4.4 Analisis Sistem Usulan
     Berdasarkan hasil pengumpulan informasi mengenai kelemahan sistem yang berjalan dan hasil identifikasi masalah, maka untuk menyelesaikan permasalahan tersebut akan dianalisis untuk keperluan sistem usulan guna untuk melakukan pengembangan sistem informasi manajemen pada proyek konstruksi. 3.4.5 Perancangan Proses
3.4.5.1 Use Case Diagram
        Pada use case diagram akan memberikan deskripsi hubungan antara pengguna sistem (aktor) dengan aktivitas-aktivitas atau proses pada sistem informasi manajemen untuk proyek kosntruksi. Setelah use case diagram sudah terbentuk, maka selanjutnya akan membuat identifikasi use case diagram pada sistem informasi manajemen untuk proyek konstruksi. Setelah proses tersebut, maka selanjutnya membuat narasi use case untuk menjelaskan use case secara lebih rinci. 3.3 Pengumpulan Data
3.3.1 Data Primer
      Data primer dikumpulkan dari hasil wawancara dan diskusi dengan pengguna jasa dan penyedia jasa disertai dengan mempresentasikan mengenai konsep sistem informasi manajemen proyek konstruksi. 3.4.5.2	Activity Diagram
        Pada activity diagram ini akan menjelaskan mengenai aktivitas- aktivitas yang terjadi pada sistem informasi manajemen untuk proyek konstruksi. 3.4.5.3	Class Diagram
        Pada class diagram ini akan membuat hubungan relasi antara objek, memiliki atribut dan operasi yang ada pada objek. Tahap pertama akan dibuat daftar objek melalui analisis dari objek-objek pada proses sistem. Setalah membuat daftar objek, maka selanjutnya akan dibuat analisis daftar objek dan membuat atribut-abtribut pada objek. Dari hasil tersebut, akan terbentuk daftar usulan objek pada sistem tersebut, kemudian akan berlanjut pada tahap pembuatan class diagram pada sistem tersebut. 3.4.5.4	Sequence Diagram
        Pada sequence diagaram ini akan memberikan penjelasan mengenai 
urutan secara rinci pada proses objek-objek yang akan dilakukan pada sistem untuk 
mencapai tujuan dari use case. 3.4.5.5	Component Diagram
        Pada component diagram ini akan digambarkan komponen- komponen dari sistem dan memberikan penjelasan mengenai masing-masing komponen yang ada pada sistem tersebut. 3.4.5.6 Deployment Diagram
        Pada deployment diagram ini akan memberikan gambaran fisik untuk perangkat-perangkat yang akan digunakan. 3.4.6 Perancangan Basis Data
3.4.6.1 Mapping Database
        Pada mapping database ini akan dilakukan pemetaan skema database untuk menentukan relasi hubungan primary-key dan foreign-key dari antar tabel-tabel yang terbentuk. 3.4.6.2 Spesifikasi Database
        Pada spesifikasi database ini akan merancangan desain tabel sistem manajemen informasi untuk proyek konstruksi. 3.4.7 Perancangan Antar Muka
     Pada perancangan antar muka ini akan dirancang antar muka sistem informasi manajemen untuk proyek konstruksi yang nanti akan dibagi berdasarkan aktor-aktor pada case diagram. 3.5 Implementasi
3.5.1 Pembangunan Sistem
      Pada pembangunan sistem ini akan dibangun menggunakan hardware dan software sesuai dengan kebutuhan spesifikasi yang akan dibutuhkan. 3.5.2 Pengujiian Sistem
      Pada pengujian sistem ini akan menggunakan pengujian blackbox testing atau white-box testing. Pengujian ini dilakukan untuk mengetahui apakah semua modul yang sudah dibentuk berjalan sesuai rancangan atau tidak, serta mengetahui apakah ada kesalahan-kesalahan terhadap proses pada sistem informasi manajemen untuk proyek konstruksi. 3.6 Kesimpulan dan Saran
      Setelah tahap penelitian selesai, maka pada tahap akhir ini peneliti akan memberikan kesimpulan mengenai hasil penelitian yang sudah didapatkan. Pada tahap akhir ini juga, peneliti akan memberikan saran kepada peneliti berikut yang akan melakukan penelitian dengan tema yang sama, untuk memberikan gambaran dalam mengembangkan penelitian yang sudah dilakukan sebelumnya.","3.3.2 Data Sekunder
     Data sekunder dikumpulkan dari hasil studi literatur, review penelitian terdahulu, pencarian perangkat lunak dan beberapa template perangkat lunak yang banyak tersedia di internet. Data sekunder ini juga akan mengumpulkan mengenai informasi proyek, sumber dana, jenis laporan baik dari pemilik (pengguna jasa), konsultan dan kontraktor, serta jadwal pelaksanaan dan kemajuan fisik, termin pembayaran serta informasi orang-orang yang berkepentingan dalam proyek konstruksi. 3.4 Pengembangan Sistem
     Untuk pengembangan sistem, sesuai yang telah disampaikan pada latar belakang bahwa metode yang digunakan dalam memodelkan sistem informasi manajemen proyek konstruksi adalah Rapid Application Development (RAD). Metode RAD digunakan karena modul yang terlalu banyak sehingga untuk fleksibilitas dalam pengembangan sistem dapat dikendalikan serta jika ada perubahan pada setiap modul, maka pengembang secara fleksibel dapat merubah modul tersebut dan modul yang berkaitan. b. RAD Design Workshop
     Pada tahap ini, tahap perancangan proses sistem, basis data dan user interface yang akan dikerjakan untuk prototype sistem, kemudian menganalisis dan mengembangkan modul-modul yang dirancang. Tahap ini akan terdiri dari dua tahap, yaitu :
     1)	Tahap Pembangunan Sistem
     Jika perancangan siap dan sudah disetujui, maka proses sistem akan dibangun dengan menggunakan bahasa Laravel Framework sesuai dengan rancangan yang sudah dibuat. 3.4.4 Analisis Sistem Usulan
     Berdasarkan hasil pengumpulan informasi mengenai kelemahan sistem yang berjalan dan hasil identifikasi masalah, maka untuk menyelesaikan permasalahan tersebut akan dianalisis untuk keperluan sistem usulan guna untuk melakukan pengembangan sistem informasi manajemen pada proyek konstruksi. Dari hasil tersebut, akan terbentuk daftar usulan objek pada sistem tersebut, kemudian akan berlanjut pada tahap pembuatan class diagram pada sistem tersebut. 3.4.6.2 Spesifikasi Database
        Pada spesifikasi database ini akan merancangan desain tabel sistem manajemen informasi untuk proyek konstruksi. 3.4.7 Perancangan Antar Muka
     Pada perancangan antar muka ini akan dirancang antar muka sistem informasi manajemen untuk proyek konstruksi yang nanti akan dibagi berdasarkan aktor-aktor pada case diagram. 3.5 Implementasi
3.5.1 Pembangunan Sistem
      Pada pembangunan sistem ini akan dibangun menggunakan hardware dan software sesuai dengan kebutuhan spesifikasi yang akan dibutuhkan. Pengujian ini dilakukan untuk mengetahui apakah semua modul yang sudah dibentuk berjalan sesuai rancangan atau tidak, serta mengetahui apakah ada kesalahan-kesalahan terhadap proses pada sistem informasi manajemen untuk proyek konstruksi. 3.6 Kesimpulan dan Saran
      Setelah tahap penelitian selesai, maka pada tahap akhir ini peneliti akan memberikan kesimpulan mengenai hasil penelitian yang sudah didapatkan. Pada tahap akhir ini juga, peneliti akan memberikan saran kepada peneliti berikut yang akan melakukan penelitian dengan tema yang sama, untuk memberikan gambaran dalam mengembangkan penelitian yang sudah dilakukan sebelumnya."
