kalimat,summary
"Berdasarkan hasil kajian Tabel 2.2, dapat dilakukan pengembangan model koperasi petani untuk produk kentang dengan tujuan ketahanan pangan dan mengoptimalkan rantai pasok. Model Platform koperasi petani berdasarkan economic sharing dan prinsip perkoperasian. Peluang terbesar dalam penelitian ini seperti yang dijelaskan pada BAB I adalah sebagai berikut. 1. Transportasi digital di bidang pertanian merupakan tren penting dalam praktik dan tata kelola yang berkelanjutan. Teknologi blockchain yang terdesentralisasi dapat menjamin keamanan data yang lebih besar dan menawarkan peluang untuk menciptakan aset dan informasi digital dengan tingkat kekekalan dan transparansi yang tinggi
2. Artificial Neural Network adalah jenis algoritma pembelajaran mesin yang terinspirasi oleh struktur dan fungsi otak manusia. Dalam konteks manajemen rantai pasok, ANN dapat digunakan untuk peramalan permintaan, optimalisasi, inventaris, perencanaan logistik, dan deteksi anomali. 3. Safety stock merupakan salah satu metode yang digunakan untuk menghindari resiko kehabisan stok. Sehingga dalam rantai pasok, inventory management yang efektif dapat memastikan layanan yang terbaik kepada pelanggan dan mempertahankan reputasi perusahaan.","Berdasarkan hasil kajian Tabel 2.2, dapat dilakukan pengembangan model koperasi petani untuk produk kentang dengan tujuan ketahanan pangan dan mengoptimalkan rantai pasok. Model Platform koperasi petani berdasarkan economic sharing dan prinsip perkoperasian. Sehingga dalam rantai pasok, inventory management yang efektif dapat memastikan layanan yang terbaik kepada pelanggan dan mempertahankan reputasi perusahaan."
"Berdasarkan beberapa penelitian terdahulu tersebut, dapat diketahui bahwa fokus penelitian sekarang berbeda dari penelitian serupa sebelumnya. Akour et al. (2022) berfokus pada kerangka konseptual untuk menentukan adopsi metaverse di lembaga pendidikan tinggi seperti universitas wilayah Teluk Timur Tengah. Talan dan Kalinkara (2022) berfokus pada pendapat mahasiswa mengenai penggunaan metaverse di lingkungan pendidikan. Srisawat dan Piriyasurawong (2022) berfokus pada pengelolaan pembelajaran virtual metaverse berdasarkan teknik gamifikasi untuk meningkatkan pengalaman total mahasiswa. Teng, Cai, Gao, Zhang, dan Li (2022) berfokus pada faktor-faktor yang mempengaruhi adopsi pembelajaran atas platform metaverse di bidang pendidikan di China. Guo dan Gao (2022) berfokus pada desain pengajaran bahasa Inggris situasional berbasis pengalaman didukung metaverse. Jadi, dapat disimpulkan bahwa sepengetahuan peneliti, penelitian terkait pengembangan sistem pembelajaran mengenai perkembangan arsitektur berbasis metaverse yang dilakukan sekarang memang sifatnya baru, orisinal, dan belum pernah dilakukan sebelumnya.","Guo dan Gao (2022) berfokus pada desain pengajaran bahasa Inggris situasional berbasis pengalaman didukung metaverse. Jadi, dapat disimpulkan bahwa sepengetahuan peneliti, penelitian terkait pengembangan sistem pembelajaran mengenai perkembangan arsitektur berbasis metaverse yang dilakukan sekarang memang sifatnya baru, orisinal, dan belum pernah dilakukan sebelumnya."
"Penelitian Cerrada et al. (2022) mengusulkan penggunaan sinyal arus sebagai metode non-intrusif untuk diagnosis kesalahan bantalan, mencapai presisi tinggi dengan metode LAMDA. Penelitian ini menawarkan solusi yang lebih sederhana dan efisien biaya dibandingkan analisis getaran tradisional, menggabungkan pendekatan berbasis data yang telah diterapkan dalam penelitian sebelumnya. Setiap penelitian membangun fondasi yang sebelumnya dan memperluas metode yang digunakan untuk diagnosis dan prediksi kerusakan kompresor reciprocating. Hal ini menunjukkan perkembangan dari analisis sederhana sinyal AE ke penggunaan kombinasi metode machine learning dan data sensor yang lebih kompleks. Sebagaimana penelitian yang akan diusulkan, pengembangan model prediksi kegagalan mesin bertujuan untuk menciptakan sistem pemeliharaan prediktif yang efektif, yang dapat membantu organisasi dalam mengoptimalkan operasi dalam meminimalkan risiko kerusakan. Konteks analisis penelitian sebelumnya mengenai diagnosis dan prediksi kerusakan pada kompresor reciprocating, diagram fishbone dapat digunakan untuk menggambarkan faktor-faktor kunci yang berkontribusi terhadap pengembangan teknologi dan metodologi dalam bidang ini. Berikut diagram fishbone yang mempengaruhi penelitian usulan pengembangan prediksi kegagalan pada kompresor reciprocating yang dapat dilihat pada Gambar 2.4.","Konteks analisis penelitian sebelumnya mengenai diagnosis dan prediksi kerusakan pada kompresor reciprocating, diagram fishbone dapat digunakan untuk menggambarkan faktor-faktor kunci yang berkontribusi terhadap pengembangan teknologi dan metodologi dalam bidang ini. Berikut diagram fishbone yang mempengaruhi penelitian usulan pengembangan prediksi kegagalan pada kompresor reciprocating yang dapat dilihat pada Gambar 2.4."
"Penelitian oleh Halomoan et al. (2023) mengembangkan model CNN yang dioptimalkan untuk mendeteksi tanda-tanda kantuk pada pengemudi. Studi ini menekankan pentingnya pre-processing data dan augmentasi data untuk meningkatkan performa model dalam berbagai kondisi pencahayaan dan posisi kepala pengemudi

Penggunaan Teknologi IoT dalam Deteksi Kelelahan 
     Penelitian oleh Abbas et al. (2022) mengeksplorasi penggunaan teknologi IoT untuk mengumpulkan dan menganalisis data fisiologis dan visual secara real-time. Sistem yang dikembangkan menggunakan sensor EKG dan kamera untuk memantau kondisi pengemudi dan memberikan peringatan dini jika tanda-tanda kelelahan terdeteksi. Deteksi Kelelahan dengan Kombinasi CNN dan LSTM
     Penelitian oleh Halomoan et al. (2023) menggabungkan CNN untuk ekstraksi fitur visual dan LSTM untuk analisis urutan waktu dari sinyal fisiologis. Hasil penelitian menunjukkan bahwa kombinasi CNN dan LSTM dapat meningkatkan keakuratan deteksi kelelahan dengan memanfaatkan kekuatan masing-masing model dalam menangani data yang berbeda. Evaluasi Model Klasifikasi dalam Deteksi Kelelahan
     Penelitian oleh Halomoan et al. (2023) mengevaluasi berbagai model klasifikasi, termasuk SVM, CNN, dan LSTM, untuk mendeteksi kelelahan pengemudi. Studi ini menunjukkan bahwa kombinasi model, seperti menggunakan CNN untuk ekstraksi fitur dan SVM untuk klasifikasi, memberikan hasil yang paling akurat dalam mendeteksi kondisi kelelahan. Literature review ini menunjukkan bahwa pendekatan yang menggabungkan data visual dan fisiologis, serta menggunakan model deep learning seperti CNN dan LSTM, dapat memberikan hasil yang sangat akurat dalam mendeteksi kelelahan pengemudi. Selain itu, penggunaan SVM sebagai model klasifikasi juga terbukti efektif dalam mengklasifikasikan kondisi kelelahan berdasarkan fitur yang diekstraksi. Penelitian lebih lanjut diperlukan untuk menguji dan mengembangkan model ini dalam kondisi mengemudi nyata yang lebih beragam. Berdasarkan penelitian-penelitian dalam tabel di atas menjelaskan mengenai peran dari teknologi Artificial Intelligence dalam mengembangkan solusi yang canggih untuk mengidentifikasi kelelahan pada pengemudi. Melalui pemrosesan visual secara mendalam dan pemahaman pola, teknologi tersebut mampu mendeteksi tanda-tanda kelelahan pada area mata, mulut, dan kepala pengemudi dengan tingkat akurasi yang semakin tinggi. Studi diatas menunjukkan bahwa terdapat potensi dalam meningkatkan keselamatan di jalan raya melalui pendekatan berbasis teknologi yang cerdas dan efektif. Penelitian-penelitian sejenis yang merupakan peneltian terdahulu antara lain implementasi pemanfaatan kecerdasan buatan dalam bidang teknologi informasi untuk mendeteksi kelelahan seperti pada tahun 2019 dengan mengusulkan sistem pengenalan aktivitas pengemudi berbasis deep learning dengan akurasi 93,2% untuk mengenali pengemudi menjawab telepon dan 94,5% mengirim pesan (Xing, Y., Lv, C., Wang, H., Cao, D., Velenis, E., & Wang, F.-Y. (2019). Pada tahun 2020 terdapat dua penelitian yang mengusulkan deteksi kelelahan berbasis multi-fitur wajah untuk meningkatkan akurasi deteksi. Algoritma yang digunakan yaitu YOLOv3-tiny dengan akurasi 95,10% (Li, K., Gong, Y., & Ren, Z., 2020). Serta penggunaan algoritma EM-CNN dengan akurasi 97,913% (Zhao, Z., Zhou, N., Zhang, L., Yan, H., Xu, Y., & Zhang, Z., 2020). Pada tahun selanjutnya, terdapat penelitian mengembangkan metode deteksi kelelahan pengemudi menggunakan CNN dengan parameter yang diukur yaitu posisi kepala dan mata. Nilai akurasi yang didapat rata-rata 89,55% (Li, X., Xia, J., Cao, L., Zhang, G., & Feng, X, 2021). Tahun 2022 terdapat dua penelitan pengembangan sistem untuk meningkatkan akurasi deteksi kelelahan dan memperbaiki kinerja sistem. Deteksi pada kondisi siang hari saat pengemudi menggunakan kacamata memiliki nilai akurasi 98% (Alharbey, R., Dessouky, M. M., Sedik, A., Siam, A. I., & Elaskily, M. A, 2022). Terdapat juga kombinasi metode CNN dan SVM untuk mendeteksi kelelahan pengemudi mencapai akurasi pengujian 99,65% (Salma Anber, Wafaa Alsaggaf, &Wafaa Shalash, 2022). Tahun 2023 terdapat penelitian deteksi kantuk berdasarkan perilaku pengemudi menggunakan pengukuruan fisiologis sensor Galvanic Skin Response (GSR) dengan akurasi 91% (Bajaj, J.S. ; Kumar, N.; Kaushal, R.K.; Gururaj, H.L. ; Flammini, F.; Natarajan, R, 2023). Penelitian terkini menunjukkan bahwa penggunaan CNN dalam pengenalan pola dan citra memiliki akurasi yang tinggi, namun pengaplikasian dalam sistem deteksi dini kantuk pada kondisi pre-driving masih terbatas. Kebaruan dari penelitian ini terletak pada pengembangan algoritma yang dioptimalkan untuk deteksi dini kantuk dengan memanfaatkan penggabungan data citra gambar dan data fisiologis untuk meningkatkan keakuratan deteksi, serta integrasinya dalam lingkungan pre-driving belum banyak dilakukan. Inovasi penelitian ini yaitu pembuatan dataset primer yang dibangun khusus untuk penelitian ini. Melibatkan berbagai kelompok pengemudi dalam pengumpulan data memungkinkan sistem untuk mengidentifikasi tanda-tanda kantuk dengan lebih tepat, mengatasi keterbatasan dataset yang umumnya digunakan yang cenderung homogen dan terbatas. Dataset yang khusus dan beragam ini memperkuat basis data untuk pelatihan dan pengujian model yang digunakan, serta meningkatkan kinerja dan reliabilitas sistem deteksi dini kantuk secara keseluruhan.","(2023) mengembangkan model CNN yang dioptimalkan untuk mendeteksi tanda-tanda kantuk pada pengemudi. Studi ini menekankan pentingnya pre-processing data dan augmentasi data untuk meningkatkan performa model dalam berbagai kondisi pencahayaan dan posisi kepala pengemudi

Penggunaan Teknologi IoT dalam Deteksi Kelelahan 
     Penelitian oleh Abbas et al. Sistem yang dikembangkan menggunakan sensor EKG dan kamera untuk memantau kondisi pengemudi dan memberikan peringatan dini jika tanda-tanda kelelahan terdeteksi. Hasil penelitian menunjukkan bahwa kombinasi CNN dan LSTM dapat meningkatkan keakuratan deteksi kelelahan dengan memanfaatkan kekuatan masing-masing model dalam menangani data yang berbeda. Tahun 2022 terdapat dua penelitan pengembangan sistem untuk meningkatkan akurasi deteksi kelelahan dan memperbaiki kinerja sistem. Penelitian terkini menunjukkan bahwa penggunaan CNN dalam pengenalan pola dan citra memiliki akurasi yang tinggi, namun pengaplikasian dalam sistem deteksi dini kantuk pada kondisi pre-driving masih terbatas. Kebaruan dari penelitian ini terletak pada pengembangan algoritma yang dioptimalkan untuk deteksi dini kantuk dengan memanfaatkan penggabungan data citra gambar dan data fisiologis untuk meningkatkan keakuratan deteksi, serta integrasinya dalam lingkungan pre-driving belum banyak dilakukan. Inovasi penelitian ini yaitu pembuatan dataset primer yang dibangun khusus untuk penelitian ini. Melibatkan berbagai kelompok pengemudi dalam pengumpulan data memungkinkan sistem untuk mengidentifikasi tanda-tanda kantuk dengan lebih tepat, mengatasi keterbatasan dataset yang umumnya digunakan yang cenderung homogen dan terbatas. Dataset yang khusus dan beragam ini memperkuat basis data untuk pelatihan dan pengujian model yang digunakan, serta meningkatkan kinerja dan reliabilitas sistem deteksi dini kantuk secara keseluruhan."
"Pada tahun 2010, dilakukan penelitian tentang pengenalan enam jenis ekspresi wajah otomatis menggunakan Gabor filter dan K-Nearest Neighbor (KNN) (Ou, Bai, Pei, Ma, & Liu, 2010). Pada tahun 2009, dilakukan pembelajaran komprehensif tentang pengenalan ekspresi wajah menggunakan Local Binary Pattern (LBP) yang digabung AdaBoost untuk melakukan ekstrasi fitur. Hasil dari LBP+Adaboost digunakan sebagai input model SVM yang digunakan untuk mengenali ekspresi wajah (Shan et al., 2009). Pada tahun 2011, dilakukan pengembangan metode ekstrasi fitur Local Monotonic Pattern (LMP) untuk pengenalan ekspresi wajah. Hasil dari LMP kemudian digunakan sebagai input model SVM. Pada tahun 2019, dikembangkan sebuah model DL MNN yang memanfaatkan opening dari morfologi matematika untuk mengklasifikasi angka dan rambu lalu lintas (Shen et al., 2019). Pada tahun 2020, dilakukan penelitian pengenalan ekspresi wajah menggunakan Local Binary Pattern (LBP) sebagai ekstrasi fitur, CNN dan SVM sebagai model Machine Learning (Ravi, Yadhukrishna, & Prithviraj, 2020). Pada tahun 2023, dilakukan pengenalan ekspresi wajah menggunakan histogram-based feature descriptor (untuk ekstrasi fitur), dan KNN sebagai model pengenalan wajah (Eleyan, 2023). Pada tahun yang sama (2023), dilakukan penelitian pembentukan skenario dataset menggunakan LBP, Local Monotonic Pattern, dan Viola Jones (VJA) sebagai ekstrasi fitur, dan CNN, SVM sebagai model pengenalan ekspresi wajah. Pada tahun ini 2024, akan diajukan penelitian ""PENGEMBANGAN MODEL KLASIFIKASI MORPHOLOGICAL NEURAL NETWORK UNTUK SISITEM PENGENALAN EKSPRESI WAJAH"".","Hasil dari LBP+Adaboost digunakan sebagai input model SVM yang digunakan untuk mengenali ekspresi wajah (Shan et al., 2009). Pada tahun 2011, dilakukan pengembangan metode ekstrasi fitur Local Monotonic Pattern (LMP) untuk pengenalan ekspresi wajah. Pada tahun ini 2024, akan diajukan penelitian ""PENGEMBANGAN MODEL KLASIFIKASI MORPHOLOGICAL NEURAL NETWORK UNTUK SISITEM PENGENALAN EKSPRESI WAJAH""."
"Berdasarkan metode dan teknik yang telah dilakukan pada penelitian terdahulu, untuk menjawab tujuan dari penelitian ini maka akan digunakan metode deep learning CNN dengan arsitektur MobileNetV3 dan menggabungkannya dengan attention module CBAM serta menggunakan pendekatan contour dalam tahap segmentasi data.","Berdasarkan metode dan teknik yang telah dilakukan pada penelitian terdahulu, untuk menjawab tujuan dari penelitian ini maka akan digunakan metode deep learning CNN dengan arsitektur MobileNetV3 dan menggabungkannya dengan attention module CBAM serta menggunakan pendekatan contour dalam tahap segmentasi data."
"Berdasarkan Tabel 2.2 State of The Art maka dapat disimpulkan mengenai kebaruan yang dapat diambil dari penelitian dengan topik pengukuran kualitas melalui 
klasifikasi. Ditemukan dari referensi-referensi terkait yang dibagi menjadi kelompok objek data pertama adalah ban dan pendukung seperti roda dan sekrup bahwa onvolutional Neural Networks (CNN) menjadi model yang paling banyak sekali digunakan. Adapun pengelompokan dalam ketertarikan pengambilan topik penelitian ini berdasarkan referensi penelitian terdahulu di mana diketahui pertama berdasarkan penerapan Convolutional Neural Networks (CNN) dalam industri, untuk menemukan cacat pada barang-barang seperti ban, roda, dan sekrup dengan teknik-teknik yang digunakan dalam penelitian jenis ini dapat dipelajari dan diterapkan pada situasi khusus produk ban karena dilatarbelakangi beberapa penelitian bahwa cacat ban seperti retak dan serpihan yang lolos dapat menimbulkan risiko keselamatan dan mempengaruhi keselamatan berkendara kendaraan. Kedua adalah penggunaan Convolutional Neural Networks (CNN) dalam pemeriksaan visual, yang telah banyak digunakan dalam sistem inspeksi visual untuk mendeteksi, mengklasifikasikan, dan mengidentifikasi objek dan fitur dalam gambar. Penelitian sebelumnya di bidang ini dapat memberikan wawasan tentang bagaimana Convolutional 
Neural Networks (CNN) dapat diterapkan untuk menganalisis gambar produk ban dan melakukan pengukuran kualitas. Ketiga segmentasi citra, metode penting dalam analisis 
gambar untuk pengukuran kualitas adalah segmentasi gambar. Penelitian sebelumnya mengenai segmentasi gambar dapat menawarkan strategi dan teknik yang dapat digunakan 
untuk mengisolasi daerah yang signifikan atau bermasalah dalam foto produk ban. Keempat analisis dan klasifikasi fitur, penelitian terkait analisis dan klasifikasi ciri-ciri pada barang manufaktur dapat menjadi sumber inspirasi untuk memahami ciri-ciri yang relevan dengan produk dan bagaimana menerapkan teknik klasifikasi untuk menentukan 
kualitas. Penggunaan dataset pada literature ada beberapa splitting data yang dilakukan, yaitu pertama (80% training data, 20% validation data), kedua (80% training data, 10% 
validation data, 10% testing data), ketiga (70% training data, 0% validation data, 10% testing data), keempat (60% training data, 20% validation data, 20% testing data). Penggunaan batch size (4, 10, 20, 16, 32, 64, 150, 256). Penggunaan layer coonvolutional (2, 3, 5, 7, 22), layer pooling (2, 3, 5). Penggunaan learning rate (0.01, 0.001, 0.0001, 0.000001). Penggunaan epoch (10, 20, 30, 100, 120, 200). Penggunaan nilai dropout (0.1, 0.2, 0.5). Penggunaan input size (256x256, 127x127, 900x900, 50x50, 
64x64). Penelitian yang dilakukan oleh Vasan, Sridharan, Sreelatha, & Vaithiyanatha (2023) melakukan perbandingan dilakukan untuk pretrained model VGG-16, GoogLeNet, AlexNet, ResNet-50. Permasalahan yang ditimbulkan oleh masing-masing jurnal referensi dominan seperti dalam beberapa penelitian yang menggambarkan dominansi permasalahan seperti 
Wang, Guo, Lu et al (2019) permasalahan penggunaan algoritma Convolutional Neural Networks (CNN) dengan arsitektur convolutional, pooling, Fully Convolutional 
Network mungkin tidak sensitif terhadap cacat kecil pada gambar ban, seperti gelembung, karena hilangnya detail yang disebabkan oleh operasi pengumpulan data. Dilanjutkan oleh penelitian Wu, Jiao, Sun et al (2021) penelitian ini mengakui bahwa hasil deteksi cacat gelembung sedikit buruk dan menyarankan penelitian lebih lanjut dengan menggunakan kombinasi metode deteksi langsung dan tidak langsung. Li, Fan, Zhang et al (2021) menyatakan meskipun algoritma ini berhasil dalam mendeteksi berbagai jenis cacat, masih terdapat kebutuhan untuk meningkatkan deteksi pada jenis cacat tertentu, seperti gelembung yang memiliki perbedaan yang halus dari bagian sekitarnya. Permasalahan yang terjadi masalah sensitivitas terhadap cacat kecil pada gambar. ban dapat diatasi dengan menggunakan algoritma Convolutional Neural Networks (CNN) dengan membangun model atau kerangka kerja menggunakan Keras (sebuah library deep learning yang dirancang untuk mempermudah proses pengembangan dan eksperimen model jaringan saraf). Membangun model menggunakan Keras, sebenarnya mendefinisikan arsitektur model dengan menambahkan lapisan-lapisan yang sesuai. Lapisan-lapisan tersebut akan membentuk struktur atau arsitektur dari model yang kemudian dapat dilatih dan dievaluasi. Keras menyediakan berbagai model pre-trained yang dapat digunakan, dengan menambahkan lapisan-lapisan convolutional, MaxPooling2D, Flatten, dan Dense (fully connected layeri) yang akan membantu model untuk mempelajari fitur-fitur yang lebih spesifik terkait dengan gambar ban dan meningkatkan sesitivitas terhadap cacat. Pengembangan algoritma Convolutional Neural Networks (CNN) salah satunya dengan melakukan perbandingan pada komponen-komponen di dalamnya berdasarkan referensi sumber penelitian terdahulu sehingga membentuk perbandingan versi baru yang dibuat seperti melakukan perbandingan penggunaan layer yang sama (konvulasi dan pooling) mulai dari (3, 4, 5, 6) layer, perbandingan penggunaan seberapa banyak jumlah epoch (20, 50, 100), perbandingan format splitting data (80:20, 60:20:20, 70:20:10, 80:10:10), perbandingan penggunaan algoritma optimasi (Stochastic Gradient Descent (SGD), Root Mean Square Propagation (RMSProp) dan Adaptive Momentum (Adam)), dan perbandingan penggunaan learning rate (0.001, 0.0001, dan 0,00001). Melakukan Evaluasi dan penyesuaian di mana setelah melatih model dengan kumpulan data, maka harus menilai performanya menggunakan ukuran terkait seperti skor F1, akurasi, presisi, dan perolehan. Sehingga meningkatkan sensitivitas terhadap cacat gambar ban dapat dicapai dengan menggabungkan teknik deteksi langsung dan tidak langsung, menambahkan lebih banyak lapisan, dan menggunakan model terlatih.","Berdasarkan Tabel 2.2 State of The Art maka dapat disimpulkan mengenai kebaruan yang dapat diambil dari penelitian dengan topik pengukuran kualitas melalui 
klasifikasi. Ditemukan dari referensi-referensi terkait yang dibagi menjadi kelompok objek data pertama adalah ban dan pendukung seperti roda dan sekrup bahwa onvolutional Neural Networks (CNN) menjadi model yang paling banyak sekali digunakan. Kedua adalah penggunaan Convolutional Neural Networks (CNN) dalam pemeriksaan visual, yang telah banyak digunakan dalam sistem inspeksi visual untuk mendeteksi, mengklasifikasikan, dan mengidentifikasi objek dan fitur dalam gambar. Penelitian sebelumnya di bidang ini dapat memberikan wawasan tentang bagaimana Convolutional 
Neural Networks (CNN) dapat diterapkan untuk menganalisis gambar produk ban dan melakukan pengukuran kualitas. ban dapat diatasi dengan menggunakan algoritma Convolutional Neural Networks (CNN) dengan membangun model atau kerangka kerja menggunakan Keras (sebuah library deep learning yang dirancang untuk mempermudah proses pengembangan dan eksperimen model jaringan saraf). Keras menyediakan berbagai model pre-trained yang dapat digunakan, dengan menambahkan lapisan-lapisan convolutional, MaxPooling2D, Flatten, dan Dense (fully connected layeri) yang akan membantu model untuk mempelajari fitur-fitur yang lebih spesifik terkait dengan gambar ban dan meningkatkan sesitivitas terhadap cacat. Pengembangan algoritma Convolutional Neural Networks (CNN) salah satunya dengan melakukan perbandingan pada komponen-komponen di dalamnya berdasarkan referensi sumber penelitian terdahulu sehingga membentuk perbandingan versi baru yang dibuat seperti melakukan perbandingan penggunaan layer yang sama (konvulasi dan pooling) mulai dari (3, 4, 5, 6) layer, perbandingan penggunaan seberapa banyak jumlah epoch (20, 50, 100), perbandingan format splitting data (80:20, 60:20:20, 70:20:10, 80:10:10), perbandingan penggunaan algoritma optimasi (Stochastic Gradient Descent (SGD), Root Mean Square Propagation (RMSProp) dan Adaptive Momentum (Adam)), dan perbandingan penggunaan learning rate (0.001, 0.0001, dan 0,00001). Sehingga meningkatkan sensitivitas terhadap cacat gambar ban dapat dicapai dengan menggabungkan teknik deteksi langsung dan tidak langsung, menambahkan lebih banyak lapisan, dan menggunakan model terlatih."
"Berdasarkan tinjauan yang sudah dibaca, maka terdapat kelebihan dan kekurangan yang diperoleh dari hasil penelitiannya, yaitu :
Berdasarkan perbandingan telaah tersebut, pada penelitian ini akan diusulkan sebuah metode untuk menghasilkan model peramalan yang sesuai untuk data runtun waktu yang ada, yaitu data jumlah kasus harian Covid 19 di Jakarta dengan metode Hybrid ARIMA-QNN berdasarkan dataset dari situs https://corona.jakarta.go.id tanggal 6 Maret 2020 sampai 30 Juni 2021 sebagai data training dan nanti akan diprediksi untuk tanggal 1 Juli 2021 sampai dengan 31 Juli 2021 sebagai data uji. Metode Hybrid ARIMA-QNN diusulkan dengan harapan akan memberikan nilai   peramalan   yang   lebih   akurat   dengan   presisisi   yang   tinggi","Berdasarkan tinjauan yang sudah dibaca, maka terdapat kelebihan dan kekurangan yang diperoleh dari hasil penelitiannya, yaitu :
Berdasarkan perbandingan telaah tersebut, pada penelitian ini akan diusulkan sebuah metode untuk menghasilkan model peramalan yang sesuai untuk data runtun waktu yang ada, yaitu data jumlah kasus harian Covid 19 di Jakarta dengan metode Hybrid ARIMA-QNN berdasarkan dataset dari situs https://corona.jakarta.go.id tanggal 6 Maret 2020 sampai 30 Juni 2021 sebagai data training dan nanti akan diprediksi untuk tanggal 1 Juli 2021 sampai dengan 31 Juli 2021 sebagai data uji. Metode Hybrid ARIMA-QNN diusulkan dengan harapan akan memberikan nilai   peramalan   yang   lebih   akurat   dengan   presisisi   yang   tinggi"
"Kegiatan inspeksi pada industri umumnya dilakukan secara manual dengan tenaga manusia sebagai operator. Dengan mengandalakan tenaga manusia yang memiliki keterbatasan tentunya kegiatan ini memiliki kendala. Revolusi industri 4.0 mendorong otomatisasi inspeksi produk untuk manufaktur yang tanpa cacat (zero defect) dan berkualitas tinggi di mana kemampuan fleksibilitas manusia berkolaborasi dengan kemampuan akurasi komputer dan mesin (Brito et al., 2020). Perkembangan computer vision dapat sangat membantu dalam dunia industri manufaktur untuk mencapai kualitas yang unggul (Schmidt et al., 2020). Pengendalian kualitas adalah proses yang	penting	dalam kegiatan manufaktur untuk memastikan bahwa produk tidak  memiliki	 kecacatan untuk memenuhi kebutuhan pelanggan. Terdapat kemungkinan manusia tidak mampu mengidentifkasi cacat pada produk karena keterbatasan dari indera penglihatan manusia. Otomatisasi dibutuhkan untuk meminimalisir produk cacat lolos sampai ke tangan pelanggan yang akan berpengaruh terhadap kepuasan pelanggan. Otomatisasi pada kegiatan inspeksi produk sangat peting untuk menjaga kualitas secara berkelanjutan (Deshpande et al., 2020). Berdasarkan perbandingan tinnjauan pustaka di atas yang kemudian disesuaikan dengan tujuan dari penelitian ini. Maka dapat disimpulkan. 1. Kegiatan inspeksi yang dilakukan dengan manual memiliki berbagai macam kendala dan keterbatasan. 2. Kegiatan inspeksi yang dilakukan dengan manual membutuhkan tenaga (operator) ahli dengan jumlah yang banyak sehingga tidak efisien mengingat perbedaan persepsi antara operator serta human error sangat mungkin terjadi. 3. Otomatisasi kegiatan inspeksi produk menggunakan artificial intelogence namun terkendala pemilihan algoritma karena membutuhkan eskperimen secara intensif dan komprehensif
4. Informasi yang disampaikan harus dapat menjelaskan kondisi produk dengan baik dan jelas sehingga tersampaikan dengan baik ke pihak terkait.","Kegiatan inspeksi pada industri umumnya dilakukan secara manual dengan tenaga manusia sebagai operator. Revolusi industri 4.0 mendorong otomatisasi inspeksi produk untuk manufaktur yang tanpa cacat (zero defect) dan berkualitas tinggi di mana kemampuan fleksibilitas manusia berkolaborasi dengan kemampuan akurasi komputer dan mesin (Brito et al., 2020). Perkembangan computer vision dapat sangat membantu dalam dunia industri manufaktur untuk mencapai kualitas yang unggul (Schmidt et al., 2020). Pengendalian kualitas adalah proses yang	penting	dalam kegiatan manufaktur untuk memastikan bahwa produk tidak  memiliki	 kecacatan untuk memenuhi kebutuhan pelanggan. Informasi yang disampaikan harus dapat menjelaskan kondisi produk dengan baik dan jelas sehingga tersampaikan dengan baik ke pihak terkait."
"Dalam melakukan perencanaan atau mendesain sebuah rangkaian SRAM, banyak metode yang ditawarkan, seperti yang nampak pada tabel 1. Berdasarkan beberapa penelitian terkait SRAM, untuk mewujudkan SRAM Low power dan High Read Stability, metode yang dapat dilakukan yakni GDI, m-GDI, FinFET, CNTFET, hingga Adiabatik. Namun yang akan menjadi focus utama penelitian ini yakni penerapan dari metode m-GDI (Modified Gate Diffusion Input). Desain sel m-GDI memanfaatkan input untuk bertindak sebagai 'sumber' dan 'penyimpan' untuk transistor MOS, yang mengurangi komponen konsumsi daya short-circuit dinamis menjadi nilai yang dapat diabaikan tanpa memerlukan pertimbangan desain sirkuit khusus. Oleh karena itu dipilih metode m-GDI sebab metode ini menawarkan solusi yang lebih efisien dalam hal konsumsi daya dan kompleksitas desain, yang sangat penting dalam pengembangan sirkuit digital yang hemat energi dan efisien[8]. Sebagai pandangan terkait metode m-GDI yang akan digunakan, pada salah satu gerbang AND yang dirangkai menggunakan komponen MOS, diperlukan sebanyak 6 transistor seperti yang tampak pada gambar 7.","Berdasarkan beberapa penelitian terkait SRAM, untuk mewujudkan SRAM Low power dan High Read Stability, metode yang dapat dilakukan yakni GDI, m-GDI, FinFET, CNTFET, hingga Adiabatik. Oleh karena itu dipilih metode m-GDI sebab metode ini menawarkan solusi yang lebih efisien dalam hal konsumsi daya dan kompleksitas desain, yang sangat penting dalam pengembangan sirkuit digital yang hemat energi dan efisien[8]."
"Berdasarkan Tabel 2.1 Penelitian Terdahulu dapat diketahui perkembangan DBSCAN dilakukan untuk meningkatkan kemampuan DBSCAN dalam pengelompokan yang besar, seperti yang dilakukan oleh (Chen et al., 2021; Chen et al., 2019; de Moura Ventorim et al., 2021; Huang et al., 2023) karena salah satu kelemahan dari algoritma DBSCAN yaitu kurang efektif dalam mengelompokkan dataset besar. Oleh karena itu dilakukan pengembangan untuk dapat mengelompokkan dataset besar. Selain itu, perkembangan DBSCAN juga dilakukan untuk dapat mengelompokkan data stream, yang dimana data stream selalu berubah ubah karena data stream bersifat real-time, seperti yang dilakukan oleh Bechini et al. (2020). Hasil penelitian yang dilakukan oleh Chen et al. (2019) menunjukkan bahwa KNN-BLOCK DBSCAN memiliki akurasi yang tinggi dan performa yang lebih baik dibandingkan varian DBSCAN lainnya, termasuk p-approximate DBSCAN dan AnyDBC, terutama dalam kecepatan proses klastering tanpa mengorbankan akurasi. Selain itu, penelitian yang dilakukan oleh de Moura Ventorim et al. (2021) dengan mengembangkan algoritma BIRCHSCAN hasil penelitian menunjukkan bahwa BIRCHSCAN efektif dalam memproses dataset besar dengan hasil yang serupa dengan DBSCAN, tetapi dengan pemrosesan waktu yang lebih cepat. Selain itu, penelitian yang dilakukan oleh Chen et al. (2021) dengan mengembangkan algoritma BLOCK-DBSCAN menunjukkan bahwa BLOCK-DBSCAN mengungguli varian DBSCAN lainnya seperti NQDBSCAN dan p-approximate DBSCAN dalam hal kecepatan dan akurasi, menjadikannya pendekatan yang menjanjikan untuk analisis dataset besar. Selain itu, penelitian yang dilakukan oleh Huang et al. (2021) dengan mengembangkan algoritma GriT- DBSCAN menunjukkan bahwa GriT-DBSCAN memiliki kompleksitas waktu linier terhadap ukuran dataset dan menawarkan kinerja yang lebih baik dibandingkan algoritma DBSCAN klasik. Berdasarkan pada tujuan pengembangan algoritma DBSCAN yang telah dilakukan pada penelitian terdahulu, yaitu untuk menjawab kelemahan dari algoritma DBSCAN yang kurang efektif dalam mengelompokkan dataset besar, peneliti tertarik untuk mengembangkan algoritma DBSCAN dengan memanfaatkan komputasi kuantum untuk mengelompokkan data supplier.","Berdasarkan Tabel 2.1 Penelitian Terdahulu dapat diketahui perkembangan DBSCAN dilakukan untuk meningkatkan kemampuan DBSCAN dalam pengelompokan yang besar, seperti yang dilakukan oleh (Chen et al., 2021; Chen et al., 2019; de Moura Ventorim et al., 2021; Huang et al., 2023) karena salah satu kelemahan dari algoritma DBSCAN yaitu kurang efektif dalam mengelompokkan dataset besar. (2021) dengan mengembangkan algoritma GriT- DBSCAN menunjukkan bahwa GriT-DBSCAN memiliki kompleksitas waktu linier terhadap ukuran dataset dan menawarkan kinerja yang lebih baik dibandingkan algoritma DBSCAN klasik. Berdasarkan pada tujuan pengembangan algoritma DBSCAN yang telah dilakukan pada penelitian terdahulu, yaitu untuk menjawab kelemahan dari algoritma DBSCAN yang kurang efektif dalam mengelompokkan dataset besar, peneliti tertarik untuk mengembangkan algoritma DBSCAN dengan memanfaatkan komputasi kuantum untuk mengelompokkan data supplier."
"Pengembangan menggunakan Large Language Model (LLM) ini mampu menjembatani modalitas dengan berbagai jenis media yang digunakan seperti teks, gambar, video dan suara. Penelitian yang sudah dilakukan (Feilong, 2023) dapat mengubah multimodal (gambar, suara dan video) kedalam bahasa Asing. Penelitian yang dilakukan (Junnan, 2023) menggunakan model BLIP-2, dimana BLIP-2 ini mampu menjembatani modalitas dengan transformator kueri yang sudah dilatih. Penelitian yang dilakukan (Chenyang, 2023) Mampu mengintegrasikan informasi visual, audio dan tekstual menggunakan MACAW-LLM. Meskipun kinerja LLM dalam pemrosesan dan pembuatan teks sudah mengesankan, ada potensi keuntungan tambahan dalam mengintegrasikan LLM dengan jaringan syaraf lainnya. Menurut (Hong Fan, 2021) Melakukan penelitian untuk mendeteksi toksisitas menggunakan BERT. Hasil evaluasi dalam melakukan klasifikasi menggunakan BERT menunjukkan bahwa BERTmemiliki kemampuan klasifikasi dan memprediksi komentar beracun dengan tingkat akurasi yang tinggi. Dengan metode ini, peneliti ingin melakukan pengembangan klasifikasi multimodal dengan jenis media teks, image dan video menggunakan LLM agar nantinya dapat lebih efektif dalam menangani toksisitas di lingkup sosial media.","Pengembangan menggunakan Large Language Model (LLM) ini mampu menjembatani modalitas dengan berbagai jenis media yang digunakan seperti teks, gambar, video dan suara. Dengan metode ini, peneliti ingin melakukan pengembangan klasifikasi multimodal dengan jenis media teks, image dan video menggunakan LLM agar nantinya dapat lebih efektif dalam menangani toksisitas di lingkup sosial media."
"Pada tabel 2.1 disajikan ringkasan penelitian berupa nama peneliti, judul artikel, metode, hasil penelitian dan keterbatasan. Hasil penelitian pada masing- masing artikel berupa hasil pengujian metode yang diusulkan peneliti. Pengujian tersebut menghasilkan nilai entropi, number of pixel change rate (NPCR), unified average changing intensity (UACI), vertical correlation (VC), horizontal correlation (HC), diagonal correlation (DC), mean squre error (MSE) dan peak signal noise to ratio (PSNR). Peneliti (Lone et al., 2021), metode enkripsi dan dekripsi menggunakan kombinasi dari algoritma Random RMAC, Henon Map dan Logistic Map yang dilakukan hanya pada citra berwarna ukuran 256 x 256. Peneliti (Sabir & Guleria, 2021) juga melakukan penelitian hanya pada citra berwarna 512 x 512 menggunakan kombinasi algoritma RMAC, RP2DfrHT dan Arnold Map. Sedangkan, peneliti (Benlashram et al., 2020) melakukan penelitian hanya pada citra Greyscale dengan ukuran 256 x 256 menggunakan kombinasi pengacakan piksel, operasi XOR dan 3D Chaotic Map. Peneliti (Ratna et al., 2021) melakukan metode enkripsi dengan menggunakan kombinasi algoritma Logistic Map dan 2DPSNCM dengan hasil penelitian berupa nilai korelasi dan entropi, tetapi tidak melakukan pengujian nilai UACI dan NPCR. Peneliti (Elghandour et al., 2021) melakukan enkripsi dengan kombinasi metode Logistic Map dan 2DPSNCM dengan hasil pengujian NPCR, UACI, korelasi dan Entropi. Dari beberapa penelitian tersebut maka pada penelitian ini dilakukan kriptografi berbasis chaotic menggunakan algoritma Cat Map, Henon Map dan Logistic Map pada citra digital Grayscale dan berwarna dengan melakukan beberapa pengujian dari hasil enkripsi dan dekripsi hasil proses metode algoritma yang diusulkan.","Pada tabel 2.1 disajikan ringkasan penelitian berupa nama peneliti, judul artikel, metode, hasil penelitian dan keterbatasan. Dari beberapa penelitian tersebut maka pada penelitian ini dilakukan kriptografi berbasis chaotic menggunakan algoritma Cat Map, Henon Map dan Logistic Map pada citra digital Grayscale dan berwarna dengan melakukan beberapa pengujian dari hasil enkripsi dan dekripsi hasil proses metode algoritma yang diusulkan."
penelitian terdahulu telah menunjukkan berbagai pendekatan dan metode yang berbeda untuk memprediksi produksi dan permintaan optimasi persediaan serta sistem pendukung keputusan dss di berbagai sektor. masingmasing model tersebut memiliki keterbatasan yang perlu diatasi seperti bergantung pada kualitas data dan overfitting . di sisi lain integrasi teknologi gen ai dan pembelajaran mesin dalam sektor pertanian dan pangan masih tergolong baru dan belum banyak dieksplorasi. penelitian ini bertujuan untuk mengembangkan model yang lebih adaptif yang mampu mengatasi fluktuasi dalam produksi dan permintaan serta memberikan rekomendasi untuk jumlah cadangan beras pemerintah yang optimal. penelitian ini juga akan membangun dss yang akan memberikan rekomendasi strategi pengadaan beras yang efektif untuk menjamin ketahanan pangan. penelitian ini akan menggunakan teknologi gen ai dan ml dengan mempertimbangkan variabelvariabel yang mempengaruhi manajemen persediaan cadangan beras pemerintah. gambar 2.5 memperlihatkan fishbone diagram yang menggambarkan usulan penelitian ini.,penelitian ini bertujuan untuk mengembangkan model yang lebih adaptif yang mampu mengatasi fluktuasi dalam produksi dan permintaan serta memberikan rekomendasi untuk jumlah cadangan beras pemerintah yang optimal. penelitian ini akan menggunakan teknologi gen ai dan ml dengan mempertimbangkan variabelvariabel yang mempengaruhi manajemen persediaan cadangan beras pemerintah.
Berdasarkan penelitian telaah pustaka yang telah dilakukan dapat disimpulkan bahwa proses telaah sejawat dapat dilakukan secara otomatis dengan bantuan teknologi kecerdasan buatan. Beberapa penelitian sebelumnya telah membahas mengenai penggunaan kecerdasan buatan terutama menggunakan model bahasa besar. Berdasarkan pemaparan tersebut maka terdapat peluang untuk dilakukan pengembangan platform tinjauan artikel ilmiah dalam bidang ilmu computer dengan menggunakan model bahasa besar.,Berdasarkan penelitian telaah pustaka yang telah dilakukan dapat disimpulkan bahwa proses telaah sejawat dapat dilakukan secara otomatis dengan bantuan teknologi kecerdasan buatan. Berdasarkan pemaparan tersebut maka terdapat peluang untuk dilakukan pengembangan platform tinjauan artikel ilmiah dalam bidang ilmu computer dengan menggunakan model bahasa besar.
"Dalam penelitian lanjutan penerapan BLockchain memperhatikan aspek governance yaitu pada permission model dan trust model dimana level skema pengkodifikasinya berada macro level yaitu tata kelola organisasi, akuntabilitas, dan pengeawasannya. Pada level meso, aspek mekanisme pengambilan keputusan, insentif dan konsensus pada smartcontract. Beberapa masalah yang dirangkum pada tata kelola data pendidikan tinggi adalah masalah kertas dan penerapan teknologi digital, mulai dari otoritas keaslian data akedemik, adanya tuntutan pihak ketiga dalam memanfaat data akadmik pendidikan tinggi. Dalam trust model dalam sistem terdesentralisasi telah dilakukan penelitian pada DApps Ecosystem yang dipetakan dalam arsitektur Blockchain sebagai penyimpanan data.","Dalam penelitian lanjutan penerapan BLockchain memperhatikan aspek governance yaitu pada permission model dan trust model dimana level skema pengkodifikasinya berada macro level yaitu tata kelola organisasi, akuntabilitas, dan pengeawasannya. Pada level meso, aspek mekanisme pengambilan keputusan, insentif dan konsensus pada smartcontract."
