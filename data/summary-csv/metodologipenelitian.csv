nama_dokumen,summary
Alfharizky Fauzi_Kualifikasi.txt,1 tahapan penelitian dokumentasi peneliti tahapan penelitian dapat dilihat pada gambar 3.1. tahapan penelitian yang dilakukan terdiri dari 9 tahapan yaitu dimulai dari studi literatur sebagai dasar penelitian analisis kebutuhan pada system yang akan dibangun pengumpulan dataset preprocessing data membangun model training model evaluasi model deployme nt model dan implementasi model yang telah dibuat ke dalam smartphone. saat program telah dijalankan program akan mengakuisisi dataset kemudian dataset akan melalui tahap preprocessing untuk m enormalkan data kemudian setelah melalui tahap preprocessing selanjutnya mentraining dataset yang sudah didapatkan jika dataset berhasil dilatih dan juga divalidasi maka berlanjut ke tahap berikutnya yaitu tahapan test ing dengan menerapkan model yang dibuat kedalam mobile phone atau smartphone. tahap selanjutnya jika camera telah menyala maka artinya sudah siap untuk mendeteksi objek jenis penyakit kulit . pada tahap terakhir yaitu saat ada objek jenis penyakit kulit yang masuk atau terdeteksi oleh camera m aka citra tersebut sudah dapat dilakukan proses klasifikasi kemudian divalidasikan bahwa data tersebut sama dengan yang ada pada database untuk memunculkan label nama pada dataset serta memunculkan nilai confidence pada citra jenis penyakit kulit yang terdete ksi. 3.2 analisis kebutuhan analisis kebutuhan merupakan menganalisis komponen yang diperlukan dalam pembuatan dan menjalankan program proses ini mencakup evaluasi identifikasi dan pemetaan kebutuhan dari berbagai perangkat yang terlibat dalam pembuatan system dan program pada penelitian ini. 3.2.1. analisis kebutuhan perangkat keras perangkat keras yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan laptop acer predator helios neo 16 dan mobile phone atau smartphone xiaomi redmi note 7 dengan bahasa pemrograman python dengan spesifikasi yang dapat dilihat pada tabel 3.1. tabel 3. 2 mobile phone smartphone 1 camera hd 48mp 169 1280x720 f1.8 wide dual led flash hdr panorama rgb red green blue 3.2.2. analisis kebutuhan perangkat lunak perangkat lunak yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan operating system windows jupyter lab dengan bahasa pemrograman python dan visual studio sebagai text editor yang dapat dilihat pada tabel 3.2. tabel 3. identifikasi berbagai macam jenis penyakit kulit dengan memunculkan citra gambar yang didapat dan deskripsi mengenai penyakit kulit yang teridentifikasi dibawah citra gambar untuk setiap objek penyakit kulit yang terdeteksi data yang digunakan memiliki variasi jenis penyakit kulit dengan kategori 2 penyakit kulit menular candidiasis dan molluscum dan 2 penyakit kulit tidak menular eczhema dan melanoma dengan masing masing kelas memiliki 1000 citra penyakit kulit yang di dapat pada website international dermnet nz dermnetnz.org 2024 dan the international skin imaging collaboration isic isicarchive.com 2024 . program identifikasi berbagai macam objek penyakit kulit pada manusia ditampilkan secara real time menggunakan file upload kamera mobile phone. website ini menyediakan gambar gambar resolusi tinggi dari berbagai penyakit kulit baik yang menular maupun tidak menular serta memberikan deskripsi lengkap tentang penyakti tersebut meliputi gejala dan pengobatan. citra yang diperoleh kemudian diseleksi berdasarkan fokus penelitian yaitu identifikasi penyakit kulit menular candidiasis dan molluscum dan tidak menular eczhema dan melanoma . dari keempat jenis penyakit kulit tersebut dibagi menjadi 2 kelompok sebagai penyakit kulit menular dan tidak menular. penggunaan data gambar sangat penting dalam penelitian ini untuk membandingkan dan mempelajari pola visual yang terkait dengan berbagai penyakit kulit. informasi ini penting untuk diagnosis dan pemahaman lebih lanjut tentang berbagai penyakit kulit seperti dermatitis eksim psoriasis dan infeksi jamur kulit. 3 data teks penyakit kulit 3.4 pre processing data pada tahapan ini data gambar penyakit kulit preprocessing mencakup berbagai teknik seperti pengubahan ukuran gambar normalisasi piksel peningkatan kontras penghapusan noise serta melakukan segmentasi dan fitur ekstraksi. teknik ini bertujuan untuk meningkatkan kualitas gambar dan memastikan konsistensi data sehingga fitur fitur penting dapat diekstraksi dengan lebih efektif oleh algoritma analisis atau mode l kecerdasan buatan. langkah langkah ini membantu dalam menyederhanakan teks mengurangi dime nsionalitas dan meningkatkan efisiensi analisis teks. dengan preprocessing yang tepat data gambar dan teks menjadi lebih bersih dan terstruktur memungkinkan model machine learning untuk menghasilkan prediksi yang lebih akurat dan andal. kedua normalisasi piksel diterapkan untuk mengatur nilai piksel dalam rentang tertentu biasanya antara 0 dan 1 guna meningkatkan stabilitas dan kecepatan konvergensi model. dapat dilihat pada algoritma 3.1. algoritma 3.1 algoritma resize citra input citra penyakit kulit dengan ukuran asli ouput citra penyakit kulit dengan ukuran sama 256x256 proses 1. simpan citra yang telah diubah ukurannya ukuran dan bentuk citra hasil resizing disimpan pada folder output masing masing penyakit kulit yang selanjutnya akan diproses pada tahap berikutnya. resize citra def resize_imageimage size256 256 resized_image cv2.resizeimage size interpolationcv2.inter_area return resized_image sehingga tampilan hasil program terlihat pada gambar 3. hasil resize data gambar 3.4.1.2. normalisasi data pada tahapan ini data yang telah di resize pada tahap sebelumya dinormalisasi. 2 algoritma no rmalisasi citra input citra penyakit kulit hasil resize ouput citra penyakit kulit dengan hasil normalisasi proses 1. simpan dan gunakan hasil normalisasi citra hasil normalisasi disimpan yang selanjutnya akan diproses pada tahap berikutnya. normalisasi citra def normalize_imageimage convert image to float32 type for normalization image image.astypenp.float32 normalize the image normalized_image image 255.0 return normalized_image sehingga tampilan hasil program terlihat pada gambar 3.7 berikut. dengan meningkatkan perbedaan antara nilai intensitas piksel proses ini membantu dalam meningkatkan ketajaman citra dan membuatnya lebih mudah untuk dianalisis. langkah langkah peningkatan kontras dapat dilihat pada algoritma 3.3 . 3 algoritma peningkatan kontras input citra penyakit kulit hasil normalisasi ouput citra penyakit kulit dengan peningkatan kontras proses 1. dengan meningkatkan perbedaan antara nilai intensitas piksel proses ini membantu dalam meningkatkan ketajaman citra dan membuatnya lebih mudah untuk dianalisis. 4 algoritma penghapusan noise input citra penyakit kulit hasil peningkatan kontras ouput citra penyakit kulit dengan penghapusan noise proses 1. seperti terlihat pada gambar proses penghapusan noise menggunakan gabungan median filter dan gaussian filter ditujukan untuk m enghilangkan objek objek yang tidak terpakai dengan menggunakan kernel rendah citra yang dihasilkan tidak terlalu mendapatkan blur yang sangat singnifikan sehingga objek suatu penyakit kulit masih dapat terlihat jelas tanpa adanya noise yang tidak terpakai . dengan menghapus noise maka citra yang dihasilkan menjadi lebih bersih proses ini membantu dalam meningkatkan fokus citra terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 9 hasil penghapusan noise 3.4.1.5. segmentasi data pada tahap ini dilakukan segmentasi dengan thresholding atau penghapusan bagian yang tidak diperlukan seperti background untuk mendapatkan objek penyakit kulit yang digunakan pada penelitian serta menambahkan active contour untuk mendapatkan objek yang ditandai sebagai penyakit kulit . pada tahap thresholding piksel dalam citra yang melebihi nilai ambang akan diberi warna atau nilai putih 255 sementara piksel yang lebih rendah akan diberi warna atau nilai hitam 0 menghasilkan citra biner. 5 algoritma segmentasi input citra penyakit kulit hasil penghapusan noise ouput citra penyakit kulit hasil segmentasi thresholding proses 1. inversi citra hasil thresholding 7. simpan hasil citra hasil segmentasi menggunakan thresholding disimpan yang selanjutnya akan diproses pada tahap berikutnya. segmentasi def segment_with_thresholdimage threshold_value _ segmented_image cv2.thresholdimage threshold_value 255 cv2.thresh_binary return segmented_image def invert_imageimage inverted_image cv2.bitwise_notimage return inverted_image def find_contoursimage contours _ cv2.findcontoursimage cv2.retr_external cv2.chain_approx_simple return contours def draw_contoursimage contours image_with_contours image.copy cv2.drawcontoursimage_with_contours contours 1 0 255 0 2 return image_with_contours def restore_colororiginal_image inverted_segmented_image mask cv2.mergeinverted_segmented_image inverted_segmented_image inverted_segmented_image inverted_mask cv2.bitwise_notmask restored_image cv2.bitwise_ororiginal_image inverted_mask return restored_image sehingga tampilan hasil program terlihat pada gambar 3.10 berikut. dengan menghapus nilainilai pada citra yang tidak terpakai maka citra yang dihasilkan menjadi lebih bersih proses ini membantu dalam menentukan focus objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 10 hasil segmentasi 3.4.1.6. ekstraksi fitur tahapan ini melibatkan pengambilan informasi relevan dari citra yang dapat digunakan untuk mengklasifikasikan dan mendiagnosis kondisi kulit. 6 ekstraksi fitur warna input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi warna proses 1. simpan fitur nilai hasil ektraksi fitur warna menggunakan rgb disimpan yang selanjutnya akan diproses pada tahap berikutnya. ektraksi fitur warna def extract_rgb_featuresimage split the image into rgb channels b g r cv2.splitimage calculate mean and standard deviation for each channel r_mean b.mean g_mean g.mean b_mean r.mean r_std b.std g_std g.std b_std r.std return r_mean g_mean b_mean r_std g_std b_std sehingga tampilan hasil program terlihat pada gambar 3.11 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan rgb dan menunjukan hasil histogram ditujukan untuk memisahkan informasi warna menjadi tiga kanal utama merah red hijau green dan biru blue. dengan mendapatkan nilai nilai pada setiap kanal rgb maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap warna yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 11 hasil ektraksi fitur warna 3.4.1.6.2. ektraksi fitur bentuk tahapan ini dimulai dengan pra pemrosesan citra untuk meningkatkan kualitas dan mempersiapkannya untuk ekstraksi fitur. 7 ekstraksi fitur bentuk input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi bentuk proses 1. simpan hasil nilai hasil ektraksi fitur bentuk menggunakan contour dan geometris disimpan yang selanjutnya akan diproses pada tahap berikutnya. ektraksi fitur bentuk def extract_shape_featuresimage gray cv2.cvtcolorimage cv2.color_bgr2gray _ thresh cv2.thresholdgray 0 255 cv2.thresh_binary cv2.thresh_otsu contours _ cv2.findcontoursthresh cv2.retr_external cv2.chain_approx_simple areas perimeters circularities eccentricities for contour in contours area cv2.contourareacontour perimeter cv2.arclengthcontour true circularity 4 np.pi area perimeter 2 if perimeter 0 else 0 if lencontour 5 ellipse cv2.fitellipsecontour center axes orientation ellipse major_axis maxaxes minor_axis minaxes eccentricity np.sqrt1 minor_axis 2 major_axis 2 if major_axis 0 else 0 else eccentricity 0 areas.appendarea perimeters.appendperimeter circularities.appendcircularity eccentricities.appendeccentricity avg_area np.meanareas avg_perimeter np.meanperimeters avg_circularity np.mean circularities avg_eccentricity np.meaneccentricities return avg_area avg_perimeter avg_circularity avg_eccentricity sehingga tampilan hasil program terlihat pada gambar 3.12 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan bentuk contour dan geometris menunjukan hasil nilai untuk setiap citra ditujukan untuk memisahkan informasi bentuk menjadi area perimeter circularity dan exccentricity . dengan mendapatkan nilainilai bentuk maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap bentuk yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 12 hasil ektraksi fitur bentuk 3.4.1.6.3. ektraksi fitur tekstur pada tahapan ekstraksi fitur tekstur melibatkan beberapa langkah kunci untuk menggambarkan dan menganalisis tekstur citra secara sistematis . langkah langkah ekstraksi fitur tekstur dengan menggunakan metode glcm sebagai acuan tekstur dapat dilihat pada algoritma 3. algoritma 3. 8 ekstraksi fitur tektur input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi tekstur proses 1. simpan hasil nilai hasil ektraksi fitur tekstur menggunakan glcm disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. ektraksi fitur tektur def calculate_glcm_featuresimage_path load gambar dan konversi ke grayscale image io.imreadimage_path gray_image color.rgb2grayimage gray_image img_as_ubytegray_image konversi ke tipe data uint8 hitung glcm dengan jarak dan arah yang ditentukan distances 1 2 3 jarak d angles 0 np.pi4 np.pi2 3np.pi4 arah θ glcm graycomatrixgray_image distancesdistances anglesangles symmetrictrue normedtrue ekstraksi fitur tekstur dari glcm contrast graycopropsglcm contrast dissimilarity graycopropsglcm dissimilarity homogeneity graycopropsglcm homogeneity energy graycopropsglcm energy correlation graycopropsglcm correlation mengembalikan hasil fitur sebagai tuple return contrast.mean dissimilarity.mean homogeneity.mean energy.mean correlation.mean sehingga tampilan hasil program terlihat pada gambar 3.13 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan glcm menunjukan hasil nilai untuk setiap citra ditujukan untuk memisahkan informasi tekstur menjadi contrast dissimilarity homogeneity energy dan correlation. dengan mendapatkan nilai nilai tekstur maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap tekstur yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 13 hasil ekstraksi fitur tekstur dengan glcm 3.4.2. preprocessing data teks tahap pre processing data teks dilakukan serangkaian langkah penting dalam pengolahan informasi teks yang bertujuan untuk membersihkan merapihkan dan mempersiapkan data sebelum dilakukan analisis lebih lanjut. proses ini krusial karena data teks sering kali tidak terstruktur dan dapat mengandu ng berbagai jenis noise atau informasi yang tidak relevan yang dapat mempengaruhi hasil analisis.
Alifurrohman_Kualifikasi.txt,3.2 pengumpulan data langkah awal adalah mengumpulkan dataset yang akurat dan relevan. dataset didapatkan dari data sekunder dataset ini merupakan hal yang penting dari simulasi dan eksperimen mencakup koordinat lokasi yang mungkin meliputi lokasi depot dan titik pengiriman jendela waktu untuk setiap pengiriman yang menentukan batas awal dan akhir kapan pengiriman harus dilakukan serta jumlah kendaraan. data ini harus mencerminkan situasi dunia nyata untuk memastikan bahwa model yang dikembangkan dapat diaplikasikan secara praktis. n ormalisasi merupakan proses penting untuk menyamakan skala data memastikan bahwa model dapat memprosesnya dengan efisien. 3.4 desain model implementasi deep q network dqn dengan mekanisme attention untuk dynamic vehicle routing problem with time windows dvrptw melibatkan beberapa langkah utama mulai dari pemilihan kerangka kerja hingga pembuatan lingkungan simulasi. memory replay untuk meningkatkan stabilitas dan efisiensi pembelajaran dqn menggunakan teknik memory replay di mana transisi state aksi reward state baru disimpan dalam sebuah buffer . multi head er attention melakukan proses ini beberapa kali secara paralel dengan beberapa heads dan hasilnya digabungkan untuk data i nput. output layer untuk q value s lapisan output menghasilkan q value s untuk setiap tindakan yang mungkin dilakukan oleh agen. misalnya jika agen memiliki 5 kemungkinan tindakan lapisan output akan menghasilkan 5 q value s satu untuk setiap tindakan. batch transisi 30 diambil secara acak dari replay buffer untuk mengurangi korelasi antara sampel pelatihan dan meningkatkan stabilitas pelatihan. informasi ini digunakan untuk memperbarui kebijakan model dengan cara mengoptimalkan parameter jaringan sehingga meningkatkan estimasi nilai q yang merepresentasikan hadiah kumulatif yang diharapkan. untuk meningkatkan stabilitas dan efisiensi pelatihan teknik seperti experience replay dan target networks digunakan. selain itu pada tahap pelatihan model ini juga dilakukan penyetelan hyperparameter untuk menemukan nilai optimal hyperparameter guna meningkatkan kinerja model. ini merupakan langkah penting dalam machine learning karena dapat menghasilkan peningkatan akurasi efisiensi dan generalizability model. 3.6 evaluasi model setelah fase pelatihan model deep q network dqn dengan multi header attention untuk dynamic vehicle routing problem with time windows dvrptw selesai langkah evaluasi menjadi penting untuk memahami seberapa efektif model dalam menyelesaikan masalah yang ditargetkan. total jarak tempuh mencerminkan efisiensi rute yang dihasilkan sementara kepatuhan terhadap jendela waktu mencerminkan kualitas layanan yang dapat dijamin oleh model. 3.7 analisis dan penyempurnaan langkah terakhir yaitu analisis secara mendalam kinerja model pada dataset pengujian. penyempurnaan dilakukan untuk mengatasi kelemahan yang telah dianalisis sebelumnya seperti penyempurnaan pada tuning hyperparameter untuk peningkatan kinerja modifikasi arsitektur dan pelatihan ulang model. 3.8 jadwal penelitian jadwal penelitian digunakan untuk meningkatkan efektivitas dalam proses penelitian. adanya jadwal penelitian ini setiap proses penelitian sudah terjadwal dalam tabel 3.1 sehingga penelitian lebih efektif dan optimal.
Armando Tirta Dwilaga_Kualifikasi.txt,3.1 gambaran umum penelitian penelitian ini digunakan untuk mengatasi sensitivitas terhadap cacat pada gambar ban dengan melibatkan penggunaan jaringan syaraf menggunakan algoritma convolutional neural network cnn dan membangun model atau kerangka kerja menggunakan keras. berikut adalah gambar 3.1 blok diagram gambaran umum penelitian. data preparation data augmentasi data splitting model training forward pass model evaluation backward passfinetuning if neededinput unit processing unit output unit model deployment inference12 gambar 3.1 blok diagram gambaran umum penelitian berdasarkan gambar 3.1 blok diagram gambaran umum penelitian maka dapat dijelaskan di blok tersebut terbagi menjadi 3 bagian yaitu bagian pertama adalah unit masukan berisikan data preparation di mana gambar ban dimuat diubah menjadi format yang sesuai dipersiapkan untuk pelatihan model convolutional neural network cnn seperti pemrosesan gambar ban selanjutnya data augmentation di mana data dibuat lebih ber variasi dari training data yang ada sehingga dapat meningkatkan keberagaman training data tanpa h arus mengambil data baru mencakup rotasi pergeseran horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel selanjutnya data di mana dataset yang telah di augmentasi dan disiapkan dibagi menjadi subset yang berbeda untuk training untuk melatih model validation untuk menyempurnakan model serta me mvalidasi performanya selama pelatihan dan testing untuk mengevaluasi kinerja model akhir . data set dibagi menjadi training data validation data dan testing data dalam proporsi tertentu. bagian kedua adalah unit pemrosesan yang bertindak adalah model training forward pass tahap di mana input diproses melalui model untuk menghasilkan prediksi tujuannya melatih model convolutional neural network cnn menggunakan dataset pelatihan di mana data dari unit masukan diteruskan melalui jaringan neural di lakukan transformasi linier konvulasi dan non linier fungsi aktivasi dilakukan pada data di setiap lapisan untuk menghasilkan output prediksi yang melibatkan komputasi di setiap neuron dan lapisan jaringan yang merupakan inti dari proses pembelajaran dalam jaringan saraf. selanjutnya unit pemrosesan finetuning tujuannya dilakukan untuk menyempurnakan model lebih lanjut setelah pelatihan awal dengan dataset yang lebih kecil atau lebih spesifik nantinya. proses di dalam finetuning menyesuaikan bobot menggunakan kumpulan data yang lebih kecil untuk menyesuaikan bobot model untuk performa yang lebih baik pelatihan khusus fokus pada fitur data yang lebih relevan dengan objek . bagian ketiga adalah unit keluaran yang bertindak ada proses model evaluatioan backward pass tahap di mana gradien memperbarui parameter model dalam arah yang akan mengurangi fungsi loss dari fungsi loss metrik yang mengukur seberapa baik atau buruk model melakukan prediksi dibandingkan nilai aktualnya dihitung dan digunakan untuk memperbarui parameter model selama pelatihan tujuannya mengevaluasi performa model yang dilatih dan model dievaluasi menggunakan metrik yang relevan accuracy precision recall dan f1 score berdasarkan prediksi yang dihasilkan dari model terhadap validasi atau uji data. output dari proses ini adalah tentang hasil evaluasi model yang memberikan informasi kinerja model. selanjutnya ada dua alur pilihan yang bisa dilakukan alur pertama jika hasil prediksi sudah sesuai dengan keinginan maka bisa langsung masuk ke model deployment inference dan alu r kedua jika hasil prediksi masih perlu diperbaiki pada bagian unit pemrosesan terlebih dahulu fine tuning untuk penggunaan data set lebih kecil jika menunjukan model belum mencapai performa yang diharapkan baru masuk ke model deployment inference tujuannya menerapkan model terlatih untuk membuat prediksi pada data baru yang belum terlihat. model deployment inference yang telah dilatih digunakan untuk membuat prediksi pada data baru atau dalam situasi dunia nyata tahap di mana model menerima input baru dan menghasilkan output berdasarkan pada pembelajaran yang dilakukan selama proses pelatihan dan merupakan output akhir dari keseluruhan proses di mana model mengambil keputusan atau membuat prediksi berdasarkan pada pengalaman yang telah diperoleh selama pelatihan. 3.2. tahapan penelitian penelitian ini di dalamnya terdapat tahapan tahapan yang dilakukan untuk membentuk satu kesatuan yang utuh dari awal sampai akhir dan membentuk kerangka penelitian mengenai klasifikasi pada produk ban menggunakan algoritma convolutional neural network cnn . 3.2.1 studi literatur tahap pertama adalah studi literatur di mana studi yang dilakukan berasal dari artikel ilmiah dan buku yang menunjang dalam menganalisis terkait dengan metode pen gukuran kualitas mengenai klasifikasi produk ban meninjau penggunaan pembelajaran mesin algoritma convolutional neural network cnn dari beberapa tahun ke belakang dalam konteks peng ukuran kualitas untuk klasifikasi terhadap kondisi kondisi produk ban . 3 tahapan study literature 3.2.2 data aquisition tahap k edua adalah data aquisition dengan mengumpulkan kumpulan data sesuai tujuan penelitian dengan target untuk kumpulan data gambar ban untuk training data validation data dan testing data memastikan bahwa kumpulan data tersebut memiliki varian yang secara akurat memang mewakili kondisi produk ban dan diperoleh dari sumber sumber terpercaya . 5 tahapan data preprocessing 3.2.4 data augmentation tahap keempat adalah data augmentation meningkatkan variasi dalam dataset dengan teknik augmentasi data menggunakan operasi seperti rotasi pergeserarn horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel untuk memperkaya dataset dan mengurangi overfitting saat disajikan dengan data baru yang belum pernah dilihat sebelumnya performa model akan menurun drastis karena model tersebut dapat menyesuaikan diri dengan kumpulan training data dengan sangat efektif. sebaliknya pada saat runtime hanya menghasilkan variasi dari gambar yang sudah ada dibuat secara dinami s dan cukup bagi model untuk berlatih dari berbagai kondisi gambar ban yang ada pada kenyataaanya. data asli pada dataset berjumlah 1 .028 data gambar ban setelah dilakukan augmentasi secara fisik menggunakan website roboflow ada data yang tidak dapat diidentifikasi ada 3 gambar sehingga total gambar asli yang berhasil di upload dan dijadikan data asli yang tetap berjumlah 1.025 data ga mbar dan setelah di augmentasi bertambah menjadi 2 .050 data gambar ban. 7 tahapan splitting data 3.2.6 model building tahap ke enam adalah model building membangun model convolutional neural network cnn dengan keras membangun arsitektur model convolutional neural network cnn menggunakan keras mengatur lapisan lapisan seperti convolutional maxpooling2d flatten dan dense untuk membangun model. learning rate dalam penggunaan algoritma optimasi menggunakan adaptive momentum adam untuk menghasilkan pembelajaran yang adaptif pemilihan penggunaan adaptive momentum adam jika dibandingkan dengan learning rate lain seperti stochastic gradient descent sgd karena kecepatan pembelajaran adaptif untuk adaptive momentum adam bisa secara otomatis menyesuaikan learning rate untuk setiap parameter dalam model klasifikasi ban sedangkan stochastic gradient descent sgd memiliki learning rate tetap selama pelatihan model klasifikasi ban yang penentuannya dari user dan tidak bisa menyesuaikan learning rate secara otomatis berdasarkan kondisi a ktual dari setiap parameter. selanjutnya secara kestabilan dan konvergensi adaptive momentum adam menyambung dari awal dapat mengubah kecepatan pembelajaran secara adaptif sehingga membuatnya lebih stabil dan kecil kemungkinannya terjebak pada tingkat minimum lokal nilai yang dianggap sebagai titik terendah dari loss function dalam model sehingga adaptive momentum adam cenderung mencapai konvergensi tingkat kinerja yang diharapkan lebih cepat dan andal dalam berbagai keadaan sedangkan stochastic gradient descent sgd mungkin lebih stuck pada nilai minimum atau terjebak pada nilai minimum lokal ya ng disebabkan oleh kemungkinan bergantung pada seberapa tepat kecepatan pemelajaran dipilih kecepatan pemelajaran yang tetap dapat membuat model mencapai konvergensi terlalu cepat atau terlalu lambat. augment asi data diterapkan setelah data melewati beberapa epoch selama proses pelatihan sehingga variasi data yang dihasilkan akan berbeda beda pada setiap epoch dan model dapat terus menerus terlatih dengan variasi data yang lebih besar . model building define cnn model compile model gambar 3 .8 tahapan building model berdasarkan hasil analisis sebelumnya maka dapat diketahui untuk j umlah data asli training data adalah 1.121 jumlah data asli validation data adalah 279 jumlah data asli training data setelah augmentasi adalah 1152 jumlah data asli validation data setelah augmentasi adalah 320 jumlah epoch yang digunakan sebanyak 100 dan ukuran batch adalah 64. 9 tahapan model evaluation testing 3.3 arsitektur convolutional neural network cnn convolutional neural network cnn yang dibangun menggunakan model atau kerangka kerja yang pada dasarnya menggunakan keras dan juga tensorflow dengan menambahkan beberapa model lapisan lapisan seperti lapisan convolutional conv2d laposan pooling maxpooling 2d flatten dan lapisan fully connected dense . filter convolutional layer pertama yang berfungsi untuk mengekstrak fitur fitur visual diterapkan pada gambar untuk menghasilkan fitur fitur yang lebih abstrak formula untuk mengetahui jumlah training datanya dengan . selanjutnya max pooling 2d di mana tahap pooling digunakan untuk mengurangi dimensi spasial dari setiap feature map yang dihasilkan oleh layer sebelumnya. max pooling memilih nilai maksimum di dalam jendela pooling untuk m engurangi ukuran fitur dan mempertahankan informasi penting. selanjutnya dense layers lapisan dense digunakan sebagai lapisan output dalam model klasifikasi di mana jumlah neuron dalam lapisan output sesuai dengan jumlah kelas yang harus diprediksi di mana ada tiga lapisan dense ditambahkan dengan fungsi pertama dan kedua menggunakan relu sebagai 0 f x max x yang artinya menunjukkan bahwa keluarannya nol jika masukannya negatif atau nol dan output x jika masukannya positif dengan 128 unit neuron dan pada dense kedua 64 unit neuron karena tugasnya mengurangi dimensi representasi pada lapisan dense pertama maka model dapat mempelajari pola yang lebih rumit dan mendalam dari data dengan menambahkan lapisan yang lebih padat yang dapat meningkatkan performa model dalam tugas klasifikasi gambar. terakhir evaluation di mana performa model pada testing data dinilai menggunakan hasil klasifikasi dan confusion matrix untuk memahami kinerjanya testing data. bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. fourth cov2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x321x16 289x16 4624 jumlah channel input menggunakan jumlah filter dari convolutional layer sebelumnya bukan lagi channel input di awal. selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 5x5 menjadi 2x2 sebagai berikut. setiap filter diubah menjadi setengah dari ukuran inputnya 2x2 menjadi 1x1 dan jumlah neuronnya 4624 mengikuti lapisan konvolusi keempat . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 12 21 1 21 0.51 9. flatten tidak mengubah parameter yang ada karena fungsi flatten hanya mengubah matriks multidimensi menjadi vektor tunggal berdasarkan hasil dari jumlah filter pada lapisan lima cov2d yaitu 8 dan maxpooling2d dengan ukuran inputnya 1x1 sehingga menjadi matriks multidimensi 1 1 16 diubah menjadi nilai vektor tunggal dengan panjang 16 atau menjadi jumlah neuron sebanyak 16. 10. dense layer 1 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 161x128 17x128 2176 11. dropout layer 1 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 1 akan dinonaktifkan secara acak. 12. dense layer 2 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 1281x64 129x64 8256 13. dropout layer 2 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 2 akan dinonaktifkan secara acak. 14. dense layer 2 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 641x1 65x1 65 ketika dimensi spasial tinggi dan lebar dikurangi menggunakan operasi lapisan pooling seperti maxpooling jumlah neuron di setiap lapisan pooling akan menurun. misalnya dimensi spasial setiap filter tinggi dan lebar di lapisan maxpooling disesuaikan menjadi setengah dari dimensi masukannya. karena hanya separuh dari masukan yang diproses lebih lanjut hal ini juga menyebabkan berkurangnya jumlah neuron pada lapisan tersebut. sedangkan penurunan pada dense terjadi karena penentuan jumlah neuron.
Robert_Kualifikasi.txt,3.1 alur penelitian gambar 3.1 menunjuk kan metode penelitian. terdapat 5 tahap utama yang akan dilakukan yang pertama adalah studi literatur untuk menyusun bab 1 dan bab 2. tahap kedua adalah pengumpulan citra ekspresi wajah data citra berupa data primer dan data sekunder. tahap ketiga adalah pembentukan dataset untuk tiap model svm cnn dan mnn skenario pembentukan dataset dilakukan berdasarkan pada penelitian robert 2023 . pada tahap keempat dilakukan pembentukan model khusus untuk svm dan cnn menggunakan model pada penelitian robert 2023 sedangkan mnn menggunakan usulan pada penelitian ini. tahap terakhir adalah pelatihan dan pengujian untuk semua model svm cnn mnn terdapat tahap parameter tuning untuk tiap model . kemudian semua performa dari tiap model akan dibandingkan satu sama lain dan juga dianalis is pada bab 4. gambar 3.1. metode penelitian 48 3.2 pengumpulan citra ekspresi wajah citra ekspresi wajah dikumpulkan secara langsung oleh peneliti data primer dan juga menggunakan data yang dikumpulkan oleh peneliti lain data sekunder. terdapat 7 ekspresi wajah yang akan digunakan dalam penelitian ini yaitu marah jijik menghina senang sedih kaget dan netral tanpa ekspresi. gambar 3.2 menunjukkan contoh 7 ekspresi wajah manusia yang digunakan penelitian ini. gambar 3.2. contoh 7 jenis ekspresi wajah dataset primer akan dilakukan pengambilan citra ekspresi wajah mahasiswa universitas gunadarma baik pria maupun wanita. gambar 3.3. contoh dataset primer 49 dataset sekunder digunakan dataset yang telah digunakan umum oleh peneliti lain terkait pengenalan ekspresi wajah. terdapat beberapa dataset yang umum digunakan dalam penelitian ekspresi wajah . pertama extended cohn kanade ck yang berisi citra ekspresi wajah pria dan wanita dari berbagai etnis dengan resolusi tinggi kanade cohn tian 2000 lucey et al. kedua taiwanese facial expression image dataset tfeid yang berisi citra ekspresi wajah pria dan wanita dari etnis taiwan chen yen 2007 . ketiga japanese female facial expression jaffe yang terdiri dari citra ekspresi wajah wanita etnis j epang lyons 2021 lyons kamachi gyoba 2020 . tabel 3.1. detail dataset sekunder ekspresi dataset ck dataset jaffe dataset tfeid total anger 45 30 34 109 disgust 59 29 40 128 fear 25 32 40 97 happy 69 31 40 140 neutral 107 30 39 176 sad 28 31 39 98 surprise 83 30 36 149 ukuran citra 640490 256256 481600 warna citra rgb gray gray rgb 51 3.3 pembentukan dataset secara garis besar dalam pembuatan model ai khususnya ml dan dl terdapat proses yang berperan penting yaitu preprocessing dataset seperti ekstrasi fitur penyesuaian ukuran citra dan augmentasi deshmukh et al. pada penelitian robert 2023 dilakukan sebuah skenario pembentukan dataset menggunakan beberapa metode pengolahan citra seperti konversi warna ke grayscale deteksi wajah dan e kstrasi fitur di mana preprocessing mempengaruhi performa dari model ml dan dl. selain itu pada penelitian alam yao 2019 juga dilakukan penelitian yang serupa di mana preprocessing mempengaruhi performa model machine learning . pertama dilakukan pendeteksian wajah menggunakan vja proses ini berguna untuk mengurangi noise pada citra . hasil vja membuat ukuran citra bervariasi oleh karena itu dilakukan resizing citra untuk menyamakan semua ukuran citra dan juga menyesuaikan dengan dimensi input model . pertama dilakukan deteksi wajah menggunakan vja guna mengurangi noise . kemudian dilakukan konversi warna dari rgb ke grayscale karena fitur warna tidak dibutuhkan untuk mengenali ekspresi wajah. gambar 3.10 menunjukkan hasil dari implementasi algoritma deteksi wajah pada sebuah citra. a citra original b hasil deteksi c hasil cropping 58 3.3.2 image resize proses perubahan ukuran citra menggunakan metode bicubic interpolation . parameter berupa koefisien a yang dapat mempengaruhi koordinat tetangga umumnya nilai dikisaran 0.75 hingga 0.5. hasil dari algoritma ini adalah citra dengan ukuran 𝐻𝑟𝑊𝑟𝐶. baris 2 dilakukan pembuatan matri ks yang digunakan untuk menyimpan hasil. baris 456 dilakukan perulangan pada channel 𝑑𝐻 𝑑𝑊 matri ks yang dibuat pada baris 2 perulangan ini digunakan untuk menentukan koordinat matri ks hasil yang akan dihitung. baris 19 dilakukan pembuatan matri ks berukuran 4 4 yang digunakan untuk menyimpan nilai piksel tetangga. hasil yang didapatkan kemudian disimpan pada variab el output . 59 algoritma 3.3. image resize menggunakan bicubic interpolation input citra ukuran 𝐻𝑊𝐶 img ratio antara 0 hingga r parameter koefisien a 0.5 a output citra ukuran 𝐻𝑟𝑊𝑟𝐶 output 1 calculate dh hr dw wr h 1ratio used for calculation 2 create matrix output dimension dhdwc to store result 3 for i 0 to c do 4 for j 0 to dh do 5 for k 0 to dw do 6 calculate x i h 2 7 calculate y j h 2 8 calculate x1 1 x floorx 9 calculate x2 x flootx 10 calculate x3 floorx 1 x 11 calculate x4 flootx 2 x 12 calculate y1 1 y floory 13 calculate y2 y flooty 14 calculate y3 floory 1 y 15 calculate y4 flooty 2 y 16 create matrix mat_l dimension 14 mat_r dimension 41 h menggunakan pers 2.19 17 calculate mat_l00 hx1 mat_l01 hx2 mat_l02 hx3 mat_l03 hx4 bobot horizontal 18 calculate mat_r00 hy1 mat_l01 hy2 mat_l02 hy3 mat_l03 hy4 bobot vertical 19 create matrix mat_m dimension 44 20 mat_l00 img yy1 xx1 21 mat_l10 img yy2xx1 22 mat_l20 img yy3xx1 23 mat_l30 img yy4xx1 24 mat_l01 img yy1 xx2 25 mat_l11 img yy2xx2 26 mat_l21 img yy3xx2 27 mat_l31 img yy4xx2 28 mat_l02 img yy1 xx3 29 mat_l12 img yy2xx3 30 mat_l22 img yy3xx3 31 mat_l32 img yy4xx3 32 mat_l03 img yy1 xx4 33 mat_l13 img yy2xx4 34 mat_l23 img yy3xx4 35 mat_l33 img yy4xx4 60 36 calculate output mat_m mat_l mat_r gambar 3.11 menunjukkan hasil perubahan ukuran citra wajah menggunakan algoritma 3.3. berdasarkan gambar 3.11 ukuran dari input citra adalah 600 480 dan ratio 05. gambar 3.12 menunjukkan contoh hasil implementasi algoritma konversi warna dari rgb ke grayscale dengan menggunakan nilai y dari yc bcr. pertama dilakukan pembuatan filter terlebih dahulu. algoritma 3.5 menunjukkan cara pembuatan gabor filter. kemudian jumlah filter luas kernel lambda 𝜆 psi 𝜑 sigma 𝜎 dan gamma 𝛾 yang akan digunakan untuk pembuatan gabor filter . baris 2 dilakukan pembuatan gabor filter berdasarkan persamaan 2.23 dan parameter yang di input . algoritma 3.5. gabor filter input citra grayscale ukuran 𝐻𝑊 img jumlah filter dari 1 hingga num_filter kernel size n n ksize lambda 𝜆 lambd psi 𝜑 psi sigma 𝜎 sigma gamma 𝛾 gamma threshold bawah min_int threshold atas max_int output citra ukuran 𝐻𝑊 output 1 for i 0 to 180 with increment 180num_filter do 2 create gabor filter filter with kernel size ksize lambda lambd theta i psi psi sigma sigma gamma gamma 3 proses konvolusi 4 for i 0 to num_filter do 5 output img filteri 6 proses deteksi tepi 7 apply canny edge detection on output with lower threshold min_int upper threshold max_int 63 perubahan nilai parameter dilakukan pada 𝜆 𝛾 dan 𝜎 pada gambar 3.14 menunjukkan hasil dari pengaplikasian gabor filter di mana a menunjukkan hasil awal sebelum dilakukan parameter tuning dan b hasil akhir setelah parameter tuning . hasil algoritma gabor filter 64 3.3.5 ekstrasi fitur lmp proses ekstrasi fitur menggunakan metode lmp. hasil dari algoritma 3.6 adalah citra lmp dengan ukuran 𝑤4ℎ 4 ukuran citra berkurang untuk menghindari perhitungan di luar dari ukuran citra. gambar 3.15 menunjukkan contoh hasil implementasi algoritma lmp pada citra wajah. berdasarkan dari penelitian robert 2023 didapatkan model terbaik untuk mengenal ekspresi wajah adalah menggunakan kernel sigmoid. operasi p ertama adalah operasi morgologi opening pada citra original kemudian dilakukan pengurangan nilai piksel antara citra original dengan hasil opening operasi opening itu sendiri adalah operasi erosi yang dilanjutkan operasi dilasi. ketiga adalah dilasi pada citra original kemudian dilakukan pengurangan hasil dilasi terhadap citra original . hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran 𝑊 𝐻. baris 12 dilakukan pengambilan nilai terkecil yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan . baris 25 dilakukan pengambilan nilai terbesar yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan 2.14. hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran 𝑊 𝐻. baris 11 dilakukan pengambilan nilai terkecil yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan 2.10. hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran 𝑊 𝐻. baris 11 dilakukan pengambilan nilai terbesar yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan 2.8. kemudian pada baris 14 dan 15 dilakukan perulangan kembali pada baris dan kolom citra untuk menentukan koordinat perhitungan. 74 3.4.3.1.3 percobaan dan perbandingan hasil operasi morfologi tabel 3.2 menunjukkan hasil operasi morfologi menggunakan se berdasarkan 3.4.3.1 dan 3.4.3.2. pada operasi morfologi tabel 3.2. digunakan citra yang memiliki objek persegi panjang berwarna putih . tabel 3.3. operasi morfologi dan structure element pada persegi panjang original image se operasi operasi dan hasil disk original opening 33 55 77 99 1515 75 disk original erosi 33 55 7x7 99 1515 disk dilasi original 33 55 77 99 1515 kotak original opening 33 55 77 99 1515 76 kotak original erosi 33 55 77 99 1515 kotak dilasi original 33 55 77 99 1515 berdasarkan dari tabel 3.3 dapat dilihat operasi gmo dengan se disk 33 menghasilkan corner pada persegi panjang. operasi gmd dengan se disk 33 memiliki hasil garis berbentuk persegi panjang dengan nilai tiap corner terdapat hilang . operasi gmd dengan se kotak 33 menghasilkan garis yang berbentuk persegi panja ng. gme dengan se kotak 33 memiliki hasil yang mirip dengan gmd namun memiliki luas yang berbeda. dari hasil yang didapatkan tiap ukuran memiliki hasil yang mirip dengan operasi yang digunakan. operasi gmd dan gme memiliki hasil yang mirip dengan perbedaan tepi pada gmd menebal kearah luar persegi sedangkan tepi pada gme menebal kearah dalam. 78 tabel 3.4 merupakan hasil morfologi menggunakan citra wajah dengan warna grayscale . operasi morfologi dan se yang digunakan berdasarkan usulan pada subbab 3.4.3.1 dan 3.4.3.2. tabel 3.4. structure element dan operasi morfologi pada wajah citra original se operasi operasi dan hasil disk gmo 33 55 77 99 1515 79 disk gme 33 55 77 99 1515 disk gmd 33 55 77 99 1515 80 kotak gmo 33 55 77 99 1515 kotak gme 33 55 77 99 1515 berdasarkan tabel 3.4 dapat dilihat hasil ekstrasi fitur menggunakan berbagai kom binasi dua bentuk dan lima ukuran . se kotak 5 5 juga memiliki hasil yang sama dengan disk 55 dengan perbedaan yang tid ak dapat dilihat kasat mata. se kotak 7 7 juga memiliki hasil yang sama dengan disk 77 dengan perbedaan yang tidak dapat dilihat kasat mata. se disk 99 dengan operasi gmo fitur yang didapatkan tidak akurat karena tidak mengekstrasi tepi bentuk dari ekspresi wajah. se kotak 9 9 dengan operasi 9 9 gme fitur yang didapatkan terlihat dengan jelas dan mirip dengan hasil yang menggunakan se disk 99 dengan operasi gme. se kotak 9 9 dengan operasi gmd hasil yang didapatkan hampir sama dengan hasil yang menggunakan se disk 99 dengan operasi gmd hanya terdapat perbedaan pada tebal garis pada hidung. 82 operasi menggunakan se 15 15 hasil yang didapatkan memiliki pola yang sama dengan operasi yang menggunakan se 9 9. berdasarkan dari hasil yang didapatkan dan analisis. se disk 55 atau kotak 55 dengan operasi gmd memiliki hasil terbaik. selain itu operasi menggunakan gme dengan se disk 55 atau kotak 5 5 juga memberikan hasil yang baik. tepi dari tiap komponen wajah terlihat namun tepi pada mata dan bola mata tergabung namun memberikan hasil ekstrasi fitur bagian hidung lebih baik dibandingkan gmd. 83 3.4.3.2 pembentukan dan pelatihan model gambar 3.18 menunjukkan arsitektur dari mnn secara garis besar. di mana terdapat beberapa variasi arsitektur variasi pertama terdapat pada morphology layer di mana akan digunakan dua jenis ekstrasi fitur berdasarkan pada hasil subbab 3.4.3.3. variasi kedua terdaoat pada hidden layer di mana akan digunakan beberapa kombinasi fullyconnected layer . model mnn yang diusulkan input layer adalah layer pertama dari model mnn yang bertugas untuk menerima input berupa citra. di mana lapisan morfologi jenis pertama menggunakan hasil terbaik dari operasi morfologi dilasi pada subbab 3.4.3.3. morphology layer jenis kedua adalah erosion layer dilanjutkan subtraction layer . di mana lapisan morfologi jenis kedua ini menggunakan hasil terbaik dari operasi m orfologi erosi pada subab 3.4.3.3. 84 lapisan ketiga adalah flatten layer lapisan yang bertugas mengubah citra menajadi feature vector. masukan dari lapisan ini adalah hasil dari subtraction layer pada lapisan morfologi. di mana hasil dari subtraction layer adalah citra dengan ukuran 160160 yang kemudian diubah mnejadi satu dimensi yaitu 25600. jika konfigurasi pertama memiliki hasil lebih baik artinya memungkinkan fc layer untuk dibuat lebih sederhana dengan mengurangi jumlah neuron . jika konfigurasi kedua lebih baik artinya terdapat kemungkinan untuk meninkatkan performa dari model karena dataset memiliki kompleksitas tinggi . tuning pertama terdapat pada bentuk se ukuran se jenis operasi pada morphological layer . terakhir adalah output layer merupakan penentuan dari ekspresi berdasarkan dari bobot hidden layer . di mana fungsi aktivasi yang digunakan untuk output layer adalah softmax yang artinya output berupa probabilitas dari tiap ekspresi. kemudian untuk loss function yang akan digunakan adalah categorical crossentropy di mana fungsi loss ini digunakan jika model memprediksi multi kelas multi class prediction . 85 3.5 time table semester 1 aktivitas 1 2 3 4 5 6 studi literatur pembuatan proposal pengumpulan dataset sekunder saja semester 2 pengumpulan dataset primer sekunder pembentukan dataset pembentukan model pelatihan pengujian model beserta tuning model menuliskan hasil penelitian bab 4 semester 3 pelatihan pengujian model beserta tuning model menuliskan hasil penelitian bab 4 bab 5 pembuatan jurnal pertama semester 4 pembuatan jurnal pertama submit jurnal pembuatan jurnal kedua semester 5 pembuatan jurnal kedua submit jurnal
Tatya Atyanti Paramastri_Kualifikasi.txt,3.1. alur penelitian 1. identifikasi masalah gambar 3.1 alur penelitian identifikasi masalah dilakukan supaya permasalahan yang diangkat jelas. identifikasi masalah dilakukan dengan cara melihat permasalahan nyata melalui literatur seperti jurnal penelitian wawancara dengan ahli dan keresahan yang dirasakan oleh peneliti secara pribadi. permasalahan yang diangkat pada penelitian ini adalah motif batik indonesia sangat beragam dan memiliki maknanya masingmasing. namun tidak banyak masyarakat yang masih mengetahui nama makna dan pemakaian dari masingmasing motif batik. menurut dewan ahli ppbi paguyuban pecinta batik indonesia sekar jagad ibu mari s. condronegoro saat ini sering kali ditemukan kesalahan dalam pemakaian motif batik seperti mengenakan kain yang seharusnya digunakan pada upacara kematian ketika menghadiri acara pernikahan. solusi yang diusulkan adalah melakukan klasifikasi motif batik. fokus studi literatur terbagi menjadi tiga topik yaitu klasifikasi motif batik komputasi kuantum dan deteksi tepi. sehingga hasil yang didapatkan memuaskan dan akurat. dataset yang akan dikumpulkan merupakan citra motif batik daur hidup yogyakarta dari kain batik tradisional yang merupakan batik cap maupun batik tulis bukan printing. motif yang akan digunakan dalam penelitian akan didiskusikan terlebih dahulu dengan narasumber supaya dapat mewakili batik daur hidup yogyakarta yang sangat penting untuk diketahui dalam bersosialdi masyarakat. hal ini dilakukan karena batik daur hidup yogyakarta tercatat memiliki ratusan motif hingga tahun 2006 sekar jagad 2015. selain itu ukuran citra yang lebih kecil dapat mempercepat proses segmentasi dan klasifikasi tanpa kehilangan informasi penting. proses selanjutnya adalah mengubah ruang warna menjadi grayscale perubahan warna ini dilakukan karena dapat meningkatkan kontras meningkatkan efisiensi komputasi dan meningkatkan ketahanan terhadap variasi pencahayaan. selanjutnya proses augmentasi digunakan untuk meningkatkan ukuran dataset dengan menambahkan data baru tanpa perlu melakukan pengumpulan data baru. komputasi kuantum diterapkan mulai dari proses segmentasi karena berdasarkan penelitian terdahulu deteksi tepi berbasis kuantum dapat mendeteksi lebih banyak tepi dibandingkan deteksi tepi klasik berdasarkan jumlah tepi yang dihasilkan sundani dkk. hal serupa juga berlaku pada metode qcnn yang memiliki hasil lebih baik dan akurat dibandingkan dengan metode cnn klasik. sehingga hipotesisnya hasil dari ekstraksi fitur dan klasifikasi akan menjadi lebih optimal. gambar 3.2 perbandingan hasil deteksi tepi berbasis kuantum dan klasik sundani dkk. pengolahan data ini dilakukan sebagai pembanding performa model segmentasi dan klasifikasi berbasis kuantum. performa akan dibandingkan dari akurasi yang dihasilkan. condronegoro untuk mempelajari batik daur hidup yogyakarta. paper kedua deteksi tepi berbasis kuantum no. paper ketiga klasifikasi citra berbasis kuantum 10. evaluasi rkp 11. sidang tertutup 12. sidang terbuka
Tia Haryanti_Kualifikasi.txt,3.1 kerangka umum penelitian ini bertujuan untuk mengembangkan sistem deteksi dini kantuk sebelum berkendara dengan menggunakan kombinasi data visual berupa data citra wajah dan data fisiologis. kondisi predriving mengacu pada kondisi sebelum pengemudi memulai perjalanan sehingga sistem ini sangat penting untuk mencegah risiko kecelakaan di jalan . sistem ini mengintegrasikan teknologi pengenalan wajah dan analisis data fisiologis untuk memberikan deteksi yang lebih akurat. blok d iagram secara umum yang digunakan pada penelitian ini dapat dilihat pada gambar 3.1 blok diagram. objek preprocessing data fisiologis ekstrasi fiturpenggabungan fitur klasifikasi data image data visual kantuk ya tidak gambar 3.1 blok diagram model ini terdiri dari tiga tahapan yaitu input proses dan output . penelitian deteksi dini kantuk untuk kondisi predriving menggabungkan data visual yaitu pengumpulan data citra wajah pengemudi yang diambil menggunakan kamera serta data fisiologis yang diukur berupa data ekg menggunakan perangkat wearable yaitu smartwatch dan pulse oximeter untuk mengukur saturasi oksigen spo2 . tahapan preprocessing dan ekstraksi fitur dilakukan pada kedua jenis data yaitu data citra gambar dan data fisiologis. model convolutional neural network cnn digunakan untuk mengekst raksi fitur dari data citra wajah yang merupakan data visual sementara long short term memory lstm digunakan untuk memproses data fisiologis yang bersifat timeseries. fitur fitur yang diekstraksi dari kedua model ini digabungkan untuk menghasilkan vect or fitur gabungan. vektor fitur ini kemudian digunakan sebagai input untuk model support vector machine 43 svm yang melakukan klasifikasi akhir untuk mendeteksi kantuk. hasil deteksi kemudian digunakan untuk memberikan peringatan kepada pengemudi layak tidak nya pengemudi untuk berkendara. 3.2 tahapan peneletian tahapan penelitian merupakan urutan atau langkah langkah yang dilakukan secara terstruktur dan sistematis pada penelitian ini secara garis besar terbagi menjadi empat tahapan. pengumpulan data data visualdata fisiologis pemilihan dan persiapan dataset preprocessing data pembuatan modelekstraksi fitur penggabungan fitur evaluasi pemisahan dataset pembangunan model pelatihan model evaluasi model implementasi gambar 3. 2 tahapan penelitian 44 3.3. pemilihan dan persiapan dataset tahapan ini merupakan tahapan identifikasi awal dari penelitian meliputi identifikasi masalah penelitian yang berfokus pada masalah utama yaitu mendeteksi kantuk pada pengemudi menggunakan pemrosesan citra dan fisiologis . pemilihan dataset memastikan bahwa dataset yang dikumpulkan relevan dengan tujuan penelitian yaitu hanya menggunakan data yang berkaitan dengan kondisi predriving serta memastikan bahwa data visual dan data fisiologis diambil pada waktu yang sama. data primer diperoleh berdasarkan pengumpulan dan pengamatan langsung oleh peneliti berdasarkan kondisi subjek penelitian dan rekaman aktivitas fisik atau ekspresi wajah menggunakan kamera serta pengukuran fisiologis yang menggunakan perangkat wearable . data visual dan fisiologis berupa data yang diambil dari partisipan dalam kondisi terjaga dan mengantuk . 3.3.2 preprocessing data melakukan analisis eksploratif data untuk memahami karakteristik dataset sehingga meningkatkan kualitas deteksi . augmentasi gambar dilakukan untuk meningkatkan variasi data seperti rotasi flipping horizontal atau vertikal zooming dan perubahan cahaya 7. 3.4. pembuatan model pembuatan model merupakan proses implementasi dari desain arsitektur yang telah direncanakan . langkah dari pembuatan model yaitu penulisan kode untuk membangun model sesuai dengan desain arsitektur yaitu cnn lstm dan svm. redness of eyes mengukur tingkat kemerahan pada ma ta. pooling layer mengurangi dimensi peta fitur sambil mempertahankan fitur penting. membangun model lstm membangun model lstm dengan lapisan lstm dan dense untuk ekstraksi fitur. 3.4.4 desain arsitektur desain a rsitektur merupakan proses menentukan struktur dan komponen model yang akan dibangun yang terdiri dari jenis model jumlah dan jenis layer fungsi aktivasi teknik regularisasi dan konfigurasi model. hasil dari kedua model digabungkan dan diklasifikasikan menggunakan support vector machine svm. 50 digunakan untuk mengolah data visual seperti mengenali mata tertutup atau mulut menguap sebagai indikator kantuk. selanjutnya yaitu menggunakan support vector machines svm untuk mengklasifikasikan data sebagai kantuk atau tidak kantuk. svm dipilih karena kemampuannya dalam mengklasifikasikan data yang kompleks dan memberikan batas keputusan yang jelas layak atau tidak layak pengemudi untuk berkendara. jika pengklasifikasi mendeteksi keadaan mengantuk maka pengklasifikasi menghasilkan alarm atau notifikasi pemberitahuan untuk memberi tahu bahwa pengemudi tidak layak untuk berkendara atau kembali ke f ase pertama dan memulai ulang prosedur. implementasi sistem ini diharapkan dapat memberikan notifikasi atau peringatan kepada pengemudi jika tanda tanda kantuk terdeteksi selama kondisi predriving sehingga dapat meningkatkan keselamatan berkendara secara signifikan. berdasarkan hasil validasi model dapat ditune atau dioptimalkan untuk meningkatkan performa misalnya dengan mengubah arsitektur parameter atau teknik training . 3.6 implementasi setelah penyempurnaan model dianggap siap untuk digunakan. model ini harus dapat secara akurat mendeteksi kantuk pengemudi dalam berbagai kondisi dengan minimal kesalahan. langkah selanjutnya yaitu penerapan model dalam sistem nyata dan pemantauan efektivitasnya dalam kondisi pengemudi pada 51 lingkungan predriving. model yang telah dioptimalkan diintegrasikan ke dalam sistem deteksi dini kantuk untuk pengujian awal. selanjutn ya yaitu m elakukan uji coba lapangan untuk mengevaluasi efektivitas sistem dalam kondisi nyata memungkinkan pengumpulan feedback untuk perbaikan lebih lanjut. 3.7 rencana kegiatan tabel 3.1 rencana kegiatan no nama kegiatan bulan 1 2 3 4 5 6 7 8 9 10 11 12 1 kajian literatur 2 perencanaan penelitian 3. pengumpulan data 4. prapemrosesan data 5. pembuatan model 6. pelatihan dan evaluasi model 7. penyusunan laporan akhir 8. presentasi laporan akhir 9. publikasi jurnal ilmiah internasional 10. pengajuan hki
Utami Lestari_Kualifikasi.txt,3.1 gambaran umum penelitian ini bertujuan untuk mengembangkan aplikasi berbasis large language model llm dengan arsitektur gpt 4 yang mampu melakukan telaah sejawatpeer review secara otomatis pada artikel ilmiah dari jurnal komputer. data utama yang digunakan adalah ar tikel ilmiah berbahasa indonesia dalam bidang ilmu komputer dari berbagai jurnal akademik. 2 tahapan preprocessing tahap pertama adalah tokenisasi di mana teks dipecah menjadi unit unit yang lebih kecil yang dikenal sebagai token memungkinkan model untuk menganalisis teks pada tingkat yang lebih granular. setelah itu token yang dihasilkan dari tokenisasi perlu diubah menjadi representasi numerik melalui token encoding menggunakan teknik embeddings dari model transformer. melalui proses preprocessing yang cermat dan terstrukt ur data teks menjadi lebih bersih terorganisir dan siap digunakan dalam pemodelan sehingga tidak hanya meningkatkan efisiensi pemrosesan data tetapi juga memungkinkan model untuk belajar dan melakukan prediksi dengan lebih akurat. 3.1.3 pembuatan model llm setelah dataset yang di kumpulkan dan melalui proses preprocessing maka dilanjutkan tahap pemodelan dengan menggunakan llm. selama fase pela tihan model dievaluasi secara be rkala untuk memastikan kinerjanya sesuai dengan harapan dan parameter model dioptimalkan untuk meningkatkan kualitas output. hal ini tidak hanya meningkatkan produktivitas tetapi juga memastikan bahwa artikel yang dipublikasikan memenuhi standar ilmiah yang tinggi. 3.1.4 evaluasi model llm evaluasi model merupakan langkah yang penting dalam pengembangan sistem kecerdasan buatan karena memungkinkan untuk menilai kinerja dan efektivitas model dalam menyelesaikan tugas tertentu. tanpa evaluasi yang tepat model yang dikembangkan dapat menghasilkan prediksi yang tidak akurat atau tidak dapat diandalkan yang berpotensi menyebabkan kinerja sistem yang buruk secara keseluruhan. recall memberikan informasi tentang seberapa banyak instance positif yang berhasil diidentifikasi oleh model dari semua instance positif yang 4. table jadwal penelitian dapat dilihat pada table 3.1 table 3. 1 jadwal penelitian no uraian kegiatan 2023 2024 9 10 11 12 1 2 3 4 5 6 7 8 9 10 11 12 1 penyusunan proposal 2 uji kualifikasi 3 evaluasi progres pertama 4 paper pertama 5 evaluasi progres kedua no uraian kegiatan 2025 2026 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 1 paper ke dua 2 evaluasi rkp 3 sidang tertutup 4 sidang terbuka
Yoga Panji Perdana Nugraha_Kualifikasi.txt,3.1 motivasi industri manufaktur memiliki berbagai macam produk yang ada di dalamnya. dalam upaya pemenuhan kualitas yang tinggi serta menjaga kepuasan pelanggan dan reputasi perusahaan maka mendeteksi produk yang cacat sedini mungkin merupakan aspek yang penting. pengembangan aplikasi pendeteksi cacat pada produk ini didasari keinginan peneliti untuk meningkatkan kinerja pengendalian kualitas pada industri manufaktur sehingga dapat membantu menjaga kualitas produk serta efisien si dalam kegiatan pengendalian kualitas. meningkatkan efisiensi pada kegiatan inspeksi produk d engan mene rapkan otomatisasi mel alui aplikasi yang dikembangkan. mengintegrasikan teknologi yang sedang berkembang seperti artificial intelligence dengan industri manufaktur sehingga tercipta manufaktur cerdas yang akan berakibat pendapatan profit perusahaan yang op timal. memberikan kontribusi pemahaman dan pengembangan teknologi baru dalam deteksi objek sehingga bisa menjadi referensi untuk pembaca serta penelitian selanjutnya. tahap awal tahap pengembanganperancangan dan pembuatan prototype alat deteksi cacatpengumpulan data cacat objek uji coba prototype alat deketsi cacat objekperancangan model deteksi cacat objek menggunakan deep learning implementasi dan pelatihan model deteksi cacat objek evaluasi dan penyempurnaan model deteksi cacat objek pengujian model deteksi objek menggunakan deep learning pembuatan aplikasi pendeteksi objek cacattahap optimasi pengajuan hki dan jurnal internasional q 1 gambar 3. tahap awal kegiatan yang dilakukan pada tahap awal ini adalah merancang dan membuat prototype alat deteksi cacat dan pengumpulan data cacat objek. luaran pada tahap ini adalah pengajuan hki untuk prototype alat pendeteksi cacat ob jek yang dirancang. kedua adalah merancang model untuk mendeteksi cacat objek dengan menggunakan deep learning . pelatihan data dilakukan untuk melatih model mengenali citra yang akan dideteksi sehingga pada penerapannya mendapatkan hasil deteksi yang akurat dan optimal. tahap optimasi tahap pengembangan telah dilakukan kemudian masuk ke tahap optimasi. tahap ini terdapat kegiatan yaitu eval uasi dan penyempurnaan model deteksi cacat objek. evaluasi dan penyempurnaan dilakukan agar fitur yang ada pada aplikasi yang akan dikembangkan dapat ditampilkan dengan maksimal. fitur yang akan ditambahkan pada model pendeteksi objek berupa kemampuan komp uter untuk secara otomatis menyimpan hasil deteksi menjadi sebuah basis data. pada akhirnya akan menampilkan output model dalam mendeteksi cacat pada produk. setelah itu maka dibangun aplikasi yang mampu mendeteksi cacat produk pada industri secara real time. aplikasi ini nantinya akan menampilkan hasil deteksi dari produk yang bergerak. selain itu diterapkan juga pengukuran evaluasi seperti precision recall dan mean average precision map untuk memastikan model yang dikembangkan dapat digunakan dengan optimal. nantinya akan dikembangkan sebuah aplikasi yang kemungkinan berbasis web untuk mempermudah pengguna untuk mengambil gambar bergerak maupun tak bergerak yang kemudian mengirimnya ke sistem pendeteksi cacat dan menerima hasil deteksi secara real time. hasil deteksi secara real time dikehendaki agar produk dapat diperiksa selama proses produksi berlangsung sehingga cacat dapat dideteksi secepat dan seakurat mungkin.
