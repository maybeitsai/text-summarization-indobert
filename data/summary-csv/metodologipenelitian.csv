nama_dokumen,summary
Alfharizky Fauzi_Kualifikasi.txt,1 tahapan penelitian dokumentasi peneliti tahapan penelitian dapat dilihat pada gambar 3.1. tahapan penelitian yang dilakukan terdiri dari 9 tahapan yaitu dimulai dari studi literatur sebagai dasar penelitian analisis kebutuhan pada system yang akan dibangun pengumpulan dataset preprocessing data membangun model training model evaluasi model deployme nt model dan implementasi model yang telah dibuat ke dalam smartphone. saat program telah dijalankan program akan mengakuisisi dataset kemudian dataset akan melalui tahap preprocessing untuk m enormalkan data kemudian setelah melalui tahap preprocessing selanjutnya mentraining dataset yang sudah didapatkan jika dataset berhasil dilatih dan juga divalidasi maka berlanjut ke tahap berikutnya yaitu tahapan test ing dengan menerapkan model yang dibuat kedalam mobile phone atau smartphone. tahap selanjutnya jika camera telah menyala maka artinya sudah siap untuk mendeteksi objek jenis penyakit kulit . pada tahap terakhir yaitu saat ada objek jenis penyakit kulit yang masuk atau terdeteksi oleh camera m aka citra tersebut sudah dapat dilakukan proses klasifikasi kemudian divalidasikan bahwa data tersebut sama dengan yang ada pada database untuk memunculkan label nama pada dataset serta memunculkan nilai confidence pada citra jenis penyakit kulit yang terdete ksi. 3.2 analisis kebutuhan analisis kebutuhan merupakan menganalisis komponen yang diperlukan dalam pembuatan dan menjalankan program proses ini mencakup evaluasi identifikasi dan pemetaan kebutuhan dari berbagai perangkat yang terlibat dalam pembuatan system dan program pada penelitian ini. 3.2.1. analisis kebutuhan perangkat keras perangkat keras yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan laptop acer predator helios neo 16 dan mobile phone atau smartphone xiaomi redmi note 7 dengan bahasa pemrograman python dengan spesifikasi yang dapat dilihat pada tabel 3.1. tabel 3. 2 mobile phone smartphone 1 camera hd 48mp 169 1280x720 f1.8 wide dual led flash hdr panorama rgb red green blue 3.2.2. analisis kebutuhan perangkat lunak perangkat lunak yang digunakan dalam penelitian identifikasi penyakit kulit pada manusia menggunakan operating system windows jupyter lab dengan bahasa pemrograman python dan visual studio sebagai text editor yang dapat dilihat pada tabel 3.2. tabel 3. 2 daftar perangkat keras no perangkat lunak version 1 operating system windows 11 pro single language 64 bit 10.0 build 22631 2 python 3.7.0 3 jupyter notebook labs 7.2.1 4.2.2 4 visual studio code may 2024 version 1.90 3.2.3. analisis objek program dengan menggunakan metode bidirectional image text matching deep learning ini mempunyai beberapa objek yang diterapkan pada penelitian ini yaitu 1. identifikasi berbagai macam jenis penyakit kulit dengan memunculkan citra gambar yang didapat dan deskripsi mengenai penyakit kulit yang teridentifikasi dibawah citra gambar untuk setiap objek penyakit kulit yang terdeteksi data yang digunakan memiliki variasi jenis penyakit kulit dengan kategori 2 penyakit kulit menular candidiasis dan molluscum dan 2 penyakit kulit tidak menular eczhema dan melanoma dengan masing masing kelas memiliki 1000 citra penyakit kulit yang di dapat pada website international dermnet nz dermnetnz.org 2024 dan the international skin imaging collaboration isic isicarchive.com 2024 . 2. program identifikasi berbagai macam objek penyakit kulit pada manusia ditampilkan secara real time menggunakan file upload kamera mobile phone. website ini menyediakan gambar gambar resolusi tinggi dari berbagai penyakit kulit baik yang menular maupun tidak menular serta memberikan deskripsi lengkap tentang penyakti tersebut meliputi gejala dan pengobatan. citra yang diperoleh kemudian diseleksi berdasarkan fokus penelitian yaitu identifikasi penyakit kulit menular candidiasis dan molluscum dan tidak menular eczhema dan melanoma . 2 citra penyakit kulit yang berasal dari website isic isicarchive.com 2024 3.3.1. dataset penyakit kulit dataset pada penelitian ini dibagi menjadi 2 bagian yaitu 80 data training dan 20 data testing objek jenis penyakit kulit . dataset bersumber dari citra data image dan deskripsi data teks beberapa jenis penyakit kulit sejumlah 4000 citra dengan 4 jenis penyakit kulit yang terdiri dari echzema melanoma candidiasis dan molluscum dengan memiliki 1000 citra berbeda setiap jenis penyakit kulit . dari keempat jenis penyakit kulit tersebut dibagi menjadi 2 kelompok sebagai penyakit kulit menular dan tidak menular. 3.3.1.1. data gambar data image ini mencakup berbagai jenis gambar yang menampilkan gejala dan karakteristik penyakit kulit yang digunakan pada peneltian ini eczhema melanoma candidiasis dan molluscum seperti ruam bintik bintik lepuhan atau lesi kulit lainnya . penggunaan data gambar sangat penting dalam penelitian ini untuk membandingkan dan mempelajari pola visual yang terkait dengan berbagai penyakit kulit. data image pada penelitian ini terdiri 4000 gambar dari 4 jenis penyakit kulit yaitu eczhema melanoma candidiasis dan molluscum yang dibagi menjadi 2 kelompok menular dan tidak menular. informasi ini penting untuk diagnosis dan pemahaman lebih lanjut tentang berbagai penyakit kulit seperti dermatitis eksim psoriasis dan infeksi jamur kulit. 3 data teks penyakit kulit 3.4 pre processing data pada tahapan ini data gambar penyakit kulit preprocessing mencakup berbagai teknik seperti pengubahan ukuran gambar normalisasi piksel peningkatan kontras penghapusan noise serta melakukan segmentasi dan fitur ekstraksi. teknik ini bertujuan untuk meningkatkan kualitas gambar dan memastikan konsistensi data sehingga fitur fitur penting dapat diekstraksi dengan lebih efektif oleh algoritma analisis atau mode l kecerdasan buatan. dapat dilihat pada algoritma 3.1. algoritma 3.1 algoritma resize citra input citra penyakit kulit dengan ukuran asli ouput citra penyakit kulit dengan ukuran sama 256x256 proses 1. inisialisasi citra 2. periksa dan buat direktori output 3. iterasi melalui citra dalam direktori input 4. muat citra 5. ubah ukuran citra 6. simpan citra yang telah diubah ukurannya ukuran dan bentuk citra hasil resizing disimpan pada folder output masing masing penyakit kulit yang selanjutnya akan diproses pada tahap berikutnya. 3 algoritma peningkatan kontras input citra penyakit kulit hasil normalisasi ouput citra penyakit kulit dengan peningkatan kontras proses 1. inisialisasi citra 2. muat data citra 3. ubah tipe data citra 4. hitung rata rata intensitas piksel 5. peningkatan kontras 6. simpan hasil peningkatan kontras citra hasil peningkatan kontras disimpan yang selanjutnya akan diproses pada tahap berikutnya. 4 algoritma penghapusan noise input citra penyakit kulit hasil peningkatan kontras ouput citra penyakit kulit dengan penghapusan noise proses 1. inisialisasi citra 2. muat data citra 3. penghapusan noise menggunakan filter median 4. penghapusan noise menggunakan filter gaussian 5. tampilakan dan simpan hasil citra hasil penghapusan noise menggunakan median filter dan gaussian filter disimpan yang selanjutnya akan diproses pada tahap berikutnya. dengan menghapus noise maka citra yang dihasilkan menjadi lebih bersih proses ini membantu dalam meningkatkan fokus citra terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 5 algoritma segmentasi input citra penyakit kulit hasil penghapusan noise ouput citra penyakit kulit hasil segmentasi thresholding proses 1. inisialisasi citra 2. muat data citra 3. konversi ke citra grayscale 4. tentukan nilai threshold 5. segmentasi dengan thresholding 6. inversi citra hasil thresholding 7. pemulihan warna asli 8. simpan hasil citra hasil segmentasi menggunakan thresholding disimpan yang selanjutnya akan diproses pada tahap berikutnya. dengan menghapus nilainilai pada citra yang tidak terpakai maka citra yang dihasilkan menjadi lebih bersih proses ini membantu dalam menentukan focus objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 6 ekstraksi fitur warna input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi warna proses 1. inisialisasi citra 2. muat data citra 3. pisahkan kanal warna r g b 4. hitung statistik kanal a ratarata mean b standar deviasi standard deviation 5. simpan fitur nilai hasil ektraksi fitur warna menggunakan rgb disimpan yang selanjutnya akan diproses pada tahap berikutnya. dengan mendapatkan nilai nilai pada setiap kanal rgb maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap warna yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 11 hasil ektraksi fitur warna 3.4.1.6.2. ektraksi fitur bentuk tahapan ini dimulai dengan pra pemrosesan citra untuk meningkatkan kualitas dan mempersiapkannya untuk ekstraksi fitur. 7 ekstraksi fitur bentuk input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi bentuk proses 1. inisialisasi citra 2. muat data citra 3. ekstraksi kontur 4. ekstraksi fitur geometris 5. simpan hasil nilai hasil ektraksi fitur bentuk menggunakan contour dan geometris disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. pseudocode 7. ektraksi fitur bentuk def extract_shape_featuresimage gray cv2.cvtcolorimage cv2.color_bgr2gray _ thresh cv2.thresholdgray 0 255 cv2.thresh_binary cv2.thresh_otsu contours _ cv2.findcontoursthresh cv2.retr_external cv2.chain_approx_simple areas perimeters circularities eccentricities for contour in contours area cv2.contourareacontour perimeter cv2.arclengthcontour true circularity 4 np.pi area perimeter 2 if perimeter 0 else 0 if lencontour 5 ellipse cv2.fitellipsecontour center axes orientation ellipse major_axis maxaxes minor_axis minaxes eccentricity np.sqrt1 minor_axis 2 major_axis 2 if major_axis 0 else 0 else eccentricity 0 areas.appendarea perimeters.appendperimeter circularities.appendcircularity eccentricities.appendeccentricity avg_area np.meanareas avg_perimeter np.meanperimeters avg_circularity np.mean circularities avg_eccentricity np.meaneccentricities return avg_area avg_perimeter avg_circularity avg_eccentricity sehingga tampilan hasil program terlihat pada gambar 3.12 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan bentuk contour dan geometris menunjukan hasil nilai untuk setiap citra ditujukan untuk memisahkan informasi bentuk menjadi area perimeter circularity dan exccentricity . dengan mendapatkan nilainilai bentuk maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap bentuk yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 12 hasil ektraksi fitur bentuk 3.4.1.6.3. ektraksi fitur tekstur pada tahapan ekstraksi fitur tekstur melibatkan beberapa langkah kunci untuk menggambarkan dan menganalisis tekstur citra secara sistematis . tahap awal mencakup pemilihan glcm sebagai metode utama untuk mengekstraksi fitur tekstur. langkah langkah ekstraksi fitur tekstur dengan menggunakan metode glcm sebagai acuan tekstur dapat dilihat pada algoritma 3. 8. algoritma 3. 8 ekstraksi fitur tektur input citra penyakit kulit hasil segmentasi ouput nilai fitur ekstraksi tekstur proses 1. inisialisasi citra 2. muat data citra 3. pembentukan glcm 4. normalisasi glcm 5. ekstraksi fitur statistik 6. simpan hasil nilai hasil ektraksi fitur tekstur menggunakan glcm disimpan yang selanjutnya akan diproses pada tahap berikutnya. algoritma 3. pseudocode 8. ektraksi fitur tektur def calculate_glcm_featuresimage_path load gambar dan konversi ke grayscale image io.imreadimage_path gray_image color.rgb2grayimage gray_image img_as_ubytegray_image konversi ke tipe data uint8 hitung glcm dengan jarak dan arah yang ditentukan distances 1 2 3 jarak d angles 0 np.pi4 np.pi2 3np.pi4 arah Î¸ glcm graycomatrixgray_image distancesdistances anglesangles symmetrictrue normedtrue ekstraksi fitur tekstur dari glcm contrast graycopropsglcm contrast dissimilarity graycopropsglcm dissimilarity homogeneity graycopropsglcm homogeneity energy graycopropsglcm energy correlation graycopropsglcm correlation mengembalikan hasil fitur sebagai tuple return contrast.mean dissimilarity.mean homogeneity.mean energy.mean correlation.mean sehingga tampilan hasil program terlihat pada gambar 3.13 berikut. seperti terlihat pada gambar proses ektraksi fitur menggunakan glcm menunjukan hasil nilai untuk setiap citra ditujukan untuk memisahkan informasi tekstur menjadi contrast dissimilarity homogeneity energy dan correlation. dengan mendapatkan nilai nilai tekstur maka informasi yang didapat akan semakin kompleks proses ini membantu dalam menentukan setiap tekstur yang paling dominan pada objek terhadap penyakit kulit dan membuatnya lebih mudah untuk dianalisis. 13 hasil ekstraksi fitur tekstur dengan glcm 3.4.2. preprocessing data teks tahap pre processing data teks dilakukan serangkaian langkah penting dalam pengolahan informasi teks yang bertujuan untuk membersihkan merapihkan dan mempersiapkan data sebelum dilakukan analisis lebih lanjut. proses ini krusial karena data teks sering kali tidak terstruktur dan dapat mengandu ng berbagai jenis noise atau informasi yang tidak relevan yang dapat mempengaruhi hasil analisis.
Alifurrohman_Kualifikasi.txt,"3.1 Kerangka Umum Penelitian
     Berikut ini merupakan kerangka penelitian yang menjelaskan tahapan yang dilakukan dalam penelitan ini. Berikut gambar 3.1 diagram alir penelitian

Persiapan Data
Definisikan Ukuran Input dan Parameter
Definisikan Multi-Head Attention
Desain Model
Definisikan DQN dengan Lapisan Tersembunyi
Output Layer untuk Q-values
Fungsi untuk Memilih Tindakan menggunakan
Strategi e-greedy
Fungsi untuk Memperbarui Model dengan
Pengalaman dari Replay Buffer
Gambar 3.1 Diagram Alir Penelitian


3.2 Pengumpulan Data
     Langkah awal adalah mengumpulkan dataset yang akurat dan relevan. Dataset didapatkan dari data sekunder, dataset ini merupakan hal yang penting dari simulasi dan eksperimen, mencakup koordinat lokasi yang mungkin meliputi lokasi depot dan titik pengiriman, jendela waktu untuk setiap pengiriman yang menentukan batas awal dan akhir kapan pengiriman harus dilakukan, serta jumlah kendaraan. Data ini harus mencerminkan situasi dunia nyata untuk memastikan bahwa model yang dikembangkan dapat diaplikasikan secara praktis. Normalisasi merupakan proses penting untuk menyamakan skala data, memastikan bahwa model dapat memprosesnya dengan efisien. Korelasi membantu mengidentifikasi fitur-fitur yang saling terkait dan memberikan wawasan tentang bagaimana setiap fitur dapat mempengaruhi model prediksi rute. 3.4 Desain model
     Implementasi Deep Q-Network (DQN) dengan mekanisme attention untuk Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) melibatkan beberapa langkah utama, mulai dari pemilihan kerangka kerja hingga pembuatan lingkungan simulasi. Informasi ini digunakan untuk memperbarui kebijakan model dengan cara mengoptimalkan parameter jaringan sehingga meningkatkan estimasi nilai Q, yang merepresentasikan hadiah kumulatif yang diharapkan. Untuk meningkatkan stabilitas dan efisiensi pelatihan, teknik seperti experience replay dan target networks digunakan. Selain itu pada tahap pelatihan model ini juga dilakukan penyetelan hyperparameter untuk menemukan nilai optimal hyperparameter guna meningkatkan kinerja model. Ini merupakan langkah penting dalam machine learning karena dapat menghasilkan peningkatan akurasi, efisiensi, dan generalizability model. 3.6 Evaluasi Model
     Setelah fase pelatihan model Deep Q-Network (DQN) dengan multi-header attention untuk Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) selesai, langkah evaluasi menjadi penting untuk memahami seberapa efektif model dalam menyelesaikan masalah yang ditargetkan. Total jarak tempuh mencerminkan efisiensi rute yang dihasilkan, sementara kepatuhan terhadap jendela waktu mencerminkan kualitas layanan yang dapat dijamin oleh model. 3.7 Analisis dan Penyempurnaan
     Langkah terakhir yaitu analisis secara mendalam kinerja model pada dataset pengujian. Penyempurnaan dilakukan untuk mengatasi kelemahan yang telah dianalisis sebelumnya seperti penyempurnaan pada tuning hyperparameter untuk peningkatan kinerja, modifikasi arsitektur dan pelatihan ulang model. 3.8 Jadwal Penelitian
     Jadwal penelitian digunakan untuk meningkatkan efektivitas dalam proses penelitian. Adanya jadwal penelitian ini setiap proses penelitian sudah terjadwal dalam tabel 3.1 sehingga penelitian lebih efektif dan optimal. Tabel 3.1 Jadwal Penelitian"
Armando Tirta Dwilaga_Kualifikasi.txt,3.1 gambaran umum penelitian penelitian ini digunakan untuk mengatasi sensitivitas terhadap cacat pada gambar ban dengan melibatkan penggunaan jaringan syaraf menggunakan algoritma convolutional neural network cnn dan membangun model atau kerangka kerja menggunakan keras. berikut adalah gambar 3.1 blok diagram gambaran umum penelitian. data preparation data augmentasi data splitting model training forward pass model evaluation backward passfinetuning if neededinput unit processing unit output unit model deployment inference12 gambar 3.1 blok diagram gambaran umum penelitian berdasarkan gambar 3.1 blok diagram gambaran umum penelitian maka dapat dijelaskan di blok tersebut terbagi menjadi 3 bagian yaitu bagian pertama adalah unit masukan berisikan data preparation di mana gambar ban dimuat diubah menjadi format yang sesuai dipersiapkan untuk pelatihan model convolutional neural network cnn seperti pemrosesan gambar ban selanjutnya data augmentation di mana data dibuat lebih ber variasi dari training data yang ada sehingga dapat meningkatkan keberagaman training data tanpa h arus mengambil data baru mencakup rotasi pergeseran horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel selanjutnya data di mana dataset yang telah di augmentasi dan disiapkan dibagi menjadi subset yang berbeda untuk training untuk melatih model validation untuk menyempurnakan model serta me mvalidasi performanya selama pelatihan dan testing untuk mengevaluasi kinerja model akhir . data set dibagi menjadi training data validation data dan testing data dalam proporsi tertentu. bagian kedua adalah unit pemrosesan yang bertindak adalah model training forward pass tahap di mana input diproses melalui model untuk menghasilkan prediksi tujuannya melatih model convolutional neural network cnn menggunakan dataset pelatihan di mana data dari unit masukan diteruskan melalui jaringan neural di lakukan transformasi linier konvulasi dan non linier fungsi aktivasi dilakukan pada data di setiap lapisan untuk menghasilkan output prediksi yang melibatkan komputasi di setiap neuron dan lapisan jaringan yang merupakan inti dari proses pembelajaran dalam jaringan saraf. selanjutnya unit pemrosesan finetuning tujuannya dilakukan untuk menyempurnakan model lebih lanjut setelah pelatihan awal dengan dataset yang lebih kecil atau lebih spesifik nantinya. proses di dalam finetuning menyesuaikan bobot menggunakan kumpulan data yang lebih kecil untuk menyesuaikan bobot model untuk performa yang lebih baik pelatihan khusus fokus pada fitur data yang lebih relevan dengan objek . bagian ketiga adalah unit keluaran yang bertindak ada proses model evaluatioan backward pass tahap di mana gradien memperbarui parameter model dalam arah yang akan mengurangi fungsi loss dari fungsi loss metrik yang mengukur seberapa baik atau buruk model melakukan prediksi dibandingkan nilai aktualnya dihitung dan digunakan untuk memperbarui parameter model selama pelatihan tujuannya mengevaluasi performa model yang dilatih dan model dievaluasi menggunakan metrik yang relevan accuracy precision recall dan f1 score berdasarkan prediksi yang dihasilkan dari model terhadap validasi atau uji data. output dari proses ini adalah tentang hasil evaluasi model yang memberikan informasi kinerja model. selanjutnya ada dua alur pilihan yang bisa dilakukan alur pertama jika hasil prediksi sudah sesuai dengan keinginan maka bisa langsung masuk ke model deployment inference dan alu r kedua jika hasil prediksi masih perlu diperbaiki pada bagian unit pemrosesan terlebih dahulu fine tuning untuk penggunaan data set lebih kecil jika menunjukan model belum mencapai performa yang diharapkan baru masuk ke model deployment inference tujuannya menerapkan model terlatih untuk membuat prediksi pada data baru yang belum terlihat. model deployment inference yang telah dilatih digunakan untuk membuat prediksi pada data baru atau dalam situasi dunia nyata tahap di mana model menerima input baru dan menghasilkan output berdasarkan pada pembelajaran yang dilakukan selama proses pelatihan dan merupakan output akhir dari keseluruhan proses di mana model mengambil keputusan atau membuat prediksi berdasarkan pada pengalaman yang telah diperoleh selama pelatihan. 3.2. tahapan penelitian penelitian ini di dalamnya terdapat tahapan tahapan yang dilakukan untuk membentuk satu kesatuan yang utuh dari awal sampai akhir dan membentuk kerangka penelitian mengenai klasifikasi pada produk ban menggunakan algoritma convolutional neural network cnn . 3.2.1 studi literatur tahap pertama adalah studi literatur di mana studi yang dilakukan berasal dari artikel ilmiah dan buku yang menunjang dalam menganalisis terkait dengan metode pen gukuran kualitas mengenai klasifikasi produk ban meninjau penggunaan pembelajaran mesin algoritma convolutional neural network cnn dari beberapa tahun ke belakang dalam konteks peng ukuran kualitas untuk klasifikasi terhadap kondisi kondisi produk ban . 5 tahapan data preprocessing 3.2.4 data augmentation tahap keempat adalah data augmentation meningkatkan variasi dalam dataset dengan teknik augmentasi data menggunakan operasi seperti rotasi pergeserarn horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel untuk memperkaya dataset dan mengurangi overfitting saat disajikan dengan data baru yang belum pernah dilihat sebelumnya performa model akan menurun drastis karena model tersebut dapat menyesuaikan diri dengan kumpulan training data dengan sangat efektif. sebaliknya pada saat runtime hanya menghasilkan variasi dari gambar yang sudah ada dibuat secara dinami s dan cukup bagi model untuk berlatih dari berbagai kondisi gambar ban yang ada pada kenyataaanya. secara lebih jelas nilai teknik augmentasi pertama dilakukan dengan manual menggunakan bantuan dari website roboflow dengan resize gambar menjadi 640 x 640 pada augmentasinya menggunakan model flip horizontal dan vertikal 90 pemutaran searah jarum jam berlawanan arah jarum jam dan terbalik rotasi 45 dan 45 shear 5 horizontal dan 5 vertikal brightness 20 sampai 20. data asli pada dataset berjumlah 1 .028 data gambar ban setelah dilakukan augmentasi secara fisik menggunakan website roboflow ada data yang tidak dapat diidentifikasi ada 3 gambar sehingga total gambar asli yang berhasil di upload dan dijadikan data asli yang tetap berjumlah 1.025 data ga mbar dan setelah di augmentasi bertambah menjadi 2 .050 data gambar ban. 7 tahapan splitting data 3.2.6 model building tahap ke enam adalah model building membangun model convolutional neural network cnn dengan keras membangun arsitektur model convolutional neural network cnn menggunakan keras mengatur lapisan lapisan seperti convolutional maxpooling2d flatten dan dense untuk membangun model. selanjutnya secara kestabilan dan konvergensi adaptive momentum adam menyambung dari awal dapat mengubah kecepatan pembelajaran secara adaptif sehingga membuatnya lebih stabil dan kecil kemungkinannya terjebak pada tingkat minimum lokal nilai yang dianggap sebagai titik terendah dari loss function dalam model sehingga adaptive momentum adam cenderung mencapai konvergensi tingkat kinerja yang diharapkan lebih cepat dan andal dalam berbagai keadaan sedangkan stochastic gradient descent sgd mungkin lebih stuck pada nilai minimum atau terjebak pada nilai minimum lokal ya ng disebabkan oleh kemungkinan bergantung pada seberapa tepat kecepatan pemelajaran dipilih kecepatan pemelajaran yang tetap dapat membuat model mencapai konvergensi terlalu cepat atau terlalu lambat. 9 tahapan model evaluation testing 3.3 arsitektur convolutional neural network cnn convolutional neural network cnn yang dibangun menggunakan model atau kerangka kerja yang pada dasarnya menggunakan keras dan juga tensorflow dengan menambahkan beberapa model lapisan lapisan seperti lapisan convolutional conv2d laposan pooling maxpooling 2d flatten dan lapisan fully connected dense . 10 tahapan convolutional neural network cnn dengan model keras. filter convolutional layer pertama yang berfungsi untuk mengekstrak fitur fitur visual diterapkan pada gambar untuk menghasilkan fitur fitur yang lebih abstrak formula untuk mengetahui jumlah training datanya dengan . max pooling memilih nilai maksimum di dalam jendela pooling untuk m engurangi ukuran fitur dan mempertahankan informasi penting. selanjutnya dense layers lapisan dense digunakan sebagai lapisan output dalam model klasifikasi di mana jumlah neuron dalam lapisan output sesuai dengan jumlah kelas yang harus diprediksi di mana ada tiga lapisan dense ditambahkan dengan fungsi pertama dan kedua menggunakan relu sebagai 0 f x max x yang artinya menunjukkan bahwa keluarannya nol jika masukannya negatif atau nol dan output x jika masukannya positif dengan 128 unit neuron dan pada dense kedua 64 unit neuron karena tugasnya mengurangi dimensi representasi pada lapisan dense pertama maka model dapat mempelajari pola yang lebih rumit dan mendalam dari data dengan menambahkan lapisan yang lebih padat yang dapat meningkatkan performa model dalam tugas klasifikasi gambar. terakhir evaluation di mana performa model pada testing data dinilai menggunakan hasil klasifikasi dan confusion matrix untuk memahami kinerjanya testing data. bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 23x23 menjadi 11x11 sebagai berikut. setiap filter diubah menjadi setengah dari ukuran inputnya 11x11 menjadi 5x5 dan jumlah neuronnya 18464 mengikuti lapisan konvolusi ketiga . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. ğ¼ğ‘›ğ‘ğ‘¢ğ‘¡ğ‘†ğ‘–ğ‘§ğ‘’ğ‘ƒğ‘œğ‘œğ‘™ğ‘†ğ‘–ğ‘§ğ‘’ ğ‘†ğ‘¡ğ‘Ÿğ‘–ğ‘‘ğ‘’1 112 21 9 21 5 7. fourth cov2d totalneuronukuranfilterxjumlahğ¶â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ğ¼ğ‘›ğ‘ğ‘¢ğ‘¡1xfilter 3x3x321x16 289x16 4624 jumlah channel input menggunakan jumlah filter dari convolutional layer sebelumnya bukan lagi channel input di awal. selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 5x5 menjadi 2x2 sebagai berikut. setiap filter diubah menjadi setengah dari ukuran inputnya 2x2 menjadi 1x1 dan jumlah neuronnya 4624 mengikuti lapisan konvolusi keempat . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. ğ¼ğ‘›ğ‘ğ‘¢ğ‘¡ğ‘†ğ‘–ğ‘§ğ‘’ğ‘ƒğ‘œğ‘œğ‘™ğ‘†ğ‘–ğ‘§ğ‘’ ğ‘†ğ‘¡ğ‘Ÿğ‘–ğ‘‘ğ‘’1 12 21 1 21 0.51 9. flatten tidak mengubah parameter yang ada karena fungsi flatten hanya mengubah matriks multidimensi menjadi vektor tunggal berdasarkan hasil dari jumlah filter pada lapisan lima cov2d yaitu 8 dan maxpooling2d dengan ukuran inputnya 1x1 sehingga menjadi matriks multidimensi 1 1 16 diubah menjadi nilai vektor tunggal dengan panjang 16 atau menjadi jumlah neuron sebanyak 16. 10. dense layer 1 totalneuronjumlahneuronğ¼ğ‘›ğ‘ğ‘¢ğ‘¡1xjumlahneuronğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡ 161x128 17x128 2176 11. dropout layer 1 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 1 akan dinonaktifkan secara acak. 12. dense layer 2 totalneuronjumlahneuronğ¼ğ‘›ğ‘ğ‘¢ğ‘¡1xjumlahneuronğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡ 1281x64 129x64 8256 13. dropout layer 2 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 2 akan dinonaktifkan secara acak. 14. dense layer 2 totalneuronjumlahneuronğ¼ğ‘›ğ‘ğ‘¢ğ‘¡1xjumlahneuronğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡ 641x1 65x1 65 ketika dimensi spasial tinggi dan lebar dikurangi menggunakan operasi lapisan pooling seperti maxpooling jumlah neuron di setiap lapisan pooling akan menurun. misalnya dimensi spasial setiap filter tinggi dan lebar di lapisan maxpooling disesuaikan menjadi setengah dari dimensi masukannya. karena hanya separuh dari masukan yang diproses lebih lanjut hal ini juga menyebabkan berkurangnya jumlah neuron pada lapisan tersebut. sedangkan penurunan pada dense terjadi karena penentuan jumlah neuron.
Devi Resviani_KUALIFIKASI.txt,"3.1 Tahapan Penelitian
Tahapan penelitian merupakan serangkaian langkah-langkah yang dilakukan dalam penelitian. Gambaran mengenai tahapan penelitian ini dapat dilihat pada Gambar 3.1. Tahapan penelitian ini terdiri dari studi literatur untuk memahami keadaan yang terfokus terhadap tentang mesin kompresor reciprocating, metode prediksi pemeliharaan mesin, predictive maintenance, dan machine learning. Preprocessing data melibatkan pembersihan data, normalisasi, dan transformasi data agar siap digunakan dalam model machine learning. Pengembangan dan melatih model machine learning menggunakan algoritma yang telah dipilih dengan data yang telah diperoses, tahap ini melibatkan pembagian data menjadi set pelatihan dan set pengujian, serta termasuk mengatur parameter model untuk mencapai kinerja terbaik. Tahap keempat analisis prediksi untuk memperkirakan kapan dan bagaimana kegagalan akan terjadi, sehingga pemeliharaan dapat direncanakan dengan tepat. Tahap kelima alert atau peringatan untuk memberikan informasi kepada tim pemeliharaan agar dapat segera mengambil tindakan. Tahap terakhir menjadwalkan tindakan pemeliharaan yang diperlukan berdasarkan peringatan untuk menghindari kegagalan mendadak dan meminimalkan downtime."
Erfiana Wahyuningsih_UK.txt,"3.1 KONSEP PENELITIAN
Untuk mempermudah dalam melakukan penelitian, maka dibuat sebuah flowchart agar penelitian tidak menyimpang dan salah. Berikut flowchart penelitian untuk rangkaian SRAM 6T Low power dan High read stability dengan metode m- GDI. Dalam memulai desain SRAM 6T dengan menggunakan metode m-GDI, diperlukan studi literatur terkait beberapa penelitian dengan metode atau hasil serupa. Referensi rangkaian diperlukan untuk melihat hasil sebagai pembanding dengan rangkaian baru yang didesain dengan metode m-GDI."
Fitriana Indah Pramitasari_Kualifikasi.txt,3.1 alur penelitian alur penelitian menggambarkan alur dari awal hingga akhir penelitian dilaksanakan. alur penelitian ini diuraikan pada gambar 3.1 di bawah ini. gambar 3.1 alur penelitian 27 3.2 identifikasi masalah identifikasi masalah adalah salah satu langkah pertama yang dilakukan sebelum melakukan penelitian. identifikasi masalah merupakan suatu proses mencari dan mengetahui masalah yang ingin diselesaikan. identifikasi masalah ini membantu penelitian untuk memah ami tantangan yang dihadapi oleh petani kentang skala nasional dan merancang solusi yang tepat sesuai dengan kebutuhan mereka. identifikasi masalah pada penelitian ini berfokus pada mengidentifikasi proses perancangan model koperasi petani mengidentifikas i metode prediksi permintaan dengan ann di dalam blockchain yang digunakan untuk mengoptimalkan permintaan pelanggan di masa depan selama periode tertentu dan mengidentifikasi metode safety stock di dalam blockchain yang digunakan agar dapat mengoptimalkan stok dan permintaan. identifikasi masalah pada penelitian ini peneliti dapat lebih memahami kendala dan kebutuhan petani kentang skala nasional. perancangan model platform koperasi untuk meningkatkan efisiensi dan kerjasama antarpetani dengan koperasi sebagai mitranya. sement ara itu metode prediksi permintaan dengan menggunakan artificial neural network ann diharapkan dapat membantu petani mengelola produksi secara lebih tepat sesuai dengan kebutuhan pasar dan koperasi dapat menyesuaikan persediaan stok dan permintaan secar a dinamis dari hasil prediksi permintaan. selain itu identifikasi masalah juga mencakup penerapan metode safety stock untuk mengoptimalkan manajemen stok memastikan ketersediaan barang dan meningkatkan responsibilitas terhadap fluktuasi permintaan pasar. dengan penerapan ann dan metode safety stock di dalam blockchain semua prediksi dan manajemen stok dapat dicatat di dlaam buku besar yang tidak dapat diubah sehingga meningkatkan transparansi dan keamanan data dalam rantai pasok. sehingga koperasi ini dapat melakukan perencanaan yang lebih akurat meminimalkan pemborosan dan meningkatkan ketersediaan kentang sesuai dengan kebutuhan pelanggan. dengan demikian platform koperasi menjadi responsif terhadap perubahan permintaan pasar mendukung pertumbuhan ekonomi para petani memperkuat kolaborasi antar anggota koperasi serta memiliki transparansi dan keamanan pada rantai pasok. 28 3.3 studi literatur studi literatur yang dilakukan pada penelitian engembangan platform koperasi petani ini dimulai dari pencarian dan review literatur literatur terbaru dan relevan yang telah diterbitkan. studi literatur juga membantu dalam mengetahui tantangan dan peluang yang mungkin dihadapi dalam pengembangan platform koperasi petani kentang. sehingga penelitian ini akan menghasilkan data yang sesuai dengan tujuan penelitian. proses ini memungkinkan peneliti untuk memahami konteks yang telah ada sebelumnya dan memanfaatkan pengetahua n serta data yang telah dihasilkan sebelumnya. beberapa wilayah indonesia berhasil dalam produksi kentang dan beberapa wilayah indonesia yang tidak dapat mempro duksi kentang. data tersebut memberikan gambaran lengkap mengenai kegiatan pertanian kentang di berbagai wilayah indonesia pada tahun 2022. berikut data bps tahun 2022 produksi kentang di berbagai wilayah indonesia. data primer yang akan digunakan pada penelitian ini adalah kebutuhan pengguna aliran data dari petani dengan koperasi sebagai mitranya data musim data historis penjualan data produksi kentang dan data harga kentang. berdasarkan informasi yang didapatkan dari salah satu petani di wonosobo jawa tengah disana terdapat banyak petani kentang dan sayuran lainnya. 30 gambar 3.2 pola distribusi kentang 3.5 blockchain pada penelitian ini untuk meningkatkan keamanan dan transparansi maka menggunakan teknologi blockchain untuk rantai pasok kentang. berikut flowchart kecerdasan buatan safety stock yang dikombinasikan di dalam blockchain. data rantai pasok yang telah dikumpulkan kemudian 31 dimasukkan ke dalam database. data tersebut diverifikasi dalam blockchain dengan proses pembuatan blok baru yang melibatkan perhitungan hash blok sebelumnya menyusun blok baru menghitung hash blok baru dan mencapai konsensus untuk menambahkan blok ke ra ntai. hasil prediksi permintaan disimpan dalam blockchain dengan proses pembuatan blok baru yang sama seperti langkah sebelumnya. hasil perhitungan safety stock disimpan dalam database dan dicatat dalam blockchain dengan pembuatan blok baru. 3.6 design sistem dengan uml pengembangan platform koperasi petani kentang menggunakan metode unified modeling language uml untuk menggambarkan struktur fungsi dan interaksi komponen sistem secara visual. analisis kebutuhan sistem dapat menentukan arah dan ruang lingkup proyek pengembang sistem serta memastikan bahwa produk akhir akan memenuhi harapan dan memecahkan masalah yang dihadapi oleh pengguna. pengguna platform ini terdiri dari consumers yang dapat mengakses produk pertanian secara langsung farmers yang memanfaatkan platform untuk memasarkan hasil panen companies yang terlibat dalam dukungan pengembangan teknologi dan partner cooperatives yang menjadi bagian dari 33 kolaborasi kerjasama antar koperasi untuk meningkatkan kesejahteraan bersama. keterlibatan seluruh pihak ini diharapkan platform koperasi petani menciptakan lingkungan yang saling mendukung dan berkelanjutan memperkuat konektivitas antar anggota untuk me ncapai tujuan bersama dalam dunia pertanian. proses verifi kasi produk kentang yang dihasilkan oleh petani. website koperasi akan mengirimkan informasi kepada konsumen bahwa transaksi telah berhasil dicatat. website koperasi mengubah status transaksi berdasarkan hasil verifikasi. input data yang akan digunakan a dalah data kuantitatif dan kualitatif yang dapat mempengaruhi permintaan di masa depan sehingga agar hasil prediksi permintaan dapat lebih akurat. dengan menerapkan metode ann pada prediksi permintaan ini penelitian dapat memberikan prediksi yang lebih tepat terkait kebutuhan pasar di masa mendatang sehingga dapat meningkatnya efektivitas rantai pasok. kemudian dilakukan data cleaning di normalisasi dan di transformasi untuk memastikan bahwa ann yang akan dibangun dapat bekerja dengan efektif dan menghasilkan prediksi yang akurat. berdasarkan hasil evaluasi model prediksi yang akurat dari model ann ini berguna untuk perusahan dalam membuat keputusan strategis seperti inventory management . proses prediksi permintaan dengan ann akan menghasilkan data permintaan yang diharapkan informasi tersebut digunakan untuk proses inventory management . 3.8 inventory management proses inventory management menggunakan metode safety stock merupakan proses untuk menjaga ketersediaan persediaan dalam platform secara efektif. tahapan pertama penelitian ini memerlukan analisis data historis 42 permintaan kentang fluktuasi pasokan dan waktu panen sehingga dapat mengidentifikasi kebutuhan pasokan dan resiko keterlambatan. penerapan metode safety stock pada penelitian ini akan menentukan tingkat persediaan tambahan yang diperlukan untuk mengatasi ketidakpastian dalam permintaan atau keterlambatan pasokan. hal ini bertujuan untuk memberikan keandalan dan menghindari kekurangan persediaan yang dapat mengha mbat operasional koperasi. metode safety stock dalam pengembangan platform koperasi petani kentang pada penelitian ini untuk meningkatkan efisiensi manajemen persediaan. selain itu integrasi ini melibatkan penggunaan artificial neural network ann dan metode safety stock yang terintegrasi dalam blockchain untuk rantai pasok. website koperasi akan terintegrasi dengan blockchain untuk memastikan efisiensi dan transparansi dalam seluruh proses manajemen rantai pasok. 3.10 pengujian sistem tahapan pengujian sistem dalam penelitian merupakan langkah untuk mengevaluasi kinerja atau fungsionalitas sistem yang dikembangkan atau diuji pada penelitian. proses pengujian sistem mencakup implementasi prototipe atau model sistem hingga serangkaian u ji coba. tujuan dari tahapan pengujian sistem adalah mengidentifikasi adanya kegagalan mengukur efektivitas sebuah sistem serta 43 memastikan sistem berjalan sesuai dengan tujuan dan persyaratan yang telah ditetapkan sebelumnya. pada penelitian ini sistem platform koperasi petani diharapkan dapat berjalan sesuai dengan tujuan dan persyaratan perkoperasian serta sesuai dengan model platform economic sharing . platform koperasi petani kentang pada penelitian ini akan berbasis website dan dilengkapi dengan kecerdasan buatan yang dikombinasikan dengan blockchain. 3.11 evaluasi tahapan selanjutnya adalah evaluasi. evaluasi dilakukan untuk memastikan bahwa semua komponen sistem berfungsi sesuai rencana. evaluasi melibatkan penilaian kinerja pada sistem secara keseluruhan dan memeriksa apakah integrasi berjalan tanpa hambatan. ta hapan evaluasi juga dapat mengidentifikasi apakah hasil pengujian sistem sesuai dengan tujuan awal dan menentukan area yang mungkin memerlukan peningkatan. hasil dari tahap evaluasi menjadi petunjuk penting untuk membuat perubahan dan peningkatan sehingga sistem dapat bekerja lebih baik lagi. 3.12 analisis hasil analisis merupakan tahapan penelitian dimana menyimpulkan serta menguraikan informasi dari hasil data yang telah diolah dan diuji sebelumnya. tahapan analisis dapat memberikan makna dari temuan temuan tersebut. tahapan ini memberikan identifikasi faktor faktor yang dapat mempengaruhi kinerja sistem dan memberikan rekomendasi untuk peningkatan di masa yang akan datang.
KUALIFIKASI_Riya Widayanti.txt,"Bab ini menyajikan desain yang digunakan dalam penelitian ini. Hal ini menentukan sumber dari mana data akan dikumpulkan dan bagaimana mengumpulkan dan menganalisis data ini. Pada bab ini akan dibahas mengenai filosofi keilmuan dari data governance, konsep teknolgi BLockchain dan penerapan data governance dalam teknologi blockchain di bidang pendidikan, yang akan memberikan pandangan utama saat melakukan penelitian. Skema Penelitian
Untuk menyelesaikan penelitian dirancang kerangka pikir yang menggambarkan langkah-langkah yang harus ditempuh, dapat dilihat penjelasan dan urutannya sebagai berikut:

3.2.1 Mendefinisikan Tata Kelola Data untuk Organisasi
Upaya Tata Kelola Data harus mendukung strategi dan tujuan bisnis. Strategi dan sasaran bisnis organisasi menginformasikan strategi data perusahaan dan bagaimana tata kelola data dan aktivitas manajemen data perlu dioperasionalkan dalam organisasi. Tata kelola data memungkinkan tanggung jawab bersama untuk keputusan terkait data. Kegiatan tata kelola data melintasi batasbatas organisasi dan sistem untuk mendukung tampilan data yang terintegrasi. Fokusnya adalah pada kesan yang dimiliki personel bisnis tentang seberapa baik perusahaan mengelola data dan menggunakan data untuk keuntungannya, serta pada kriteria objektif, seperti penggunaan alat, tingkat pelaporan, dll. Hasilnya ada bagaimana kerangka komunikasi dijelaskan dalam gambar 3.3. Kebijakan Penggunaan Data: Kebijakan tersebut menentukan tindakan tata kelola data termasuk hak, izin, dan kondisi. Penyimpanan Data Off-chain: Data pribadi harus disimpan off-chain untuk skalabilitas yang lebih baik dan efisiensi yang lebih tinggi. Selain itu, menyimpan data pribadi langsung ke clockchain, bahkan dalam bentuk terenkripsi, dapat menimbulkan potensi kebocoran privasi dan mengakibatkan ketidakpatuhan terhadap GDPR. Tergantung pada skenario tertentu, DBMS konvensional (misalnya, Oracle atau MongoDB), layanan penyimpanan awan (misalnya, S3, AWS atau Azure), atau sistem penyimpanan dapat digunakan untuk penyimpanan data. Hanya referensi ke data yang disimpan secara on-chain (yaitu, disimpan dalam buku besar terdistribusi). Referensi disebut penunjuk data itu bisa menjadi hash, string koneksi, jalur absolut, atau pengidentifikasi yang merujuk ke kumpulan data; tergantung pada sistem penyimpanan off-chain tertentu yang digunakan dalam platform."
Kualifikasi Witta Listiya Ningrum.txt,"3.1 Tahapan Penelitian
Penelitian ini melakukan pengembangan model klasifikasi toksisitas pada platform sosial media. Selain itu juga untuk menentukan dan membandingkan metode serta algoritma yang sudah digunakan pada penelitian sebelumnya, yang nantinya akan mengembangkan atau menciptakan suatu metode atau algoritma terbaru. Data tersebut harus mencakup berbagai jenis media, seperti teks, gambar dan video, untuk memungkinkan model mengenali toksisitas dari berbagai jenis konten yang ada pada platform sosial media. Large Language Model (LLM)
Large Language Model merupakan jenis model kecerdasan buatan (Artificial Intelligence) yang dilatih untuk memahami, menghasilkan dan memproses bahasa alami (Natural Languange) dalam skala besar. Generate Caption
Pada tahapan ini menggunakan model LLM, seperti BLIP atau Flamingo untuk menggabungkan kemampuan visual dan bahasa dalam menghasilkan teks/captioning dari representasi gambar dan video. Model Klasifikasi Toksisitas
Pada tahapan ini dilakukan pengembangan model dari hasil penggabungan ketiga representasi tersebut, dengan menggunakan teknik fusion, seperti concatenation atau attention mechanism untuk menghasilkan hasil klasifikasi akhir. Evaluasi Model
Pada tahapan ini dilakukan evaluasi untuk mengetahui kinerja terhadap model yang dikembangkan dengan menggunakan pengukuran akurasi, seperti precision, recall dan juga F1-score untuk klasifikasi teks, dan mengukur akurasi dengan confusion matrix untuk gambar dan video. Hasil
Tahapan ini menghasilkan klasifikasi sesuai dengan label yang sudah dikategorikan ke dalam 3 kategori toksisitas yaitu toxic, non-toxic, dan netral."
Kualifikasi_Aris Gunaryati.txt,"3.1 Gambaran Umum Penelitian
     Motivasi dari Metodologi yang diusulkan adalah membuat suatu metode peramalan yang sesuai dengan data runtun waktu yang ada serta meningkatkan akurasinya dengan tetap memperhatikan efisiensi waktu komputasinya. Langkah-langkah yang dilakukan dalam penelitian ini adalah menganalisis data jumlah kasus harian Covid 19 di Jakarta berdasarkan dataset dari situs https://corona.jakarta.go.id tanggal 6 Maret 2020 sampai 30 Juni 2021 sebagai data training dan nanti akan diprediksi untuk tanggal 1 Juli 2021 sampai dengan 31 Juli 2021 sebagai data uji dengan tahapan sebagai berikut :
1. Mempersiapkan data runtun waktu yang akan dianalisis
2. Menganalisis data runtun waktu yang ada menggunakan metode statistika ARIMA
3. Menganalisis data runtun waktu yang ada menggunakan metode Quantum Neural Network
4. Mengembangkan model Hybrid ARIMA-Quantum Neural Network
5. Melakukan perbandingan tingkat akurasi hasil peramalan dengan tiap model

Untuk mendapatkan model peramalan yang diharapkan sesuai dengan data runtun waktu yang ada, maka perlu dilakukan pendekatan ilmiah yaitu dengan melihat pola data runtun waktu yang ada terlebih dahulu. Pendekatan lainnya adalah menggunakan tools untuk menentukan secara otomatis Bentuk model statistik ARIMA yang sesuai dengan runtun waktu yang ada, lalu model tersebut dilatih menggunakan quantum neural network agar diketahui pola-pola data yang	sudah	ada	dan	dapat	diuji	akurasinya. Tahapan Analisis Time Series (ARIMA)
a. Membuat Plot Time Series
Identifikasi asumsi stasioneritas data runtun waktu. Suatu deret pengamatan dikatakan stasioner apabila proses tidak berubah seiring dengan perubahan waktu
Tidak stasioner dalam mean : jika trend tidak datar (tidak sejajar smbu waktu)
Tidak stasioner dalam varian : jika trend datar atau hampir datar, tetapi data tersebar membangun pola melebar atau menyempit (pola terompet)
Tidak stasioner dalam mean & varians : jika trend tidak datar dan data membentuk pola terompet. Semua sinyal yang diberi pengali bobot ini kemudian dijumlahkan satu sama lain untuk menghasilkan unit aktivasi. Unit aktivasi ini kemudian dibandingkan dengan sebuah nilai ambang, dan hasilnya dimasukkan kedalam fungsi transfer (fungsi non-linier) yang akan menghasilkan sebuah keluaran. Untuk fungsi hyperbolic tangent,

3.4 MODEL HYBRID ARIMA NEURAL NETWORK
      Berdasarkan hasil peramalan model ARIMA, akan dilakukan proses analisis runtun waktu menggunakan metode jaringan syaraf tiruan. Dengan kata lain, output dari peramalan model ARIMA akan menjadi input pada proses pengolahan data menggunakan metode jaringan syaraf tiruan. Kemudian akan ditentukan model jaringan syaraf tiruan yang sesuai dan cocok untuk data runtun waktu tersebut. Secara matematis, hasil ramalan secara keseluruhan yang diperoleh adalah sebagai berikut :
Zt merupakan hasil peramalan yang merupakan gabungan nilai ramalan dari model ARIMA atau Exponential Smoothing dan nilai ramalan dari model JST. 3.5 MODEL QUANTUM HYBRID ARIMA NEURAL NETWORK
      Ada banyak pendekatan untuk pengembangan model Quantum Arima NN. Mirip dengan bit klasik, gerbang dasar dapat membentuk gerbang kuantum bemacam-macam dan menyelesaikan keadaan kuantum dari beberapa logika transformasi. berbasis elemen pada gerbang pergeseran fasa 1 bit dan gerbang kontrol-Tidak 2 bit dalam dinamika kuantum diambil sebagai fungsi aktivasi dalam Jaringan saraf. Untuk memudahkan aplikasi, formulir berikut:
Fungsi kompleks diberikan untuk menyatakan keadaan kuantum:
adalah bilangan imaginer adalah kuantum fase

3.6 Pengukuran Kinerja
3.6.1 Mean Squared Error
      Dalam statistik, Mean Squared Error (MSE) sebuah estimator adalah nilai yang diharapkan dari kuadrat error. Error yang ada menunjukkan seberapa besar perbedaan hasil estimasi dengan nilai yang akan diestimasi. Perbedaan itu terjadi karena adanya keacakan pada data atau karena estimator tidak mengandung informasi yang dapat menghasilkan estimasi yang lebih akurat
3.6.2 Komparasi Hasil Peramalan
      Setelah nilai Mean Squared Error dari kedua metode didapatkan, maka akan dilakukan komparasi terhadap nilai MSE yang didapatkan pada periode testing (out- sample)
Jika nilai MSESTATISTIKA < MSEANN maka metode Statistika memiliki performa lebih baik dibandingkan metode ANN karena memiliki tingkat kesalahan relatif lebih kecil. Sebaliknya, jika MSESTATISTIKA > MSEANN maka metode Statistika memilki performa lebih buruk dibandingkan metode ANN karena tingkat kesalahan yang dihasilkan relatif lebih besar."
Kualifikasi_Rama Dian Syah.txt,"3.1   Tahapan Penelitian
      Tahapan penelitian dibagi atas beberapa tahapan yang dilakukan dari awal sampai akhir. Pada penelitian ini mengajukan pengembangan algoritma kriptografi citra digital dengan mengkombinasi teknik konfusi dengan algoritma Cat Map dan Henon Map serta teknik difusi dengan algoritma Logistic Map. Pengembangan pada algoritma ini diharapkan dapat memiliki keamanan yang lebih tinggi dengan melalui beberapa parameter pengujian. Nilai PSNR = 30 dB membuktikan kualitas yang baik pada citra asli atau citra terdekripsi (Lone et al., 2021)."
Kualifikasi_Remigius.txt,"Dalam proses pengembangan sistem pembelajaran arsitektur berbasis metaverse ini, peneliti juga ingin menunjukkan perlunya keterlibatan komunitas dan persepsi pengguna bidang arsitektur agar sistem pembelajaran yang dihasilkan sesuai dengan kebutuhan dan harapan mereka dalam meningkatkan efektivitas pembelajaran arsitektur itu sendiri. Diharapkan, sistem pembelajaran arsitektur berbasis metaverse ini dapat memberi kemudahan kepada komunitas dosen dan mahasiswa dalam mempelajari berbagai sisi arsitektur dengan memasuki dunia virtual dan mereka dapat memahami materi yang diajarkan serta memecahkan permasalahan arsitektur yang dihadapi secara interaktif, kolaboratif, dan imersif dengan solusi tepat tanpa harus mencari berbagai referensi wujud nyata arsitektur di dunia fisik atau dunia nyata. Dengan konsep pembelajaran matakuliah Perkembangan Arsitektur 1 yang dilakukan dengan metode metaverse, pembelajaran secara online ini dapat dilakukan dengan lebih interaktif. 3.2 Kerangka Penelitian
      Penelitian ini dilakukan dalam mencapai tujuan utama, yaitu pengembangan sistem pembelajaran arsitektur berbasis metaverse, terutama terkait perkembangan arsitektur. Penelitian ini dilakukan melalui beberapa tahap, antara lain:
      Tahapan Pengembangan Sistem Pembelajaran Perkembangan Arsitektur 1 Berbasis Metaverse

4. Efektivitas Pembelajaran Kolaboratif
- Presensi
- Imersi
- Kehadiran dalam realitas yang disimulasi
- Kapabilitas metaverse dalam membentuk lingkungan pengguna untuk memahami
realitas


- Pemahaman materi pembelajaran
- Kemampuan memahami materi pembelajaran Perkembangan Arsitektur berbasis
metaverse
Penelitian mengenai pengembangan sistem pembelajaran Perkembangan Arsitektur 1 berbasis metaverse ini dilakukan dengan melibatkan komunitas, yang terdiri dari dosen dan mahasiswa, di Program Studi S1 Arsitektur, Jurusan Teknik Arsitektur. Dalam mewujudkan sistem pembelajaran Perkembangan Arsitektur 1 berbasis metaverse ini, peneliti juga melakukan konstruksi avatar dan konten pembelajaran Perkembangan Arsitektur 1 di dalam dunia digital, sehingga terbentuk dunia virtual berbasis konten pembelajaran Perkembangan Arsitektur. Dalam hal ini, komunitas dosen dan mahasiswa ini melakukan koneksi ke dunia virtual berupa sistem pembelajaran Perkembangan Arsitektur berbasis metaverse dan semua jenis kegiatan yang dilakukan dalam menyelesaikan masalah dan menyediakan solusi yang diperlukan dapat tersimpan dalam basis data server, sehingga dapat diambil kembali setiap kali mereka masuk dan terlibat kembali dalam sistem pembelajaran virtual kolaboratif ini. Dalam sistem pembelajaran virtual kolaboratif ini, komunitas dosen dan mahasiswa dapat berinteraksi satu sama lain dalam penyelesaian masalah yang ada dan mencari solusi yang diperlukan, sehingga mereka benar-benar dapat hadir dan terlibat di dalam sistem pembelajaran Perkembangan Arsitektur 1 berbasis metaverse secara intensif, interaktif, dan imersif. Efektivitas Pembelajaran Kolaboratif
      Pada tahap ini, peneliti menguji efektivitas pembelajaran kolaboratif yang didasarkan pada persepsi pengguna mengenai sistem pembelajaran Perkembangan Arsitektur 1 berbasis metaverse. Keempat, pada aspek outcome, persepsi pengguna juga dieksplorasi dan dievaluasi tentang ketercapaian tujuan dari pembelajaran Perkembangan Arsitektur 1 berbasis metaverse sesuai dengan kriteria dan indikator yang ditetapkan dosen pengampu. 3.3 Pendekatan Penelitian
      Penelitian ini dilakukan menggunakan pendekatan kuantitatif eksperimental terhadap sistem pembelajaran Perkembangan Arsitektur berbasis metaverse yang dikembangkan dalam komunitas dosen dan mahasiswa Jurusan Teknik Arsitektur, Program Studi S1 Arsitektur Universitas Gunadarma. Sistem pembelajaran berbasis metaverse ini dikembangkan sesuai dengan materi pembelajaran Perkembangan Arsitektur 1 di kalangan mahasiswa Jurusan Teknik Arsitektur semester 3. Apabila pengembangan sistem pembelajaran ini sudah selesai, model pembelajaran berbasis metaverse tersebut diuji validitas dan reliabilitasnya dengan melibatkan penilaian objektif dan otoritatif dari para ahli,
baik ahli materi maupun media pembelajaran. Jika model sistem pembelajaran berbasis metaverse ini sudah dinyatakan valid dan reliabel, model tersebut diujicobakan kepada komunitas pengguna yang terdiri dari dosen dan mahasiswa dari Jurusan Teknik Arsitektur semester 3, sehingga akhirnya dapat diketahui efektivitas pembelajaran kolaboratif berbasis metaverse tersebut sesuai dengan kriteria dan indikator yang ditetapkan oleh dosen pengampu. Efektivitas pembelajaran kolaboratif berbasis metaverse dalam penelitian ini dievaluasi dengan melihat peningkatan pemahaman mahasiswa mengenai materi pembelajaran Perkembangan Arsitektur sesuai dengan kriteria dan indikator yang ditetapkan oleh dosen pengampu. Dari hasil uji efektivitas sistem pembelajaran ini, diharapkan dapat diketahui sejumlah kelebihan dan kekurangannya, sehingga dapat dijadikan sebagai bahan pertimbangan rekomendasi dalam meningkatkan kualitas sistem pembelajaran Perkembangan Arsitektur berbasis metaverse tersebut."
Miftakhul Zaen_KUALIFIKASI.txt,3.1 tahapan penel itian dalam penelitian mengenai pengembangan algoritma dbscan dengan kuantum terdapat langkahlangkah yang dilakukan seperti pada gambar 3.1. langkah langkah yang dilaukan d iantaranya yaitu pengumpulan data definisi qubits kriteria inisialis asi sistem kuantum hingga evaluasi klaster. data definisi qubits kriteria inisialisasi sistem kuantum penentuan eps dan minpts kuantum identifikasi core supplier dengan kuantum sirkuitidentifikasi noise supplier dengan kuantum sirkuit penanganan noise dengan kuantum stateformasi klaster supplier dengan kuantum measurementimplementasi quantum distance measure identifikasi core supplier dengan kuantum sirkuit evaluasi klaster1 2 3 4 5 6 9 10 117 8 gamb ar 3.1 tahapan penel itian 1. data tahap awal dalam penelitian di awali dengan pembuatan data dimana data yang digunakan pada penel itian ini adalah data s intetik. data sintetik digunakan untuk mendapatkan jumlah data yang besar sela in itu data sintetik juga b ersifat fleksibel kar ena ju mlah data yang digunakan dapat ditentukan sesuai dengan kebutuhan pengujian algo ritma yang dikembang kan. data sintetik yang dibuat berisikan nama supplier harga kualitas dan waktu pengiriman. 2. definis i qubits kriteria pada taha p ini kriteria yang digunak an untuk pengelompokan supplier diubah menjadi representasi kuantum menggunakan qubits. 10. formasi kluster supplier dengan quantum measurement pada tahapan ini m embentukan klaster supplier dengan mengukur state kuantum yang telah diubah melalui interaksi antar qubits yang mewakili supplier . tahapan ini bertujuan untuk menilai seberapa baik kluster yang terbentuk mengguna kan. 3.2 rangkuman langkah langk ah penelitian setelah mengembangkan algoritma kuantum dbscan selanjutnya membandingk annya dengan algo ritma dbscan untuk mengetahui seberapa baik algoritma dbscan jika dibandingkan dengan algorit ma klasiknya . data definisi qubits kriteria inisialisasi sistem kuantum penentuan eps dan minpts kuantum identifikasi core supplier dengan kuantum sirkuitidentifikasi noise supplier dengan kuantum sirkuit penanganan noise dengan kuantum stateformasi klaster supplier dengan kuantum measurementimplementasi quantum distance measure identifikasi core supplier dengan kuantum sirkuitnormalisasi data penentuan epsilon dan minpts hitung jarak antar supplier identifikasi core supplier identifikasi core supplieridentifikasi noise supplier supplier tidak termasuk dalam klasterformasi klaster supplier evaluasi klasterusulan algoritma gambar 3.2 rangkuman langkah langkah prosedur penelitian
Ragmar Faikar Eka_Kualifikasi.txt,tahapan penelitian dijelaskan dalam bentuk flowchart sehingga dapat menjelaskan proses yang dilakukan mulai dari studi literatur sampai dengan kesimpulan jadwal dan estimasi penelitian digambarkan dalam bentuk time table untuk menjadwalkan dan melakukan estimasi waktu dari tiap tahap yang dilakuk an. 3.1.2 pengumpulan data tahap kedua yaitu pengumpulan data data yang digunakan pada penelitian ini adalah data citra digital kelapa sawit dengan tingkat kematangan belum matang setengah matang matang terlalu matang dan tandan buah yang kosong . gambar asli akan dilakukan resize menjadi ukuran 224x224 piksel lalu data tersebut akan di augmentasi untuk memperbanyak dan m emvariasi data agar dan hasil augmentasi akan dijadikan sebagai data latih untuk model yang dibuat. 32 3.1.4 pembuatan model tahap keempat yaitu pembuatan model machine learning menggunakan mobilenetv3 smalllarge dan menggabungkannya dengan attention module cbam convolutional block attention module. proses pembuatannya meliputi pembuatan tampilan user memasukan tflite ke dalam aplikasi sehingga aplikasi dapat menggunakan model machine learning untuk mengklasifikasi kematangan kelapa sawit menggunakan kamera smartphone. tahun pertama tahun kedua tahun ketiga studi literatur evaluasi model submit jurnal pertama pembuatan proposal bab 1 sampai bab 3 deploy dimplementasi model pembuatan jurnal kedua pengumpulan dataset pembua tan aplikasi submit jurnal kedua preprocessing data menulis hasil penelitian bab 4 pembuatan model pengujian dan evaluasi aplikasi melatih model menulis hasil penelitian bab 4 dan bab 5 pembuatan jurnal pertama tabel 2. kegiatan penelitian kegiatan yang dilakukan pada tahun pertama yaitu melakukan studi literaur untuk pembuatan proposal penelitian bab 1 sam pai bab 3 lalu dilanjutkan dengan pengumpulan dan preprocessing data setelah mendapatkan data kegiatan pembuatan dan pelatihan m odel dapat dilakukan. pada tahun kedua dilakukan evaluasi model dan saat hasil evaluasi model sudah cukup baik model akan di deploy untuk dapat diimp lementasi ke dalam aplikasi yang sudah dibuat. aplikasi akan dievaluasi dan diuji kinerjanya sehingga mendapatkan kesimpulan dari peneli tian untuk ditulis da lam b ab 4 sampai bab 5 . pada akhir tahun kedu a setelah mendapatkan kesimpulan penelitian dilakukan pembuatan jurnal pertama dan dilanjutkan pada tahun ketiga untuk pembuatan jurnal kedua.
Reviana Siti Mardiah_Kualifikasi.txt,3.1 tahapan penelitian tahapan penelitian merupakan gambaran dari langkah langkah atau proses yang akan dilakukan dalam suatu penelitian. tahap an kedua adalah membuat model manajemen persediaan beras perum bulog berdasarkan hasil wawancara awal dengan pihak terkait. tahap ketiga adalah melakukan analisis terhadap model manajemen persediaan beras perum bulog untuk mengidentifikasi area yang perlu ditingkatkan . hasil analisis ini akan digunakan untuk merumuskan solusi terhadap permasalahan yang ada . tahap keempat adalah pengembangan solusi berbasis teknologi yang terdiri dari pengembangan be rbagai model dan prototype sistem yang akan diuji . usulan yang pertama adalah model generative ai untuk menghasilkan data sintetis yang realistis yang dapat digunakan sebagai data pelatihan untuk model prediksi . model ini kemudian diintegrasikan ke dalam model ml prediksi produksi hasil panen . usulan yang kedua adalah model prediksi permintaan beras yang merupakan model yang mirip dengan model prediksi produksi hasil panen beras dengan beberapa penyesuaian agar sesuai dengan karakteristik data untuk prediksi permintaan beras. usulan yang ketiga adalah pengembangan prototype decision support system yang mengintegrasikan model prediksi dan optimasi untuk mendukung kebijakan terkait pengadaan cadangan beras . tahap kelima adalah uji coba terhadap prototype decision support system . 1 tahapan penelitian 3.2 pemodelan manajemen persediaan beras perum bulog manajemen persediaan cadangan beras nasional telah menjadi perhatian penting dalam beberapa tahun terakhir karena meningkatnya permintaan pangan global perubahan iklim dan ketidakstabilan ekonomi. cadangan ini merupakan stok strategis yang diawasi oleh pemerintah untuk menstabilkan persediaan dan harga beras memberikan bantuan saat terjadi kekurangan pangan dan mendukung tujuan ketahanan pangan nasional . manajemen persed iaan cadangan beras yang efektif sangat penting untuk memitigasi risiko yang terkait dengan gangguan persediaan dan fluktuasi harga beras yulianis rachman 2021 yang pada akhirnya akan menjamin ketahanan pangan dan stabilitas ekonomi octania 2021 usdianto setiyowati 2023 . 60 para pemangku kepentingan yang terlibat dalam manajemen cadangan beras ini termasuk kementerian pertanian kementerian perdagangan kem enteri an keuangan dan kem enteri badan usaha milik negara sebagai regulator serta perum bulog yang bertanggung jawab untuk mengelola persediaan beras pemerintah dan stabilisasi harga di tingkat produsen dan konsumen octania 2021 . perum bulog bertanggung jawab untuk menjaga stabilitas harga dengan membeli gabah dan beras dari petani dengan harga yang ditentukan pemerintah ketika harga beli gabah turun sehingga melindungi petani dari kerugian dan menjual beras dengan harga yang lebih rendah daripada harga pasar ketika terjadi kenaikan harga beras untuk memastikan keterjangkauan harga beras bagi masyarakat octania 2021 . lembaga ini bertanggung jawab atas manajemen salah satu komponen cadangan beras nasional yaitu cadangan beras pemerintah cbp termasuk pada pengadaan dalam negeri dan impor penyimpanan dan penyaluran beras untuk kebutuhan stabilisasi harga bantuan pangan dan keadaan darurat fang chen zhang pei gao wang 2020 octania 2021 . beberapa penelitian telah menekankan peran penting perum bulog dalam manajemen persediaan cadangan beras di indonesia . melalui manajemen cbp perum bulog memainkan peran penting dalam menjaga ketahanan pangan nasional terutama saat terjadi fluktuasi harga atau gangguan p ersediaan . keberadaan cbp yang dikelola perum bulog tidak hanya menstabilkan harga beras di pasar tetapi juga menjamin ketersediaan beras bagi masyarakat sehingga berkontribusi terhadap stabilitas ekonomi nasional octania 2021 putro purwaningsih sensuse suryono 2022 silalahi et al. mengingat peran penting ini penerapan teknologi ai dapat membantu perum bulog dalam mengoptimalkan berbagai aspek dalam manajemen cadangan beras pemerintah seperti prediksi permintaan dan produksi hasil panen optimasi cadangan beras dan pengambilan keputusan yang lebih baik. ai dapat digunakan untuk menganalisis data historis dan realtime guna menghasilkan prediksi yang akurat mengenai permintaan dan produksi hasil panen beras mehmood et al. 2021 sehingga memungkinkan 61 perum bulog untuk mengoptimalkan cadangan beras menghindari kelebihan atau kekurangan cadangan beras dan mengambil keputusan yang lebih baik dalam manajemen cadangan beras pemerintah h. qin 2023 . berdasarkan kajian model manajemen persediaan beras perum bulog maka penelitian ini berfokus pada pemanfaatan teknologi ai untuk efektivitas manajemen cadangan beras pemerintah terutama pada proses pengadaan . gambar 3.1 menggambarkan model manajemen persediaan beras perum bulog . 2 model manajemen persediaan perum bulog 3.3. analisis analisis ini bertujuan untuk mengungkap kelemahan dan proses yang kompleks dalam manajemen persediaan cadangan beras pemerintah di perum bulog . penelitian ini menggunakan metode analisis swot untuk mengidentifikasi titik titik lemah yang krusial dalam manajemen persediaan cadangan beras pemerintah dan mengembangkan strategi untuk meningkatkan efisiensi dan efektivitas pengelolaan persediaan cadangan beras di indonesia analisis swot bertujuan untuk mengetahui kekuatan kelemahan peluang dan ancaman bisnis. 62 1. analisis swot 1. strengths kekuatan s1 dukungan pemerintah perum bulog didukung oleh berbagai kebijakan pemerintah yang bertujuan menjaga stabilitas harga dan ketersediaan beras seperti yang diatur dalam uu no. s2 infrastruktur logistik yang memadai perum bulog memiliki infrastruktur logistik yang cukup baik termasuk gudang penyimpanan yang tersebar di berbagai daerah yang berperan penting dalam menjaga kecukupan persediaan cadangan beras octania 2021 utomo 2020 s3 pengalaman dan keahlian perum bulog memiliki pengalaman puluhan tahun dalam manajemen persediaan beras mulai dari pengadaan hingga distribusi yang menjadi keunggulan dalam menjaga stabilitas harga dan persediaan beras anggraini et al. gambar 3.3 menggambarkan perbedaan yang signifikan antara harga gabah di tingkat petani dengan harga beli yang ditetapkan pemerintah. kon disi ini menyebabkan petani lebih memilih menjual hasil panennya ke sektor swasta. 1 jumlah impor beras bps 2024 negara asal 2017 2018 2019 2020 2021 2022 2023 berat bersih ton india 32209.7 337999 7973.3 10594.4 215386.46 178533.57 69715.7 thailand 108944.8 795600.1 53278 88593.1 69360.037 80182.506 1381921.2 vietnam 16599.9 767180.9 33133.1 88716.4 65692.874 81828.039 1147705.3 pakistan 87500 310990 182564.9 110516.5 52479.011 84407 309309.7 myanmar 57475 41820 166700.6 57841.4 3790 3830 141204 jepang 72.1 0.2 90 0.3 230.291 56.087 61.5 tiongkok 2419 227.7 24.3 23.8 42.601 6 7 lainnya 54.3 6.5ssss 744.6 0.3 760.146 364.065 12933.3 total 305274.8 2253824.4 444508.8 356286.2 407741.42 429207.27 3062857.6 02000400060008000 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024perbandingan harga rata rata gkp di tingkat petani dan harga pembelian pemerintah tingkat petani kelompok kualitas gkp gabah kering panen tingkat petani hpp harga pembelian pemerintah gkp gkp gabah kering panen64 gambar 3. 3. opportunities peluang o1 memanfaatkan teknologi canggih integrasi teknologi canggih seperti blockchain dan ai berpotensi meningkatkan presisi transparansi dan efisiensi dalam mengelola persediaan cbp anggraini et al. 0500000100000015000002000000250000030000003500000 2017 2018 2019 2020 2021 2022 2023berat bersih tonimpor beras tahun 2017 2023 impor beras65 o2 pengembangan sistem yang terintegrasi terdapat peluang untuk mengembangkan sistem yang lebih terintegrasi dan canggih yang dapat memfasilitasi pengelolaan cbp yang lebih baik anggraini et al. 2. strategi setelah dilakukan analisis swot maka dapat dirumuskan strategi yang dapat digunakan perum bulog untuk meningkatkan kekuatan mengatasi kelemahan memanfaatkan peluang dan meminimalkan potensi ancaman . a. strategi s o leveraging strengths to optimize opportunities so1 pemanfaatan teknologi blockchain untuk transparansi dan efisiensi memanfaatkan dukungan pemerintah untuk mengadopsi teknologi blockchain dalam manajemen pangan yang dapat meningkatkan transparansi efisiensi dan keamanan dalam transaksi dan pencatatan. 66 so2 pengembangan sistem terintegrasi meningkatkan infrastruktur yang sudah ada dengan mengembangkan sistem manajemen data yang terintegrasi dan canggih untuk memperkuat pengelolaan cbp secara lebih efektif s2 o2. so3 pengembangan model prediksi permintaan dan produksi hasil panen memanfaatkan ai untuk mengembangkan model prediksi permintaan dan produksi hasil panen beras yang akurat sehingga memungkinkan pengambilan keputusan pengadaan yang lebih tepat untuk menghindari kelebihan atau kekurangan persediaan s3 o1 o2. so4 optimalisasi program peningkatan produksi pangan memanfaatkan tenaga ahli dan infrastruktur yang ada untuk mendukung program pemerintah dalam meningkatkan produksi pangan lokal mengurangi ketergantungan impor serta memperkuat stabilitas harga dan persediaan beras s1 s3 o3. b. strategi s t using strengths to counter threats st1 pengembangan alat pendukung keputusan untuk pengadaan impor mengembangkan decision support tool dst dengan menggunakan input dari model prediksi untuk membantu menentukan kebijakan impo r beras. st2 optimalisasi manajemen krisis dengan prediksi produksi hasil panen menerapkan model prediksi hasil panen untuk mempersiapkan dan merespons secara efektif dampak perubahan iklim pada produksi beras . model prediksi ini dimanfaatkan untuk meningkatkan ketahanan pangan dan kesiapan dalam menghadapi fluktuasi hasil panen yang tidak terduga s3 t2. wo2 peningkatan koordinasi antar lembaga melalui sistem terintegrasi membangun sistem terintegrasi yang melibatkan semua lembaga terkait untuk mengatasi masalah kurangnya koordinasi dan perbedaan data serta memfasilitasi pengambilan keputusan yang lebih cepat dan akurat w5 o2. wt2 peningkatan manajemen persediaan melalui analisis tingkat lanjut meningkatkan sistem manajemen persediaan dengan model prediksi agar lebih responsif terhadap perubahan permintaan dan kondisi darurat serta mengurangi risiko kekurangan persediaan dan mengatasi fluktuasi harga w3 t2. strategi tersebut meliputi pengembangan model prediksi permintaan dan produksi optimasi manajemen krisis dengan prediksi produksi pembuatan alat pendukung keputusan untuk pengadaan optimasi kebijakan impor dengan model prediksi dan peningkatan manajemen persediaan melalui analisis lanjutan. strategi strategi ini bertujuan untuk meningkatkan kinerja perum bulog dalam manajemen cadangan beras pemerintah cbp dan dapat memberikan rekomendasi berbasis data untuk mendukung kebijakan pengadaan cadangan beras . 3.4. pengembangan model prediksi produksi hasil panen beras gambar 3. 6 menggambarkan delapan tahapan yang dijalani dalam pengembangan model prediksi untuk produksi hasil panen beras pada penelitian ini. setiap tahap dirancang untuk memastikan keakuratan dan efektivitas model dalam memprediksi hasil panen . 3.4.1 pengumpulan data pengembangan model prediksi produksi hasil panen ini akan menggunakan data yang dikumpulkan dari website badan pusat statistik bps dan bmkg . eda memungkinkan prediksi produksi hasil panen yang tepat dengan membangun fondasi yang kuat untuk pemodelan tingkat lanjut . tahap ini sangat penting untuk menghasilkan model prediksi berbasis machine learning yang akurat dan efektif. proses untuk memilih hyperparameter terbaik dalam model machine learning untuk meningkatkan kinerja dikenal sebagai penyetelan hyperparameter tuning soleymani mohammadzadeh 2023 . meskipun memerlukan upaya yang cukup besar penyetelan ulang dapat menghasilkan peningkatan signifikan dalam performa prediksi. rmse mengukur besarnya tingkat kesalahan prediksi dimana semakin rendah nilainya mendekati nol maka hasil prediksi akan semakin akurat. 13 flowchart evaluasi model pada tahap evaluasi model juga diuji dengan dua rancangan yang berbeda yaitu model tanpa features engineering serta pada model dengan features engineering. 6 adalah hasil evaluasi model pada penelitian ini. 6 hasil evaluasi model dataset kondisi tanpa feature engineering kondisi dengan feature engineering r2 rmse mae r2 rmse mae 7030 0773 0441 0176 0933 0209 0115 8020 0795 0418 0155 0956 0163 0099 9010 0976 0111 0079 0976 0109 0076 84 hasil evaluasi menunjukkan pengaruh positif dari penggunaan feature engineering fe terhadap kinerja model machine learning dalam skema pembagian dataset yang berbeda 7030 8020 dan 9010. khususnya penggunaan feature engineering membantu meningkatkan nilai rÂ² yang menandakan peningkatan kemampuan model dalam menjelaskan variabilitas data yang diamati. analisis lebih lanjut pada perbedaan skema pembagian data menunjukkan bahwa model dengan proporsi data pelatihan yang lebih besar 9010 menunjukkan hasil yang paling stabil dan akurat. hal i ni menyoroti pentingnya fe dalam meningkatkan efektivitas model dan menunjukkan keuntungan dari alokasi yang lebih besar pada data pelatihan dalam pengembangan model prediksi berbasis machine learning . nilai rmse terendah yang diperoleh adalah 0109 yang me nunjukkan potensi model untuk menghasilkan prediksi produksi yang sangat akurat jika terus dikembangkan. 2021 mendapatkan nilai rmse 33.575.59574 untuk model prediksi nya hal ini menunjukkan bahwa model prediksi yang diusulkan memiliki potensi untuk menyaingi model yang ada dalam hal keakuratan hasil prediksi . meskipun hal ini tidak mutlak karena model ini dibangun dengan algoritma dan data yang berbeda. namun potensi model ini menghasilkan prediksi yang sangat akurat masih terlihat. berdasarkan hasil ini penelitian ini akan fokus pada penambahan data pelatihan menggunakan generative adversarial network gan dan pengembangan lebih lanjut pada teknik feature engineering untuk meningkatkan kinerja prediksi. 3.5 pengembangan model prediksi permintaan model prediksi yang digunakan untuk prediksi permintaan adalah model yang sama dengan yang digunakan untuk memprediksi produksi atau hasil panen . gambar 85 3.14 adalah tahapan pengembangan model prediksi permintaan pada penelitian ini. 14 tahapan penelitian prediksi permintaan yang diusulkan 86 pengembangan model prediksi permintaan beras ini terdiri dari delapan tahap. tahap kedelapan adalah evaluasi hasil yang meliputi pengukuran performa model yang dapat dilihat dari nilai r2 root mean squared error rmse dan mean absolute error mae. jika performa model perlu ditingkatkan hyperparameter dapat disesuaikan kembali di tahap k etujuh . setelah performa terbaik tercapai model dapat diintegrasikan ke dalam model decision support system . 3.6 prototype decision support system dss untuk pengadaan cadangan beras pemerintah decision support system dss pada penelitian ini akan digunakan untuk mendukung proses pengambilan keputusan internal terkait kebijakan pengadaan cadangan beras pemerintah . dss ini akan mengintegrasikan data hasil prediksi produksi hasil panen permintaan dan persediaan aktual untuk menentukan variabel keputusan pengadaan yang optimal. alat ini memungkinkan perum 87 bulog untuk merencanakan dan mengelola cadangan beras pemerintah cbp secara efisien sesuai dengan kebutuhan masyarakat . proses ini dimulai dengan perum bulog memeriksa tingkat persediaan cbp. proses ini dimulai dengan penerimaan data tentang prediksi produksi hasil panen dalam negeri dan kebutuhan beras mendatang. selanjutnya evaluasi kondisi pasar beras internasional kebijakan pemerintah dan perubahan iklim global . lalu dilakukan perhitungan terhadap jumlah cadangan beras pemerintah cbp yang optimal yang menentukan jumlah beras yang harus disimpan untuk kebutuhan darurat. berbeda dengan metode heuristik drl lebih kuat dengan hasil konvergensi yang stabil dan lebih cocok untuk masalah pengambilan keputusan z. zhang zhang qiu 2019 . 16 diagram alir skenario dasar pengambilan keputusan 89 berdasarkan data persediaan aktual dilakukan evaluasi apakah jumlah tersebut sudah mencukupi untuk memenuhi prediksi permintaan atau kebutuhan beras mendatang . sebaliknya jika persediaan dinilai belum mencukupi kebutuhan maka akan dilakukan penyerapan atau pengadaan dari produksi hasil panen dalam negeri . pada kondisi di mana produksi hasil panen dalam negeri yang ada pada petani atau mitra kerja perum bulog sangat minim maka akan dilakukan pengadaan dari sumber dalam negeri dan impor untuk mengisi kekurangan tersebut. jika kondisi di mana produksi hasil panen dalam negeri kosong. output dari dss ini adalah sebuah rekomendasi untuk strategi dan jumlah pengadaan beras. rekomendasi ini dapat digunakan oleh perum bulog untuk membuat kebijakan pengadaan beras khususnya dalam menentukan kebutuhan akan impor beras. dss yang diusulkan adalah sebuah platform yang mengintegrasikan dua model prediksi dan proses optimasi untuk cadangan persediaan beras pemerintah . sistem ini membantu perum bulog dan lembaga terkait dalam me ngambil kebij akan strategis terkait pengadaan cadangan beras pemerintah . hal ini untuk memastikan ketersediaan cadangan beras pemerintah cbp sehingga mendukung stabilitas harga dan ketahanan pangan n asional. 17 prototype dss yang diusulkan 3.7 uji coba uji coba sistem bertujuan untuk memvalidasi apakah sistem yang dikembangkan sesuai dengan tujuan awal dan layak untuk digunakan. hal ini termasuk fungsi yang salah atau hilang kesalahan interface masalah dengan struktur data atau akses database eksternal kesalahan kinerja serta kesalahan yang terkait dengan operasi dan shutdown sistem corso moss koren lee kochenderfer 2021 .
Reza Al Husna_Kualifikasi.txt,3.1 tahapan penelitian secara garis besar penelitian ini terdiri dari beberapa tahapan yaitu akuisisi data preprocessing data pengembangan dan pelatihan model pengujian dan evaluasi model serta pengembangan system deteksi penyakit daun kakao ditunjukkan pada gambar 3.1. gambar 3.1 tahapan penelitian 3.2 akuisisi data penyakit daun tanaman kakao pengumpulan citra penyakit daun tanaman kakao dikumpulkan secara langsung oleh peneliti data primer dan juga menggunakan data yang dikumpulkan oleh peneliti lain data sekunder. terdapat 4 kelas penyakit dan satu kelas daun sehat yang akan digunakan dalam penelitian ini yaitu daun sehat penyakit antraknosa colletotrichum gloeosporioides penyakit vascular streak dieback vsd penyakit leaf blotch dan penyakit cocoa swollen shoot virus disease cssvd. 46 gambar 3.2 contoh 4 jenis penyakit daun tanaman kakao dataset primer akan dilakukan pengambilan foto penyakit daun tanaman kakao yang terdapat pada kebun kakao di daerah kabupaten solok provinsi sumatra barat. dataset sekunder meng gunakan dataset yang telah digunakan u mum oleh para peneliti lain terkait penyakit daun tanaman kakao. 3.4 pengembangan dan pelatihan model data citra daun kakao yang telah melalui preprocessing dan ekstraksi fitur kemudian digunakan untuk pelatihan dan pembuatan model deep learning menggunakan pendekatan feature fusion berbasis attention yaitu fitur ekstraksi hog dan lbp digabungkan ke dalam vision transformer yang menggunakan attention mechanism . penggunaan attention mechanism dapat meningkatkan akurasi model dengan mengurangi pengaruh noise atau informasi yang tidak relevan dalam gambar. gambar 3.3 pengembangan dan pelatihan model 3.5 pengujian dan evaluasi model pengujian dan evaluasi model dilakukan untuk me lihat akurasi model saat mengidentifikasi penyakit daun tanaman kakao. 4 pengujian dan evaluasi model 3.6 pengembangan sistem deteksi penyakit daun kakao setelah melakukan pelatihan dan pengembangan model serta tahap pengujian dan evaluasi model system deteksi untuk penyakit daun kakao diimplemetasikan dengan melibatkan pengintegrasian model ke dalam aplikasi atau perang kat keras. pengembangan system menciptakan solusi yang efektif dan efisien dalam mengidentifikasi penyakit daun kakao. 5 alur identifikasi penyakit tanaman kakao
Robert_Kualifikasi.txt,"3.1 Alur Penelitian
     Gambar 3.1 menunjukkan metode penelitian. Terdapat 5 tahap utama yang akan dilakukan, yang pertama adalah studi literatur untuk menyusun bab 1 dan bab
2. Tahap kedua adalah pengumpulan citra ekspresi wajah (data citra berupa data primer dan data sekunder). Tahap ketiga adalah pembentukan dataset untuk tiap model (SVM, CNN, dan MNN), skenario pembentukan dataset dilakukan berdasarkan pada penelitian (Robert, 2023). Pada tahap keempat dilakukan pembentukan model, khusus untuk SVM dan CNN menggunakan model pada penelitian (Robert, 2023), sedangkan MNN menggunakan usulan pada penelitian ini. Tahap terakhir adalah pelatihan dan pengujian untuk semua model (SVM, CNN, MNN), terdapat tahap parameter tuning untuk tiap model. Kemudian semua performa dari tiap model akan dibandingkan satu sama lain, dan juga dianalisis pada bab 4. Gambar 3.1. Metode penelitian
3.2 Pengumpulan Citra Ekspresi Wajah
Citra ekspresi wajah dikumpulkan secara langsung oleh peneliti (data primer) dan juga menggunakan data yang dikumpulkan oleh peneliti lain (data sekunder). Terdapat 7 ekspresi wajah yang akan digunakan dalam penelitian ini, yaitu: marah, jijik, menghina, senang, sedih, kaget, dan netral (tanpa ekspresi). Gambar 3.2 menunjukkan contoh 7 ekspresi wajah manusia yang digunakan penelitian ini. Gambar 3.2. Contoh 7 jenis ekspresi wajah
Dataset primer akan dilakukan pengambilan citra ekspresi wajah mahasiswa Universitas Gunadarma baik pria maupun wanita. Pengambilan akan dilakukan dari beberapa sudut pandang guna menambah variasi dataset. Gambar 3.3 menunjukan contoh dataset primer dari berbagai sudut pandang. Gambar 3.3. Contoh dataset primer
Dataset sekunder digunakan dataset yang telah digunakan umum oleh peneliti lain terkait pengenalan ekspresi wajah. Terdapat beberapa dataset yang umum digunakan dalam penelitian ekspresi wajah. Pertama, Extended Cohn- Kanade (CK+) yang berisi citra ekspresi wajah pria dan wanita dari berbagai etnis dengan resolusi tinggi (Kanade, Cohn, & Tian, 2000; Lucey et al., 2010). Kedua, Taiwanese Facial Expression Image Dataset (TFEID) yang berisi citra ekspresi wajah pria dan wanita dari etnis Taiwan (Chen & Yen, 2007). Ketiga, Japanese Female Facial Expression (JAFFE) yang terdiri dari citra ekspresi wajah wanita etnis Jepang (Lyons, 2021; Lyons, Kamachi, & Gyoba, 2020). Gambar 3.4 menunjukan contoh citra dataset CK+ (a), JAFFE (b), dan TFEID (c). Gambar 3.4. Contoh dataset sekunder
Tabel 3.1 menunjukkan detail dari tiap dataset, mulai dari jumlah citra dari tiap kelas serta ruang warna dan ukuran citra. CK+ memiliki jumlah yang tidak seimbang pada kelas neutral dan memiliki ruang warna campur antara RGB dan Gray, dengan ukuran citra dikisaran 640 490. JAFFE dataset memiliki jumlah citra pada tiap kelas yang seimbang dengan perbedaan diantara 0 hingga 2 citra, ukuran citra 256 256, dan ruang warna grayscale. TFEID juga memiliki jumlah citra yang seimbang ditiap kelas, ukuran citra dikisaran 481 600, ruang warna RGB. 3.3 Pembentukan Dataset
Secara garis besar, dalam pembuatan model AI (khususnya ML dan DL) terdapat proses yang berperan penting, yaitu preprocessing dataset seperti ekstrasi fitur, penyesuaian ukuran citra, dan augmentasi (Deshmukh et al., 2016; Franchi et al., 2020; Mohammad & Ali, 2011; Ravi et al., 2020; Sawardekar & Naik, 2018; Shan et al., 2009). Pada penelitian (Robert, 2023), dilakukan sebuah skenario pembentukan dataset menggunakan beberapa metode pengolahan citra (seperti konversi warna ke grayscale, deteksi wajah, dan ekstrasi fitur), di mana preprocessing mempengaruhi performa dari model ML dan DL. Selain itu, pada penelitian (Alam & Yao, 2019) juga dilakukan penelitian yang serupa, di mana preprocessing mempengaruhi performa model machine learning. Pada tahap ketiga, dilakukan pembentukan dataset. Gambar 3.5 menunjukkan alur pembentukan dataset untuk SVM. Pertama, dilakukan pendeteksian wajah menggunakan VJA, proses ini berguna untuk mengurangi noise pada citra. Hasil VJA membuat ukuran citra bervariasi, oleh karena itu dilakukan resizing citra untuk menyamakan semua ukuran citra dan juga menyesuaikan dengan dimensi input model. Selanjutnya dilakukan konversi warna citra dari RGB ke Grayscale dikarena fitur warna tidak dibutuhkan dan agar dapat diekstrasi fiturnya menggunakan LMP. Terakhir, terdapat dua proses ekstrasi fitur berbeda. Proses ekstrasi fitur pertama menggunakan LMP (Robert, 2023). Proses ekstrasi fitur kedua adalah usulan dari penelitian ini, di mana pertama diaplikasikan Gabor Filter terlebih dahulu kemudian diekstrasi menggunakan LMP. Gambar 3.5. Pembentukan dataset untuk SVM
Gambar 3.6 menunjukkan alur pembentukan dataset untuk CNN dan MNN. Terdapat 3 proses yang akan dilakukan. Pertama, dilakukan deteksi wajah menggunakan VJA guna mengurangi noise. Kemudian dilakukan konversi warna dari RGB ke Grayscale karena fitur warna tidak dibutuhkan untuk mengenali ekspresi wajah. Terakhir, mengubah ukuran citra untuk menyamakan semua ukuran citra dan sesuai dengan dimensi input model. Skema pembentukan dataset ini berdasarkan performa terbaik dari penelitian (Robert, 2023). Gambar 3.6. Pembentukan dataset untuk CNN dan MNN
Dataset yang sudah melalui pembentukan dataset, dilakukan augmentasi dari sisi geometris seperti membalikan flipping secara horizontal dan vertikal, dan rotasi dari 0  hingga 45 . SVM training dataset digunakan untuk melatih model, sedangkan testing dataset digunakan untuk menguji dataset. CNN dan MNN terdapat pembagian lagi pada training, di mana 90% dari training dataset digunakan untuk melatih model dan 10% dari training dataset digunakan untuk validasi, dan testing dataset digunakan untuk menguji model. Visualisasi pembagian dataset
3.3.1 Deteksi wajah
Proses deteksi wajah menggunakan VJA, VJA memanfaatkan dua komponen yaitu integral image dan Haar Basis Function. Parameter ketiga adalah nilai threshold untuk masing-masing Haar yang digunakan untuk menentukan apakah Haar tersebut merupakan fitur wajah atau bukan. Output dari algoritma ini adalah berupa koordinat wajah yang dimulai pada koordinat [? Selain itu, jika semua nilai fitur lebih besar dari threshold maka detection window tersebut merupakan wajah, dan algoritma akan memberikan empat nilai yaitu ? Gambar 3.10 menunjukkan hasil dari implementasi algoritma deteksi wajah pada sebuah citra. Baris 2 dilakukan pembuatan matriks yang digunakan untuk menyimpan hasil. Image Resize (menggunakan Bicubic Interpolation)
Gambar 3.11 menunjukkan hasil perubahan ukuran citra wajah menggunakan Algoritma 3.3. Gambar 3.15 menunjukkan contoh hasil implementasi algoritma LMP pada citra wajah. 3.4 Pembentukan Model
3.4.1 Pembentukan Model SVM
Dalam penelitian sebelumnya (Robert, 2023), telah dilakukan pengenalan ekspresi wajah menggunakan SVM dengan menggunakan 4 kernel yaitu: Linear, Polynomial, Sigmoid, dan RBF. Berdasarkan dari penelitian (Robert, 2023), didapatkan model terbaik untuk mengenal ekspresi wajah adalah menggunakan kernel Sigmoid. Operasi pertama adalah operasi morgologi opening pada citra original, kemudian dilakukan pengurangan nilai piksel antara citra original dengan hasil opening, operasi opening itu sendiri adalah operasi erosi yang dilanjutkan operasi dilasi. Operasi kedua adalah erosi pada citra original, kemudian dilakukan pengurangan citra original terhadap hasil erosi. Ketiga adalah dilasi pada citra original, kemudian dilakukan pengurangan hasil dilasi terhadap citra original. Hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran (?? Baris 12 dilakukan pengambilan nilai terkecil yang digunakan untuk sebagai hasil fitur citra berdasarkan persamaan. Baris 25 dilakukan pengambilan nilai terbesar yang digunakan untuk sebagai hasil fitur citra berdasarkan Persamaan (2.14). Hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran (?? Baris 11 dilakukan pengambilan nilai terkecil yang digunakan untuk sebagai hasil fitur citra berdasarkan Persamaan (2.10). Hasil dari algoritma ini adalah sebuah fitur dalam bentuk citra dengan ukuran (?? Baris 11 dilakukan pengambilan nilai terbesar yang digunakan untuk sebagai hasil fitur citra berdasarkan Persamaan (2.8). 3.4.3.1.3 Percobaan dan Perbandingan Hasil Operasi Morfologi
Tabel 3.2 menunjukkan hasil operasi morfologi menggunakan SE berdasarkan 3.4.3.1 dan 3.4.3.2. Operasi Morfologi dan Structure Element pada Persegi Panjang
Berdasarkan dari Tabel 3.3 dapat dilihat operasi GMO dengan SE disk 3 3 menghasilkan corner pada persegi panjang. Operasi GMD dengan SE disk 3 3 memiliki hasil garis berbentuk persegi panjang dengan nilai tiap corner terdapat hilang. Operasi GMD dengan SE kotak 3 3 menghasilkan garis yang berbentuk persegi panjang. GME dengan SE kotak 3 3 memiliki hasil yang mirip dengan GMD, namun memiliki luas yang berbeda. Dari hasil yang didapatkan, tiap ukuran memiliki hasil yang mirip dengan operasi yang digunakan. Operasi GMD dan GME memiliki hasil yang mirip dengan perbedaan tepi pada GMD menebal kearah luar persegi, sedangkan tepi pada GME menebal kearah dalam. Tabel 3.4 merupakan hasil morfologi menggunakan citra wajah dengan warna grayscale. Structure Element dan Operasi Morfologi pada Wajah
Berdasarkan Tabel 3.4, dapat dilihat hasil ekstrasi fitur menggunakan berbagai kombinasi dua bentuk dan lima ukuran. SE kotak 5 5 juga memiliki hasil yang sama dengan disk 5 5 dengan perbedaan yang tidak dapat dilihat kasat mata. SE kotak 7 7 juga memiliki hasil yang sama dengan disk 7 7 dengan perbedaan yang tidak dapat dilihat kasat mata. SE disk 9 9 dengan operasi GMO fitur yang didapatkan tidak akurat karena tidak mengekstrasi tepi (bentuk) dari ekspresi wajah. Selain itu luas pada lubang hidung dan mulut juga lebih luas dibandingkan dengan SE 5 5, dan memiliki garis tepi yang lebih tebal. SE kotak 9 9 dengan operasi GMO, fitur yang didapatkan mirip dengan disk 9 9 dengan operasi GMO namun memiliki fitur yang lebih jelas terlihat. SE kotak 9 9 dengan operasi 9 9 GME fitur yang didapatkan terlihat dengan jelas dan mirip dengan hasil yang menggunakan SE disk 9 9 dengan operasi GME. Namun terdapat perbedaan fitur yang signifikan pada bagian hidung, di mana bentuk dari hidung sedikit berubah menjadi sedikit kotak. SE kotak 9 9 dengan operasi GMD, hasil yang didapatkan hampir sama dengan hasil yang menggunakan SE disk 9 9 dengan operasi GMD, hanya terdapat perbedaan pada tebal garis pada hidung. Operasi menggunakan SE 15 15, hasil yang didapatkan memiliki pola yang sama dengan operasi yang menggunakan SE 9 9. SE disk atau kotak 15 15 dengan operasi GMO fitur lebih terlihat jelas dibandingkan dengan ukuran 9 9. SE disk atau kotak 15 15 dengan operasi GME fitur lebih tebal, namun untuk SE kotak bagian hidung menjadi lebih kotak dari ukuran sebelumnya. Berdasarkan dari hasil yang didapatkan dan analisis. SE disk 5 5 atau kotak 5 5 dengan operasi GMD memiliki hasil terbaik. Tepi pada bagian mata tergabung, bagian mulut tidak menjadi lebih luas. Namun pada bagian hidung menjadi lebih kecil dibandingkan citra original. Selain itu operasi menggunakan GME dengan SE disk 5 5 atau kotak 5 5 juga memberikan hasil yang baik. Tepi dari tiap komponen wajah terlihat namun tepi pada mata dan bola mata tergabung, namun memberikan hasil ekstrasi fitur bagian hidung lebih baik dibandingkan GMD. Karena luas hidung lebih sesuai pada GME dibandingkan GMD. 3.4.3.2 Pembentukan dan Pelatihan Model
Gambar 3.18 menunjukkan arsitektur dari MNN secara garis besar. Di mana terdapat 5 layer utama yang memiliki tugas masing-masing. Di mana terdapat beberapa variasi arsitektur Variasi pertama terdapat pada morphology layer, di mana akan digunakan dua jenis ekstrasi fitur berdasarkan pada hasil subbab 3.4.3.3. Variasi kedua terdaoat pada hidden layer, di mana akan digunakan beberapa kombinasi fully-connected layer. Gambar 3.18. Model MNN yang diusulkan
Input Layer adalah layer pertama dari model MNN yang bertugas untuk menerima input berupa citra. Di mana dimensi dari intput layer itu sendiri sesuai dengan ukuran citra pada dataset yaitu 160 160. Kedua adalah morphology layer. Menerima masukan dari input layer kemudian dilakukan proses morfologi. Terdapat dua jenis morfologi layer yang akan digunakan. Morfology layer pertama adalah dilation layer kemudian subtraction layer. Di mana lapisan morfologi jenis pertama menggunakan hasil terbaik dari operasi morfologi dilasi pada subbab 3.4.3.3. Morphology layer jenis kedua adalah erosion layer dilanjutkan subtraction layer. Di mana lapisan morfologi jenis kedua ini menggunakan hasil terbaik dari operasi morfologi erosi pada subab 3.4.3.3. Lapisan ketiga adalah flatten layer, lapisan yang bertugas mengubah citra menajadi feature vector. Masukan dari lapisan ini adalah hasil dari subtraction layer pada lapisan morfologi. Di mana hasil dari subtraction layer adalah citra dengan ukuran 160 160 yang kemudian diubah mnejadi satu dimensi yaitu 25600. Lapisan keempat adalah Fully Connected Layer (FC Layer) yang bertugas untuk mempelajari dan menganalisa nilai feature vector dari flatten layer. Pada lapisan ini dilakukan beberapa konfigurasi FC Layer mulai dari jumlah FC Layer, dan jumlah Neuron pada FC Layer. Konfigurasi pertama akan diuji coba 2 FC Layer dengan masing-masing neuron adalah 512, dan 256. Konfigurasi kedua akan dicoba 1024, dan 512. Kemudian dari situ akan dicoba analisis mana yang lebih baik sehingga dapat dikonfigurasi lebih lanjut. Jika konfigurasi pertama memiliki hasil lebih baik artinya memungkinkan FC Layer untuk dibuat lebih sederhana dengan mengurangi jumlah neuron. Jika konfigurasi kedua lebih baik artinya terdapat kemungkinan untuk meninkatkan performa dari model karena dataset memiliki kompleksitas tinggi. Beberapa lapisan akan dilakukan tuning paramter. Tuning pertama terdapat pada bentuk SE, ukuran SE, jenis operasi pada morphological layer. Tuning kedua terdapat pada FC-Layer yaitu fungsi aktivasi (ReLu/Sigmoid/Tanh), dan jumlah neuron pada tiap hidden layer. Selain arsitektur, pada proses pelatihan juga dilakukan tuning pada learning rate, jumlah epoch, dan batch size. Terakhir adalah Output Layer, merupakan penentuan dari ekspresi berdasarkan dari bobot hidden layer. Di mana fungsi aktivasi yang digunakan untuk output layer adalah softmax yang artinya output berupa probabilitas dari tiap ekspresi. Kemudian untuk loss function yang akan digunakan adalah categorical crossentropy, dimana fungsi loss ini digunakan jika model memprediksi multi- kelas (multi-class prediction)."
Tatya Atyanti Paramastri_Kualifikasi.txt,permasalahan yang diangkat pada penelitian ini adalah motif batik indonesia sangat beragam dan memiliki maknanya masingmasing. namun tidak banyak masyarakat yang masih mengetahui nama makna dan pemakaian dari masingmasing motif batik. menurut dewan ahli ppbi paguyuban pecinta batik indonesia sekar jagad ibu mari s. condronegoro saat ini sering kali ditemukan kesalahan dalam pemakaian motif batik seperti mengenakan kain yang seharusnya digunakan pada upacara kematian ketika menghadiri acara pernikahan. solusi yang diusulkan adalah melakukan klasifikasi motif batik. fokus studi literatur terbagi menjadi tiga topik yaitu klasifikasi motif batik komputasi kuantum dan deteksi tepi. sehingga hasil yang didapatkan memuaskan dan akurat. dataset yang akan dikumpulkan merupakan citra motif batik daur hidup yogyakarta dari kain batik tradisional yang merupakan batik cap maupun batik tulis bukan printing. motif yang akan digunakan dalam penelitian akan didiskusikan terlebih dahulu dengan narasumber supaya dapat mewakili batik daur hidup yogyakarta yang sangat penting untuk diketahui dalam bersosialdi masyarakat. selain itu ukuran citra yang lebih kecil dapat mempercepat proses segmentasi dan klasifikasi tanpa kehilangan informasi penting. proses selanjutnya adalah mengubah ruang warna menjadi grayscale perubahan warna ini dilakukan karena dapat meningkatkan kontras meningkatkan efisiensi komputasi dan meningkatkan ketahanan terhadap variasi pencahayaan. selanjutnya proses augmentasi digunakan untuk meningkatkan ukuran dataset dengan menambahkan data baru tanpa perlu melakukan pengumpulan data baru. komputasi kuantum diterapkan mulai dari proses segmentasi karena berdasarkan penelitian terdahulu deteksi tepi berbasis kuantum dapat mendeteksi lebih banyak tepi dibandingkan deteksi tepi klasik berdasarkan jumlah tepi yang dihasilkan sundani dkk. 2019. hal serupa juga berlaku pada metode qcnn yang memiliki hasil lebih baik dan akurat dibandingkan dengan metode cnn klasik. sehingga hipotesisnya hasil dari ekstraksi fitur dan klasifikasi akan menjadi lebih optimal. gambar 3.2 perbandingan hasil deteksi tepi berbasis kuantum dan klasik sundani dkk. pengolahan data ini dilakukan sebagai pembanding performa model segmentasi dan klasifikasi berbasis kuantum. pengolahan data kedua model komputasi kuantum dan komputasi klasik akan dilakukan dengan menggunakan komputer yang sama yaitu komputer klasik. performa akan dibandingkan dari akurasi yang dihasilkan.
Tia Haryanti_Kualifikasi.txt,3.1 kerangka umum penelitian ini bertujuan untuk mengembangkan sistem deteksi dini kantuk sebelum berkendara dengan menggunakan kombinasi data visual berupa data citra wajah dan data fisiologis. kondisi predriving mengacu pada kondisi sebelum pengemudi memulai perjalanan sehingga sistem ini sangat penting untuk mencegah risiko kecelakaan di jalan . sistem ini mengintegrasikan teknologi pengenalan wajah dan analisis data fisiologis untuk memberikan deteksi yang lebih akurat. blok d iagram secara umum yang digunakan pada penelitian ini dapat dilihat pada gambar 3.1 blok diagram. objek preprocessing data fisiologis ekstrasi fiturpenggabungan fitur klasifikasi data image data visual kantuk ya tidak gambar 3.1 blok diagram model ini terdiri dari tiga tahapan yaitu input proses dan output . penelitian deteksi dini kantuk untuk kondisi predriving menggabungkan data visual yaitu pengumpulan data citra wajah pengemudi yang diambil menggunakan kamera serta data fisiologis yang diukur berupa data ekg menggunakan perangkat wearable yaitu smartwatch dan pulse oximeter untuk mengukur saturasi oksigen spo2 . tahapan preprocessing dan ekstraksi fitur dilakukan pada kedua jenis data yaitu data citra gambar dan data fisiologis. model convolutional neural network cnn digunakan untuk mengekst raksi fitur dari data citra wajah yang merupakan data visual sementara long short term memory lstm digunakan untuk memproses data fisiologis yang bersifat timeseries. fitur fitur yang diekstraksi dari kedua model ini digabungkan untuk menghasilkan vect or fitur gabungan. vektor fitur ini kemudian digunakan sebagai input untuk model support vector machine 43 svm yang melakukan klasifikasi akhir untuk mendeteksi kantuk. hasil deteksi kemudian digunakan untuk memberikan peringatan kepada pengemudi layak tidak nya pengemudi untuk berkendara. pengumpulan data data visualdata fisiologis pemilihan dan persiapan dataset preprocessing data pembuatan modelekstraksi fitur penggabungan fitur evaluasi pemisahan dataset pembangunan model pelatihan model evaluasi model implementasi gambar 3. 2 tahapan penelitian 44 3.3. pemilihan dan persiapan dataset tahapan ini merupakan tahapan identifikasi awal dari penelitian meliputi identifikasi masalah penelitian yang berfokus pada masalah utama yaitu mendeteksi kantuk pada pengemudi menggunakan pemrosesan citra dan fisiologis . pemilihan dataset memastikan bahwa dataset yang dikumpulkan relevan dengan tujuan penelitian yaitu hanya menggunakan data yang berkaitan dengan kondisi predriving serta memastikan bahwa data visual dan data fisiologis diambil pada waktu yang sama. 3.3.2 preprocessing data melakukan analisis eksploratif data untuk memahami karakteristik dataset sehingga meningkatkan kualitas deteksi . langkah dari pembuatan model yaitu penulisan kode untuk membangun model sesuai dengan desain arsitektur yaitu cnn lstm dan svm. 2. membangun model lstm membangun model lstm dengan lapisan lstm dan dense untuk ekstraksi fitur. 3.4.4 desain arsitektur desain a rsitektur merupakan proses menentukan struktur dan komponen model yang akan dibangun yang terdiri dari jenis model jumlah dan jenis layer fungsi aktivasi teknik regularisasi dan konfigurasi model. hasil dari kedua model digabungkan dan diklasifikasikan menggunakan support vector machine svm. 50 digunakan untuk mengolah data visual seperti mengenali mata tertutup atau mulut menguap sebagai indikator kantuk. menggabungkan fitur yang diekstrak dari cnn dan lstm untuk mendapatkan representasi data yang komprehensif memastikan bahwa model dapat mengidentifikasi kantuk berdasarkan kombinasi indikator visual dan fis iologis. selanjutnya yaitu menggunakan support vector machines svm untuk mengklasifikasikan data sebagai kantuk atau tidak kantuk. svm dipilih karena kemampuannya dalam mengklasifikasikan data yang kompleks dan memberikan batas keputusan yang jelas layak atau tidak layak pengemudi untuk berkendara. jika pengklasifikasi mendeteksi keadaan mengantuk maka pengklasifikasi menghasilkan alarm atau notifikasi pemberitahuan untuk memberi tahu bahwa pengemudi tidak layak untuk berkendara atau kembali ke f ase pertama dan memulai ulang prosedur. 3.5 evaluasi model gabungan ini dievaluasi menggunakan metrik seperti akurasi presisi recall dan f1score untuk memastikan performa dan keandalannya. implementasi sistem ini diharapkan dapat memberikan notifikasi atau peringatan kepada pengemudi jika tanda tanda kantuk terdeteksi selama kondisi predriving sehingga dapat meningkatkan keselamatan berkendara secara signifikan. berdasarkan hasil validasi model dapat ditune atau dioptimalkan untuk meningkatkan performa misalnya dengan mengubah arsitektur parameter atau teknik training . 3.6 implementasi setelah penyempurnaan model dianggap siap untuk digunakan. model ini harus dapat secara akurat mendeteksi kantuk pengemudi dalam berbagai kondisi dengan minimal kesalahan. langkah selanjutnya yaitu penerapan model dalam sistem nyata dan pemantauan efektivitasnya dalam kondisi pengemudi pada 51 lingkungan predriving. model yang telah dioptimalkan diintegrasikan ke dalam sistem deteksi dini kantuk untuk pengujian awal. selanjutn ya yaitu m elakukan uji coba lapangan untuk mengevaluasi efektivitas sistem dalam kondisi nyata memungkinkan pengumpulan feedback untuk perbaikan lebih lanjut. 3.7 rencana kegiatan tabel 3.1 rencana kegiatan no nama kegiatan bulan 1 2 3 4 5 6 7 8 9 10 11 12 1 kajian literatur 2 perencanaan penelitian 3. pengumpulan data 4. prapemrosesan data 5. pembuatan model 6. pelatihan dan evaluasi model 7. penyusunan laporan akhir 8. presentasi laporan akhir 9. publikasi jurnal ilmiah internasional 10. pengajuan hki
Utami Lestari_Kualifikasi.txt,"Penelitian ini bertujuan untuk mengembangkan aplikasi berbasis Large Language Model (LLM) dengan arsitektur GPT-4 yang mampu melakukan telaah sejawat(peer review) secara otomatis pada artikel ilmiah dari jurnal komputer. Data utama yang digunakan adalah artikel ilmiah berbahasa Indonesia dalam bidang ilmu komputer dari berbagai jurnal akademik. Sebelum digunakan, data akan diperiksa untuk menghilangkan informasi pribadi yang dapat mengidentifikasi penulis atau reviewer. Aplikasi ini diharapkan dapat membantu para peneliti dan editor jurnal dalam menganalisis dan memperoleh wawasan dari artikel yang seringkali bersifat kompleks dan teknis. Proses ini melibatkan beberapa tahap penting yang bertujuan untuk membersihkan dan menyiapkan data teks agar sesuai dengan kebutuhan model serta meningkatkan kualitas dan konsistensi representasi teks. 2 Tahapan Preprocessing
Tahap pertama adalah tokenisasi, di mana teks dipecah menjadi unit-unit yang lebih kecil yang dikenal sebagai token, memungkinkan model untuk menganalisis teks pada tingkat yang lebih granular. 3.1.4 Evaluasi Model LLM
Evaluasi model merupakan langkah yang penting dalam pengembangan sistem kecerdasan buatan, karena memungkinkan untuk menilai kinerja dan efektivitas model dalam menyelesaikan tugas tertentu. Tanpa evaluasi yang tepat, model yang dikembangkan dapat menghasilkan prediksi yang tidak akurat atau tidak dapat diandalkan, yang berpotensi menyebabkan kinerja sistem yang buruk secara keseluruhan. Recall memberikan informasi tentang seberapa banyak instance positif yang berhasil diidentifikasi oleh model dari semua instance positif yang
4. sebenarnya dalam dataset. 3.1.5 Validasi Ahli
Proses validasi ahli ini memastikan bahwa model GPT-4 yang digunakan untuk telaah sejawat mampu memberikan evaluasi yang akurat, relevan, dan sesuai dengan standar akademik, dengan masukan berharga dari para ahli di bidangnya. 3.2 Jadwal Penelitian
Jadwal penelitian bertujuan untuk mengatasi target waktu penelitian, memastikan bahwa penelitian ini dapat diselesaikan sesuai dengan batas waktu yang telah ditetapkan. Adanya jadwal penelitian, diharapkan penelitian dapat berjalan secara efisien dan sesuai rencana, sehingga memberikan kepastian bahwa semua tahapan penelitian dapat diselesaikan tepat pada waktunya. Table jadwal penelitian dapat dilihat pada table 3.1"
Yoga Panji Perdana Nugraha_Kualifikasi.txt,3.1 motivasi industri manufaktur memiliki berbagai macam produk yang ada di dalamnya. dalam upaya pemenuhan kualitas yang tinggi serta menjaga kepuasan pelanggan dan reputasi perusahaan maka mendeteksi produk yang cacat sedini mungkin merupakan aspek yang penting. 1. pengembangan aplikasi pendeteksi cacat pada produk ini didasari keinginan peneliti untuk meningkatkan kinerja pengendalian kualitas pada industri manufaktur sehingga dapat membantu menjaga kualitas produk serta efisien si dalam kegiatan pengendalian kualitas. 2. untuk meminimalisir pemborosan waktu bahan baku biaya dan sumber daya lainnya karena deteksi cacat pada produk dilakukan sedini dan secepat mungkin. 3. meningkatkan efisiensi pada kegiatan inspeksi produk d engan mene rapkan otomatisasi mel alui aplikasi yang dikembangkan. 4. mengintegrasikan teknologi yang sedang berkembang seperti artificial intelligence dengan industri manufaktur sehingga tercipta manufaktur cerdas yang akan berakibat pendapatan profit perusahaan yang op timal. 5. memberikan kontribusi pemahaman dan pengembangan teknologi baru dalam deteksi objek sehingga bisa menjadi referensi untuk pembaca serta penelitian selanjutnya. tahap awal tahap pengembanganperancangan dan pembuatan prototype alat deteksi cacatpengumpulan data cacat objek uji coba prototype alat deketsi cacat objekperancangan model deteksi cacat objek menggunakan deep learning implementasi dan pelatihan model deteksi cacat objek evaluasi dan penyempurnaan model deteksi cacat objek pengujian model deteksi objek menggunakan deep learning pembuatan aplikasi pendeteksi objek cacattahap optimasi pengajuan hki dan jurnal internasional q 1 gambar 3. 1. tahap awal kegiatan yang dilakukan pada tahap awal ini adalah merancang dan membuat prototype alat deteksi cacat dan pengumpulan data cacat objek. 2 rancangan prototipe alat gambar 3.2 di atas menggambarkan rancangan alat yang akan dikembangkan. tahap ini terdapat kegiatan yaitu eval uasi dan penyempurnaan model deteksi cacat objek. evaluasi dan penyempurnaan dilakukan agar fitur yang ada pada aplikasi yang akan dikembangkan dapat ditampilkan dengan maksimal. p engujian data dilakukan untuk menguji model sejauh mana dapat mendeteksi cacat dari suatu produk. pada akhirnya akan menampilkan output model dalam mendeteksi cacat pada produk. setelah itu maka dibangun aplikasi yang mampu mendeteksi cacat produk pada industri secara real time. aplikasi ini nantinya akan menampilkan hasil deteksi dari produk yang bergerak. selain itu diterapkan juga pengukuran evaluasi seperti precision recall dan mean average precision map untuk memastikan model yang dikembangkan dapat digunakan dengan optimal. nantinya akan dikembangkan sebuah aplikasi yang kemungkinan berbasis web untuk mempermudah pengguna untuk mengambil gambar bergerak maupun tak bergerak yang kemudian mengirimnya ke sistem pendeteksi cacat dan menerima hasil deteksi secara real time. hasil deteksi secara real time dikehendaki agar produk dapat diperiksa selama proses produksi berlangsung sehingga cacat dapat dideteksi secepat dan seakurat mungkin.
