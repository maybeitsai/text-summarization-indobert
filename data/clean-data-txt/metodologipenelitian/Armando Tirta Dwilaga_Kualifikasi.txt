3.1 gambaran umum penelitian penelitian ini digunakan untuk mengatasi sensitivitas terhadap cacat pada gambar ban dengan melibatkan penggunaan jaringan syaraf menggunakan algoritma convolutional neural network cnn dan membangun model atau kerangka kerja menggunakan keras. berikut adalah gambar 3.1 blok diagram gambaran umum penelitian. data preparation data augmentasi data splitting model training forward pass model evaluation backward passfinetuning if neededinput unit processing unit output unit model deployment inference12 gambar 3.1 blok diagram gambaran umum penelitian berdasarkan gambar 3.1 blok diagram gambaran umum penelitian maka dapat dijelaskan di blok tersebut terbagi menjadi 3 bagian yaitu bagian pertama adalah unit masukan berisikan data preparation di mana gambar ban dimuat diubah menjadi format yang sesuai dipersiapkan untuk pelatihan model convolutional neural network cnn seperti pemrosesan gambar ban selanjutnya data augmentation di mana data dibuat lebih ber variasi dari training data yang ada sehingga dapat meningkatkan keberagaman training data tanpa h arus mengambil data baru mencakup rotasi pergeseran horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel selanjutnya data di mana dataset yang telah di augmentasi dan disiapkan dibagi menjadi subset yang berbeda untuk training untuk melatih model validation untuk menyempurnakan model serta me mvalidasi performanya selama pelatihan dan testing untuk mengevaluasi kinerja model akhir . data set dibagi menjadi training data validation data dan testing data dalam proporsi tertentu. bagian kedua adalah unit pemrosesan yang bertindak adalah model training forward pass tahap di mana input diproses melalui model untuk menghasilkan prediksi tujuannya melatih model convolutional neural network cnn menggunakan dataset pelatihan di mana data dari unit masukan diteruskan melalui jaringan neural di lakukan transformasi linier konvulasi dan non linier fungsi aktivasi dilakukan pada data di setiap lapisan untuk menghasilkan output prediksi yang melibatkan komputasi di setiap neuron dan lapisan jaringan yang merupakan inti dari proses pembelajaran dalam jaringan saraf. selanjutnya unit pemrosesan finetuning tujuannya dilakukan untuk menyempurnakan model lebih lanjut setelah pelatihan awal dengan dataset yang lebih kecil atau lebih spesifik nantinya. proses di dalam finetuning menyesuaikan bobot menggunakan kumpulan data yang lebih kecil untuk menyesuaikan bobot model untuk performa yang lebih baik pelatihan khusus fokus pada fitur data yang lebih relevan dengan objek . bagian ketiga adalah unit keluaran yang bertindak ada proses model evaluatioan backward pass tahap di mana gradien memperbarui parameter model dalam arah yang akan mengurangi fungsi loss dari fungsi loss metrik yang mengukur seberapa baik atau buruk model melakukan prediksi dibandingkan nilai aktualnya dihitung dan digunakan untuk memperbarui parameter model selama pelatihan tujuannya mengevaluasi performa model yang dilatih dan model dievaluasi menggunakan metrik yang relevan accuracy precision recall dan f1 score berdasarkan prediksi yang dihasilkan dari model terhadap validasi atau uji data. output dari proses ini adalah tentang hasil evaluasi model yang memberikan informasi kinerja model. selanjutnya ada dua alur pilihan yang bisa dilakukan alur pertama jika hasil prediksi sudah sesuai dengan keinginan maka bisa langsung masuk ke model deployment inference dan alu r kedua jika hasil prediksi masih perlu diperbaiki pada bagian unit pemrosesan terlebih dahulu fine tuning untuk penggunaan data set lebih kecil jika menunjukan model belum mencapai performa yang diharapkan baru masuk ke model deployment inference tujuannya menerapkan model terlatih untuk membuat prediksi pada data baru yang belum terlihat. model deployment inference yang telah dilatih digunakan untuk membuat prediksi pada data baru atau dalam situasi dunia nyata tahap di mana model menerima input baru dan menghasilkan output berdasarkan pada pembelajaran yang dilakukan selama proses pelatihan dan merupakan output akhir dari keseluruhan proses di mana model mengambil keputusan atau membuat prediksi berdasarkan pada pengalaman yang telah diperoleh selama pelatihan. 3.2. tahapan penelitian penelitian ini di dalamnya terdapat tahapan tahapan yang dilakukan untuk membentuk satu kesatuan yang utuh dari awal sampai akhir dan membentuk kerangka penelitian mengenai klasifikasi pada produk ban menggunakan algoritma convolutional neural network cnn . berikut gambar 3.2 tahapan penelitian. study of literature data acquisition data augmentation data splitting model buildingdata preprocessing model evaluation testing gambar 3.2 tahapan penelitian berdasarkan gambar 3.2 tahapan penelitian maka dapat dijelaskan proses yang terlibat di dalamnya ada 8 yaitu studi literatur data aquisition data preprocessing data augmentation texture feature extraction data splitting model building dan model evaluation testing di mana tahap ke dua sampai lima merupakan tahap proses menyiapkan sebuah data sebelum dilakukan pemodelan. 3.2.1 studi literatur tahap pertama adalah studi literatur di mana studi yang dilakukan berasal dari artikel ilmiah dan buku yang menunjang dalam menganalisis terkait dengan metode pen gukuran kualitas mengenai klasifikasi produk ban meninjau penggunaan pembelajaran mesin algoritma convolutional neural network cnn dari beberapa tahun ke belakang dalam konteks peng ukuran kualitas untuk klasifikasi terhadap kondisi kondisi produk ban . sehingga dapat menemukan teknik terbaik yang dapat diaplikasikan pada masalah yang ada. berikut merupakan gambar 3. 3 tahapan study literature . study of literature load libraries initialize imagedatagenerator set image directory and parameters create test training and validation dataset gambar 3. 3 tahapan study literature 3.2.2 data aquisition tahap k edua adalah data aquisition dengan mengumpulkan kumpulan data sesuai tujuan penelitian dengan target untuk kumpulan data gambar ban untuk training data validation data dan testing data memastikan bahwa kumpulan data tersebut memiliki varian yang secara akurat memang mewakili kondisi produk ban dan diperoleh dari sumber sumber terpercaya . berikut merupakan gambar 3. 4 tahapan data aquisition . data acquisition normal defecttire dataset gambar 3. 4 tahapan data aquisition 3.2.3 data preprocessing tahap ketiga adalah data preprocessing melakukan pra pemrosesan data untuk menyiapkan gambar untuk model pelatihan dan pengujian proses ini meliputi normalisasi dan penskalaan dengan fitur dalam program image data generator . bermaksud merapikan menata dan menyiapkan data untuk pemeriksaan tambahan. normalisasi data pengkodean variabel mengatasi nilai yang hilang menghapus data yang tidak relevan atau hilang dan modifikasi data lainnya untuk memenuhi persyaratan analisis a dalah persiapan data. berikut merupakan gambar 3.5 tahapan data preprocessing . data preprocessing data normalization data scalinginitiation split data into training and validation sets rescale target_size gambar 3. 5 tahapan data preprocessing 3.2.4 data augmentation tahap keempat adalah data augmentation meningkatkan variasi dalam dataset dengan teknik augmentasi data menggunakan operasi seperti rotasi pergeserarn horizontalvertikal perbesar gambar perubahan kecerahan gambar sampai mengubah nilai pixel untuk memperkaya dataset dan mengurangi overfitting saat disajikan dengan data baru yang belum pernah dilihat sebelumnya performa model akan menurun drastis karena model tersebut dapat menyesuaikan diri dengan kumpulan training data dengan sangat efektif. augmentasi data dilakukan dengan dua cara secara statis dan dinamis yang artinya secara statis yaitu menambah data secara fisiknya dan dinamis tidak menambah secara fisik tetapi secara k uantitas dataset yang dapat diakses secara fisik di komputer tidak bertambah ketika image data generator digunakan pada dataset. sebaliknya pada saat runtime hanya menghasilkan variasi dari gambar yang sudah ada dibuat secara dinami s dan cukup bagi model untuk berlatih dari berbagai kondisi gambar ban yang ada pada kenyataaanya. secara lebih jelas nilai teknik augmentasi pertama dilakukan dengan manual menggunakan bantuan dari website roboflow dengan resize gambar menjadi 640 x 640 pada augmentasinya menggunakan model flip horizontal dan vertikal 90 pemutaran searah jarum jam berlawanan arah jarum jam dan terbalik rotasi 45 dan 45 shear 5 horizontal dan 5 vertikal brightness 20 sampai 20. data asli pada dataset berjumlah 1 .028 data gambar ban setelah dilakukan augmentasi secara fisik menggunakan website roboflow ada data yang tidak dapat diidentifikasi ada 3 gambar sehingga total gambar asli yang berhasil di upload dan dijadikan data asli yang tetap berjumlah 1.025 data ga mbar dan setelah di augmentasi bertambah menjadi 2 .050 data gambar ban. rinciannya pada data asli training adalah 560 gambar dan setelah dilakukan augmentasi bertambah menjadi sebanyak 1.121 gambar. rincian data asli pada validation data berjumlah 140 gambar dan setelah dilakukan augmentasi bertambah menjadi sebanyak 279 gambar. rincian data asli pada testing data berjumlah 328 gambar dan setelah dilakukan augmentasi bertambah menjadi sebanyak 6 50 gambar. testing data pada prosesnya sebenarnya tidak mengalami augmentasi karena pada proses pengujian atau evaluasi mode l ingin menggunakan data asli yang sebenarnya untuk melihat kinerja model pada kasus kasus yang belum pernah dilihat sebelumnya. augmentasi kedua yaitu dilakukan rotasi melakukan pemutaran gambar secara penuh dan secara acak dengan nilai 360 atau rentang nilai 0 360 derajat kedua width shift range yang menggeser gambar secara acak ke kiri atau kanan dengan nilai 0 .05 atau gambar dapat digeser sampai 5 dari lebar aslinya . ketiga height shift range gambar dapat digeser secara vertikal dengan nilai 0 .05 atau gambar dapat digeser sampai 5 dari tinggi aslinya . keempat shear range untuk menggeser gambar dengan sudut geser berlawanan arah jarum jam dengan nilai 0.05. kelima zoom range memperbesar gambar sebanyak 0.05 atau gambar dapat diperbesar sampai 5. keenam horizontal flip adalah memberikan variasi tambahan dengan mengubah orientasi gambar secara horizontal acak dengan keterangan nilai true. ketujuh vertikal flip adalah memberikan variasi tambahan dengan mengubah orientasi gambar secara vertikal acak dengan keterangan nilai true. kedelapan brightness range mengubah atau menentukan kecerahan pada gambar secara acak dengan nilai rentan 0.75 1.25 atau kecerahan dapat diubah mulai dari rentnag 75 sampai 125 dari kecerahan asli gambarnya. kesembilan resecale mengubah nilai skala piksel 0.1 dengan membaginya setiap nilai piksel pada nilai 255 sehingga dapat membant u untuk normalisasi data. kesepuluh validation split mengatur pembagian data untuk validasi dengan nilai 0.2 atau 20 data dari keseluruhan data untuk alokasi validation data dan 80 un tuk alokasi training data. merupakan pendekatan augmentasi awal di mana sebelum data masuk ke model untuk proses pelatihan dan akan diperbesar sebelum pembagian dataset menjadi batch untuk setiap epoch nya sehingga model akan dilatih menggunakan dataset yang telah diaugmentsi sejak awal dan seluruh augmentasi akan diterapkan pada setiap epoch nya dengan penggunaan ukuran batch 64 dengan jumlah batch training 36 dan validasi 10. rinciannya data asli pada training data berjumlah 1.121 gambar dan setelah dilakukan augmentasi bertambah sebanyak 1.152 gambar sehingga data pada training data berjumlah total menjadi 2 .273 gambar. rincian data asli pada validation data berjumlah 2 79 gambar dan setelah dilakukan augmentasi bertambah sebanyak 320 gambar sehingga data pada validation data berjumlah total menjadi 59 9 gambar. testing data tidak mengalami augmentasi karena pada proses pengujian atau evaluasi mode l ingin menggunakan data asli yang sebenarnya untuk melihat kinerja model pada kasus kasus yang belum pernah dilihat sebelumnya. berikut merupakan gambar 3. 6 tahapan data augmentation . data augmentation flip rotation shear brightness gambar 3. 6 tahapan data augmentation 3.2.5 data splitting tahap ke lima data splitting dengan membagi file dataset menjadi subset training data validation data dan testing data berisikan gambar ban normal dan gambar ban tidak normal sehingga subset training data digunakan untuk melatih model sedangkan subset validation data digunakan untuk menguji kinerja model. sebenarnya langkah langkah dalam proses pra pemrosesan data yang mempersiapkan data mentah untuk digunakan dalam pelatihan model adalah tahapan yang sudah disebutkan sebelumnya data aquisition data prerocessing data augmentation dan splitting data. prosedur yang disebutkan di atas berkonsentrasi pada pengumpulan sanitasi pengorganisasian dan penambahan jumlah data yang diperlukan untuk pelatihan model. rinciannya yaitu file yang tersimpan di dalam komputer total data gambar sebanyak 2.050 gambar yang dibagi menjadi dua pertama adalah file testing data dengan jumlah data tersimpan sebanyak 650 gambar yang dibagi menjadi sub file crack berjumlah 420 dan sub file normal berjumlah 230 data. kedua adalah file training data dengan jumlah data tersimpan sebanyak 1400 gambar yang dibagi menjadi sub file crack berjumlah 654 dan sub file normal berjumlah 746 data. maka ketika dilakukan data splitting pada program secara otomatis yang pada data augmentasi diatur menjadi pembagian 80 untuk training data dan 20 untuk validation data yaitu untuk train data sebanyak 1.121 gambar dengan 2 kelas validation data sebanyak 279 gambar dengan 2 kelas dan test data sebanyak 650 gambar dengan 2 kelas. testing data bernilai tetap h al ini bertujuan agar kuantitas data awal yang telah ditentukan sebelumnya tetap terjaga dan testing data tidak terpengaruh oleh prosedur pemisahan. setelah model dilatih dan divalidasi testing data digunakan untuk mengevaluasi performa akhir model. akibatnya testing data tidak terbagi dan rincian asli 648 foto masih berlaku. berikut merupakan gambar 3.7 tahapan splitting data . data splitting training data validation data testing data gambar 3. 7 tahapan splitting data 3.2.6 model building tahap ke enam adalah model building membangun model convolutional neural network cnn dengan keras membangun arsitektur model convolutional neural network cnn menggunakan keras mengatur lapisan lapisan seperti convolutional maxpooling2d flatten dan dense untuk membangun model. learning rate dalam penggunaan algoritma optimasi menggunakan adaptive momentum adam untuk menghasilkan pembelajaran yang adaptif pemilihan penggunaan adaptive momentum adam jika dibandingkan dengan learning rate lain seperti stochastic gradient descent sgd karena kecepatan pembelajaran adaptif untuk adaptive momentum adam bisa secara otomatis menyesuaikan learning rate untuk setiap parameter dalam model klasifikasi ban sedangkan stochastic gradient descent sgd memiliki learning rate tetap selama pelatihan model klasifikasi ban yang penentuannya dari user dan tidak bisa menyesuaikan learning rate secara otomatis berdasarkan kondisi a ktual dari setiap parameter. selanjutnya secara kestabilan dan konvergensi adaptive momentum adam menyambung dari awal dapat mengubah kecepatan pembelajaran secara adaptif sehingga membuatnya lebih stabil dan kecil kemungkinannya terjebak pada tingkat minimum lokal nilai yang dianggap sebagai titik terendah dari loss function dalam model sehingga adaptive momentum adam cenderung mencapai konvergensi tingkat kinerja yang diharapkan lebih cepat dan andal dalam berbagai keadaan sedangkan stochastic gradient descent sgd mungkin lebih stuck pada nilai minimum atau terjebak pada nilai minimum lokal ya ng disebabkan oleh kemungkinan bergantung pada seberapa tepat kecepatan pemelajaran dipilih kecepatan pemelajaran yang tetap dapat membuat model mencapai konvergensi terlalu cepat atau terlalu lambat. adapun melakukan pendekatan kedua penam bahan data keti ka masuk ke model building dan terjadi proses pemodelan setelah menggunakan epoch . augment asi data diterapkan setelah data melewati beberapa epoch selama proses pelatihan sehingga variasi data yang dihasilkan akan berbeda beda pada setiap epoch dan model dapat terus menerus terlatih dengan variasi data yang lebih besar . menggunakan 100 epoch sehingga total training data yang diproses menjadi 230.400 gambar dan validation data menjadi 6.400 gambar. sehingga jumlah data yang diproses selama pelatihan menjadi sangat besar dan pada akhirnya nanti akan menyiapkan m odel kompilasi dalam mengatur pengoptimal adam fungsi kerugian biner crossentropy dan metrik evaluasi akurasi. berikut merupakan gambar 3. 8 tahapan building model . model building define cnn model compile model gambar 3 .8 tahapan building model berdasarkan hasil analisis sebelumnya maka dapat diketahui untuk j umlah data asli training data adalah 1.121 jumlah data asli validation data adalah 279 jumlah data asli training data setelah augmentasi adalah 1152 jumlah data asli validation data setelah augmentasi adalah 320 jumlah epoch yang digunakan sebanyak 100 dan ukuran batch adalah 64. berikut merupakan perhitungan manualnya ketika masuk ke model building dan terjadi proses pemodelan setelah menggunakan epoch . 1. jumlah batch per epoch untuk training data . 𝑆𝑡𝑒𝑝𝑝𝑒𝑟𝑒𝑝𝑜𝑐ℎjumlahdatatrainjumlahdataaugmentasi train 𝐵𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒 11211152 64 2273 64 35515636𝑏𝑎𝑡𝑐ℎ 2. jumlah batch per epoch untuk validation data. 𝑆𝑡𝑒𝑝𝑝𝑒𝑟𝑒𝑝𝑜𝑐ℎjumlahdatavalidjumlahdataaugmentasi valid 𝐵𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒 279320 64 599 64 9359310𝑏𝑎𝑡𝑐ℎ 3. total jumlah data setelah augmentasi untuk semua epoch . a. training data total𝑇𝑟𝑎𝑖𝑛𝑖𝑛𝑔 datajumlah𝐵𝑎𝑡𝑐ℎx𝐵𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒xjumlah𝐸𝑝𝑜𝑐ℎ𝑠 36x64x100 230.400 b. validation data total𝑉𝑎𝑙𝑖𝑑𝑎𝑡𝑖𝑜𝑛 datajumlah𝐵𝑎𝑡𝑐ℎx𝐵𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒xjumlah𝐸𝑝𝑜𝑐ℎ𝑠 10x64x100 64.000 3.2.7 model evaluation testing tahap kedelapan adalah model evaluation testing digunakan sebagai bahan terusan pada model building yang dibuat untuk melakukan evaluasi performanya dengan menggunakan bagian pengujian dan parameter yang digunakan pada metrik evaluasi seperti akurasi presisi recall dan f1score . berikut merupakan gambar 3. 9 tahapan model evaluation testing . model evaluation testing accuracy precision recall f1score gambar 3. 9 tahapan model evaluation testing 3.3 arsitektur convolutional neural network cnn convolutional neural network cnn yang dibangun menggunakan model atau kerangka kerja yang pada dasarnya menggunakan keras dan juga tensorflow dengan menambahkan beberapa model lapisan lapisan seperti lapisan convolutional conv2d laposan pooling maxpooling 2d flatten dan lapisan fully connected dense . berikut merupakan gambar 3. 10 tahapan convolutional neural network cnn dengan model keras. conv2d filter 128 ukuran filter 3 atau 3x3 strides 2 input size 189x189 jumlah neuron 1280maxpooling2d pool size 2 strides 2 input size 94x94 jumlah neuron 1280conv2d 2nd filter 64 ukuran filter 3 atau 3x3 strides 2 input size 46x46 jumlah neuron 73792maxpooling2d 2nd pool size 2 strides 2 input size 23x23 jumlah neuron 73792 conv2d 3nd filter 32 ukuran filter 3 atau 3x3 strides 2 input size 11x11 jumlah neuron 18464maxpooling2d 2nd pool size 2 strides 2 input size 5x5 jumlah neuron 18464conv2d 4nd filter 16 ukuran filter 3 atau 3x3 strides 2 input size 2x2 jumlah neuron 4624maxpooling2d 4nd pool size 2 strides 2 input size 1x1 jumlah neuron 4624 flatten input size 1x1x16 jumlah neuron 16dense layer 1 dengan aktivasi relu jumlah neuron 128 jumlah parameter 2176dropout layer 1 rate 0.2 20dense layer 2 dengan aktivasi relu jumlah neuron 64 jumlah parameter 8256 dropout layer 2 rate 0.2 20dense layer 3 dengan aktivasi sigmoid jumlah neuron 1 biner sigmoid jumlah parameter 65 training fit callbacks optimizer adam evaluation confusion matrix report epochs 100 gambar 3. 10 tahapan convolutional neural network cnn dengan model keras berdasarkan gambar 3. 10 tahapan convolutional neural network cnn dengan model keras maka dapat dijelaskan mulai dari yang mencakup lapisan lapisan konvolusi yang telah dilatih pada dataset besar seperti imagenet untuk mengekstrak fitur dari gambar gambar penggunaan image size diatur dengan 379 379 batch size 64 kernel size 3 strides 2 untuk cov2d dan 2 untuk maxpooling2d dan pool size 2. selanjutnya conv2d yang merupakan convolutional layer pertama yang berfungsi untuk mengekstrak fitur fitur visual dari gambar. filter convolutional layer pertama yang berfungsi untuk mengekstrak fitur fitur visual diterapkan pada gambar untuk menghasilkan fitur fitur yang lebih abstrak formula untuk mengetahui jumlah training datanya dengan . selanjutnya max pooling 2d di mana tahap pooling digunakan untuk mengurangi dimensi spasial dari setiap feature map yang dihasilkan oleh layer sebelumnya. max pooling memilih nilai maksimum di dalam jendela pooling untuk m engurangi ukuran fitur dan mempertahankan informasi penting. selanjutnya conv2d dan max pooling 2d diulang sampai 4 layer karena untuk terus mengekstrak fitur fitur yang semakin kompleks dari gambar. selanjutnya flatten digunakan untuk mengubah tensor multi dimensi menjadi tensor satu dimensi di mana setelah serangkaian layer konvolusi dan pooling masukan dari layer terakhir perlu diubah menjadi vektor tunggal sebelum dimasukkan ke dalam layer dense . flatten layer melakukan hal ini dengan mengubah matriks output menjadi array satu dimensi. selanjutnya dense layers lapisan dense digunakan sebagai lapisan output dalam model klasifikasi di mana jumlah neuron dalam lapisan output sesuai dengan jumlah kelas yang harus diprediksi di mana ada tiga lapisan dense ditambahkan dengan fungsi pertama dan kedua menggunakan relu sebagai 0 f x max x yang artinya menunjukkan bahwa keluarannya nol jika masukannya negatif atau nol dan output x jika masukannya positif dengan 128 unit neuron dan pada dense kedua 64 unit neuron karena tugasnya mengurangi dimensi representasi pada lapisan dense pertama maka model dapat mempelajari pola yang lebih rumit dan mendalam dari data dengan menambahkan lapisan yang lebih padat yang dapat meningkatkan performa model dalam tugas klasifikasi gambar. lapisan dense ketiga dengan fungsi aktivasi sigmoid untuk output biner dengan menunjukan kelas prediksi dari gambar yaitu normal atau crack . di antara tig a lapisan dense di ikuti dengan lapisan dropout untuk mencega h overfitting di mana model pembelajaran mesin terlalu menghafal pola dari training data yang tersedia sehingga kinerjanya menurun secara signifikan saat diuji dengan data baru yang tidak dilihat sebelumnya juga dimasukkan setelah setiap lapisan dense untuk mencegah overfitting dengan secara acak menonaktifkan seba gian unit sebanyak 0.2 atau 20 dari neuron selama pelatihan. selanjutnya training di mana model diterapkan pada training data dengan menggunakan metode fit dan callback . model fit digunakan untuk melatih model dengan training data dan model callback menggunakan modelcheckpoint untuk menyimpan model terba ik selama pelatihan berkaitan dengan performa pada validation data mengontrol proses pelatihan. terakhir evaluation di mana performa model pada testing data dinilai menggunakan hasil klasifikasi dan confusion matrix untuk memahami kinerjanya testing data. banyaknya parameter atau bobot dan jumlah data yang harus dipelajari selama pelatihan bergantung pada jumlah neuron pada lapisan. jumlah data yang harus dipelajari model selama pelatihan tercermin dalam jumlah parameter ini. berikut merupakan perhitungan dalam mengetahui total neuron yang dikerjakan oleh setiap lapisan. 1. first conv2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x11x128 10x128 1280 kedalaman gambar yang diproses lapisan konvolusi sebenarnya ditunjukkan oleh jumlah saluran masukan. tiga saluran merah hijau dan biru membentuk sebuah gambar jika diwarnai artinya ada tiga saluran masukan. karena kata grayscale digunakan untuk mendeskripsikan gambar ini hanya ada satu saluran warna dan bernilai 1 . sehingga jumlah neuronnya 1280 yang berarti ada 1280 parameter yang harus dipelajari selama pelatihan dan akan mencerminkan jumlah data yang harus dipelajari ketika pelatihan . selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 379x379 menjadi 189x189 sebagai berikut. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝐾𝑒𝑟𝑛𝑒𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 3793 11 376 21 189 2. first maxpooling2d tidak ada parameter baru yang ditambahkan dan jumlah neuron dalam contoh ini lapisan konvolusi pertama tetap sama. setiap filter diubah menjadi setengah dari ukuran inputnya 189x189 menjadi 94x94 dan jumlah neuronnya 1280 mengikuti lapisan konvolusi pertama . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 1892 21 187 21 94 3. second cov2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x1281x64 1153x128 73792 jumlah channel input menggunakan jumlah filter dari convolutional layer sebelumnya bukan lagi channel input di awal. sehingga jumlah neuronnya 73792 yang berarti ada 73792 parameter yang harus dipelajari selama pelatihan dan akan mencerminkan jumlah data yang harus dipelajari ketika pelatihan . selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 94x94 menjadi 46x46 sebagai berikut. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝐾𝑒𝑟𝑛𝑒𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 943 21 91 21 46 4. second maxpooling2d tidak ada parameter baru yang ditambahkan dan jumlah neuron dalam contoh ini lapisan konvolusi kedua tetap sama. setiap filter diubah menjadi setengah dari ukuran inputnya 46x46 menjadi 23x23 dan jumlah neuronnya 73792 mengikuti lapisan konvolusi kedua . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 462 21 44 21 23 5. third cov2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x641x32 577x32 18464 jumlah channel input menggunakan jumlah filter dari convolutional layer sebelumnya bukan lagi channel input di awal. sehingga jumlah neuronnya 18464 yang berarti ada 18464 parameter yang harus dipelajari selama pelatihan dan akan mencerminkan jumlah data yang harus dipelajari ketika pelatihan . selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 23x23 menjadi 11x11 sebagai berikut. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝐾𝑒𝑟𝑛𝑒𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 233 21 20 21 11 6. third maxpooling2d tidak ada parameter baru yang ditambahkan dan jumlah neuron dalam contoh ini lapisan konvolusi ketiga tetap sama. setiap filter diubah menjadi setengah dari ukuran inputnya 11x11 menjadi 5x5 dan jumlah neuronnya 18464 mengikuti lapisan konvolusi ketiga . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 112 21 9 21 5 7. fourth cov2d totalneuronukuranfilterxjumlah𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝐼𝑛𝑝𝑢𝑡1xfilter 3x3x321x16 289x16 4624 jumlah channel input menggunakan jumlah filter dari convolutional layer sebelumnya bukan lagi channel input di awal. sehingga jumlah neuronnya 4624 yang berarti ada 4624 parameter yang harus dipelajari selama pelatihan dan akan mencerminkan jumlah data yang harus dipelajari ketika pelatihan . selanjutnya adalah dalam penentuan ukuran spasialnya s etiap filter diubah menjadi setengah dari ukuran input nya 5x5 menjadi 2x2 sebagai berikut. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝐾𝑒𝑟𝑛𝑒𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 53 21 1 21 1.52 8. fourth maxpooling2d tidak ada parameter baru yang ditambahkan dan jumlah neuron dalam contoh ini lapisan konvolusi keempat tetap sama. setiap filter diubah menjadi setengah dari ukuran inputnya 2x2 menjadi 1x1 dan jumlah neuronnya 4624 mengikuti lapisan konvolusi keempat . bisa juga menggunakan rumus seperti berikut untuk mengetahui dimensi atau ukuran filter. 𝐼𝑛𝑝𝑢𝑡𝑆𝑖𝑧𝑒𝑃𝑜𝑜𝑙𝑆𝑖𝑧𝑒 𝑆𝑡𝑟𝑖𝑑𝑒1 12 21 1 21 0.51 9. flatten tidak mengubah parameter yang ada karena fungsi flatten hanya mengubah matriks multidimensi menjadi vektor tunggal berdasarkan hasil dari jumlah filter pada lapisan lima cov2d yaitu 8 dan maxpooling2d dengan ukuran inputnya 1x1 sehingga menjadi matriks multidimensi 1 1 16 diubah menjadi nilai vektor tunggal dengan panjang 16 atau menjadi jumlah neuron sebanyak 16. 10. dense layer 1 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 161x128 17x128 2176 11. dropout layer 1 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 1 akan dinonaktifkan secara acak. 12. dense layer 2 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 1281x64 129x64 8256 13. dropout layer 2 menggunakan 0.2 yang artinya sebanyak 20 dari neuron dalam dense layer 2 akan dinonaktifkan secara acak. 14. dense layer 2 totalneuronjumlahneuron𝐼𝑛𝑝𝑢𝑡1xjumlahneuron𝑂𝑢𝑡𝑝𝑢𝑡 641x1 65x1 65 ketika dimensi spasial tinggi dan lebar dikurangi menggunakan operasi lapisan pooling seperti maxpooling jumlah neuron di setiap lapisan pooling akan menurun. misalnya dimensi spasial setiap filter tinggi dan lebar di lapisan maxpooling disesuaikan menjadi setengah dari dimensi masukannya. karena hanya separuh dari masukan yang diproses lebih lanjut hal ini juga menyebabkan berkurangnya jumlah neuron pada lapisan tersebut. sedangkan penurunan pada dense terjadi karena penentuan jumlah neuron.