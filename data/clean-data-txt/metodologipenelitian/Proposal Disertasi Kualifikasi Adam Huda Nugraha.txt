3.1 Kerangka Metode Penelitian yang diusulkan
       Penelitian ini bertujuan untuk mendapatkan model arsitektur LSTM untuk suara digit desimal berbahasa Indonesia sehingga tingkat akurasi pengenalan dapat lebih tinggi dibandingkan dengan penelitian sebelumnya. Akurasi atau tingkat akurasi pengenalan adalah jumlah ketepatan suara digit desimal yang diucapkan dibagi dengan jumlah data suara yang akan diterjemahkan menjadi teks, sehingga semakin tinggi akurasi pengenalan menunjukkan semakin tingginya hasil ketepatan sistem menterjemahkan sinyal-sinyal suara ini menjadi teks. Model LSTM telah diterapkan untuk pengenalan suara berbahasa Bengali (Nahid, et al. 2017) (LSTM Nahid) dan Parsi (Daneshvar dan Veisi. 2016) (LSTM Daneshvar), kedua model ini diteliti untuk dibandingkan tingkat akurasi pengenalan dengan model yang diusulkan untuk mengenali digit desimal bahasa Indonesia. Kerangka metode yang diusulkan diilustrasikan pada gambar 3.1.

3.2 Pengumpulan Data Latih Dan Data Uji
       Tahapan penelitian dilakukan seperti yang terlihat pada gambar 3.1, meliputi tahap pengumpulan data, tahap pra-pengolahan data yang mengektraksi fitur suara menggunakan spektrogram atau MFCC, tahap pembelajaran untuk mencari model, tahap klasifikasi untuk menguji model yang dihasilkan dan evaluasi dengan menghitung akurasi pengenalan. Pada tahap pengumpulan data, dilakukan perekaman data suara digit desimal berbahasa Indonesia mulai dari digit 0 hingga digit 9, kemudian dilakukan pemotongan data suara sesuai dengan digit yang diucapkan dan dilanjutkan dengan pemberian label untuk setiap file digit yang disimpan. Tahap berikutnya adalah mentransformasi sinyal suara menjadi matriks koefisien spektrogram dan mengambil ciri data suara tersebut menjadi matriks koefisien MFCC. Proses pembelajaran dilakukan dengan menggunakan DTW, HMM, RNN, model LSTM Nahid, model LSTM Daneshvar dan model LSTM yang diusulkan terhadap matriks koefisien spektrogram dan MFCC. Untuk melihat tingkat akurasi, pengujian kemudian dilakukan terhadap DTW, HMM, RNN, model LSTM Daneshvar, model LSTM Nahid dan model LSTM yang diusulkan.
       Data digit suara 0-9 yang digunakan dalam penelitian ini diambil di dalam ruang kelas ujian komputer Universitas Gunadarma. Proses perekaman dilakukan dalam jangka waktu 4 minggu, sehingga didapatkan sekitar 799 mahasiswa. Pada minggu pertama perekaman, didapatkan 100 pembicara masing-masing mengucapkan digit 0 sampai 9 sehingga terdapat 1000 data suara. 1000 data ini kemudian dilakukan proses klasifikasi LSTM menggunakan fitur spektrogram dengan 900 data latih dan 100 data uji, akurasi yang dihasilkan masih rendah sekitar 60%. Minggu kedua dilakukan kembali perekaman data dengan total data yang didapatkan 3000 data suara. Klasifikasi LSTM yang dihasilkan dari 3000 data ini meningkat menjadi 70%. Perekaman dilanjutkan dengan mendapatkan 5000 data suara dari 500 pembicara, hasil klasifikasi LSTM meningkat menjadi 80%. Pada saat 6000 data suara diklasifikasi oleh LSTM, akurasi sudah mencapai 90%, begitu juga dengan 7000 data suara. Perekaman data kemudian dilanjutkan di sisa minggu ke-empat sehingga didapatkan 7990 data suara dari 799 pembicara. Pembicara adalah mahasiswa Gunadarma dengan rentang usia 19-22 tahun, terdiri dari 389 perempuan dan 410 laki-laki. Data suara yang diambil masing-masing mengucapkan digit dengan pelafalan dapat dilihat pada tabel 2.1, sehingga total basis data suara yang didapatkan sebanyak 7990 data. Data ini kemudian disebut dengan data latih.
       Proses perekaman dilakukan dengan telepon genggam iPhone 6 menggunakan aplikasi voice memos .yang terdapat pada telepon genggam, setiap mahasiswa mengucapkan digit 0 hingga digit 9 sekaligus dengan jeda antara setiap digit, kemudian data tersebut disimpan. Perekaman terjadi dalam lingkungan pengucapan yang terdapat suara AC, suara pintu tertutup dan terbuka, suara mahasiswa lain batuk, suara keyboard, walaupun tidak disemua data. Semua noise- noise ini pada background sinyal ikut terekam oleh microphone telepon genggam. Data suara tersebut kemudian di-transfer ke laptop dan disimpan dalam format wav, dengan sample-rate 8000Hz, karena suara manusia berbicara berada pada rentang 34- 3400Hz, dan menurut Nyquist Theorem harus mengambil s dua kali dari rentang paling tinggi, maka sample-rate yang ditentukan adalah 8000Hz.
       Data-data tersebut lalu dipotong sesuai dengan digit yang diucapkan, masing-masing digit disimpan dengan satu file dan di-labelkan sesuai dengan digit yang diucapkan. Pengucapan kata "nol" dari data suara mahasiswa A, data ini akan disimpan dalam satu file dengan diberi label seperti "A-O", sehingga terdapat 10 file pengucapan digit untuk satu mahasiswa. Noise-noise yang ada, tidak dihilangkan dari sinyal suara. Untuk melihat tingkat akurasi diambil, sekitar 10 % data dari data latih. Suara 79 mahasiswa menjadi data uji, terdiri dari 3 7 perempuan dan 42 laki-laki yang tidak terdapat dalam data latih, masing-masing mengucapkan 10 digit (0-9), sehingga total data untuk pengujian berjumlah 790 data. Proses perekaman dilakukan dengan cara yang sama seperti pada pembentukan data latih. Dengan proses pengumpulan basis data seperti ini, didapatkan model yang speaker independent, karena pembicara pada data latih berbeda dengan pembicara pada data uji.

3.3 Pra Pengolahan Data
       Pada tahap ini, data latih dan data uji, diubah menjadi spektrogram dan fitur MFCC. Data suara yang masih berbentuk amplitudo sangat sulit langsung digunakan untuk pengenalan suara. Nilai-nilai amplitudo tersebut sangat berfluktuasi tergantung dari tekanan pengucapan, kualitas microphone, noise, dan lain-lain. Algoritma untuk mengekstraksi ciri dari nilai-nilai amplitudo ini kemudian dikembangkan agar mempermudah proses pengenalan sinyal suara. MFCC digunakan untuk mengekstraksi ciri suara pada penelitian ini, karena hampir semua penelitian dengan DTW, HMM dan RNN menggunakan fitur MFCC pada digit bahasa Jepang (Sakoe dan Chiba. 1978), pada digit bahasa Spanyol Gomez. 2005), pada digit bahasa Arab (Alotaibi et al. 2010), pada digit bahasa Kroasia (Gulic, Lucanin dan Simic. 2011), pada digit bahasa Hindi (Dhandhania, Hansen, Kandi dan Ramesh. 2012; Saxena dan Wahi. 2015), pada digit bahasa Myanmar (Tun dan Srijuntongsiri. 2016), dan pada digit bahasa Gujarati (Pandit dan Bhatt. 2014). Spektrogram mulai digunakan oleh (Sak, et al. 2014) untuk pemodelan dengan LSTM dengan harapan agar LSTM dapat menemukan sendiri model akustik dari pembicara tanpa perlu fitur ekstraksi ciri seperti MFCC, sehingga spektrogram juga digunakan pada penelitian pengenalan suara digit desimal berbahasa Indonesia ini saat proses pra-pengolahan data.

3.3.1 Spektrogram
      Sinyal suara dapat dilihat dalam domain frekuensi yang menggambarkan kerapatan spektrum sinyal atau disebut dengan spektrogram. Untuk merubah sinyal dari domain waktu (amplitudo) ke domain frekuensi (spektrogram) dapat dilakukan dengan langkah seperti pada gambar 3.2. Sinyal suara dipotong per 20 milidetik, lalu dilakukan windowing dengan menggunakan metode hamming agar didapatkan rentang nilai magnitude di dalam sinyal, kemudian data yang telah di-windowing ini ditransformasi Fourier dan menghitung magnitude Fourier (log absolut). Untuk setiap 20 milidetik didapatkan 64 koefisien spektrogram.
Pemotongan 20 milidetik atau 0.02 detik pada sample rate 8000Hz menghasilkan 160 sample. Jumlah sample didapatkan dari formula berikut:
Sample = sample-rate x time (detik)
=8000 x 0.02 =160
Pada gambar 3.3 diperlihatkan hasil pemotongan dari 20 milidetik atau 160 sample sinyal suara setelah dilakukan proses windowing dengan menggunakan hamming.
       Koefisien magnitude dari Fourier kemudian didapatkan dari sinyal suara yang telah di windowing. Nilai FFT size yang digunakan adalah 128, sehingga didapatkan 64 (128 dibagi 2) koefisien Fourier. Untuk data suara dengan sample rate 8000Hz, nilai fft size 128, 256, 512 tidak terlalu berpengaruh, sehingga bisa menggunakan nilai fft size yang paling kecil agar proses transformasi fourier lebih cepat.
       Flowchart mengubah sinyal amplitudo menjadi spektrogram pada Matlab dapat dilihat pada gambar 3.4.

3.3.2 Mel-Frequency Ceptral Ceptrum (MFCC)
       Ekstraksi ciri pada dasarnya adalah mengubah sinyal-sinyal amplitudo atau spektrogram menjadi hanya beberapa vektor koefisien yang diperkirakan mengandung informasi yang penting. Mel-Frequency Cepstrum Coefficient (MFCC) yang dikenalkan oleh Davis dan Mermelstein pada tahun 1990, mengambil sekitar 12 vektor frekuensi dari sinyal suara. Koefisien MFCC ini merupakan fitur ekstraksi ciri suara paling sering digunakan karena menunjukkan akurasi yang tinggi pada sinyal yang terdapat noise (Davis dan Mermelstein. 1990). Pada penelitian ini MFCC juga digunakan sebagai fitur ciri.
       Langkah awal untuk mencari koefisien MFFC mirip dengan spektrogram, namun setelah mendapatkan nilai koefisien fourier, ditambahkan menghitung log mel-frekuensi dan mencari ceptral koefisien dengan menghitung- Discrete Cosinus Transform (DCT) dari log mel-frekuensi. Langkah lengkap dapat dilihat pada gambar 3.5.
       Pada gambar 3.5, menunjukkan plot hasil 64 koefisien FFT kemudian dilakukan perhitungan mel-frekuensi dengan 12 parameter. Flowchart mengekstraksi ciri suara dengan MFCC pada Matlab dapat dilihat pada gambar 3.6.

3.4 Dynamic Time Warping (DTW)
       Untuk melakukan pengenalan suara dengan algoritma DTW, sebelumnya dilakukan pengambilan fitur ciri spektrogram atau MFCC dari 7990 data latih, begitu juga dengan 790 data uji. Koefisien spektrogram atau MFCC tersebut kemudian yang dijadikan data matriks untuk pengenalan dengan DTW. Terdapat 12 koefisien yang dihasilkan jika menggunakan MFCC, dan 64 koefisien jika menggunakan spektrogram.
       DTW membuat distance matriks untuk me-normalisasi perbedaan ukuran antara matriks yang akan dibandingkan, sehingga jika matriks data uji (A) menggunakan MFCC berukuran 83x12 dan matriks data latih (B) berukuran 52x12, maka distance matriks DTW akan berukuran 83x52. Distance matriks DTW menggunakan spektrogram juga berukuran yang sama, jika matriks data uji (A) berukuran 83x64 dan matriks data latih (B) berukuran 52x64, maka distance matriks DTW akan berukuran 83x52. Flowchart pengujian dengan DTW dapat dilihat pada gambar 3.7.
       Setiap sel distance matriks (D) berisi kombinasi antara jarak euclidean dan bobot 
antara sel A dan sel B. Proses ini dihitung hingga semua sel matriks D terisi. Jarak DTW antara matriks A dan matriks B kemudian didapatkan dari sel matriks D yang berada di sel terakhir dari distance matriks atau di sel pada baris 83 dan kolom 52.