Berbicara adalah bentuk komunikasi paling umum dan paling mudah yang dimiliki oleh manusia. Setiap manusia umumnya terlahir mempunyai organ-organ biologis yang dapat membuatnya berkomunikasi dengan cara berbicara dan belajar mengembangkan kemampuan tersebut sejak kecil mengikuti lingkungan dan budaya tempatnya berada, sehingga dengan berbicara manusia dapat saling berinteraksi dan menyampaikan informasi dengan cepat dan mudah, walaupun masih terbatas oleh jarak. Perkembangan teknologi memperluas dalam penyampaian informasi, sehingga manusia bias berbicara dalam jarak jauh dengan menggunakan telepon (kabel), telepon genggam (cdma dan gsm) dan komputer (voip), namun kemampuan teknologi ini hanya sebatas menjadi perantara sinyal-sinyal suara.
Teknologi pengenalan suara kemudian berkembang menjadi teknologi yang mempermudah manusia dan memberikan kenyaman terhadap manusia dalam memanfaatkan informasi menggunakan perantara suara. Saat ini teknologi bukan hanya sekedar perantara dalam membantu peranan manusia dalam berkomunikasi dan bertukar informasi dalam melakukan berbagai interaksi dengan adanya alat-alat yang tersedia saat ini. Seperti halnya teknologi antarmuka yang mempermudah manusia dalam mengekspresikan apa yang dimaksud dalam upaya berinteraksi untuk mencapai tujuan yang sama. Antarmuka suara akan sangat mendukung aplikasi-aplikasi seperti memberikan perintah tertentu lewat suara untuk dij alankan, menterjemahkan sinyal suara menjadi teks kemudian menterjemahkan kembali menjadi suara dalam bahasa lain, memverifikasipasswordataupin yang diucapkan, dan lain-lain. Aplikasi-aplikasi ini mendorong para peneliti sejak 1970-an untuk mengembangkan algoritma pengolahan suara agar dapat dikenali dengan baik oleh komputer.
Suara adalah sinyal gelombang yang merambat melalui udara karena adanya getaran dalam molekul udara (McLoughlin, 2009). Di dalam udara suara merambat sebagai variasi tekanan tinggi dan rendah yang disebut dengan amplitude. Microphone manangkap sinyal suara ini dan diubah menjadi sinyal digital oleh Analog to Digital Coverter (ADC), proses pengubahan ini di-digitalisasi dengan format standar tertntu yang telah ditetapkan (McLoughlin, 2009). Pulse Code Modulation (PCM) adalah format standar yang digunakan saat ini. Sinyal-sinyal ini disimpan dengan mengukur tingginya amplitude pada waktu tertentu, kemudian agar menjadi gelombang, diambil dua nilai dalam satu siklus, nilai positif dan negative (Jurafsy dan Martin, 2008). Banyaknya nilai sinyal yang diambil dalam satu detik disebut dengan sampling rate. Semakin tinggi sampling rate menyebabkan semakin akurat nilai sinyal, sehingga dalam pongelolan suara umumnya dimabil sample rate dua kali dari frekuensi minimum seperti yang ditetapkan dalam Nyquist frequency (Jurafsy dan Martin, 2008). Minimum sampling rate suara manusia berada pada kisaran dibawah 4000Hz, seperti yang digunakan pada jalur telepon, sehingga pengolahan suara dengan frekuensi 8000Hz merupakan nilai dengan sampling rate yang cukup untuk mewakili suara manusia.
Suara manusia terbentuk dari gelombang akustik yang bergetar ketika udara keluar dari paru-paru melalui tenggorokan dan mulut atau hidung. Terdapat tiga rongga utama yang membuat manusia bersuara yaitu rongga hidung, rongga mulut, dan rongga faring (Chu. 2003). Saluran vokal (vocal tract) mengacu pada rongga faring dan rongga mulut. Saluran nasal (nasal tract) berawal dari rongga langit- langit tenggorokan (velum) dan berakhir pada rongga hidung (Chu. 2003). Suara hidung adalah suara yang dihasilkan ketika langit-langit tenggorokan menutup. Dalam laring (larynx) atau pangkal tenggorokan terdapat komponen penting dalam pengolahan suara yang disebut dengan pita suara (vocalfolds). Pita suara ini terdiri atas pasangan otot dan membran yang menutup dan membuka dengan cepat (bergetar). Kecepatan pita suara dalam bergetar atau disebut juga dengan pitch ini unik dalam setiap manusia dan mendefinisikan ciri dari pembicara (Stevens. 2000). Secara umum pitch berada antara rentang 50 - 250 siklus per detik (Hz) untuk suara laki-laki dewasa sampai dengan lebih dari 120 - 500 siklus per detik (Hz) untuk suara perempuan, atau dalam domain waktu berada antara 4 ms - 20 ms untuk laki-laki dan 2 ms - 8 ms untuk perempuan (Chu. 2003). Bentuk dan formasi dari saluran vokal dan saluran nasal ini juga berubah secara terus menerus dalam waktu, ketika udara keluar dari paru-paru melalui tenggorokan, spektrum frekuensi yang terbentuk tergantung dari bentuk dan panjang dimensi saluran vokal (Chu. 2003). Spektrum frekuensi yang dihasilkan ini juga unik tergantung dari panjang saluran vokal tiap manusia, panjang saluran vokal (vocal tube) ini secara umumadalah 14,1 cm untuk perempuan hingga 16,9 cm untuk laki-laki (Stevens. 2000).
Pemanfaatan teknologi informasi sebagai sumber informasi yang cepat sangat menunjang dalam berbagai hal, seseorang bisa menemukan informasi yang diinginkan hanya dengan hitungan menit tanpa harus bersusah payah mendatangi pusat informasi ataupun membeli koran dan sebagainya. Perkembangan teknologi saat ini telah memberikan pengaruh yang sangat besar bagi dunia teknologi informasi. Sinyal-sinyal suara yang di-digitalisasi dalam bentuk amplitudo inilah yang diolah untuk dapat dikenali. Amplitudo sinyal suara selain dinyatakan dalam domain waktu dapat dilihat juga dalam domain frekuensi yang disebut dengan spektrogram. Spektrogram menggambarkan sinyal dalam bentuk dua dimensi dengan waktu sebagai sumbu-x, frekuensi dalam sumbu-y dan energi frekuensi digambarkan dengan intensitas warna. Sinyal suara diubah kedalam bentuk spektrogram menggunakan Fourier Transform, karena formula Fourier dapat mengekstrak kandungan frekuensi yang terdapat dalam sinyal suara.
Dalam kondisi nyata yang dihadapi oleh manusia, untuk satu pembicara walaupun mengucapkan suara atau kata yang sama, nilai-nilai dari sinyal suara ini tidak akan sama persis, cara pengucapan (panjang atau pendek dalam mengucapkan kata), dialek (bahasa yang berbeda) pembicara, ekspresi yang menghasilkan intonasi tekanan tinggi rendah suara yang dikeluarkan saat berbicara dan emosi saat berbicara seringkali berubah-ubah setiap waktu. Suara (kata) yang sama diucapkan oleh pembicara yang berbeda juga memiliki keunikannya masing-masing (misal, jenis kelamin dan usia), karena setiap sinyal suara dihasilkan melalui saluran vokal dan saluran nasal yang berbeda-beda setiap manusia. Sinyal suara juga dapat bercampur dengan sinyal bunyi-bunyi lain (noise) seperti suara hujan, suara kendaraan, suara pendingin udara dalam ruangan dan lain-lain, tergantung dengan lingkungan tempatnya berbicara. Hal inilah yang membuat pengenalan suara menjadi topik penelitian yang terus berkembang hingga saat ini.
Pengenalan suara pada dasarnya membutuhkan basis data suara (training) dan proses pengenalan (klasifikasi). Basis data suara berisi koleksi sinyal-sinyal suara yang telah diberi label. Proses pengenalan adalah proses untuk mengidentifikasi sinyal-sinyal yang diucapkan dengan cara membandingkan dengan sinyal-sinyal suara yang terdapat dalam basis data (Chavan dan Sable. 2013). Sinyal-sinyal suara dalam bentuk amplitudo atau spektrogram sangat sulit dilakukan proses pengenalan karena selain banyaknya data yang harus diproses (untuk sample rate 8000Hz dalam satu detik terdapat 16000 data numerik), nilai- nilai amplitudo tersebut juga sangat berfluktuasi tergantung dari tekanan pengucapan, kualitas microphone, noise, dan lain-lain. Algoritma untuk mengekstraksi ciri (koefisien) dari nilai-nilai amplitudo ini kemudian dikembangkan agar mempermudah proses pengenalan sinyal suara. Ekstraksi ciri adalah mengubah sinyal-sinyal amplitudo atau spektrogram menjadi hanya beberapa vektor koefisien yang diperkirakan mengandung informasi yang penting. Beberapa algoritma ekstraksi ciri yang paling sering digunakan adalah Linier Predictive Coding (LPC) yang mengambil nilai koefisien berdasarkan prediksi dari nilai sebelumnya, biasanya sekitar 10 koefisien. Mel-Frequency Cepstrum Coefficient (MFCC) yang dikenalkan oleh Davis dan Mermelstein pada tahun 1980, yang mengambil koefisien frekuensi dari sinyal suara, sekitar 12 vektor koefisien (Davis dan Mermelstein. 1990), dan Perceptual Linier Prediction (PLP) yang menambahkan filter loudness untuk menghilangkan noise dan berasumsi bahwa intensitas pendengaran manusia berada di sekitar 40 db (Ningthoujam dan Prathima. 2016).
Terdapat berbagai metode yang digunakan dalam pengenalan suara, yaitu: Template Based (1970), Statistical Learning (1980), Machine Learning (1990) dan Deep Learning (2000). Sakoe dan Chiba pada tahun 1978 mengenalkan algoritma Dynamic Time Warping (DTW) untuk mengenali suara digit dalam bahasa Jepang berdasarkan template based. Basis data template menggunakan ekstraksi ciri FBANK diambil dari 10 laki-laki mengucapkan digit 0-9 dalam bahasa Jepang yang diulang sebanyak 6 kali. Untuk pengenalan (matching) 10 pembicara yang sama mengucapkan digit 0-9 diulang sebanyak 5 kali. Tingkat akurasi yang dihasilkan mencapai 90% (Sakoe dan Chiba. 1978). Algoritma ini mampu mengatasi masalah perbedaan panjang data suara setiap pembicara. Algoritma ini telah digunakan untuk mengenali suara digit di beberapa bahasa, seperti bahasa Arab dengan ekstraksi ciri MFCC (Darabkh, Khalifeh, Bathech dan Sabah. 2013; Hachkar, Farchi, Mounir dan El-Abbadi. 2011), bahasa Inggris dengan ekstraksi ciri MFCC (Limkar, Rao dan Sagvekar. 2012) dan WMFCC (Chapaneri dan Jayaswal. 2013), bahasa Malaysia dengan ekstraksi ciri MFCC (Al-Haddad, Samad, Hussain, Ishak dan Mirvaziri. 2007), bahasa Gujarati dengan ekstraksi ciri MFCC (Pandit dan Bhatt. 2014) dan bahasa Spanyol dengan ekstraksi ciri MFCC (Terissi dan Gomez. 2005), walaupun semuanya menunjukkan tingkat akurasi yang cukup tinggi, diatas 90%, namun algoritma ini hanya mampu mengenali jika data suara pembicara telah berada dalam basis data (speaker dependent). Untuk data pembicara yang tidak terdapat dalam basis data, template based DTW menunjukkan tingkat akurasi yang rendah. Tingkat akurasi pengenalan adalah jumlah ketepatan suara digit yang diucapkan berbanding dengan jumlah data suara yang akan diterjemahkan menjadi teks, sehingga semakin tinggi akurasi pengenalan menunjukkan semakin tingginya hasil ketepatan sistem menterjemahkan sinyal-sinyal suara ini menjadi teks. Sehingga proses dalam menterjemahkan sebuah informasi dapat berjalan lebih cepat dan efektif.
Ekstraksi ciri adalah mengubah sinyal-sinyal amplitudo atau spektrogram menjadi hanya beberapa vektor koefisien yang diperkirakan mengandung informasi yang penting. Beberapa algoritma ekstraksi ciri yang paling sering digunakan adalah Linier Predictive Coding (LPC) yang mengambil nilai koefisien berdasarkan prediksi dari nilai sebelumnya, biasanya sekitar 10 koefisien. Mel-Frequency Cepstrum Coefficient (MFCC) yang dikenalkan oleh Davis dan Mermelstein pada tahun 1980, yang mengambil koefisien frekuensi dari sinyal suara, sekitar 12 vektor koefisien (Davis dan Mermelstein. 1990), dan Perceptual Linier Prediction (PLP) yang menambahkan filter loudness untuk menghilangkan noise dan berasumsi bahwa intensitas pendengaran manusia berada di sekitar 40 db (Ningthoujam dan Prathima. 2016).
Pengenalan suara berdasarkan pengucapan dapat diklasifikasikan sebagai (Ningthoujam dan Prathima. 2016): Isolated Words, Connected Words dan Continuous Speech. Isolated words adalah mengenali suara per kata yang diucapkan, sistem pengenalan menunggu satu kata selesai diucapkan lalu proses pengenalan dimulai. Connected words mirip dengan isolated words, namun mampu mengenali lebih dari satu kata yang diucapkan, sedangkan pada continuous speech sistem mengenali terus menerus setiap kata yang diucapkan tanpa ada jeda menunggu. Terdapat berbagai metode yang digunakan dalam pengenalan suara, yaitu: Template Based (1970), Statistical Learning (1980), Machine Learning (1990) dan Deep Learning (2000).
Sakoe, Isotani, Yoshida, Iso dan Watanabe pada tahun 1989 mengenalkan algoritma machine learning: Dynamic Programming Neural Network untuk mengenali suara digit berbahasa Jepang. Data untuk pembelajaran (training) dengan ekstraksi ciri MFCC diambil dari 50 pembicara mengucapkan digit 0-9 dalam bahasa Jepang, dan data suara dari 57 pembicara berbeda digunakan saat proses pengenalan. Tingkat akurasi mencapai 90% (Sakoe, Isotani, Yoshida, Iso dan Watanabe. 1990). Jumlah basis data suara yang digunakan saat proses pembelajaran (training) sangat penting dalam machine learning, semakin banyak data suara yang digunakan akan semakin meningkatkan akurasi pengenalan, dan seperti pada statistical learning dengan HMM, ekstraksi ciri yang digunakan dalam proses pembelajaran machine learning juga sangat menentukan tingkat akurasi. Proses pembelajaran neural network dengan spektrogram membutuhkan layer yang besar (deep), sehingga diperlukan neural network khusus untuk proses pengenalan suara. Neural Network untuk pengenalan suara dengan layer yang besar (diatas 100 hidden layer), mempunyai dua masalah utama untuk mencapai network yang optimal, yaitu: Vanishing Gradient (Hochreiter dan Schmidhuber. 1997) dan Dependency (Lekshmi dan Sherly. 2016). Vanishing Gradient adalah kondisi hilangnya nilai error (nilai selisih antara prediksi output dengan prediksi sesungguhnya, yang dibutuhkan untuk memperbaiki bobot layer) saat proses backward-pass dari hidden layer di ujung output ke hidden layer di dekat input (Hochreiter dan Schmidhuber. 1997). Dependency terjadi karena pada neural network, semua input layer diasumsikan tidak saling berhubungan (independent) (Lekshmi dan Sherly. 2016), sedangkan pada data suara, setiap 20 milidetik yang diambil pada dasarnya saling berhubungan dengan data 20 milidetik berikutnya.
Jumlah basis data suara yang digunakan saat proses pembelajaran (training) sangat penting dalam machine learning, semakin banyak data suara yang digunakan akan semakin meningkatkan akurasi pengenalan, dan seperti pada statistical learning dengan HMM, ekstraksi ciri yang digunakan dalam proses pembelajaran machine learning juga sangat menentukan tingkat akurasi. Ekstraksi ciri mana yang akan dipakai? siapa yang lebih baik dari berbagai macam ekstraksi ciri yang ada? atau apakah perlu menemukan ekstraksi ciri yang lebih baik? bagaimana jika tidak menggunakan ekstraksi ciri, kembali ke data mentah yang berupa amplitudo atau spektrogram?. Tingkat akurasi dengan MFCC terbukti lebih baik dari LPC. MFCC berbasis frekuensi. Spektrogram berbasis frekuensi. Neural Network dengan dataspektrogram?. Pertanyaan-pertanyaan ini yang kemudian mendorong para peneliti menemukan metode Deep Learning.
Data spektrogram dapat di input langsung ke neural network, dan diharapkan neural network sendiri yang menemukan pola ekstraksi ciri suara (model akustik pembicara). Untuk sample rate 8000Hz, vektor data spektrogram berjumlah 64 koefisien setiap 20 milidetik sehingga dalam satu detik terdapat sekitar 64x50 vektor data suara, dibandingkan dengan MFCC yang hanya 12x50 koefisien atau LPC yang 10x50 koefisien. Proses pembelajaran neural network dengan spektrogram membutuhkan layer yang besar (deep), sehingga diperlukan neural network khusus untuk proses pengenalan suara. Neural Network untuk pengenalan suara dengan layer yang besar (+ diatas 100 hidden layer), mempunyai dua masalah utama untuk mencapai network yang optimal, yaitu: Vanishing Gradient (Hochreiter dan Schmidhuber. 1997) dan Dependency (Lekshmi dan Sherly. 2016). Vanishing Gradient adalah kondisi hilangnya nilai error (nilai selisih antara prediksi output dengan prediksi sesungguhnya, yang dibutuhkan untuk memperbaiki bobot layer) saat proses backward-pass dari hidden layer di ujung output ke hidden layer di dekat input (Hochreiter dan Schmidhuber. 1997). Dependency terjadi karena pada neural network, semua input layer diasumsikan tidak saling berhubungan (independent) (Lekshmi dan Sherly. 2016), sedangkan pada data suara, setiap 20 milidetik yang diambil pada dasarnya saling berhubungan dengan data 20 milidetik berikutnya.
Long-Short Term Memory (LSTM) Network yang dikenalkan oleh Hochreiter dan Schmidhuber pada tahun 1997 memperbaiki masalah vanishing gradient dan keterhubungan antara input layer (long-term dependencies) yang dibuat khusus untuk mengatasi masalah di pengenalan suara (Hochreiter dan Schmidhuber. 1997). LSTM menjadi model Deep Learning yang sering digunakan hingga saat penelitian ini dilakukan. Google pada tahun 2010 mulai menggunakan LSTM untuk mengenali data suara berbahasa Inggris pada 22500 kosakata bahasa Inggris, kemudian menjadi awal dari sistem pengenalan suara di Google Voice Search Task yang diimplementasikan di situs Google (Sak, Senior dan Beaufays. 2014). Microsoft menggunakan Deep Learning LSTM untuk sistem pengenalan suara multi-bahasa di internal Microsoft dengan data suara yang besar pada proses pembelajaran, 138 jam data suara berbahasa Perancis, 195 jam data suara berbahasa Italia (Deng, Li, Huang, Yao, Yu, Seide, Seltzer, Zweig, He dan Williams. 2013). Model LSTM dengan penambahan satu layer untuk pengenalan aksen digunakan untuk mengenali suara berbahasa Mandarin, dengan tingkat akurasi 90% (Yi, Ni, Wen, Liu dan Tao. 2016). LSTM digunakan untuk mengenali suara pada basis data TIMIT (basis data fonem berbahasa Inggris dengan dialek Amerika, direkam dari 630 pembicara yang dikumpulkan oleh Massachusetts Institute of Technology, SRI International dan Texas Instrument) menunjukkan tingkat akurasi yang lebih tinggi dibandingkan dengan metode lainnya (Graves, Mohamed dan Hinton. 2013).
Akurasi atau tingkat akurasi pengenalan adalah jumlah ketepatan suara digit yang diucapkan berbanding dengan jumlah data suara yang akan diterjemahkan menjadi teks, sehingga semakin tinggi akurasi pengenalan menunjukkan semakin tingginya hasil ketepatan sistem menterjemahkan sinyal-sinyal suara ini menjadi teks. Lawrence Rabiner dan Biing Hwang Juang pada tahun 1986, mengusulkan penggunaan model Hidden Markov (HMM) yang telah diketahui sejak lama di kalangan matematikawan (pertama kali dikenalkan oleh L.E. Baum pada tahun 1966) untuk memodelkan banyak suara pembicara menjadi hanya beberapa model sehingga menghilangkan ketergantungan dengan basis data dan pengenalan suara yang speaker independent dapat dihasilkan. Speaker independent adalah pengenalan suara yang tidak tergantung pada siapa pembicaranya, pembicara pada basis data suara berbeda dengan pembicara pada basis data uji. Basis data pada HMM hanya dipakai saat proses pembelajaran (train) dan setelah didapatkan model, basis data tidak digunakan lagi. Proses pengenalan akan mencari kemiripan ke model-model yang dihasilkan sehingga dapat mempercepat proses. Rabiner dan Juang menunjukkan metode HMM ini dapat memodelkan pengucapan dari beberapa pembicara dan mampu menyamai tingkat akurasi dari template based. Basis data dengan ekstraksi ciri MFCC diambil dari pembicara mengucapkan digit 0-9 dalam bahasa Inggris. Tingkat akurasi yang dihasilkan mencapai 98% (Rabiner dan Juang. 1986). Model ini hingga sekarang masih banyak digunakan untuk mengenali suara digit dari berbagai bahasa yang berbeda dengan rata-rata tingkat akurasi juga mencapai diatas 90%, seperti bahasa Arab dengan ekstraksi ciri MFCC (Hachkar, et al. 2011; Alotaibi, Alghamdi dan Alotaiby. 2010), bahasa Kroasia dengan ekstraksi ciri MFCC (Gulic, Lucanin dan Simic. 2011), bahasa Perancis dengan ekstraksi ciri LPC (Tassy dan Miclet. 1986), bahasa India dengan ekstraksi ciri MFCC (Dhandhania, Hansen, Kandi dan Ramesh. 2012; Saxena dan Wahi. 2015), bahasa Malaysia dengan ekstraksi ciri MFCC (Al-Haddad, et al. 2007), dan bahasa Rumania dengan ekstraksi ciri MFCC (Cucu, Caranica, Buzo dan Burileanu. 2015), serta dalam bahasa Inggris dengan memodelkan ciri suara yang berbeda untuk suara digit yang tercampur dengan background suara yang tidak jernih (noise), seperti di keramaian, di jalan raya, di bandara, dan di dalam kereta dengan ekstraksi ciri BFCC dan WMFCC (Mukhedkar dan Alex. 2014. Basis data suara dimodelkan oleh HMM saat proses pembelajaran berdasarkan maksimum probabilitas dari ekstraksi ciri data suara, sehingga menentukan ekstraksi ciri suara yang tepat menjadi sangat penting dalam HMM.
Keberhasilan dari HMM dalam memodelkan data suara dengan ekstraksi ciri tertentu mendorong peneliti untuk memodelkan data suara dengan Neural Network (Machine Learning), dengan harapan menyederhanakan dan membuat model yang lebih baik. Pada neural network hanya menghasilkan satu model yang diasumsikan sudah optimal, dibandingkan dengan beberapa model yang dihasilkan oleh HMM (model fonem, model bahasa atau model word). Neural Network telah terbukti mampu memodelkan data yang tidak linier dan telah diaplikasikan pada berbagai macam bidang mulai dari memprediksi kebangkrutan, mengenali tulisan tangan hingga mendiagnosis penyakit (Zhang. 2000).
Pada tahun 2013 penelitian untuk pengenalan suara digit berbahasa Indonesia telah dilakukan dengan menggunakan CMU-Sphinx (Dewi, Firdausillah dan Supriyanto. 2013). CMU-Sphinx merupakan sistem pengenalan suara berbasis Hidden Markov Model dengan fitur ekstraksi ciri MFCC yang dikembangkan oleh Carnegie Melon University (CMU) dan Sun Microsystem (Lamere, Kwok, Gouvea, Raj, Singh, Walker, Warmuth dan Wolf. 2003). Proses pembelajaran untuk mendapatkan model HMM diambil dari 7 orang laki-laki mengucapkan digit 0-9 sebanyak 3 kali dalam lingkungan yang bebas noise. Untuk proses pengenalan setiap pembicara yang sama diharuskan mengucapkan digit seperti dalam percakapan yang normal. Tingkat akurasi yang dicapai kurang dari 50%, disebabkan oleh faktor tekanan pengucapan, cara pengucapan dan panjang pengucapan yang berbeda antara model data yang dihasilkan oleh HMM dengan data suara yang diuji-cobakan (Dewi, et al. 2013).
Pada tahun 2016 dilakukan penelitian untuk mengenali suara digit berbahasa Indonesia, hal ini dilakukan dengan menggunakan CMU-Sphinx (Prakoso, Ferdiana dan Hartanto. 2016). Proses pembelajaran model HMM suara digit berbahasa Indonesia pada penelitian ini diambil dari 8 laki-laki dan 7 perempuan mengucapkan digit sebanyak 2 kali dalam lingkungan yang bebas noise. Proses pengenalan dilakukan dengan mengambil 6 pembicara yang mengucapkan 54 digit secara acak dari 99 digit yang disediakan. Tingkat akurasi mencapai 80% (Prakoso, et al. 2016).