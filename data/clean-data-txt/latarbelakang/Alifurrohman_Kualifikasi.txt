Machine Learning (ML) adalah cabang dari kecerdasan artifisial yang memanfaatkan teknik statistik dan algoritma agar dapat belajar dan membuat keputusan atau prediksi berdasarkan data. Dengan menggunakan algoritma ML, komputer dapat meningkatkan efisiensi dalam melakukan berbagai jenis pekerjaan tanpa harus di program secara eksplisit untuk setiap tugasnya (Karimi-Mamaghan, M., Mohammadi, M., Meyer, P., Karimi-Mamaghan, A. M., & Talbi, E. G, 2022). ML memanfaatkan berbagai teknik dari statistik, teori probabilitas, matematika, dan ilmu komputer untuk membangun model dari dataset yang ada. Machine learning adalah metode yang secara otomatis menganalisis data untuk mendapatkan aturan, kemudian menggunakan aturan ini untuk memprediksi data yang tidak diketahui. Algoritma dan metode statistik diterapkan untuk memberikan komputer kemampuan untuk "belajar" dari data dan meningkatkan kinerjanya dalam memecahkan masalah tanpa harus memprogram secara eksplisit untuk setiap masalah (Ni, Qiuping & Tang, Yuanxiang, 2023).
Machine learning dibagi menjadi tiga kategori supervised learning, unsupervised learning dan reinforcement learning (Karimi-Mamaghan, M., Mohammadi, M., Meyer, P., Karimi-Mamaghan, A. M., & Talbi, E. G, 2022). Reinforcement learning merupakan bagian dari machine learning yang membedakan dari supervised learning dan unsupervised learning yaitu pada reinforcement learning dengan trial and eror selama interaksi langsung dengan lingkungan sekitar (Panzer & Bender, 2022). Reinforcement learning (RL) tidak memerlukan sinyal yang diawasi untuk belajar, RL bergantung pada sinyal umpan balik dari individu (agent) di lingkungannya. Umpan balik ini mengoreksi keadaan dan tindakan agen, sehingga agen secara bertahap dapat mempelajari cara memaksimalkan hadiah (reward) dengan cara memaksimalkan nilai cumulativereward (hadiah atau imbalan yang dikumpulkan secara kumulatif) dan mencapai kemampuan belajar mandiri yang kuat (Ni & Tang, 2023).
Algoritma RL dapat dibagi menjadi dua kategori yaitu pembelajaran berbasis model dan pembelajaran bebas model (Mousavi, Seyed Sajad, Howley, Enda & Schukat, Michael, 2018). Pembelajaran berbasis model memiliki pengetahuan sebelumnya tentang lingkungan yang dapat dioptimalkan terlebih dahulu. Pembelajaran bebas model lebih rendah daripada yang pertama dalam hal kecepatan pelatihan, tetapi lebih mudah diimplementasikan dan dapat dengan cepat menyesuaikan diri dengan keadaan yang lebih baik dalam skenario nyata. Penerapan reinforcement learning telah menunjukkan hasil yang signifikan pada berbagai bidang seperti robotika (Jens Kober, J Andrew Bagnell, Jan Peters, 2013), permainan (Silver, D., Huang, A., Maddison, C. et al. 2016), kesehatan (Liu Siqi,See Kay Choong, Ngiam Kee Yuan, Celi Leo Anthony, Sun Xingzhi, Feng Mengling,2020) dan distribusi logistik (He Zhenhua, Chen Liang, Liu Bin, 2024). Perkembangan teknik machine learning, khususnya dalam deep learning,
telah memungkinkan penggunaan arsitektur neural network yang lebih kompleks untuk memecahkan berbagai masalah yang sulit diselesaikan dengan pendekatan konvensional. Salah satu teknik yang telah menunjukkan hasil signifikan adalah penggunaan mekanisme perhatian ganda atau multi-header attention. Multi-header attention adalah mekanisme di mana lapisan perhatian direplikasi beberapa kali untuk memungkinkan model fokus pada bagian berbeda dari urutan masukan secara bersamaan (Cordonnier, Loukas & Jaggi, 2020). Mekanisme ini pertama kali diperkenalkan dalam konteks model Transformer (Vaswani et al., 2017), dan telah digunakan secara luas dalam berbagai aplikasi salah satunya pengoptimalan rute logistik (Xin, Liang, Wen Song, Zhiguang Cao, and Jie Zhang, 2021).
Distribusi merupakan kegiatan proses penyaluran produk dari produsen sampai ke tangan masyarakat atau konsumen secara tepat waktu dan efisien (Tjiptono & Diana, 2020). Pengiriman yang tepat waktu merupakan salah satu tujuan dari proses distribusi yang dapat dilakukan dengan memahami lokasi tujuan distribusi. Terdapat beberapa lokasi tujuan pada proses pendistribusian yangmengakibatkan biaya transportasi yang cukup tinggi. Biaya transportasi yang melebihi anggaran dikarenakan penentuan rute pendistribusian masih dilakukan secara manual atau acak yaitu penentuan jalur distribusi berdasarkan perkiraan saja.
Vehicle routing problem (VRP) merupakan masalah optimasi kombinatorial klasik yang pertama kali diusulkan oleh George Danztig pada tahun 1959 (Dantzig & Ramser, 1959). Vehicle routing problem (VRP) termasuk permasalahan NP-Hard yang umum dalam optimasi kombinatorial dan telah dipelajari selama beberapa dekade. Tujuan utama untuk menentukan rute optimal bagi armada kendaraan untuk melayani sekumpulan pelanggan. Penelitian terkait VRP adalah kunci untuk meningkatkan daya saing pada industri logistik. Perkembangan distribusi di dunia nyata dengan bermacam-macam karakteristik membuat banyaknya variasi VRP dari single objective hingga VRP multi objective. Terdapat berbagai jenis vehicle routing problem (VRP) misalnya capacited vehicle routing problem (CVRP), VRP with time windows (VRPTW), Multi-Depot Vehicle Routing Problem (MDVRP) (Abdirad Maryam, Krishnan Krishna, Gupta Deepak, 2022), dynamic vehicle routing problem with time windows (DVRPTW) (Ghannam & Gleixner, 2023) dan vehicle routing problem with pickup and delivery (VRRPPD) (M. Liu, Q. Song, Q. Zhao, L. Li, Z. Yang, Y. Zhang, 2022).
Dynamic vehicle routing problem with time window (DVRPTW) merupakan permasalahan optimasi rute yang menambahkan batasan jendela waktu ke dalam permasalahan. Hal ini berarti bahwa pelanggan memiliki periode waktu tertentu untuk dilayani. DVRPTW harus menjadwalkan pengiriman supaya barang diterima dalam rentang waktu yang ada sekaligus untuk meminimalkan biaya operasional (Liu et al., 2023). Permasalahan yang terjadi pada DVRPTW yaitu perubahan dinamis seperti pesanan baru, pembatalan, atau keterlambatan serta ketidak pastian lalu lintas, waktu pengiriman dan durasi pelayanan menambah kompleksitas permasalahan. Pengiriman dilakukan dalam jendela waktu yang menjadi kendala penting pada proses distribusi. Sebab jika pengiriman melebihi jendela waktu yang ditetapkan akan mengakibatkan ketidakpuasan pelanggan. Permasalahan ini yang perlu untuk diselesaikan untuk meningkatkan solusi yang optimal untuk permasalahan yang ada.
Terdapat berbagai solusi untuk menyelesaikan permasalahan ini diantaranya metode eksak, metode heuristik dan metode metaheuristik (M. Liu, Q. Zhao, Q. Song, Y. Zhang,2023). Penggunaan machine learning, khususnya reinforcement learning dalam penyelesaian VRP menawarkan pendekatan baru. Ini memungkinkan pengembangan algoritma yang dapat secara otomatis belajar dari lingkungan untuk menghasilkan solusi optimal dalam kondisi yang dinamis, seperti arus lalu lintas dan kedatangan pelanggan baru. Metode reinforcement learning yang umum untuk menyelesaikan VRP termasuk dynamic programing, algoritma Q learning, algoritma deep Q-network (DQN), policy-based reinforce algorithms, value and policy combined actor-critic algorithms, dan advantage actor-critic algorithms (Ni & Tang, 2023).
Pada masalah dynamic vehicle routing problem with time window (DVRPTW) sudah banyak metode yang digunakan untuk menyelesaikan permasalahan ini seperti brain storm optimization (BSO) dan ant colony optimization (ACO) (Liu et al. 2022), algoritma hybrid brain storm optimization (BSO) (Liu et al. 2023), Algoritma dynamic hybrid genetic search (HGS) (Ghannam & Gleixner, 2023). Penggunaan reinforcement learning juga banyak digunakan untuk menyelesaikan permasalahan ini seperti yang dilakukan oleh Joe & Lau (2020) menggabungkan deep reinforcement learning dan simulated annealing (DRLSA).
Penggunaan deep reinforcement learning juga dapat digunakan pada berbagai permasalahan optimasi rute seperti yang dilakukan oleh Li et al. (2021) pada model permasalahan heterogeneous capacited vehicle routing problem (HCVRP), Jiuxiu Zhao (2020) meneliti pada vehicle routig problem. Penggunaan deep Q-network seperti yang dilakukan oleh Bdeir et al. (2021) untuk permasalahan route mengusulkan routing problem deep q-network (RPDQN) untuk masalah vehicle  routing  problem  hasilnya  bahwa  pendekatan  RP-DQN  berhasil meningkatkan kinerja dalam menyelesaikan masalah perutean kendaraan dengan memanfaatkan representasi status dinamis dan efisiensi sampel yang lebih baik.
Penggunaan model berbasis perhatian (attenttion) yang telah diteliti oleh Kool et al. (2018) untuk menyelesaikan masalah optimisasi kombinatorial, khususnya masalah perutean seperti Travelling Salesman Problem (TSP) dan Vehicle Routing Problem (VRP). Hasilnya menunjukkan bahwa model yang dibuat menunjukkan fleksibilitas yang baik dalam menangani berbagai jenis masalah optimisasi kombinatorial dengan satu set hyperparameters.
Berdasarkan penelitian terdahulu penerapan reinforcement learning dapat secara otomatis mengidentifikasi pola dan strategi terbaik untuk mengoptimalkan rute distribusi dalam menghadapi berbagai kondisi dinamis yang sering berubah, seperti variabilitas arus lalu lintas yang tidak terduga dan permintaan pelanggan yang muncul tidak dapat diprediksi. Dengan kemampuan adaptasi ini, algoritma berbasis reinforcement learning tidak hanya meningkatkan efisiensi logistik dengan menemukan solusi rute yang optimal tetapi juga meningkatkan responsivitas terhadap kebutuhan pelanggan yang berfluktuasi, secara signifikan mengurangi waktu tunggu dan biaya operasional. Pendekatan ini, tidak hanya menjanjikan peningkatan dalam kinerja logistik tetapi juga menawarkan kemampuan untuk merespons secara lebih fleksibel terhadap tantangan operasional yang kompleks, memastikan kepuasan pelanggan dan keberlanjutan operasional dalam lingkungan bisnis yang semakin kompetitif.
Penelitian ini diharapkan mampu meingkatkan efisiensi dalam pemilihan rute pada konteks logistik dan distribusi yang dinamis, khususnya dalam menghadapi dynamic vehicle routing problem with time windows (DVRPTW). Masalah ini ditandai oleh kondisi yang terus berubah, seperti fluktuasi dalam arus lalu lintas, kedatangan pelanggan baru dan adanya jendela waktu untuk pengiriman, serta kebutuhan untuk mengirim produk dalam berbagai jenis atau kategori akan mempengaruhi proses pengiriman. Untuk mengatasi tantangan tersebut, penelitian ini mengusulkan penerapan Deep Q-Network (DQN) yang diperkaya dengan mekanisme Multi-Header Attention. Pendekatan ini dirancang untuk memanfaatkan kemampuan DQN dalam memahami dan beradaptasi dengan kondisi dinamis, serta mengintegrasikan Multi-Header Attention untuk meningkatkan pemrosesan informasi. Penggabungan kedua teknologi ini, diharapkan sistem dapat secara efektif mengidentifikasi rute optimal yang memenuhi semua kriteria dan batasan yang ada, sekaligus menyesuaikan diri dengan perubahan kondisi yang ada.