judul
Pengembangan Model Klasifikasi Anomali Penyakit Paru Akibat COVID-19 Pada Citra Sinar-X Paru

latarbelakang
       Artificial Intelligence (Kecerdasan Buatan) merupakan cabang dari ilmu komputer yang berfokus pada pembuatan perangkat keras dan perangkat lunak yang dapat "berpikir" dan "belajar" seperti manusia (Kumar Verma & Verma, 2018). Karakteristik utama dari kecerdasan buatan adalah knowledge (pengetahuan). Knowledge seringkali direpresentasikan dalam bentuk struktur data yang dapat dimengerti dan diolah oleh sistem, seperti basis pengetahuan, grafik pengetahuan, atau model statistik (Amrizal, 2013).
       Salah satu pendekatan dalam pengembangan kecerdasan buatan adalah machine learning (pembelajaran mesin). Pendekatan ini mencakup berbagai teknik seperti supervised learning (pembelajaran terawasi) dan unsupervised learning (pembelajaran tanpa pengawasan). Salah satu subbidang dari pembelajaran mesin adalah deep learning (pembelajaran mendalam). Deep learningmenggunakan deep neural networks (Goodfellow, Bengio, Courville, 2016). Deep learning memiliki kemampuan untuk memproses, menganalisis data, dan mengekstraksi fitur secara otomatis yang berguna dalam berbagai bidang. Dalam bidang kesehatan, deep learning dapat digunakan untuk membantu deteksi penyakit, salah satunya saat pandemi Coronavirus Disease 2019 (COVID-19) pada tahun 2019.
       COVID-19 merupakan penyakit yang disebabkan oleh infeksi virus Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) (WHO, 2024). Virus ini pertama kali diidentifikasi pada 31 Desember 2019 di kota Wuhan, provinsi Hubei, Tiongkok (Rehman, Fariha, Anwar, 2021). Penyakit ini biasanya menginfeksi sistem pernafasan dan menimbulkan gejala yang mirip dengan Pneumonia. Gejala klinis infeksi COVID-19 meliputi demam, batuk kering, sesak nafas, kelelahan dan kekeruhan ground-glass bilateral pada CT scan dan sinar-X paru (Huang, Wang, Li, Ren, Zhao, Hu, 2020). Penularan COVID-19 dapat terjadi dari manusia ke manusia melalui droplet atau penularan langsung (Lai, Shih, Ko, Tang, Hsueh, 2020). COVID-19 telah menyebar ke seluruh dunia dalam waktu yang relatif singkat dan menyebabkan pandemi global. Sejak pertama kali diidentifikasi sampai dengan 13 April 2024, tercatat total 775 juta kasus COVID- 19 di seluruh dunia dengan 7 juta kasus menyebabkan kematian (Sumber: COVID - Coronavirus Statistics - Worldometer, 2024). Sampai saat ini penyebaran COVID- 19 secara global masih berlangsung, terdapat lebih dari 30 ribu kasus baru setiap minggu (WHO, 2024).
       Dalam menghadapi penyebaran virus yang terus berlangsung, kecepatan dan keakuratan dalam deteksi menjadi sangat penting karena virus ini mudah menular. Teknik laboratorium untuk mendeteksi COVID-19 yang menjadi standar adalah Reverse Transcription Polymerase Chain Reaction (RT-PCR) dan Rapid Antigen Testing (RAT) (Munne, Bhanothu, & Pande 2021). RT-PCR memiliki keterbatasan karena membutuhkan waktu yang lama serta peralatan dan biaya yang mahal (Rakhmina, & Herlina 2022). RAT memiliki sensitivitas yang rendah (Agustina, Fajrunni, 2020). Melihat keterbatasan tersebut, pendekatan melalui pencitraan radiologi seperti sinar-X paru dan Tomografi Komputer (CT) menjadi metode diagnostik alternatif yang umum digunakan. Menggunakan gambar radiografi seperti sinar-X paru untuk klasifikasi, memiliki kelebihan karena prosedurnya yang cepat, non-invasif, dan biaya yang relatif rendah (Zhang, Xie, Pang & Xia, 2021) dibandingkan dengan tes PCR. Selain itu, sinar-X paru lebih ekonomis daripada tes radiologi lainnya seperti CT scan dan tersedia di hampir setiap klinik (Das, Ghosh, Thunder, 2021).
       Salah satu cara untuk membedakan penyakit COVID-19 dengan penyakit paru-paru lainnya adalah melalui pemeriksaan radiologi yang dilakukan dengan memeriksa kondisi organ paru-paru. Metode pemeriksaan radiologi yang umum digunakan adalah menggunakan citra sinar-x paru untuk mengetahui kondisi organ paru-paru. Paru-paru yang terkena penyakit COVID-19 memiliki ciri terdapat bintik-bintik putih yang menandakan peradangan pada bagian paru-paru disebabkan infeksi virus SARS-Cov-2. Perbedaan citra Xray (Marginean, Popescu, Vasile, Cioboata, 2022) COVID-19 dengan 
penyakit paru-paru umum lainnya adalah letak bintik putih (Rousan, Elobeid, Karrar & Khader, 2020) yang menandakan infeksi dapat terjadi pada bagian atas maupun bawah paru-paru. Hal ini berbeda dengan penyakit Viral Pneumonia yang disebabkan oleh bakteri maupun virus yang letak peradangan berada di bagian bawah paru-paru (Balasubramaniam, Varma, Das, Lomoro, 2020). Hasil citra sinar-x COVID-19 juga memiliki perbedaan dengan penyakit Lung Opacity yang memiliki hasil lebih buram yang menandakan bahwa paru-paru terjadi infeksi, pendarahan, maupun edema paru.
       Salah satu metode yang digunakan untuk membedakan antara paru yang terinfeksi COVID-19 dengan penyakit paru lainnya adalah dengan melakukan klasifikasi menggunakan metode deep learning berbasiskan algoritma Convolutional Neural Network (CNN) (Chang & Huang, 2022). Penelitian tentang klasifikasi COVID-19 menggunakan citra sinar-X paru telah banyak dilakukan. Beberapa penelitian mencoba untuk mengembangkan model deteksi COVID-19 diantaranya dilakukan oleh Nour, Comert & Polat mengembangkan model diagnosis infeksi COVID-19 menggunakan CNN untuk ekstraksi fitur. Hasil dari CNN digunakan sebagai input untuk algoritma KNN, SVM, dan Decision Tree, dengan hyperparameter yang dioptimalkan menggunakan algoritma optimasi Bayesian. Hasil terbaik diperoleh dari penggunaan algoritma SVM, dengan akurasi 98.97%, Akurasi 3 kelas sebesar 87,02%. Penelitian ini masih memiliki keterbatasan dalam mendeteksi pada kelas jamak (Nour, Comert & Polat, 2020).
       Ozturk T, Talo M & Yildirim E mengembangkan DarkCovidNet. Model ini memiliki 17 lapisan konvolusi dengan struktur end-to-end. Akurasi untuk deteksi biner COVID-19 sebesar 98.08% dan 87,02% untuk deteksi pada kelas jamak. Penelitian ini memiliki kelemahan dalam klasifikasi kelas jamak, prediksi citra berkualitas rendah yang tidak akurat, dan kesulitan dalam mengklasifikasikan gambar dengan detail halus (Ozturk, Talo, Yildirim, 2020). Lingzhi Kong & Jinyong Cheng menggabungkan arsitektur DenseNet dan VGG16 dengan mengintegrasikan vektor fitur sebelum lapisan klasifikasi akhir. Mereka juga menerapkan mekanisme perhatian Global Attention Block (GAB) dan Category Attention Block (CAB). Model dilatih menggunakan teknik k-fold cross-validation dengan membagi dataset menjadi 5 subset. Model ini mencapai akurasi 98% untuk klasifikasi biner (sehat vs. pneumonia) dan 97.3% untuk klasifikasi tiga kategori (sehat, pneumonia, dan COVID-19) (Kong & Cheng, 2022).
       Sreejith & George menerapkan metode transfer learning dengan menggunakan model ResNet50V2 dan InceptionResNetV2. Proses pelatihan menggunakan optimizer adam dan dilakukan sebanyak 100 epoch. Hasil pengujian pada dataset uji menunjukkan bahwa model dengan arsitektur tersebut memiliki performa yang baik dengan nilai accuracy mencapai 96% untuk model ResNet50V2 dan 94% IncceptionResNetV2 (Sreejith & George, 2021)
       Penelitian (Liu, Mao, Wu, Feichtenhofer, Darrell, Saining Xie, 2020) mengimplementasikan model klasifikasi menggunakan CNN dengan arsitektur ConvNeXt berbasis Residual Depth-wise Convolution yang membuat model memiliki berbagai macam varian. Varian model yang digunakan adalah ConvNeXt base yang merupakan original arsitektur model ConvNeX (Bekhet, Alkinani, Soto, Hassaballah, 2021). Model berbasis arsitektur ConvNeXt merupakan salah satu model yang mencapai top-1 accuracy pada dataset ImageNet dengan accuracy sebesar 87.6% yang menjadikan model ini sebagai salah satu model terbaik untuk kasus klasifikasi citra (Nugroho, Puspaningrum, Munir, 2022).
       Berbeda dengan beberapa penelitian diatas yang menggunakan satu model tunggal, penelitian ini mengintegrasikan berbagai model pengklasifikasi menjadi satu model menggunakan teknik stacking. Integrated stacking merupakan teknik pembelajaran ensemble. Metode ini menggabungkan prediksi dari berbagai model yang berbeda, sehingga dapat meningkatkan kemampuan model untuk membuat prediksi yang lebih akurat (Rajagopal, Kundapur & Hareesha, 2020). Konsep stacking dilakukan melalui dua tahap utama: Pertama, beberapa model dasar (atau model level-0) dilatih pada dataset yang sama. Kedua, prediksi yang dihasilkan oleh model-model dasar digunakan sebagai input untuk meta-learner (atau model level- 1). Meta-learner ini kemudian dilatih untuk membuat prediksi akhir berdasarkan prediksi dari model dasar (AlMohimeed, Saleh, El-Rashidy, Saad, El-Sappagh & Mostafa, 2023).
       Rajkumar, Himanshu & Marimuthu mengembangkan model WavStaCov Net-19. Model ini terdiri dari ResNet50, VGG19, Xception, dan DarkNet19, keempat arsitektur ini digabungkan dengan teknik stacking. Akurasi untuk klasifikasi tiga kelas adalah 96,10%, sementara untuk klasifikasi empat kelas 94,24% (Rajkumar, Himanshu & Marimuthu, 2023).
       Dalam pelatihan model CNN dengan metode transfer learning, beberapa parameter seperti Pemilihan learning rate pada optimizer dan batch size berperan penting untuk mencapai bobot yang optimal. Proses pemelihan parameter tersebut dapat mempengaruhi kinerja model. He, Zhang, Xie & Muli mengimplementasikan perubahan nilai learning rate secara dinamis berbasis Cosine Learning Rate Decay. Penelitian tersebut menunjukkan bahwa penggunaan teknik Cosine Learning Rate Decay pada model ResNet-50-D berhasil meningkatkan akurasi top-1 pada dataset ImageNet dari 77.16% menjadi 77.91%. Penelitian ini juga menjelaskan mengenai penggunaan batch size. penggunaan batch size yang besar membuat model dapat mempelajari lebih banyak varisi data dalam satu batch pelatihan. Hal ini dapat menghasilkan nilai metrik performa yang lebih baik dibandingkan dengan penggunaan batch size yang kecil (He, Zhang, Xie & Muli, 2018).
       Penelitian ini melakukan pembentukan model klasifikasi anomali penyakit paru akibat COVID-19 pada citra sinar-X paru menggunakan arsitektur CNN antara lain : DenseNet, VGG19, ResNetV2_50, Xception, dan ConvNext. Pengembangan pada penelitian ini dilakukan dengan menerapkan metode stacking dengan cara menumpuk keluaran (output) dari setiap arsitektur dengan mengambil kelebihan dari masing-masing arsitektur. Setiap arsitektur CNN tersebut dilatih secara independen untuk menghasilkan prediksi, dimana hasil prediksinya akan digunakan sebagai masukan meta-model dalam kerangka stacking. Meta-model merupakan model yang dilatih pada prediksi yang dihasilkan oleh model dasar. Model ini berfungsi untuk mempelajari prediksi dari model dasar (ground model) dapat digabungkan untuk menghasilkan klasifikasi akhir yang lebih akurat. Pelatihan model tunggal pada penelitian ini menerapkan pembobotan ulang pada fungsi loss untuk mengatasi ketidakseimbangan data pada dataset. Proses pelatihan model menggunakan metode transfer learning dan optimasi Cosine Learning Rate Decay untuk mengubah nilai learning rate sehingga lebih cepat mencapai nilai gradientoptimal pada dataset yang digunakan.

rumusanmasalah
Permasalahan dalam penelitian ini adalah:
1. Bagaimana mendeteksi anomali pada citra sinar-X paru-paru yang dapat mengindikasikan adanya penyakit paru akibat infeksi COVID-19 menggunakan arsitektur CNN?
2. Bagaimana mengintegrasikan beberapa arsitektur CNN untuk mengklasiikasikan penyakit paru akibat covid-19 menjadi satu model ensemble?
3. Bagaimana komparasi hasil akurasi dari model arsitektur tunggal dan model stacking dalam melakukan klasifikasi penyakit paru akibat COVID-19.

tujuanpenelitian
Berdasarkan permasalahan yang diuraikan, penelitian ini bertujuan :
1. Menghasilkan model CNN untuk mendeteksi anomali pada citra sinar-X paru- paru yang dapat mengindikasikan adanya penyakit paru akibat infeksi COVID- 19.
2. Menghasilkan ensamble model hasil integrasi output beberapa arsitektur CNN untuk mengklasifikasikan penyakit paru akibat covid-19.
3. Menghasilkan komparasi akurasi model arsitektur tunggal dan model stacking dalam melakukan klasifikasi penyakit paru akibat COVID-19.

rangkumanpenelitianterkait
Tidak ada rangkuman penelitian terkait.

metodologipenelitian
Dalam disertasi ini diusulkan metode klasifikasi anomali paru akibat Covid- 19 pada citra sinar-X paru yang terbagi ke dalam tiga tahap utama, seperti yang ditunjukkan pada Gambar 3.1.
Gambar 3,1 menggambarkan peta penelitian yang terdiri dari tiga tahap utama: pelatihan model tunggal, ensemble learning dengan metode stacking dan implementasi model. Tahap pertama terdiri dari beberapa langkah, dimulai dari preprocessing dataset. Pada tahap preprocessing dilakukan augmentasi citra untuk meningkatkan variasi data pada dataset. Tahap selanjutnya adalah dataset splitting dengan membagi dataset menjadi tiga subset: dataset pelatihan, dataset validasi, dan dataset pengujian. Tahapan selanjutnya adalah pembuatan dan pelatihan model.
Proses pembuatan dan pelatihan model memanfaatkan teknik transfer learning pada beberapa arsitektur (ConvNext, DenseNet, Vgg19, ResnetV2_50 dan Xception). Teknik transfer learning bertujuan untuk mempercepat proses pelatihan dengan mentransfer bobot dari model yang sudah dilatih sebelumnya. Proses pelatihan juga memanfaatkan teknik penjadwalan learning rate, agar model dapat mencapai nilai gradient optimal sehingga mendapatkan performa model terbaik dari proses pelatihan. Tahap berikutnya adalah mengevaluasi model yang telah dilatih menggunakan dataset uji yang tidak digunakan selama proses pelatihan. Evaluasi model dilakukan dengan mengukur performanya menggunakan classification metric seperti accuracy, precision, recall, danfl-score. Hasil dari proses ini berupa beberapa model terbaik. Hasil prediksi dari beberapa model ini disimpan untuk digunakan pada tahap kedua.
Tahap kedua dalam penelitian ini adalah ensemble learning dengan metode stacking. Pada tahap ini hasil prediksi dari berbagai model tunggal yang telah dilatih sebelumnya dikumpulkan. Hasil prediksi ini mencakup probabilitas atau kelas yang diprediksi oleh masing-masing model tunggal untuk setiap sampel dalam dataset. Hasil prediksi yang dikumpulkan digunakan untuk membentuk dataset baru. Dataset baru ini terdiri dari fitur-fitur yang merupakan prediksi dari model-model tunggal sebelumnya, serta label asli dari dataset. Dataset baru ini bertujuan untuk merepresentasikan pola dan kesalahan yang dihasilkan oleh model- model tunggal. Dataset baru yang telah dibuat kemudian digunakan untuk melatih meta-model. Meta-model bertujuan untuk belajar dari kesalahan dan pola prediksi yang dihasilkan oleh model-model tunggal. Meta-model akan menggabungkan prediksi dari berbagai model tunggal untuk menghasilkan prediksi akhir yang lebih 
akurat. Setelah meta-model dilatih, dilakukan evaluasi model untuk memastikan kinerjanya.
Langkah selanjutnya adalah tahap inferensi model, yang bertujuan untuk menerapkan model yang telah dilatih pada data baru agar dapat membuat prediksi. Proses inferensi ini menggunakan layanan web API (Application Programming Interface) berbasis web yang akan dimuat dalam sebuah gambar Docker, sehingga mempermudah proses penyebaran (deployment) pada perangkat dengan berbagai lingkungan yang berbeda.

3.1 Dataset COVID-19 Radiography
       Dataset COVID-19 Radiography adalah kumpulan data citra sinar-X paru- paru. Dataset ini terdiri dari 21165 citra sinar-X paru yang dikategorikan menjadi 4 kelas seperti: 3616 citra sinar-X positif Covid-19, 10119 citra normal, 6012 citra lung opacity dan 1345 citra pneumonia virus. Gambar 3.2 menunjukkan beberapa citra sinar-X paru COVID-19, viral pneumonia, lung opacity dan normal yang disediakan oleh database Radiografi COVID-19. Dataset Radiograph COVID-19 dapat diakses di platform Kaggle pada url COVID-19 Radiography Database .
       Gambar 3.2 di atas merupakan contoh sampel citra dari dataset Radiograph COVID-19. Citra sinar-X Normal memiliki paru-paru yang bersih tanpa bintik- bintik putih, yang menandakan bahwa paru-paru tidak mengalami peradangan atau infeksi. Citra sinar-X COVID-19 memiliki ciri khas berupa bintik-bintik putih, yang menunjukkan adanya cairan dan menandakan infeksi pada paru-paru. Citra sinar-X Lung Opacity menunjukkan ciri khas berupa bintik-bintik putih keabu- abuan. Pada citra sinar-X Viral Pneumonia, terdapat bintik-bintik putih pada bagian atas paru-paru yang menunjukkan infeksi pada saluran pernapasan atas.

3.2 Preprocessing Dataset
       Sebelum digunakan dalam model deep learning, dataset yang telah disiapkan perlu diolah terlebih dahulu melalui tahap preprocessing. Tahap preprocessing pertama yang dilakukan adalah augmentasi citra untuk memperkaya dataset dengan berbagai variasi citra. Tahap selanjutnya adalah mengubah ukuran (resize) semua citra dalam dataset agar sesuai dengan kebutuhan model. Tahap terakhir adalah normalisasi citra, dimana nilai piksel setiap citra diubah ke rentang 0 hingga 1. Memperlihatkan tahapanpreprocessing dataset yang digunakan dalam penelitian ini. Pada tahap preprocessing dataset, dilakukan augmentasi citra dengan memutar citra-citra dalam dataset untuk menghasilkan variasi gambar yang terotasi. Hasil augmentasi citra ini kemudian diubah ukurannya menjadi dimensi yang sama. Selanjutnya, tipe data citra diubah ke format torch.Tensor agar dapat diproses oleh GPU. Tahap selanjutnya adalah normalisasi citra menggunakan nilai rata-rata dan standar deviasi dari dataset ImageNet, penggunaan nilai tersebut memiliki tujuan agar hasil normalisasi sama dengan proses pelatihan bobot untuk transfer learning model. Proses preprocessing pada dataset pelatihan dilakukan menggunakan algoritma 3.1.

Algoritma 3.1 Proses Preprocessing pada Dataset
Input:
Citra dari dataset COVID-19 Radiography
Output:
Citra yang telah dipreprocessing
Proses:
1. Mulai.
2. Melakukan random rotation pada citra menggunakan fungsi Random Rotation() dari PyTorch dengan parameter rotation_range sebesar 10.
3. Mengubah ukuran citra menjadi 224x224 menggunakan fungsi Resize() dengan parameter cfg['model']['input_size'].
4. Mengonversi citra menjadi tensor menggunakan fungsi ToTensor().
5. Melakukan normalisasi citra menggunakan nilai mean dan std dari dataset ImageNet yang diberikan, yaitu mean=[0.485, 0.456, 0.406] dan std=[0.229, 0.224, 0.225] menggunakan fungsi Normalize().
6. Selesai.
       Algoritma 3.1 menggambarkan langkah-langkah preprocessing yang dilakukan pada dataset. Langkah pertama adalah melakukan augmentasi citra menggunakan RandomRotation() dengan parameter rotation_range sebesar 10 derajat. Langkah selanjutnya adalah mengubah ukuran citra dengan nilai parameter (224, 224) menggunakan fungsi Resize(). Setelah itu, tipe data diubah menjadi torch.Tensor dengan fungsi ToTensor() untuk persiapan pengolahan pada perangkat. Terakhir, gambar dinormalisasi dengan fungsi Normalize() menggunakan nilai mean dan standard deviasi dari dataset ImageNet, yaitu [0.485, 0.456, 0.406] dan [0.229, 0.224, 0.225].

3.3 Dataset Splitting
      Dataset Splitting merupakan proses membagi dataset menjadi beberapa subset. Pada penelitian ini dataset dibagi menjadi 3 subset: yaitu dataset pelatihan, dataset validasi, dan dataset pengujian. Dataset pelatihan dan dataset validasi digunakan untuk melatih model deep learning. Dataset latih digunakan untuk model dalam mengekstraksi fitur-fitur dari data tersebut. Fitur fitur yang diekstraksi kemudian divalidasi menggunakan dataset validasi. Dataset pengujian adalah subset yang digunakan untuk menguji kinerja model setelah proses pelatihan selesai. Proses pembagian dataset dapat dilihat pada gambar 3.3
       Gambar 3.3 menggambarkan tahapan dataset splitting. Proses pembagian dilakukan dengan membagi total dataset menjadi 80% untuk dataset pelatihan, 10% untuk dataset validasi dan 10% untuk dataset pengujian. Proses ini memastikan bahwa sebagian besar data digunakan untuk melatih model, sementara sisanya digunakan untuk memvalidasi performa model.
       Langkah berikutnya adalah membagi dataset menjadi beberapa batch pelatihan. Pembagian ini dilakukan untuk mengurangi beban pelatihan yang berat dan validasi hasil pelatihan dapat dilakukan secara perbatch.
Algoritma 3.2 Proses Pemuatan Data dan Pembagian ke Batch Pelatihan, Validasi, dan Pengujian
Input:
Dataset pelatihan (train_set)
Dataset validasi (val_set)
Dataset uji (test_set)
Ukuran batch untuk dataset pelatihan (train_bs) 
Ukuran batch untuk dataset uji (test_bs)
Output:
DataLoader untuk dataset pelatihan (train_dl) 
DataLoader untuk dataset validasi (val_dl) 
DataLoader untuk dataset uji (test_dl)
Proses:
1. Mulai
2. Pemuatan Data Pelatihan:
� Atur kwargs dengan batch_size=self.train_bs, shuffle=True, num_workers=2.
� Buat DataLoader untuk train_set dengan pin_memory=True dan kwargs.
� Simpan DataLoader ke dalam train_dl.
3. Pemuatan Data Validasi:
� Atur kwargs dengan batch_size=self.train_bs, shuffle=True, num_workers=2.
� Buat DataLoader untuk val_set dengan pin_memory=True dan kwargs.
� Simpan DataLoader ke dalam val_dl.
4. Pemuatan Data Uji:
� Atur kwargs dengan batch_size=test_bs, shuffle=True, num_workers=2.
� Buat DataLoader untuk test_set dengan pin_memory=True dan kwargs.
� Simpan DataLoader ke dalam test_dl.
5. Kembalikan train_dl, val_dl, dan test_dl sebagai output.
6. Selesai.
       Algoritma di atas mengimplementasikan proses pemuatan dataset dan pembagian data ke dalam batch pelatihan. Setiap batch memiliki jumlah citra sesuai dengan nilai batch size yang ditentukan. Proses pemuatan ini juga mencakup pengacakan dataset untuk setiap batch size, sehingga variasi citra dalam setiap batch pelatihan menjadi lebih beragam. Selain itu, pengaturan parameter 'pin_memory=True' diaktifkan dengan tujuan untuk melakukan caching memory, sehingga proses pelatihan lebih cepat karena dataset hanya dimuat pada iterasi pertama dari setiap batch pelatihan.

3.4 Pembuatan dan Pelatihan Model
3.4.1 Model ConvNeXt
       Model ConvNeXt adalah salah satu variasi dari arsitektur Convolutional Neural Network (CNN). Model ini mengadopsi dasar Residual Network dan memperkenalkan empat tahapan proses konvolusi. Salah satu fitur utama dari ConvNeXt adalah penggunaan layer patchify yang mengimplementasikan konvolusi 7x7 dengan stride 2, diikuti oleh layer max-pooling. Selain itu, arsitektur ini menggunakan fungsi aktivasi GELU pada blok ConvNeXt, yang sering digunakan dalam model berbasis transformer. Model ConvNeXt juga menerapkan Layer Normalization (LN), yang merupakan perbedaan signifikan dengan model berbasis CNN lainnya. Contoh blok ConvNeXt dapat dilihat pada Gambar di bawah ini.
       Model ConvNeXt memiliki beberapa varian ukuran, yaitu tiny, small, base, large, dan xlarge. Ukuran model ditentukan oleh jumlah blok ConvNeXt yang digunakan. Semakin besar modelnya, semakin banyak blok yang digunakan. Pada penelitian ini, model ConvNeXt yang digunakan adalah ukuran base, yang terdiri dari 4 stage dengan komponen blok ConvNeXt sebanyak [3, 3, 9, 3], dan ukuran dimensi fitur untuk setiap stage adalah [96, 192, 384, 768].

3.4.2 Transfer Learning
       Transfer Learning adalah proses dimana model dilatih pada sebuah dataset baru. Proses ini memanfaatkan model yang telah dilatih sebelumnya pada dataset lain (model pre-trained). Proses ini diawali dengan mengubah lapisan klasifikasi atau lapisan output agar sesuai dengan jumlah kelas yang ada pada dataset baru, yaitu 4. Langkah berikutnya adalah mentransfer bobot dari lapisan ekstraksi fitur, yang bertujuan untuk menginisialisasi model berdasarkan fitur-fitur yang telah dipelajari sebelumnya pada dataset ImageNet. Tujuan dari transfer learning adalah untuk mempercepat proses pelatihan dengan memanfaatkan bobot dari model pretrained. Implementasi proses transfer learning dapat dilihat pada Algoritma di bawah ini.
Algoritma 3.3 Proses Implementasi Transfer Learning
Input:
Pretrained (boolean): Pilihan untuk menggunakan bobot yang sudah dilatih sebelumnya dari dataset ImageNet. num_classes (int): Jumlah kelas keluaran dari model. x (torch.Tensor): Batch dari Tensor Input.
Output:
Probabilitas kelas setelah softmax (torch.Tensor).
Proses:
1. Mulai
2. Inisialisasi Model
� Inisialisasi kelas ConvNext dengan argumen pretrained dan output_class.
� Buat model convnext_base menggunakan paket timm dengan bobot pretrained dan jumlah num_classes sesuai output_class.
3. Metode Forward Pass
� Terima input tensor x.
� Proses input melalui model convnext_base.
� Terapkan fungsi softmax pada output untuk mendapatkan probabilitas kelas.
4. Metode Freeze Weights
� Iterasi melalui semua parameter di feature extractor dan set 
requires_grad ke False untuk membekukan bobot.
� Iterasi melalui semua parameter di classifier dan set requires_grad 
ke True agar dapat dilatih.
5. Metode Unfreeze Weights
� Iterasi melalui semua parameter di feature extractor dan set 
requires_grad ke True untuk membuka pembekuan bobot.
6. Selesai
       Kelas ConvNeXt pada Algoritma di atas memiliki 4 buah method yaitu init, forward, freeze, dan unfreeze. Method init adalah sebuah fungsi yang bertujuan melakukan inisiasi model sesuai dengan inputan parameter yang ada, yaitu pretrained dan num_classes. Parameter pretrained merupakan sebuah inputan boolean agar model dapat melakukan proses inisiasi dengan menggunakan bobot pra-pelatihan yang tersedia dari pytorch, sedangkan parameter num_classes merupakan parameter yang bertujuan untuk menginisasi jumlah kelas output pada model. Method forward adalah sebuah fungsi yang menerima parameter x berupa torch.Tensor dan akan dilakukan proses forward pass pada model untuk melakukan prediksi pada model. Method freeze memiliki tujuan untuk membekukan bobot agar tidak terbaharui pada proses backpropagation, sedangkan method unfreeze memiliki tujuan untuk memasukan parameter model dan melakukan pembaharuan bobot pada proses backpropagation. Model yang telah dibuat akan digunakan pada proses pelatihan model.

3.5 Pelatihan Model
       Proses pelatihan model pada penelitian ini menerapkan teknik transfer learning yang terdiri dari dua tahap, yaitu tahap adaptation dan fine tuning. Pada tahap adaotation, pelatihan model hanya dilakukan pada lapisan klasifikasi dan lapisan output. Tujuan tahap ini adalah untuk menginisialisasi dan menyesuaikan bobot pada lapisan-lapisan tersebut. Tahap adaptation dalam proses pelatihan menggunakan nilai learning rate yang tinggi sehingga model dapat dengan cepat mencapai titik optimal gradien untuk memperoleh bobot yang tepat pada lapisan klasifikasi dan lapisan output. Tahap ini berperan penting dalam proses pengklasifikasian suatu hasil feature extraction menjadi suatu output prediksi.
       Proses fine tuning adalah tahap pelatihan model secara menyeluruh yang mencakup lapisan feature extraction dan lapisan klasifikasi. Pada tahap fine tuning, nilai learning rate yang kecil digunakan agar bobot pra-pelatihan model tidak mengalami perubahan signifikan yang dapat mengakibatkan hasil pelatihan model kurang baik. Selain itu, penggunaan nilai learning rate yang kecil membantu dalam mencapai konvergensi yang stabil. Dalam penelitian ini, teknik penjadwalan learning rate berbasis Cosine Learning Rate Decay diterapkan untuk mengoptimalkan proses pelatihan baik pada tahap adaptation maupun fine tuning.
       Gambar 3.8 merupakan rancangan alur pelatihan dalam penelitian ini. Alur pelatihan model terbagi menjadi 3 tahapan yakni proses inisialisasi, proses pelatihan dan proses log hasil pelatihan. Tahap pertama merupakan inisialisasi proses pelatihan berdasarkan dataset dan config yang diinput. Langkah pertama dalam inisialisasi adalah mengatur ulang bobot fungsi loss berdasarkan distribusi dataset untuk mengatasi masalah ketidakseimbangan data.
       Proses perhitungan bobot menggunakan rumus total data dibagi total kelas dikali total data pada kelas tersebut. Langkah selanjutnya adalah proses mengubah bobot menjadi tensor dan memindahkan bobot ke hardware yang digunakan. Bobot yang telah dipindahkan ke hardware kemudian akan dimasukan ke dalam fungsi CrossEntropyLoss untuk digunakan pada proses pelatihan model. Proses inisialisasi kedua adalah inisialisasi optimizer berdasarkan pilihan yang diinginkan.
       Proses inisiasi optimizer yang menggunakan fungsi get_optimizer() merupakan fungsi yang memiliki tujuan untuk mengembalikan inisiasi optimizer berdasarkan inputan konfigurasi yang ada. Proses berikutnya adalah initialisasi learning rate scheduler yang berfungsi untuk mengubah nilai learning rate secara adaptif selama proses pelatihan berlangsung. Proses learning rate scheduler memanfaatkan Cosine Learning Rate Decay dengan pengulangan.
       Proses kedua adalah proses pelatihan model ConvNeXt yang meliputi pelatihan, proses transfer learning model, dan juga proses penghitungan fungsi loss dan metrik performa. Proses melatih model akan dilakukan oleh komponen Trainer yang akan memproses pelatihan model ConvNeXt menggunakan Optimizer dan juga EarlyStopCallback. Proses pelatihan bagian adaptation akan dilakukan sebanyak 2 epoch pertama untuk mendapatkan bobot pada classification layer. Proses pelatihan bagian fine tuning akan dilakukan sebanyak total epoch dikurangi 2, contoh jika total epoch sama dengan 25, maka model akan melakukan proses pelatihan fine tuning sebanyak 23 epoch. Proses validasi performa model merupakan proses dimana hasil pelatihan model tiap peoch dilakukan validasi pada data validasi yang telah disiapkan sebelumnya dengan cara mengukur nilai loss dan juga performa metric yang meliputi accuracy, recall, precision, dan f1-score. Hal ini bertujuan agar model dapat memperbaharui nilai bobot pengetahuan dengan cara melakukan backpropagation berdasarkan nilai loss dan akan menyimpan file model terbaik berdasarkan hasil validasi metrik performa pada data validasi.
       Proses ketiga adalah log hasil pelatihan model yang meliputi menyimpan hasil output model dan juga log pelatihan menggunakan Comet logger. Comet logger akan menyimpan nilai hasil pelatihan seperti loss, learning rate, dan metrik performa pada platform CometML untuk visualisasi grafik pelatihan model. Proses penyimpanan log ini juga bertujuan agar dapat membandingkan berbagai hasil pelatihan dengan konfigurasi berbeda sehingga mendapatkan model dengan performa terbaik berdasarkan metrik performa pada data validasi.

3.7 Evaluasi Model
       Evaluasi Model adalah tahap di mana model yang telah dilatih dievaluasi menggunakan dataset uji. Tujuan dari pengujian ini adalah untuk mengevaluasi kinerja model pada data yang belum pernah dipelajari sebelumnya. Hasil pengujian model akan diukur menggunakan beberapa metrik performa, seperti akurasi, presisi, recall, dan fl-score.
       Gambar 3.9 merupakan alur pengujian model dalam penelitian ini. Pengujian model dimulai dengan input berupa dataset pengujian dan model yang telah dilatih sebelumnya. Semua model yang telah dilatih sebelumnya diuji menggunakan dataset ini untuk membandingkan performa tiap model pada dataset yang sama. Proses berikutnya adalah perhitungan metrik performa yang terdiri dari accuracy, precision, recall, dan Fl-score.
       Penggunaan metrik accuracy memiliki tujuan untuk mengetahui tingkat keakuratan prediksi yang dibuat oleh model terhadap data uji. Metrik ini dihitung dengan mengambil jumlah total prediksi yang benar baik true positives (kasus positif yang diprediksi dengan benar) dan true negatives (kasus negatif yang diprediksi dengan benar) dan membaginya dengan jumlah total sampel dalam dataset. Metrik precision mengukur ketepatan sebuah model dalam memprediksi label kelas positif. Precision merupakan proporsi dari true positives terhadap jumlah keseluruhan prediksi yang dinyatakan sebagai positif oleh model, termasuk false positives. Metrik recall bertujuan untuk mengukur seberapa akurat model dalam mengidentifikasi semua kasus positif yang ada dalam suatu kelas tertentu. Recall dihitung dengan membandingkan jumlah prediksi yang benar-benar positif yang berhasil diidentifikasi oleh model dengan jumlah total kasus positif sebenarnya dalam kelas tersebut. Penggunaan F1-score bertujuan untuk menilai keseimbangan antara precision dan recall dalam performa model klasifikasi. Metrik ini sangat penting untuk menghindari permasalahan di mana model memiliki precision tinggi tapi recall rendah, atau sebaliknya.

3.8 Metode Stacking
      Stacking atau Stacked generalization merupakan teknik ensemble learning yang mengintegrasikan prediksi dari beberapa model untuk menghasilkan prediksi yang lebih akurat. Stacking berbeda dari metode ensemble lain seperti bagging dan bosting. Fokus utama model stacking adalah menggabungkan kekuatan model yang berbeda melalui model meta. Komponen utama metode stacking terbagi menjadi 2, yaitu model dasar dan meta-model. Model dasar adalah beberapa model tunggal yang masing masing dilatih menggunakan dataset yang sama. Output dari setiap model dasar, yang merupakan prediksi digunakan sebagai input untuk meta-model. Meta-model adalah model yang dilatih pada prediksi yang dihasilkan oleh model dasar. Model ini berfungsi untuk mempelajari bagaimana prediksi dari model dasar dapat digabungkan untuk menghasilkan prediksi akhir yang lebih akurat.
       Proses implementasi metode stacking dalam penelitian ini terdiri dari 3 tahap. Tahap pertama, hasil prediksi dari beberapa model dasar dikumpulkan. Hasil prediksi yang dikumpulkan dari model-model dasar kemudian digunakan untuk membentuk dataset baru. Setelah dataset baru dibuat, yang terdiri dari prediksi dari model-model dasar sebagai fitur, langkah selanjutnya adalah pelatihan meta-model.

3.9 Evaluasi Model Stacking
       Pengujian model stacking dalam penelitian ini dilakukan seperti pengujian pada model tunggal. Pengujian dilakukan dengan menghitung metrik akurasi seperti accuracy, precision, recall, dan Fl-score.

3.10 Inference dan Deployment
       Inference dan Deployment adalah tahap di mana model terbaik yang telah melalui proses pengujian digunakan untuk membuat prediksi pada data baru. Inference dilakukan melalui sebuah API yang dibuat menggunakan framework Flask untuk menjalankan model. API yang dibuat menerima file citra X-ray dada sebagai input. Output dari API ini adalah hasil prediksi yang mencakup nama kelas dan confidence score untuk citra tersebut. confidence score ini mengindikasikan tingkat keyakinan model terhadap prediksinya. Tahapan deployment merupakan tahapan proses mengepak API yang telah dibuat ke dalam satu environment yang siap dijalankan. Proses pengepakan ini menggunakan teknologi Docker yang memiliki tujuan mengisolasi environment yang digunakan oleh API dengan environment yang ada pada mesin utama. Hal ini juga memudahkan proses deployment karena tahapan installasi semua komponen seperti library, framework, dan interpreter yang digunakan telah diinisiasi dalam bentuk docker image.