{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Extract Text from All PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text from Alfharizky Fauzi_Kualifikasi.pdf and saved to Alfharizky Fauzi_Kualifikasi.txt\n",
      "Extracted text from Alifurrohman_Kualifikasi.pdf and saved to Alifurrohman_Kualifikasi.txt\n",
      "Extracted text from Armando Tirta Dwilaga_Kualifikasi.pdf and saved to Armando Tirta Dwilaga_Kualifikasi.txt\n",
      "Extracted text from Devi Resviani_KUALIFIKASI.pdf and saved to Devi Resviani_KUALIFIKASI.txt\n",
      "Extracted text from Erfiana Wahyuningsih_UK.pdf and saved to Erfiana Wahyuningsih_UK.txt\n",
      "Extracted text from Robert_Kualifikasi.pdf and saved to Robert_Kualifikasi.txt\n",
      "Extracted text from Tatya Atyanti Paramastri_Kualifikasi.pdf and saved to Tatya Atyanti Paramastri_Kualifikasi.txt\n",
      "Extracted text from Tia Haryanti_Kualifikasi.pdf and saved to Tia Haryanti_Kualifikasi.txt\n",
      "Extracted text from Utami Lestari_Kualifikasi.pdf and saved to Utami Lestari_Kualifikasi.txt\n",
      "Extracted text from Yoga Panji Perdana Nugraha_Kualifikasi.pdf and saved to Yoga Panji Perdana Nugraha_Kualifikasi.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from modules.extract import extract_text_from_pdfs\n",
    "\n",
    "# Specify the folder containing PDFs and the folder to save extracted text\n",
    "pdf_folder = 'data/clean-data-pdf'\n",
    "output_folder = 'data/data-txt'\n",
    "extract_text_from_pdfs(pdf_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Alfharizky Fauzi_Kualifikasi.txt\n",
      "Preprocessed Alifurrohman_Kualifikasi.txt\n",
      "Preprocessed Armando Tirta Dwilaga_Kualifikasi.txt\n",
      "Preprocessed Devi Resviani_KUALIFIKASI.txt\n",
      "Preprocessed Erfiana Wahyuningsih_UK.txt\n",
      "Preprocessed Robert_Kualifikasi.txt\n",
      "Preprocessed Tatya Atyanti Paramastri_Kualifikasi.txt\n",
      "Preprocessed Tia Haryanti_Kualifikasi.txt\n",
      "Preprocessed Utami Lestari_Kualifikasi.txt\n",
      "Preprocessed Yoga Panji Perdana Nugraha_Kualifikasi.txt\n"
     ]
    }
   ],
   "source": [
    "from modules.preprocessing import preprocess_text_files\n",
    "\n",
    "# Preprocess all extracted text files\n",
    "cleaned_texts = preprocess_text_files(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Save to .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned text to data/clean-data-txt\\Alfharizky Fauzi_Kualifikasi.txt\n",
      "Saved cleaned text to data/clean-data-txt\\Alifurrohman_Kualifikasi.txt\n",
      "Saved cleaned text to data/clean-data-txt\\Armando Tirta Dwilaga_Kualifikasi.txt\n",
      "Saved cleaned text to data/clean-data-txt\\Devi Resviani_KUALIFIKASI.txt\n",
      "Saved cleaned text to data/clean-data-txt\\Erfiana Wahyuningsih_UK.txt\n",
      "Saved cleaned text to data/clean-data-txt\\Robert_Kualifikasi.txt\n",
      "Saved cleaned text to data/clean-data-txt\\Tatya Atyanti Paramastri_Kualifikasi.txt\n",
      "Saved cleaned text to data/clean-data-txt\\Tia Haryanti_Kualifikasi.txt\n",
      "Saved cleaned text to data/clean-data-txt\\Utami Lestari_Kualifikasi.txt\n",
      "Saved cleaned text to data/clean-data-txt\\Yoga Panji Perdana Nugraha_Kualifikasi.txt\n"
     ]
    }
   ],
   "source": [
    "from modules.preprocessing import save_cleaned_texts\n",
    "\n",
    "# Specify the folder to save cleaned text files\n",
    "output_clean_folder = 'data/clean-data-txt'\n",
    "\n",
    "# Save the cleaned texts\n",
    "save_cleaned_texts(cleaned_texts, output_clean_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Split Text into Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses selesai.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from modules.load import split_text_into_sections, create_directory\n",
    "\n",
    "# Direktori sumber dari file .txt\n",
    "source_dir = 'data/clean-data-txt'\n",
    "# Nama-nama bagian yang akan dijadikan nama direktori\n",
    "sections = ['judul', 'latarbelakang', 'rumusanmasalah', 'tujuanpenelitian', 'rangkumanpenelitianterkait', 'metodologipenelitian']\n",
    "\n",
    "# Proses setiap file .txt dalam direktori\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(source_dir, filename)\n",
    "\n",
    "        # Baca konten file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Memecah konten menjadi bagian-bagian\n",
    "        sections_content = split_text_into_sections(content, sections)\n",
    "\n",
    "        # Simpan setiap bagian ke dalam direktori dan file yang sesuai\n",
    "        for section in sections:\n",
    "            section_dir = os.path.join(source_dir, section)\n",
    "            create_directory(section_dir)\n",
    "\n",
    "            # Simpan ke file baru dengan nama asli\n",
    "            section_file_path = os.path.join(section_dir, filename)\n",
    "            if section in sections_content:\n",
    "                with open(section_file_path, 'w', encoding='utf-8') as section_file:\n",
    "                    section_file.write(sections_content[section].strip())  # Menyimpan konten tanpa bagian judul\n",
    "            else:\n",
    "                # Jika tidak ada konten untuk bagian tersebut, bisa dilewatkan atau dibuat file kosong\n",
    "                with open(section_file_path, 'w', encoding='utf-8') as section_file:\n",
    "                    section_file.write('')\n",
    "\n",
    "print(\"Proses selesai.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
