{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Training with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harry\\anaconda3\\envs\\torch-nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "from transformers import EncoderDecoderModel, BertTokenizer\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_directml\n",
    "device = torch_directml.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fungsi untuk melakukan pengujian\n",
    "def generate_summary(text,tokenizer,model):\n",
    "    # Tokenisasi input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Generate ringkasan\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        num_beams=4,\n",
    "        max_length=256,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    # Decode ringkasan\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latar Belakang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dan tokenizer telah dimuat kembali.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"model/saved_model_latarbelakang\"\n",
    "# 2. Memuat kembali model yang telah disimpan\n",
    "loaded_model = EncoderDecoderModel.from_pretrained(model_save_path)\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "# Pindahkan model ke device yang sesuai\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "print(\"Model dan tokenizer telah dimuat kembali.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat asli:\n",
      "Persaingan dalam dunia industri semakin ketat. Setiap perusahaan berlomba-lomba menciptakan produk yang berukualitas.. Kualitas produk merupakan faktor kunci agar perusahaan dapat bertahan dan bersaing dalam dunia bisms (Psarommatis, Sousa, Mendoza, & Kiritsis, 2022). Kualitas produk akan mempengaruhi kepercayaan pelanggan terhadap perusahaan. Kualitas produk yang tinggi tentunya merupakan keinginan perusahaan. Namun, kecacatan produk merupakan hal yang hampir pasti terjadi. Salah satu kegiatan yang perlu dilakukan untuk menjaga kualitas produk adalah inspeksi. Kecepatan dan akurasi inspeksi pada industri diperlukan untuk memastikan standar kualitas produk yang tinggi namun harga tetap terjangkau (Villalba-Diez et al., 2019). Hal ini merupakan tantangan bagi para pelaku industri. Otomatisasi pada proses inspeksi kualitas adalah salah satu cara untuk meningkatkan kinerja kegiatan inspeksi sehingga kepuasan pelanggan atas produk yang berkualitas baik dapat terjaga (Deshpande, Minai, & Kumar, 2020). Penelitian tersebut menghasilkan perbandingan kinerja relevance machine vector dengan support vector machine, artificial neural network dan beta regression model menghasilkan bahwa pemantauan proses berbasis relevance machine vector adalah alat pemantauan kualitas produk cacat dalam proses manufaktur yang baik dibandingkan dengan algoritma machine learing yang lain. Kecerdasan buatan (machine learning) yang diimplementasikan bermanfaat untuk meningkatkan akurasi prediksi model regresi serta menyempurnakan kecerdasan yang dimiliki dengan mempelajari parameter proses mana yang dapat membuat produk cacat sehingga nantinya dapat menyesuaikan parameter proses dengan mengabaikan pengaturan manual. Wu, Guo, Liu, and Huang (2020) mengembangkan metode deep learning yang lebih feksibel untuk deteksi cacat pada industri dengan menggunakan End- to-end learning framework. Penelitian ini dilakukan untuk mengatasi kesulitan deteksi cacat blade. Sehingga dikembangkan arsitektur baru yang mengintegrasikan residue learning untuk melakukan deteksi cacat yang efisien. Selain itu, operasi pemerataan data membantu hasil deteksi cacat yang lebih baik. Hasilnya menunjukkan bahwa pengembangan algoritma kode rantai dapat menghasilkan jumlah objek, panjang kode rantai, dan nilai kemungkinan laju kemunculan setiap kode rantai dalam suatu motif, meskipun terdapat beberapa objek dalam suatu motif. (2023) mengusulkan kerangka kerja deteksi cacat berdasarkan pembelajaran adversial tanpa pengawasan untuk rekonstruksi gambar guna memecahkan masalah deteksi berlebihan atau kesalahan deteksi karena tidak dapat beradaptasi dengan pola kompleks kain berpola warna. Hasil eksperimen berbagai pola/kelas pada YDFID-1 dan MvTecAD menunjukkan efektivitas dan keunggulan metode ini dalam deteksi cacat kain. Hasil eksperimen menunjukkan bahwa akurasi diagnostic model diagnosis ringan yang dibangun dapat mencapai 96,55% untuk lima jenis cacat las baja tahan karat, antara lain retak, porositas, inklusi, kurang lusi, dan penetrasi tidak lengkap. Metode ini memberikan landasan teori dan referensi teknis untuk mengembangkan dan menerapkan teknologi diagnosis cacat ultrasonik yang cerdas, efisien dan akurat. Revolusi industri 4.0 mendorong otomatisasi inspeksi produk untuk manufaktur yang tanpa cacat (zero defect) dan berkualitas tinggi dimana kemampuan fleksibilitas manusia berkolaborasi dengan kemampuan akurasi komputer dan mesin (Brito et al., 2020). Perkembangan computer vision dapat sangat membantu dalam dunia industri manufaktur untuk mencapai kualitas yang unggul (Schmidt, Gevers, Schwiep, Ordieres-Mere, & Villalba-Diez, 2020). Citra produk industri pada basis data sendiri dapat terdiri dari berbagai macam model dengan kecacatan yang bervariasi juga. Sehingga dikembangkan aplikasi pendeteksi objek untuk meningkatkan kinerja inspeksi produk. Pengembangan aplikasi dengan mengaplikasikan kemampuan penglihatan komputer menggunakan artificial intelligence yaitu deep learning. Harapan dari penelitian ini nantinya dapat membantu perusahaan terutama departemen pengendalian kualitas untuk melakukan inspeksi produk pada lantai produksi secara mendekati real-time. Sehingga efisiensi dan efektivitas kegiatan inspeksi produk dapat dicapai.\n",
      "\n",
      "Ringkasan yang dihasilkan:\n",
      "kualitas produk merupakan faktor kunci agar perusahaan dapat bertahan dan bersaing dalam dunia bisms ( psarommatis, sousa, mendoza, & kiritsis, 2022 ). kualitas produk akan mempengaruhi kepercayaan pelanggan terhadap perusahaan. namun, kecacatan produk merupakan hal yang hampir pasti terjadi. salah satu kegiatan yang perlu dilakukan untuk menjaga kualitas produk adalah inspeksi. kecepatan dan akurasi inspeksi pada industri diperlukan untuk memastikan standar kualitas produk yang tinggi namun harga tetap terjangkau ( deshpande, minai, & kumar, 2020 ). hal ini merupakan tantangan bagi para pelaku industri. otomatisasi pada proses inspeksi kualitas adalah salah satu cara untuk meningkatkan kinerja kegiatan inspeksi. penelitian tersebut menghasilkan perbandingan kinerja relevance machine vector machine learning yang diimplementasikan oleh para pengguna cacat dalam proses manufaktur yang baik dapat terjaga. penelitian ini menghasilkan bahwa metode deep learning yang dikembangkan untuk meningkatkan akurasi dan efisiensi. kecerdasan buatan machine learing yang berkualitas baik dapat menjaga kecerdasan buatan ( machine learning ) menghasilkan bahwa pemantauan kualitas produk cacat pada proses pembelajaran yang baik dibandingkan dengan algoritma machine learning machine learning model berbasis relevan dengan metode berbasis relevancy model angige network ( machine learn network ) yang diimplementasikan bermanfaat untuk meningkatkan kecerdasan buatan dengan mempelajari parameter proses berbasis relevance model angi angi angio - angi angige. penelitian menunjukkan bahwa metode pembelajaran berbasis relevan\n"
     ]
    }
   ],
   "source": [
    "# 4. Melakukan pengujian dengan kalimat sendiri\n",
    "test_sentence = \"Persaingan dalam dunia industri semakin ketat. Setiap perusahaan berlomba-lomba menciptakan produk yang berukualitas.. Kualitas produk merupakan faktor kunci agar perusahaan dapat bertahan dan bersaing dalam dunia bisms (Psarommatis, Sousa, Mendoza, & Kiritsis, 2022). Kualitas produk akan mempengaruhi kepercayaan pelanggan terhadap perusahaan. Kualitas produk yang tinggi tentunya merupakan keinginan perusahaan. Namun, kecacatan produk merupakan hal yang hampir pasti terjadi. Salah satu kegiatan yang perlu dilakukan untuk menjaga kualitas produk adalah inspeksi. Kecepatan dan akurasi inspeksi pada industri diperlukan untuk memastikan standar kualitas produk yang tinggi namun harga tetap terjangkau (Villalba-Diez et al., 2019). Hal ini merupakan tantangan bagi para pelaku industri. Otomatisasi pada proses inspeksi kualitas adalah salah satu cara untuk meningkatkan kinerja kegiatan inspeksi sehingga kepuasan pelanggan atas produk yang berkualitas baik dapat terjaga (Deshpande, Minai, & Kumar, 2020). Penelitian tersebut menghasilkan perbandingan kinerja relevance machine vector dengan support vector machine, artificial neural network dan beta regression model menghasilkan bahwa pemantauan proses berbasis relevance machine vector adalah alat pemantauan kualitas produk cacat dalam proses manufaktur yang baik dibandingkan dengan algoritma machine learing yang lain. Kecerdasan buatan (machine learning) yang diimplementasikan bermanfaat untuk meningkatkan akurasi prediksi model regresi serta menyempurnakan kecerdasan yang dimiliki dengan mempelajari parameter proses mana yang dapat membuat produk cacat sehingga nantinya dapat menyesuaikan parameter proses dengan mengabaikan pengaturan manual. Wu, Guo, Liu, and Huang (2020) mengembangkan metode deep learning yang lebih feksibel untuk deteksi cacat pada industri dengan menggunakan End- to-end learning framework. Penelitian ini dilakukan untuk mengatasi kesulitan deteksi cacat blade. Sehingga dikembangkan arsitektur baru yang mengintegrasikan residue learning untuk melakukan deteksi cacat yang efisien. Selain itu, operasi pemerataan data membantu hasil deteksi cacat yang lebih baik. Hasilnya menunjukkan bahwa pengembangan algoritma kode rantai dapat menghasilkan jumlah objek, panjang kode rantai, dan nilai kemungkinan laju kemunculan setiap kode rantai dalam suatu motif, meskipun terdapat beberapa objek dalam suatu motif. (2023) mengusulkan kerangka kerja deteksi cacat berdasarkan pembelajaran adversial tanpa pengawasan untuk rekonstruksi gambar guna memecahkan masalah deteksi berlebihan atau kesalahan deteksi karena tidak dapat beradaptasi dengan pola kompleks kain berpola warna. Hasil eksperimen berbagai pola/kelas pada YDFID-1 dan MvTecAD menunjukkan efektivitas dan keunggulan metode ini dalam deteksi cacat kain. Hasil eksperimen menunjukkan bahwa akurasi diagnostic model diagnosis ringan yang dibangun dapat mencapai 96,55% untuk lima jenis cacat las baja tahan karat, antara lain retak, porositas, inklusi, kurang lusi, dan penetrasi tidak lengkap. Metode ini memberikan landasan teori dan referensi teknis untuk mengembangkan dan menerapkan teknologi diagnosis cacat ultrasonik yang cerdas, efisien dan akurat. Revolusi industri 4.0 mendorong otomatisasi inspeksi produk untuk manufaktur yang tanpa cacat (zero defect) dan berkualitas tinggi dimana kemampuan fleksibilitas manusia berkolaborasi dengan kemampuan akurasi komputer dan mesin (Brito et al., 2020). Perkembangan computer vision dapat sangat membantu dalam dunia industri manufaktur untuk mencapai kualitas yang unggul (Schmidt, Gevers, Schwiep, Ordieres-Mere, & Villalba-Diez, 2020). Citra produk industri pada basis data sendiri dapat terdiri dari berbagai macam model dengan kecacatan yang bervariasi juga. Sehingga dikembangkan aplikasi pendeteksi objek untuk meningkatkan kinerja inspeksi produk. Pengembangan aplikasi dengan mengaplikasikan kemampuan penglihatan komputer menggunakan artificial intelligence yaitu deep learning. Harapan dari penelitian ini nantinya dapat membantu perusahaan terutama departemen pengendalian kualitas untuk melakukan inspeksi produk pada lantai produksi secara mendekati real-time. Sehingga efisiensi dan efektivitas kegiatan inspeksi produk dapat dicapai.\"\n",
    "generated_summary = generate_summary(test_sentence, loaded_tokenizer, loaded_model)\n",
    "\n",
    "print(\"Kalimat asli:\")\n",
    "print(test_sentence)\n",
    "print(\"\\nRingkasan yang dihasilkan:\")\n",
    "print(generated_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rumusan Masalah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dan tokenizer telah disimpan di: model/saved_model_rumusanmasalah\n",
      "Model dan tokenizer telah dimuat kembali.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"model/saved_model_rumusanmasalah\"\n",
    "# 2. Memuat kembali model yang telah disimpan\n",
    "loaded_model = EncoderDecoderModel.from_pretrained(model_save_path)\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "# Pindahkan model ke device yang sesuai\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "print(\"Model dan tokenizer telah dimuat kembali.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat asli:\n",
      "Hasil dari LBP+Adaboost digunakan sebagai input model SVM yang digunakan untuk mengenali ekspresi wajah (Shan et al., 2009). Pada tahun 2011, dilakukan pengembangan metode ekstrasi fitur Local Monotonic Pattern (LMP) untuk pengenalan ekspresi wajah. Pada tahun ini 2024, akan diajukan penelitian PENGEMBANGAN MODEL KLASIFIKASI MORPHOLOGICAL NEURAL NETWORK UNTUK SISITEM PENGENALAN EKSPRESI WAJAH\n",
      "\n",
      "Ringkasan yang dihasilkan:\n",
      "hasil dari lbp + adaboost digunakan sebagai input model svm yang digunakan untuk mengenali ekspresi wajah ( shan et al., 2009 ). pada tahun ini, akan diajukan penelitian pengembangan model klasifikasi morphological neural network untuk pengenalan ekspresi wajah.\n"
     ]
    }
   ],
   "source": [
    "# 4. Melakukan pengujian dengan kalimat sendiri\n",
    "test_sentence = \"Hasil dari LBP+Adaboost digunakan sebagai input model SVM yang digunakan untuk mengenali ekspresi wajah (Shan et al., 2009). Pada tahun 2011, dilakukan pengembangan metode ekstrasi fitur Local Monotonic Pattern (LMP) untuk pengenalan ekspresi wajah. Pada tahun ini 2024, akan diajukan penelitian \"\"PENGEMBANGAN MODEL KLASIFIKASI MORPHOLOGICAL NEURAL NETWORK UNTUK SISITEM PENGENALAN EKSPRESI WAJAH\"\n",
    "generated_summary = generate_summary(test_sentence, loaded_tokenizer, loaded_model)\n",
    "\n",
    "print(\"Kalimat asli:\")\n",
    "print(test_sentence)\n",
    "print(\"\\nRingkasan yang dihasilkan:\")\n",
    "print(generated_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tujuan Penelitian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dan tokenizer telah dimuat kembali.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"model/saved_model_tujuanpenelitian\"\n",
    "# 2. Memuat kembali model yang telah disimpan\n",
    "loaded_model = EncoderDecoderModel.from_pretrained(model_save_path)\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "# Pindahkan model ke device yang sesuai\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "print(\"Model dan tokenizer telah dimuat kembali.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat asli:\n",
      "1. mereduksi jumlah transistor pada rangkaian sram dengan menggunakan metode m gdi. 2. mampu menunjukkan kinerja dari penggunaan low power pada rangkaian sram 6t 3. mampu mempertahankan high read stability pada rangkaian sram 6t\n",
      "\n",
      "Ringkasan yang dihasilkan:\n",
      "mereduksi jumlah transistor pada rangkaian ampas dengan menggunakan metode m gdi. kumbang mampu menunjukkan kinerja dari penggunaan low power pada rangkaian his pada rangkaianode produknya pada rangkaian tidak pada rangkaian atta pada rangkaian tertentu pada rangkaian itu.\n"
     ]
    }
   ],
   "source": [
    "# 4. Melakukan pengujian dengan kalimat sendiri\n",
    "test_sentence = \"1. mereduksi jumlah transistor pada rangkaian sram dengan menggunakan metode m gdi. 2. mampu menunjukkan kinerja dari penggunaan low power pada rangkaian sram 6t 3. mampu mempertahankan high read stability pada rangkaian sram 6t\"\n",
    "generated_summary = generate_summary(test_sentence, loaded_tokenizer, loaded_model)\n",
    "\n",
    "print(\"Kalimat asli:\")\n",
    "print(test_sentence)\n",
    "print(\"\\nRingkasan yang dihasilkan:\")\n",
    "print(generated_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rangkuman Penelitian Terkait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dan tokenizer telah dimuat kembali.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"model/saved_model_rangkumanpenelitianterkait\"\n",
    "# 2. Memuat kembali model yang telah disimpan\n",
    "loaded_model = EncoderDecoderModel.from_pretrained(model_save_path)\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "# Pindahkan model ke device yang sesuai\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "print(\"Model dan tokenizer telah dimuat kembali.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat asli:\n",
      "berdasarkan tabel perbandingan di atas dapat diketahui berbagai perbedaan pada masing masing penelitian. mode l permasalahan pada penelitian terdahulu terbagi menja di beberapa model yaitu dynamic vehicle routing problem dvrp dynamic vehicle routi ng problem with time window s dvrp tw capacited vehicle routing problem cvrp heterogeounus capac ited vehicle routing problem hcvrp trave l salesman problem tsp. terkait fokus permasalahan yang diambil pada berbagai penelitian mulai dari permintaan pelangg an yang tidak pasti keadaan lalu lintas dan terkait kendaraan yang diguna kan pada proses pengirim an. penyelesaian dilakukan dengan menggun akan metaheuristi k dianta ranya hybrid brain storm optimi zation bso ant colony optimizat ion dan yang lainnya . pengga bunga n algorit ma juga dilakuka n pada beberapa penelitian terdahulu seperti hybrid antara brain strom optimizat ion dengan ant colony optimization. pengguna an machine learning yaitu reinforcement learning deep reinforcement learning dan deep qnetwork digunaka n pada berbagai penelitian sebab memil iki kelebiha n yaitu lebih optimal pada data yang banyak. multi attention juga digunaka n pada penyelesaian permasalahan optimasi rute dan menunjuk an hasil yang optimal. pada penelitian selanjut nya fokus penelitian pada model masa lah dynamic vehicle routing problem with time windows dvrp tw dengan fokus terhadap ketidakpastian jalan raya serta ketidakpastian pelangga n yang berubahubah dimana pada prose s pengiriman ke pelangga n terdapat jende la waktu atau batasan waktu pengirim an sampai ke pelangga n. pada penelitian terdahulu hanya fokus pada salah satu saja seperti hanya fokus pada pelangga n yang tidak pasti atau ketidakpastian jalan raya. penyelesaian dilakukan dengan mengguna kan deep reinforcement learning pada hal ini mengguna kan metode deep qnetwork dqn dengan mengga bungk an multi header attention kedalam a rsitektur dqn.\n",
      "\n",
      "Ringkasan yang dihasilkan:\n",
      "berdasarkan tabel perb and i ngan d i atas dapat d i ketahu i berbagai perbedaan pada penelitian sebelumnya terbag i menja d i beberapa model ya i tu d i ndow s dvrp v nd melihat salah satu saja yang d i lakukan dengan mengguna kan metode deep q network d i akan dengan menguna kan proses i n i ke an la lu li nt i akan menjadi model yang i yang i guna pada proses peng i r i m dalam berbagai penelitian se bab mem i k i k d i ant i tuamt i a d i dengan fokus terh ada p ket i daks i th time w i v v v k i tal i tu tu s s ( ( ( batasan ) d i n n i tu ) dan terkait dengan menggunakan metode deep qi li li li dan terkait kegiatan deep q ( batasan waktu yang ada di dalam a ket i k ) dan pelaksanaan pelaksanaan pelaksanaan d i g g g ( ( perbandingan ) dan men i k f d i kan pada berbagai i n ng ada di salah satu f d d d i k k i dakpast i kan kan pada prose s ng i dak perun i dakan d i ng i h h h yang t d i h ( batasan (\n"
     ]
    }
   ],
   "source": [
    "# 4. Melakukan pengujian dengan kalimat sendiri\n",
    "test_sentence = \"Berdasarkan tabel perbandingan di atas dapat diketahui berbagai perbedaan pada masing masing penelitian. mode l permasalahan pada penelitian terdahulu terbagi menja di beberapa model yaitu dynamic vehicle routing problem dvrp dynamic vehicle routi ng problem with time window s dvrp tw capacited vehicle routing problem cvrp heterogeounus capac ited vehicle routing problem hcvrp trave l salesman problem tsp. terkait fokus permasalahan yang diambil pada berbagai penelitian mulai dari permintaan pelangg an yang tidak pasti keadaan lalu lintas dan terkait kendaraan yang diguna kan pada proses pengirim an. penyelesaian dilakukan dengan menggun akan metaheuristi k dianta ranya hybrid brain storm optimi zation bso ant colony optimizat ion dan yang lainnya . pengga bunga n algorit ma juga dilakuka n pada beberapa penelitian terdahulu seperti hybrid antara brain strom optimizat ion dengan ant colony optimization. pengguna an machine learning yaitu reinforcement learning deep reinforcement learning dan deep qnetwork digunaka n pada berbagai penelitian sebab memil iki kelebiha n yaitu lebih optimal pada data yang banyak. multi attention juga digunaka n pada penyelesaian permasalahan optimasi rute dan menunjuk an hasil yang optimal. pada penelitian selanjut nya fokus penelitian pada model masa lah dynamic vehicle routing problem with time windows dvrp tw dengan fokus terhadap ketidakpastian jalan raya serta ketidakpastian pelangga n yang berubahubah dimana pada prose s pengiriman ke pelangga n terdapat jende la waktu atau batasan waktu pengirim an sampai ke pelangga n. pada penelitian terdahulu hanya fokus pada salah satu saja seperti hanya fokus pada pelangga n yang tidak pasti atau ketidakpastian jalan raya. penyelesaian dilakukan dengan mengguna kan deep reinforcement learning pada hal ini mengguna kan metode deep qnetwork dqn dengan mengga bungk an multi header attention kedalam a rsitektur dqn.\"\n",
    "generated_summary = generate_summary(test_sentence, loaded_tokenizer, loaded_model)\n",
    "\n",
    "print(\"Kalimat asli:\")\n",
    "print(test_sentence)\n",
    "print(\"\\nRingkasan yang dihasilkan:\")\n",
    "print(generated_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodologi Penelitian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dan tokenizer telah dimuat kembali.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"model/saved_model_metodologipenelitian\"\n",
    "# 2. Memuat kembali model yang telah disimpan\n",
    "loaded_model = EncoderDecoderModel.from_pretrained(model_save_path)\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "# Pindahkan model ke device yang sesuai\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "print(\"Model dan tokenizer telah dimuat kembali.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat asli:\n",
      "3.1 tahapan penel itian dalam penelitian mengenai pengembangan algoritma dbscan dengan kuantum terdapat langkahlangkah yang dilakukan seperti pada gambar 3.1. langkah langkah yang dilaukan d iantaranya yaitu pengumpulan data definisi qubits kriteria inisialis asi sistem kuantum hingga evaluasi klaster. data definisi qubits kriteria inisialisasi sistem kuantum penentuan eps dan minpts kuantum identifikasi core supplier dengan kuantum sirkuitidentifikasi noise supplier dengan kuantum sirkuit penanganan noise dengan kuantum stateformasi klaster supplier dengan kuantum measurementimplementasi quantum distance measure identifikasi core supplier dengan kuantum sirkuit evaluasi klaster1 2 3 4 5 6 9 10 117 8 gamb ar 3.1 tahapan penel itian 1. data tahap awal dalam penelitian di awali dengan pembuatan data dimana data yang digunakan pada penel itian ini adalah data s intetik. data sintetik digunakan untuk mendapatkan jumlah data yang besar sela in itu data sintetik juga b ersifat fleksibel kar ena ju mlah data yang digunakan dapat ditentukan sesuai dengan kebutuhan pengujian algo ritma yang dikembang kan. data sintetik yang dibuat berisikan nama supplier harga kualitas dan waktu pengiriman. 2. definis i qubits kriteria pada taha p ini kriteria yang digunak an untuk pengelompokan supplier diubah menjadi representasi kuantum menggunakan qubits. setia p kriteria mungkin diwakili ol eh satu atau lebih qubits tergantung pada kompleksitas yang diperlukan. kriteri a yang digunakan dalam peng elompokan supplier yaitu harga kualitas dan waktu pengiri man. 3. inisialisasi sistem kuantum pada tahapan ini melakukan p ersiapan awal dari komputer k uantum yaitu mengatur qubits ke state awal dan memas tikan semua qubits berada dalam keadaan awal sebelum operasi kuantum dijalankan. pada tahapan ini juga menentuk kan jumlah qubits yan g digunakan. 4. implementasi quantum distance measure pada tahapan ini melakukan p enerapan metode untuk mengukur jarak antar supplier dalam ruang kuantum dengan menggunakan prins ipprinsip mekanika kuantum . tahapan ini digunakan dalam proses pengelom pokkan data menggunakan quantum dbscan karena jarak antar supplier akan digunakan untuk menentukan klaster 5. penentuan eps dan minpts kuan tum pada tahap ini men entukan nilai nilai epsilo n atau eps dan minimum poi nts minpts dalam konteks kuantum untuk menentukan batas batas klaster . epsilon atau eps digunakan u ntuk menen tukan radius yang menentukan lingkungan di sekitar setiap titik data. dua titik dianggap ber tetangga jika jarak antara mereka kurang dari nilai e ps. minimum points atau min pts untuk menentukan jumlah minimum titik yang diperlukan untuk membentuk sebuah klaster . 6. identi fikasi core supplier dengan kuantum sirkuit pada tahapan ini m enggunakan rangka ian kuantum untuk mengident ifikasi supplier ini core suppl ier. supplier inti adalah supplier yang memiliki cukup banyak tetangga yang s esuai dengan minpts dalam radius epsilon yang telah ditentukan. 7. identifikasi noise supplier dengan kuantum sirkuit pada tahapan ini mengi dentifikasi supplier noise atau outlier yang mem iliki jarak tidak cukup dek at atau memiliki jarak yang jauh dengan supplier lain untuk dianggap bagian dari klaster . 8. penanganan noise dengan quantum state pada tahapan ini menge lola supplier noise yang telah diidentifikasi menggunakan teknik kuantu m untuk memisahkan atau mengelompok kan noise secara terpisah. dalam dbscan klasik noise adalah titik data yang tidak termasuk dalam klaster apa pun. titik titik ini tidak memiliki cuku p tetangga dalam radius epsilon eps atau tidak terhubung ke core poin t. 9. identifikasi core supplier dengan quantum circuit pada tahapan ini mengidentifikasi titik titik data yang berada dalam jarak epsilon atau e ps dari titik inti tetapi tidak memiliki cukup tetanga untuk masuk ke dalam klaster dengan menggunakan kuantum sirkuit . 10. formasi kluster supplier dengan quantum measurement pada tahapan ini m embentukan klaster supplier dengan mengukur state kuantum yang telah diubah melalui interaksi antar qubits yang mewakili supplier . 11. evaluasi kluster tahap terakhir di mana kualit as dan k eefektifan kluster yang ter bentuk dievaluasi. tahapan ini bertujuan untuk menilai seberapa baik kluster yang terbentuk mengguna kan. 3.2 rangkuman langkah langk ah penelitian setelah mengembangkan algoritma kuantum dbscan selanjutnya membandingk annya dengan algo ritma dbscan untuk mengetahui seberapa baik algoritma dbscan jika dibandingkan dengan algorit ma klasiknya . langkah langka h tersebut dapat dilihat pada gambar 3.2 rangkuman langkah langka h prosedur peneli tian. data definisi qubits kriteria inisialisasi sistem kuantum penentuan eps dan minpts kuantum identifikasi core supplier dengan kuantum sirkuitidentifikasi noise supplier dengan kuantum sirkuit penanganan noise dengan kuantum stateformasi klaster supplier dengan kuantum measurementimplementasi quantum distance measure identifikasi core supplier dengan kuantum sirkuitnormalisasi data penentuan epsilon dan minpts hitung jarak antar supplier identifikasi core supplier identifikasi core supplieridentifikasi noise supplier supplier tidak termasuk dalam klasterformasi klaster supplier evaluasi klasterusulan algoritma gambar 3.2 rangkuman langkah langkah prosedur penelitian\n",
      "\n",
      "Ringkasan yang dihasilkan:\n",
      "3. 1 tahapan penel itian dalam penelitian mengenai pengembangan algoritma dbscan dengan kuantum sirkuit statistik hingga evaluasi klaster. data definisi qubits kriteria inisialisasi sistem kuantum penentuan eps dan minpts kuantum data ( kuantum sirkuit penanganan noise supplier dengan kuantum data, data sintetik juga b ersifat fleksibel kar ena ju mlah data pengiriman. 2 tahapan ini kriteria yang digunak untuk pengelompokan supplier yang dibuat berisikan nama supplier kualitas dan waktu pengiriman. dua di antaranya adalah supplier harga dan waktu pelaksaan dapat ditentukan sesuai dengan kebutuhan pengujian algo ritma yang dikembangan quantum distance measure model kuantum data yang dibuat untuk mendapatkan jumlah data yang besar sela in time identifikasi core supplier, sehingga memungkinkan pengguna supplier nilai dan waktu pelaksanaan quantum data yang digunakan dapat ditentukan berdasarkan kebutuhan pengujian daripada kebutuhan pengujian supplier. 2. 3 tahapan mungkin diwakili ola atau lebih qubits tergantung pada kebutuhan pengujian formalin yang dibuat dapat ditentukan tepat untuk mengelompokkan supplier pada model kuantum yang dikembangkan dengan memahami karakter supplier dalam bagan bagan bagan prediksi prediksi prediksi untuk mengkategorikannya dengan kuantum dengan kuantum informasi yang dikembangkan.\n"
     ]
    }
   ],
   "source": [
    "# 4. Melakukan pengujian dengan kalimat sendiri\n",
    "test_sentence = \"3.1 tahapan penel itian dalam penelitian mengenai pengembangan algoritma dbscan dengan kuantum terdapat langkahlangkah yang dilakukan seperti pada gambar 3.1. langkah langkah yang dilaukan d iantaranya yaitu pengumpulan data definisi qubits kriteria inisialis asi sistem kuantum hingga evaluasi klaster. data definisi qubits kriteria inisialisasi sistem kuantum penentuan eps dan minpts kuantum identifikasi core supplier dengan kuantum sirkuitidentifikasi noise supplier dengan kuantum sirkuit penanganan noise dengan kuantum stateformasi klaster supplier dengan kuantum measurementimplementasi quantum distance measure identifikasi core supplier dengan kuantum sirkuit evaluasi klaster1 2 3 4 5 6 9 10 117 8 gamb ar 3.1 tahapan penel itian 1. data tahap awal dalam penelitian di awali dengan pembuatan data dimana data yang digunakan pada penel itian ini adalah data s intetik. data sintetik digunakan untuk mendapatkan jumlah data yang besar sela in itu data sintetik juga b ersifat fleksibel kar ena ju mlah data yang digunakan dapat ditentukan sesuai dengan kebutuhan pengujian algo ritma yang dikembang kan. data sintetik yang dibuat berisikan nama supplier harga kualitas dan waktu pengiriman. 2. definis i qubits kriteria pada taha p ini kriteria yang digunak an untuk pengelompokan supplier diubah menjadi representasi kuantum menggunakan qubits. setia p kriteria mungkin diwakili ol eh satu atau lebih qubits tergantung pada kompleksitas yang diperlukan. kriteri a yang digunakan dalam peng elompokan supplier yaitu harga kualitas dan waktu pengiri man. 3. inisialisasi sistem kuantum pada tahapan ini melakukan p ersiapan awal dari komputer k uantum yaitu mengatur qubits ke state awal dan memas tikan semua qubits berada dalam keadaan awal sebelum operasi kuantum dijalankan. pada tahapan ini juga menentuk kan jumlah qubits yan g digunakan. 4. implementasi quantum distance measure pada tahapan ini melakukan p enerapan metode untuk mengukur jarak antar supplier dalam ruang kuantum dengan menggunakan prins ipprinsip mekanika kuantum . tahapan ini digunakan dalam proses pengelom pokkan data menggunakan quantum dbscan karena jarak antar supplier akan digunakan untuk menentukan klaster 5. penentuan eps dan minpts kuan tum pada tahap ini men entukan nilai nilai epsilo n atau eps dan minimum poi nts minpts dalam konteks kuantum untuk menentukan batas batas klaster . epsilon atau eps digunakan u ntuk menen tukan radius yang menentukan lingkungan di sekitar setiap titik data. dua titik dianggap ber tetangga jika jarak antara mereka kurang dari nilai e ps. minimum points atau min pts untuk menentukan jumlah minimum titik yang diperlukan untuk membentuk sebuah klaster . 6. identi fikasi core supplier dengan kuantum sirkuit pada tahapan ini m enggunakan rangka ian kuantum untuk mengident ifikasi supplier ini core suppl ier. supplier inti adalah supplier yang memiliki cukup banyak tetangga yang s esuai dengan minpts dalam radius epsilon yang telah ditentukan. 7. identifikasi noise supplier dengan kuantum sirkuit pada tahapan ini mengi dentifikasi supplier noise atau outlier yang mem iliki jarak tidak cukup dek at atau memiliki jarak yang jauh dengan supplier lain untuk dianggap bagian dari klaster . 8. penanganan noise dengan quantum state pada tahapan ini menge lola supplier noise yang telah diidentifikasi menggunakan teknik kuantu m untuk memisahkan atau mengelompok kan noise secara terpisah. dalam dbscan klasik noise adalah titik data yang tidak termasuk dalam klaster apa pun. titik titik ini tidak memiliki cuku p tetangga dalam radius epsilon eps atau tidak terhubung ke core poin t. 9. identifikasi core supplier dengan quantum circuit pada tahapan ini mengidentifikasi titik titik data yang berada dalam jarak epsilon atau e ps dari titik inti tetapi tidak memiliki cukup tetanga untuk masuk ke dalam klaster dengan menggunakan kuantum sirkuit . 10. formasi kluster supplier dengan quantum measurement pada tahapan ini m embentukan klaster supplier dengan mengukur state kuantum yang telah diubah melalui interaksi antar qubits yang mewakili supplier . 11. evaluasi kluster tahap terakhir di mana kualit as dan k eefektifan kluster yang ter bentuk dievaluasi. tahapan ini bertujuan untuk menilai seberapa baik kluster yang terbentuk mengguna kan. 3.2 rangkuman langkah langk ah penelitian setelah mengembangkan algoritma kuantum dbscan selanjutnya membandingk annya dengan algo ritma dbscan untuk mengetahui seberapa baik algoritma dbscan jika dibandingkan dengan algorit ma klasiknya . langkah langka h tersebut dapat dilihat pada gambar 3.2 rangkuman langkah langka h prosedur peneli tian. data definisi qubits kriteria inisialisasi sistem kuantum penentuan eps dan minpts kuantum identifikasi core supplier dengan kuantum sirkuitidentifikasi noise supplier dengan kuantum sirkuit penanganan noise dengan kuantum stateformasi klaster supplier dengan kuantum measurementimplementasi quantum distance measure identifikasi core supplier dengan kuantum sirkuitnormalisasi data penentuan epsilon dan minpts hitung jarak antar supplier identifikasi core supplier identifikasi core supplieridentifikasi noise supplier supplier tidak termasuk dalam klasterformasi klaster supplier evaluasi klasterusulan algoritma gambar 3.2 rangkuman langkah langkah prosedur penelitian\"\n",
    "generated_summary = generate_summary(test_sentence, loaded_tokenizer, loaded_model)\n",
    "\n",
    "print(\"Kalimat asli:\")\n",
    "print(test_sentence)\n",
    "print(\"\\nRingkasan yang dihasilkan:\")\n",
    "print(generated_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
